{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ca5525-621f-4874-b22d-871b986abcb3",
   "metadata": {},
   "source": [
    "# Assignment 2: Theses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3049213-915e-4a0e-9745-27d90524de81",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2) Theses Inspiration\n",
    "\n",
    "Imagine you'd have to write another thesis, and you just can't find a good topic to work on.\n",
    "Well, n-grams to the rescue!\n",
    "Download the `theses.txt` data set from the `Supplemental Materials` in the `Files` section of our Microsoft Teams group.\n",
    "This dataset consists of approx. 1,000 theses topics chosen by students in the past.\n",
    "\n",
    "In this assignment, you will be sampling from n-grams to generate new potential thesis topics.\n",
    "Pay extra attention to preprocessing: How would you handle hyphenated words and acronyms/abbreviations?\n",
    "\n",
    "*In this Jupyter Notebook, we will provide the steps to solve this task and give hints via functions & comments. However, code modifications (e.g., function naming, arguments) and implementation of additional helper functions & classes are allowed. The code aims to help you get started.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d72777fd-95a9-43c4-94a1-6212835f4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import random\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb92ea7f-7008-4345-9f71-6a452a411322",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "\n",
    "1.1 Spend some time on pre-processing. How would you handle hyphenated words and abbreviations/acronyms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91b2bc86-c193-4aa0-99b6-dd5615451fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\André\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "def load_theses_titles(filepath):\n",
    "    \"\"\"Loads all theses titles and returns them as a list.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        titles = [line.strip() for line in file.readlines()]\n",
    "    return titles\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28048a13-313e-4d54-a34a-13fbb70a4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    \"\"\"Preprocesses and tokenizes the given theses titles for further use.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    preprocessed_data = []\n",
    "    \n",
    "    for title in data:\n",
    "        tokens = nltk.word_tokenize(title) # title.lower()\n",
    "        hyphenated_tokens = []\n",
    "        \n",
    "        for token in tokens:\n",
    "            hyphenated_tokens.extend(re.split(r'[-\\s]', token))\n",
    "            \n",
    "        tokens = hyphenated_tokens\n",
    "        tokens = [re.sub(r'[^\\w\\s-]', '', token) for token in tokens]\n",
    "        tokens = [token for token in tokens if token]\n",
    "        #tokens = filtered = ['<s>'] + tokens + ['</s>']\n",
    "        preprocessed_data.append(tokens)\n",
    "        \n",
    "    return preprocessed_data\n",
    "\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd461e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "theses_data = preprocess(load_theses_titles(\"./data/theses.txt\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf63d00c-717f-4db4-8d6b-71d4d2e42041",
   "metadata": {},
   "source": [
    "### Train N-gram Models\n",
    "\n",
    "2.1 Train n-gram models with n = [1, ..., 5]. What about \\<s> and \\</s>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fd849acd-5a69-4ca3-9511-bd6fa56b8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_n_gram_models(n, data):\n",
    "    \"\"\"This method does calculate all n-grams up to the given n.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    models = {}\n",
    "    for i in range(1, n+1):\n",
    "        n_gram_counts = {}\n",
    "        prefix_counts = {}\n",
    "        for tweet in data:\n",
    "            # Generate n-grams and their respective prefixes\n",
    "            # Ensure everything is a tuple to avoid TypeError\n",
    "            n_grams = [tuple(tweet[j:j+i]) for j in range(len(tweet) - i + 1)]\n",
    "            prefixes = [tuple(tweet[j:j+i-1]) for j in range(len(tweet) - i + 1)] if i > 1 else [('<s>',) * (i-1)] * (len(tweet) - i + 1)\n",
    "\n",
    "            for n_gram in n_grams:\n",
    "                if n_gram in n_gram_counts:\n",
    "                    n_gram_counts[n_gram] += 1\n",
    "                else:\n",
    "                    n_gram_counts[n_gram] = 1\n",
    "\n",
    "            for prefix in prefixes:\n",
    "                if prefix in prefix_counts:\n",
    "                    prefix_counts[prefix] += 1\n",
    "                else:\n",
    "                    prefix_counts[prefix] = 1\n",
    "\n",
    "        # Calculate probabilities for the model of order i\n",
    "        model = {}\n",
    "        for n_gram, count in n_gram_counts.items():\n",
    "            prefix = n_gram[:-1]\n",
    "            model[n_gram] = count / prefix_counts[prefix]\n",
    "        models[i] = model\n",
    "\n",
    "    return models\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e5dbbcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005902752158193757\n"
     ]
    }
   ],
   "source": [
    "n_gram_models = build_n_gram_models(5, theses_data)\n",
    "print(n_gram_models[1][(\"Cloud\",)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271b7344-cce3-4003-a404-6bb84fac037d",
   "metadata": {},
   "source": [
    "### Generate the Titles\n",
    "\n",
    "3.1 Write a generator that provides thesis titles of desired length. Please do not use the available `lm.generate` method but write your own.\n",
    "\n",
    "3.2 How can you incorporate seed words?\n",
    "\n",
    "3.3 How do you handle </s> tokens (w.r.t. the desired length?)\n",
    "\n",
    "3.4 If you didn't just copy what nltk's lm.generate does: compare the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6d8644a-4d85-4bdd-aac2-c1607f7b6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice: If you fix the seed in numpy.random.choice, you get reproducible results.\n",
    "\n",
    "def sample_next_token(prev, n_gram_model):\n",
    "    \"\"\"Samples the next word for the given n_grams.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    if len(prev) != len(next(iter(n_gram_model.keys()))) - 1:\n",
    "        raise ValueError(\"The size of the previous tokens must match the n-1 value of the n-gram model.\")\n",
    "\n",
    "    possible_continuations = {key[-1]: n_gram_model[key] for key in n_gram_model if key[:-1] == prev}\n",
    "\n",
    "    if not possible_continuations:\n",
    "        return random.choice(list(n_gram_model.keys()))[-1]\n",
    "\n",
    "    next_words = list(possible_continuations.keys())\n",
    "    probabilities = list(possible_continuations.values())\n",
    "\n",
    "    next_word = random.choices(next_words, weights=probabilities, k=1)[0]\n",
    "    return next_word\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def generate(n, n_gram_models, seed, title_length):\n",
    "    \"\"\"Generates a thesis title using the n_grams, seed word and title length.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    generated_title = [seed]\n",
    "\n",
    "    # Generate additional tokens to complete the title\n",
    "    while len(generated_title) < title_length:\n",
    "        # Determine the context for the next token\n",
    "        context = generated_title[-(min(len(seed.split()), len(generated_title))):]\n",
    "        # Sample the next token based on the context and n-gram model\n",
    "        next_token = sample_next_token(tuple(context), n_gram_models[min(len(context) + 1, n)])\n",
    "        # Add the next token to the generated title\n",
    "        generated_title.append(next_token)\n",
    "\n",
    "    # Combine the tokens into a single string\n",
    "    generated_title = ' '.join(token for token in generated_title)\n",
    "\n",
    "    return generated_title\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6514c19e-0f09-4453-9d56-ea6f7ae6dddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entwicklung einer Customer Journey Map für Hardware Ereignisse im Anwendungsbereich der DATEV\n",
      "Cloud basierte Musik Streaming Dienste für SPS Anwenderprogramme auf die IT Service\n"
     ]
    }
   ],
   "source": [
    "title_length = 12\n",
    "seed_word =  \"Entwicklung\"\n",
    "thesis_title = generate(3, n_gram_models, seed_word, title_length)\n",
    "print(thesis_title)\n",
    "seed_word =  \"Cloud\"\n",
    "thesis_title = generate(3, n_gram_models, seed_word, title_length)\n",
    "print(thesis_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "41fabd8b-74e2-4dc8-ad45-67622119419e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Software', 'für', 'die', 'IT', 'Dienstleistungsbranche', 'im', 'Kontext', 'eines', 'Reputationssytems', 'für']\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "train, vocab = padded_everygram_pipeline(5, theses_data)\n",
    "lm = MLE(2)\n",
    "lm.fit(train, vocab)\n",
    "\n",
    "generated_text = lm.generate(10)\n",
    "\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0293a068-7c58-4ad7-a342-09dc5bc2ea4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
