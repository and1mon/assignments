Anmeldedatum;Abgabedatum;JahrAkademisch;Art;Grad;Sprache;Titel;Abstract
31.07.94;30.09.94;1994;intern;Diplom;DE;EMail am Beispiel SMTP im Internet;
01.10.94;01.03.95;1995;intern;Diplom;DE;Einführung des Configuration Management-Systems PCMS zur strukturierten Versions-Release- und Änderungskontrolle in Projekten der Abteilung Information-Systems der Firma Motorola;
05.10.94;05.03.95;1995;extern;Diplom;DE;Analyse und Leistungsvergleich von zwei Echtzeitsystemen für eingebettete Anwendungen;
19.10.94;19.03.95;1995;intern;Diplom;DE;Erfassung und automatische Zuordnung von Auftragsdaten für ein Dienstleistungsunternehmen mit Hilfe von Standardsoftware - Konzeption und Realisierung;
25.10.94;24.03.95;1995;extern;Diplom;DE;Organisationskonzept zur Administration von Lehrgangsrechnern für eine DV-Fortbildungsinstitution;
27.10.94;14.07.95;1995;intern;Diplom;DE;Monte Carlo-Simulation für ein gekoppeltes Round-Robin-System;
02.11.94;02.04.95;1995;intern;Diplom;DE;Untersuchung der elektrischen Eigenschaften von Supraleitern mit Hilfe eines Gas-Kryosystems;
02.11.94;02.04.95;1995;intern;Diplom;DE;Prioritätsfreies Scheduling in verteilten Echtzeit-Systemen unter Berücksichtigung von Zeit- und Betriebsmittelanforderungen;
04.11.94;14.03.95;1995;intern;Diplom;DE;Implementierung eines Testüberdeckungsgrad-Analysators für RAS;
08.11.94;08.04.95;1995;intern;Diplom;DE;Eine objektorientierte Fuzzy-Entwicklungsumgebung - Entwurf und Implementierung des Kerns;
22.11.94;22.04.95;1995;intern;Diplom;DE;Eine objektorientierte Fuzzy-Entwicklungsumgebung - Entwurf und Implementierung der Bedienoberfläche;
28.11.94;14.03.95;1995;extern;Diplom;DE;Strukturierung und Dokumentenmanagement von Gebrauchsanweisungen auf der Basis von SGML;
01.12.94;01.05.95;1995;intern;Diplom;DE;Untersuchung von 4 Netzwerksystemen im Hinblick auf ihre Einsatzmöglichkeiten insbesondere im Weitverkehrsnetz einer EDV-Dienstleistungsfirma;
01.12.94;28.04.95;1995;intern;Diplom;DE;Erstellung eines Konzeptes zur Umstellung eines bestehenden Netzwerkmanagementsystems von CMIP/CMOL auf SNMP;
12.12.94;12.05.95;1995;intern;Diplom;DE;Migration der Bearbeitung des Schriftverkehrs der Kreissparkasse Nürnberg von einem großrechnerorientierten System auf eine Client-Server-Architektur (Arbeitstitel);
13.12.94;13.08.95;1995;intern;Diplom;DE;Lösung von Zuordnungsproblemen unter Berücksichtigung verschiedenartiger Randbedingungen beim Verkabeln einer Vermittlungsanlage;
15.12.94;15.05.95;1995;extern;Diplom;DE;"Konzeption und Realisierung eines multimedialen Sammlerkataloges am Beispiel ""altes Spielzeug""";
20.12.94;20.05.95;1995;intern;Diplom;DE;Analyse und Konzeption der zukünftigen Informatikunterstützung für ein Ing.-Büro;
02.01.95;02.06.95;1995;extern;Diplom;DE;Konzeption eines Netzwerkmanagementsystems für eine heterogene Netzwerkumgebung;
03.01.95;05.06.95;1995;extern;Diplom;DE;Aufbau, Inbetriebnahme und Optimierung eines hoch repetierlichen Ho: YAG-Laser für med. Anwendung;
04.01.95;03.06.95;1995;extern;Diplom;DE;Untersuchung verschiedener Lernverfahren für Neuro-Fuzzy-Systeme;
10.01.95;10.06.95;1995;intern;Diplom;DE;Untersuchung der Echtzeit-Eignung eines Betriebssystems am Beispiel von Varianten des UNIX-Kerns;
08.02.95;08.07.95;1995;intern;Diplom;DE;Schnelle Berechnung von Ray-Tracing-Animationen durch Voxelisierung des Szenenraums;
17.02.95;17.07.95;1995;intern;Diplom;DE;Computergestützte und kundenorientierte Erfassung und Verarbeitung von Gesteinsprobensiebwerten zur Bestimmung eines optimalen Mischungsverhältnisses;
03.03.95;03.08.95;1995;intern;Diplom;DE;Rechnergestützte Einzelworterkennung. Ein Vergleich von Methoden zur Analyse und Klassifikation;
08.03.95;08.08.95;1995;intern;Diplom;DE;Komprimierung, Übertragung, Auswertung und Aufbereitung von Meßdaten aus einer Solaranlage;
30.03.95;30.12.95;1995;intern;Diplom;DE;Redesign und aTRACktive-Datenbank und Portierung des Auswertungssystems auf einem PC;
12.04.95;11.09.95;1995;intern;Diplom;DE;Computergestützte Wertstoffsammlung;
27.04.95;27.11.95;1995;intern;Diplom;DE;Entwurf und Implementierung einer offenen Schnittstelle zum Repository eines CASE-Tools mittels der Standard-Skript-Sprache TCL;
01.05.95;30.09.95;1995;intern;Diplom;DE;Einführung der digitalen Dokumentenannahme und -verarbeitung in einem Kleinbetrieb der Druckindustrie;
04.05.95;30.10.95;1995;intern;Diplom;DE;Portierung der hardwarenahen Komponenten des Echtzeitbetriebssystems EUROS auf die Alpha-Architektur;
11.05.95;22.11.95;1995;intern;Diplom;DE;"Erstellung eines aktiven Kommunikationsmoduls mit ""Gateway""-Eigenschaften im Prozeßleitbereich unter OSF/1";
01.07.95;01.12.95;1995;extern;Diplom;DE;Auswahl und Implementierung von Kommunikationswerkzeugen zum Datenaustausch zwischen Windows- und UNIX-Systemen. Einsatz der Werkzeuge im Rahmen eines BDE-Systems;
01.07.95;30.09.95;1995;intern;Diplom;DE;"Sinnentstellung bei der Übersetzung englischsprachiger Fachbücher ins deutsche und deren Ursachen. Eine linguistische Untersuchung für Informatiker ""Übergehen Sie die Elementfunktion um die Ikone ...""";
05.07.95;05.12.95;1995;intern;Diplom;DE;Entwicklung eines plattformunabhängigen 3964R-Treibers für Windows-NT;
20.07.95;20.12.95;1995;intern;Diplom;DE;RSA-Schlüsselgenerierung im Siemens Chipkartenprozessor SLE 44 C 200;
20.07.95;20.12.95;1995;intern;Diplom;DE;Konzeption und Erstellung einer Klassenbibliothek für Benutzeroberflächen in der Automatisierungstechnik;
01.08.95;01.01.96;1995;intern;Diplom;DE;Parallelverarbeitung im Workstation-Verbund. Implementierung ausgewählter Beispielanwendungen mit Hilfe geeigneter Werkzeuge;
01.08.95;30.11.95;1995;extern;Diplom;DE;Konzeption und Modellierung eines Unternehmens-Führungs-Systems (UFS) für ein Dienstleistungsunternehmen und Realisierung der Teilkomponenten Mitarbeiter- und Projektverwaltung;
15.08.95;15.01.96;1995;intern;Diplom;DE;Telearbeit in einem Industriebetrieb der Elektrobranche - Einsatzmöglichkeiten, technische, organisatorische und rechtliche Rahmenbedingungen;
15.08.95;15.01.96;1995;intern;Diplom;DE;Notfallkonzept zur Steigerung der Verfügbarkeit einer bestehenden IT/DV-Infrastruktur innerhalb der SAG, basierend auf Compaq-HW mit MS-NTAS Betriebssystem;
18.08.95;18.01.96;1995;intern;Diplom;DE;Erstellung und Einführung eines grafisch-interaktiven Systems zur Unterstützung von Administration und Controlling der Unterschriftenregelung;
15.09.95;15.04.96;1995;intern;Diplom;DE;Analyse, Design und Implementierung des Bereichs Ausschreibung eines AVA-Programms mit objektorientierten Methoden;
19.09.95;19.02.96;1995;extern;Diplom;DE;Erstellung eines Bibliothekskonzeptes zur Verwaltung versionierter, über OLE-Technik verbundener Objekte. Realisierung der Basisfunktionalität des Konzeptes basierend auf OLE 2;
06.10.95;06.03.96;1996;intern;Diplom;DE;Einsatzmöglichkeit von kooperativen Systemen am Beispiel eines Unternehmens im Maschinenbau;
11.10.95;11.03.96;1996;extern;Diplom;DE;Arbeitstitel: Darstellung der Information neuronaler Netze in chemischen Anwendungen;
11.10.95;11.03.96;1996;extern;Diplom;DE;Kern eines Simulationswerkzeuges für AWL-Programmstrukturen und Tasks nach SPS-Norm IEC 1131;
13.10.95;13.03.96;1996;extern;Diplom;DE;Umsetzung eines Logistik Controlling Verfahrens von einer lokalen PC-Version auf eine Client Server Umgebung unter SAP R/3;
13.10.95;13.03.96;1996;extern;Diplom;DE;Überarbeitung des Einkaufscontrollings und DV-technische Realisierung mittels SAP R/3 bei einem Konzernunternehmen;
13.10.95;13.03.96;1996;extern;Diplom;DE;Zielvereinbarungen und Prozeßkenngrößen. Eine Maßnahme zur Einführung von Total Quality Management;
16.10.95;15.04.96;1996;intern;Diplom;DE;Konzeption und Realisierung einer Netzterminierung als Bestandteil des graphischen Leitstandes SIFLEX;
02.11.95;31.03.96;1996;intern;Diplom;DE;Ablösung des DESTI UNIX-Verfahrens durch eine Client-Server Applikation;
06.11.95;25.04.96;1996;extern;Diplom;DE;Adaptive Parametrierung einer Image-Hardwarepipeline;
15.11.95;15.04.96;1996;extern;Diplom;DE;Konzept für das Management von Online-Diensten im Internet;
15.11.95;10.06.96;1996;intern;Diplom;DE;Konzeption und Realisierung einer Datenbankanwendung für die Kundenbetreuung am Beispiel der Firma S.E.P.P.;
20.11.95;19.04.96;1996;extern;Diplom;DE;Einrichtung einer Datenbasis für die Hardware-Dokumentation des Netzwerks einer Großfirmenniederlassung;
01.12.95;31.05.96;1996;intern;Diplom;DE;Neuorientierung des Management-Accounting in einer Bank;
01.12.95;30.04.96;1996;extern;Diplom;DE;Entwurf und Teilimplementierung von Backup- und Restore-Verfahren für eine Festplatte auf DRAM-Basis;
01.12.95;01.07.96;1996;intern;Diplom;DE;Analyse, Design und Implementierung der Bereiche Vergabe und Kostenkontrolle eines AVA-Programmes mit objektorientierten Methoden;
06.12.95;06.05.96;1996;intern;Diplom;DE;Datenbanken in parallelen Rechnerarchitekturen;
07.12.95;14.03.96;1996;intern;Diplom;DE;Die Bedienoberfläche für ein System von Kfz-Testgeräten - Simulation und Entwicklung eines objektorientierten Modells;
11.12.95;04.06.96;1996;intern;Diplom;DE;Konzeption und Realisierung einer computerunterstützten Unterrichtseinheit für HTML auf der Basis von Asymetri Todbock;
21.12.95;20.05.96;1996;intern;Diplom;DE;Datenintegration in der Dermatologischen Universitätsklinik Erlangen: Migration von Insellösungen zu einer integrierten Datenbank-Anwendung (Arbeitstitel).;
08.01.96;14.05.96;1996;intern;Diplom;DE;Einführung eines kundenorientierten Qualitätsmanagements in Verkauf und Service einer Unternehmung der Bürotechnik-Branche;
23.01.96;23.08.96;1996;intern;Diplom;DE;Fraktale Bildkompression. Entwurf, Realisierung und Vergleich von Methoden der Bildcodierung und Decodierung;
31.01.96;02.07.96;1996;extern;Diplom;DE;Ein Fachkonzept zur Integration der bestehenden DV-Insellösungen für CAD und PPS der Firma Hydrometer GmbH;
01.02.96;01.07.96;1996;intern;Diplom;DE;Algorithmen zur automatischen Regelinduktion aus Tabellenwissen;
05.02.96;05.09.96;1996;extern;Diplom;DE;Erstellung eines Software-Assistenten zur Unterstützung bei der Projektierung von Netzwerksystemen in der Automatisierungstechnik;
01.03.96;01.10.96;1996;intern;Diplom;DE;Entwicklung eines Werkzeugs zur Selektion von Analysedaten  - formale Datenbeschreibung, Vorübersetzung, Interpretation;
26.03.96;26.10.96;1996;extern;Diplom;DE;Entwurf eines Entwicklungskonzeptes zur Erstellung von Client-/Server-Datenbankanwendungen mit CA OpenRoad für den Bereich Software Factory/Tool Support;
11.04.96;11.01.97;1996;intern;Diplom;DE;Erstellen eines Outsourcing-Konzeptes und Durchführung einer Angebotsphase;
12.04.96;12.01.97;1996;extern;Diplom;DE;Spezifikation und Teilimplementierung eines Produktionsleitstandes im Bereich Tabakvorbereitung;
12.04.96;12.01.97;1996;intern;Diplom;DE;Erstellen eines interaktiven Telegramminterpreters zur Simulation von Telegrammen in einem bestehenden Kommunikationssystem. Erarbeiten der nötigen Funktionen, Konzepterstellung, Realisierung mit Visu;
12.04.96;12.01.97;1996;intern;Diplom;DE;OLE als Object Request Broker, demonstriert an einem Beispiel für die Lehre;
12.04.96;12.03.97;1996;intern;Diplom;DE;Entwicklung medizinspezifischer Standardkomponenten auf der Basis von OLE;
12.04.96;12.01.97;1996;intern;Diplom;DE;DV-technische Unterstützung einer effektiven Werksinstandhaltung unter Einsatz von Datenbanken am Beispiel eines Werkes für medizinische Geräte;
15.04.96;11.10.96;1996;intern;Diplom;DE;"Entwurf und Implementierung einer Speicherverwaltung mit ""Garbage-Collector""";
06.05.96;30.09.96;1996;intern;Diplom;DE;Konzept über den Einsatz neuer Medien für einen regionalen Fernsehsender;
21.05.96;21.10.96;1996;intern;Diplom;DE;Vom gesprochenen Satz zum SQL-Befehl: semantische Schlüsselwortanalyse natürlich sprachlicher Datenbankabfragen im Verbund mit einem Spracherkennungssystem;
17.06.96;17.03.97;1996;extern;Diplom;DE;"Entwicklung eines Werkzeugs zur Querübersetzung der Sprache ""Strukturierter Text"" in die Sprache ""Anweisungsliste"" für die Programmierung von SPS-Steuerungen nach IEC 1131-3 Base-Level";
04.07.96;29.11.96;1996;intern;Diplom;DE;Analyse eines bestehenden Programmsystems hinsichtlich konzeptioneller und struktureller Optimierung;
08.07.96;30.11.96;1996;extern;Diplom;DE;Entwurf und Implementierung eines Testdatengenerators für C++ Klassen;
15.07.96;15.12.96;1996;intern;Diplom;DE;Zertifizierung nach DIN EN 9001. Einführung und EDV-Unterstützung in einem kunststoffverarbeitenden Betrieb;
23.07.96;22.12.96;1996;extern;Diplom;DE;Anwendung von Methoden und Techniken des Compilerbaus auf natürlich-sprachliche Texte zur Erkennung formal definierter Textstrukturen in juristischen Texten;
25.07.96;25.12.96;1996;intern;Diplom;DE;"Authentifizierung von Internet/Intranet Anwendern - Lösungsansätze und Realisierung mittels Chipkarte unter Verwendung von ""Java""";
26.07.96;26.12.96;1996;extern;Diplom;DE;Definition und Realisierung einer generischen, objektorientierten Datenbank-Schnittstelle für ein ICE-Fahrgastinformationssystem;
27.08.96;27.01.97;1996;intern;Diplom;DE;Organisations- und DV-Konzept für die Kundenbetreuung eines Dienstleistungsunternehmens;
02.09.96;02.02.97;1996;intern;Diplom;DE;HTML-basiertes System zur kontrollierten Strukturierung und Workflowüberwachung technischer Dokumente;
15.09.96;30.11.96;1996;intern;Diplom;EN;Aeronautical Information System;
30.09.96;12.04.97;1996;extern;Diplom;DE;Entwurf und Realisierung eines Monitors und Debuggers für einen Digitalen Signalprozessor;
02.10.96;03.03.97;1997;extern;Diplom;DE;Entwicklung einer Netzwerk-Komponente auf TCP/IP- und Ethernet-Basis für das Echtzeit-Betriebssystem EUROS;
08.10.96;07.03.97;1997;intern;Diplom;DE;Objektorientiertes Testen von Frameworks und Komponenten;
13.10.96;14.05.97;1997;intern;Diplom;DE;Optimierung der grundlegenden Arbeitsabläufe einer Volkshochschule mit einem EDV-System am Beispiel der VHS-Forchheim. Teilsystem 2: Teilnahme und Abrechnung;
13.10.96;14.05.97;1997;intern;Diplom;DE;Optimieirung der grundlegenden Arbeitsabläufe einer Volkshochschule mit einem EDV-System am Beispiel der VHS-Forchheim. Teilsystem 1: Stammdatenverwaltung und Kursplanung;
14.10.96;14.05.97;1997;extern;Diplom;DE;Entwicklung eines Streams Moduls, welches das IEC 870 - 5 - 101 Protokoll auf Verbindungsebene unter SUN Solaris 2.4 realisiert;
14.10.96;14.03.97;1997;extern;Diplom;DE;Optimierung des Echtzeit-Verhaltens der File-Systeme im MS-DOS- und EUROS-Format für das Echtzeitbetriebssystem EUROS;
14.10.96;14.03.97;1997;extern;Diplom;DE;Automatische Erstellung von Quellcode für grafische Benutzeroberflächen unter dem X-Window-System IMOTIF aus Resourc-Files unter MS-Windows;
20.10.96;14.05.97;1997;intern;Diplom;DE;Transaktionsmanagement in objektorientierten Datenbank-Anwendungen am Beispiel eines AVA-Programms;
21.10.96;21.03.97;1997;extern;Diplom;DE;Konzept für einen Informationsservice auf Intranetbasis;
04.11.96;04.04.97;1997;extern;Diplom;DE;Konzeption und Einrichtung eines Applikationsservers für GT;
04.11.96;03.04.97;1997;intern;Diplom;DE;Meßtechnische und rechnerische Bestimmung schalltechnischer Kennwerte in der Bauakustik;
05.11.96;05.05.97;1997;extern;Diplom;DE;Portierung der hardwarenahen Komponenten des Echtzeitbetriebssystems EUROS auf die DEC-Alpha-Mikroprozessor-Architektur;
05.11.96;05.05.97;1997;extern;Diplom;DE;Portierung der hardwarenahen Komponenten des Echtzeitbetriebssystems EUROS auf die Mikrokontroller-Familie C 166 für eingebettete Systeme;
07.11.96;07.04.97;1997;intern;Diplom;DE;Wavelet Bildkompression - Entwurf, Realisierung und Vergleich von Methoden der Bildcodierung und -decodierung;
13.11.96;13.04.97;1997;intern;Diplom;DE;"Entwurf und Implementierung eines ""OLE for Process Control"" (OPC) Server";
15.11.96;15.04.97;1997;intern;Diplom;DE;Verbesserung der unternehmensinternen Informationsversorgung durch EDV-gestütztes Dokumentenmanagement mit Langzeitarchivierung;
18.11.96;16.05.97;1997;extern;Diplom;DE;Entwicklung eines Pentium TM- und MMX TM - optimierten ActiveMovieTM Software Filters für die Echtzeitkomprimierung und Dekomprimierung von Video-Datenströmen;
27.11.96;14.05.97;1997;extern;Diplom;DE;Ein Informationssystem für ein Sprachlabor;
28.11.96;27.06.97;1997;extern;Diplom;DE;Konzept für die Geschäftsprozeßoptimierung der Provisionsbearbeitung bei einem Versicherungskonzern;
05.12.96;05.03.97;1997;extern;Diplom;DE;Reengeneering eines QS-Werkzeuges für eine grafische Benutzeroberfläche;
19.12.96;19.05.97;1997;intern;Diplom;DE;Erstellung eines Konzepts zur Stammdatenhaltung konfigurierbarer Erzeugnisse in SAP R/3;
13.01.97;13.06.97;1997;intern;Diplom;DE;Patientenregistrierung in einem medizinischen SW-System:  Realisierung der Anwendungslogik als DCOM-Komponente;
15.01.97;15.05.97;1997;extern;Diplom;DE;Arrival Manager-Anwendung des objektorientierten Ansatzes beim Requirements-Engineering verbunden mit einer Methodendiskussion;
02.02.97;02.07.97;1997;intern;Diplom;DE;Objektorientierte Modellierung von Softwarearchitekturen. Konzepte für die inhaltliche Ausgestaltung und Formen der Beschreibungen;
24.02.97;24.09.97;1997;intern;Diplom;DE;Konzeption (und Realisierung) eines Verkaufsterminals für Kino-Eintrittskarten mit Platzreservierung unter Verwendung von Chipkarten für die Bezahlung (elektronische Geldbörse);
03.03.97;03.08.97;1997;intern;Diplom;DE;Erarbeitung eines Konzeptes zur Abrechnung des Lizenzentgeltes für Verpackungen innerhalb der Standardsoftware R/3 von SAP;
15.03.97;01.07.97;1997;intern;Diplom;DE;Der Weg zum Niedrigenergiehaus - Entwicklung von Varianten;
16.03.97;01.07.97;1997;intern;Diplom;DE;Messung passiver solarer Energiegewinne;
17.03.97;15.09.97;1997;intern;Diplom;DE;Konzeption und Umsetzung eines Werkzeugs zur Anonymisierung von Datenbank-Inhalten mit dem Ziel der Erzeugung von Testdaten;
17.03.97;18.08.97;1997;intern;Diplom;DE;Konzeption und Realisierung eines Programms zur Sicherung der Aufwärtskompatibilität eines Projektierungssystems;
01.04.97;01.09.97;1997;extern;Diplom;DE;Entwicklung eines Protokollanalysators für das mobile Datenträgersystem MOBY-L;
10.04.97;10.09.97;1997;intern;Diplom;DE;Untersuchung und Bewertung von SAP Business Workflow, einem Zusatztool des SAP R/3-Systems;
11.04.97;10.09.97;1997;extern;Diplom;DE;Moderne Methoden des Requirements Engineering - Die Vorgehensweise BRE9000;
14.04.97;14.01.98;1997;extern;Diplom;DE;Implementierung eines Datentransfers mittels TCP/IP unter einem Multitasking-Kernel für ein Kassenterminal;
16.04.97;16.09.97;1997;intern;Diplom;DE;Multidimensionale Optimierung mit Hilfe Genetischer Algorithmen und Evolutionssstrategien am Beispiel der Stundenplanerstellung für Schulen;
16.04.97;16.07.97;1997;extern;Diplom;DE;Untersuchung der Wärmeabgabe von Rohrleitungsarmaturen der Heiz- und Warmwasseranlagen bis DN 32;
30.04.97;30.09.97;1997;intern;Diplom;DE;Entwurf und Entwicklung eines Frühwarnsystems zur systematischen Überwachung von frei konfigurierbaren EDV-Systemen und automatischen Beseitigung von Störungen;
01.05.97;30.11.97;1997;intern;Diplom;DE;Optimierung eines Fuzzy-Reglers durch ein neuronales Netz am Beispiel eines mechanischen Stabilitätsproblems;
23.06.97;23.01.98;1997;intern;Diplom;DE;Entwurf und Realisierung eines Suchsystems für elektronische Bauelemente mittels des EDM-Systems CADIM;
01.07.97;28.11.97;1997;intern;Diplom;DE;Konzeption und Realisierung eines Multiprojektplanungssystems;
24.07.97;19.12.97;1997;intern;Diplom;DE;Stärkung der Schlagkraft des Unternehmens am Absatzmarkt durch geeignete EDV-Unterstützung in Marketing und Vertrieb;
29.07.97;29.12.97;1997;intern;Diplom;DE;Wareneingangsplanung;
30.09.97;28.02.98;1997;extern;Diplom;DE;Entwurf und Realisierung eines Änderungsmanagement-Systems für Softwareentwicklung als Intranetanwendung;
30.09.97;28.02.98;1997;intern;Diplom;DE;Entwurf und Realisierung eines objektorientierten Termin- und Ressourcenplanungssystems unter besonderer Berücksichtigung geeigneter Optimierungsalgorithmen;
02.10.97;02.03.98;1998;intern;Diplom;DE;Realisierung einer wiederverwendbaren Softwarekomponente zur Visualisierung von Hierarchien mit Java Beans und ihre Verwendung in einer SGML-Datenbank;
02.10.97;27.02.98;1998;intern;Diplom;DE;Untersuchung der Eignung eines objektorientierten Analyse-Modells bezüglich der Verifikation betrieblicher Anforderungen anhand eines Beispiels aus der Flugsicherung;
20.10.97;20.03.98;1998;intern;Diplom;DE;Konzeption einer Benutzer- und Rechteverwaltung zur Integration von Windows NT-Workstations in eine bestehende heterogene Infrastruktur;
20.10.97;15.01.98;1998;extern;Diplom;DE;Realisierung eines Windows 95-Treibers für den 3D-Steuergriff SpaceMaster;
20.10.97;20.03.98;1998;intern;Diplom;DE;Entwicklung einer PC-CD-ROM-Steuerung zur Sprachaudiometrie und Feinanpassung von Hörgeräten;
21.10.97;21.03.98;1998;intern;Diplom;DE;Entwurf und Implementierung der Datenreplikation für ein Vertriebsinformationssystem;
22.10.97;22.03.98;1998;intern;Diplom;DE;Dynamisierung von statischen  Intranet-Seiten mit Hilfe einer Datenbank-Anwendung;
29.10.97;29.03.98;1998;intern;Diplom;DE;Architektur eines komponentenbasierten Verschaltungseditors in der Automatisierungstechnik;
30.10.97;30.03.98;1998;intern;Diplom;DE;Visualisierung interner Abläufe im Echtzeit-Betriebssystem EUROSplus unter MS-Windows;
01.11.97;31.03.98;1998;extern;Diplom;DE;Konzeption und Realisierung eines Internet-Marketingsystems für den Geschäftsbereich Nutzlastentwicklung/Mikrogravitation der Daimler-Benz Aerospace AG;
01.11.97;31.03.98;1998;extern;Diplom;DE;Konzeption und Realisierung eines Internet-Marketingsystems für den Geschäftsbereich Nutzlastentwicklung/Mikrogravitation der Daimler-Benz AG;
03.11.97;03.04.98;1998;extern;Diplom;DE;Erstellung eines Sicherheitskonzeptes für das Projekt Internetserver ZKT (Zentrum für Kartenanwendungen Telekom);
13.11.97;13.04.98;1998;intern;Diplom;DE;Analyse und Grobkonzeption der Geschäftsprozesse des Customer Support eines IT Dienstleisters;
17.11.97;17.04.98;1998;intern;Diplom;DE;Schutz sensibler Firmendaten und die Sicherstellung ihrer Übertragung im Internet;
01.12.97;30.04.98;1998;intern;Diplom;DE;Abbildung zwischen objektorientierten Klassenmodellen und konzeptionellen Schemata relationaler Datenbanken im CASE-Werkzeug Innovator - Konzeption und Realisierung eines Werkzeugs;
01.12.97;30.04.98;1998;extern;Diplom;DE;Konzeption eines Werkzeuges und Realisierung eines Prototypen zum automatisierten Testen von OLE-Komponenten;
04.12.97;04.05.98;1998;intern;Diplom;DE;Entwicklung von Java-Beans zur Darstellung vorhandener Modelle des CAD-Systems I-DEAS auf Internet-Browsern mit VRML;
10.12.97;10.05.98;1998;extern;Diplom;DE;Erstellen einer Meß- und Steuersoftware für Impedanzspektrometrie an Brennstoffzellen;
08.01.98;08.06.98;1998;intern;Diplom;DE;Performancemessung und selektive Telegrammdarstellung auf dem PROFIBUS-DP;
15.01.98;15.06.98;1998;intern;Diplom;DE;Entwurf und Implementierung eines OSEK-konformen Echtzeitbetriebssystems für den Mikrocontroller SAB 80C167;
16.01.98;16.06.98;1998;intern;Diplom;DE;Verwaltung von Änderungen technischer Dokumente - Konzeption und Entwicklung eines Prototypen;
30.01.98;30.06.98;1998;intern;Diplom;DE;Konzeption eines Data Warehouse im Bereich Marktforschung;
16.03.98;15.08.98;1998;extern;Diplom;DE;Funktionskonzept und Datenmodell für die Jobverwaltung in einer Marketingagentur;
01.04.98;20.12.98;1998;intern;Diplom;DE;"Entwicklung von Lernsoftware zum Thema ""Numerische Mathematik für Informatiker""";
01.04.98;30.12.98;1998;intern;Diplom;DE;Objektorientierte Modellbildung in der Wirtschaftsinformatik;
01.04.98;30.12.98;1998;intern;Diplom;??;siehe lfd. Nr. 436;
01.04.98;31.08.98;1998;extern;Diplom;DE;Integration und Steuerung eines Spektralphotometers zur automatischen Durchführung biochemischer Analytik;
01.04.98;31.08.98;1998;extern;Diplom;DE;Entwickung, Realisierung und Test einer druckdichten Prozeßzelle für die Kristallisation von Zeolithen in einer neuartigen Mikrowellenheizanlage;
07.04.98;07.01.99;1998;intern;Diplom;DE;Konzeption eines Marketinginformationssystems für ein unternehmerweites Leistungsspektrum;
07.04.98;31.12.98;1998;extern;Diplom;DE;"""Konzeption und Implementation eines Funktionstabellen Editors für das ASIC Design""";
07.04.98;07.09.98;1998;intern;Diplom;DE;Entwurf und Realisierung eines Redaktionssystems für die automatisierte Erstellung von Internet-Seiten;
12.04.98;11.01.99;1998;intern;Diplom;DE;Die notwendige Schulung des Programmieranfängers vor dem Einstieg in die Syntax einer speziellen Programmiersprache anhand ausgewählter Beispiele - Unterweisung im Umgang mit den formalen Konstrukten;
30.04.98;30.09.98;1998;intern;Diplom;DE;Entwurf und Realisierung eines Sendungsverfolgungssystems unter besonderer Berücksichtigung offnerer Schnittstellen;
30.04.98;30.09.98;1998;intern;Diplom;DE;Entwurf und Teilimplementierung einer datenbankbasierten Intranetlösung zur projektorientierten Zeiterfassung;
30.04.98;30.09.98;1998;intern;Diplom;DE;Erkennung musikalischer Symbolschrift und Transformation nach MIDI;
30.04.98;30.09.98;1998;intern;Diplom;DE;Entwicklung der Software zur Verwaltung einer Milchviehherde und der Steuerung eines Fütterungsautomaten zur Verteilung von Kraftfutter;
01.05.98;03.09.98;1998;intern;Diplom;DE;Entwurf und Realisierung eines Entscheidungsunterstützungssystems. Teilweise Implementierung am Beispiel PC-Kauf.;
01.05.98;30.09.98;1998;extern;Diplom;DE;Verbesserung und Optimierung vorhandener Werkzeuge zur verfahrenstechnischen Planung von Kraftanlagen;
04.05.98;04.10.98;1998;intern;Diplom;DE;Internet fähige 3-Ebenen C/S Anwendung auf Basis des Framework FROC/S-Erarbeitung eines Konzepts und beispielhafte Implementierung;
11.05.98;10.10.98;1998;intern;Diplom;DE;Konzept zur Nutzung von Internet-Technologien und prototypische Realisierung eines Teilaspektes dieses Konzeptes, angewendet auf SGML-Datenbestände der Abteilung Informationsdienste der Fa. DATEV e.G.;
11.05.98;25.09.98;1998;intern;Diplom;DE;Untersuchung eines Debug-Systems für embedded Anwendungen unter Java;
15.06.98;16.11.98;1998;intern;Diplom;DE;DV-Konzept und Softwareauswahl für ein mittelständiges Unternehmen;
01.07.98;30.09.98;1998;intern;Diplom;DE;Vereinheitlichung der objektorientierten Modellierung UML - eine kritische Würdigung;
01.07.98;30.11.98;1998;intern;Diplom;DE;Reengineeringkonzept f. ein derz. Dateiorient. Informationssystem f. techn. Komponenten unter Einsatz e.geeign. Datenbanksystems m. Mehrbenutzerzugriff und Schnittstelle z. Internet;
07.07.98;07.12.98;1998;intern;Diplom;DE;Konzeption und Auswahl eines Management-Informations-Systems für ein Ingenieur-Büro;
15.07.98;15.12.98;1998;intern;Diplom;DE;Das Konzept des Passivhauses in Theorie;
20.07.98;20.12.98;1998;intern;Diplom;DE;Konzept für Backup und Recovery der Oracle-Datenbanken bei der Firma Bosch in Nürnberg;
31.07.98;30.12.98;1998;intern;Diplom;DE;Informationssicherheit in lokalen und globalen Netzen als Gegenstand des strategischen Informationsmanagements;
07.09.98;07.02.99;1998;intern;Diplom;DE;Entwurf und Implementierung von Kommunikationsstrategien mit CORBA am Beispiel einer Virtual-Reality-Anwendung;
01.10.98;01.03.99;1999;intern;Diplom;DE;Untersuchung von Methoden zum unscharfen Zugriff auf Datenbestände;
06.10.98;06.03.99;1999;intern;Diplom;DE;Konzeption und Realisierung einer DCOM-basierten Komponentenarchitektur für ein existierendes, mit TCP/IP-Sockets realisiertes Kommunikationssystem;
06.10.98;06.03.99;1999;intern;Diplom;DE;Implementierung von Prioritätsschrankenalgorithmus und verwandten Synchronisationsverfahren zur Untersuchung des Echtzeit- und Laufzeitverhaltens;
20.10.98;20.03.99;1999;intern;Diplom;DE;Konzeption eines Geschäftsprozeßmodells für einen Dienstleister im Bereich Internet, Datenbanken und innovative Technologien;
22.10.98;22.03.99;1999;intern;Diplom;DE;Konzeption und Realisierung eines graphischen Editors für Objekte in der DCOM-basierten Laufzeitsystem Object Engine;
06.11.98;06.04.99;1999;intern;Diplom;DE;Benutzeridentifikation anhand der Bedienmuster für standar. Texte mit Hilfe von Methoden der Neuronalen Netze;
10.11.98;10.04.99;1999;intern;Diplom;DE;Komponentenbasierte 3-Ebenen-SW-Architekturen am Beispiel eines internetfähigen Informationssystems;
03.12.98;03.05.99;1999;intern;Diplom;DE;Hochverfügbare Systeme im NT-Umfeld;
09.12.98;09.09.99;1999;intern;Diplom;DE;Entwurf und Realisierung eines datenbankbasierten Systems zur strukturierten Verwaltung mehrsprachiger Textdokumente;
15.12.98;15.05.99;1999;intern;Diplom;DE;IT -Unterstützung im Vertrieb - Budgetangebote im Anlagengeschäft;
15.03.99;16.08.99;1999;intern;Diplom;DE;Untersuchung der Realisierung fuzzy-logischer Konzepte für das Datenbank-Retrieval;
22.03.99;02.07.99;1999;intern;Diplom;DE;Entwurf und Implementierung eines Echtzeit-Betriebssystems-Kerns für den digitalen Signalprozessor Motorola 56 300;
22.03.99;22.08.99;1999;intern;Diplom;DE;Konzeption eines Informationssystems für das Qualitätsmanagement im Produktdefinition- und -entwicklungsprozeß;
07.04.99;07.01.00;1999;intern;Diplom;DE;Entwurf und Einführung eines skalierbaren Kommunikationskonzepts für den Mittelstand auf Basis von Komponenten und Funktionen;
08.04.99;07.01.00;1999;intern;Diplom;DE;Automatische Robotoprogrammierung zum Zeichnen von 2 D-Grafiken;
12.04.99;12.01.00;1999;extern;Diplom;DE;Design und Implementierung eines Werkzeugs zur computerunterstützten Dokumentation von Programmquellcode;
14.04.99;14.01.00;1999;intern;Diplom;DE;Administration und Visualisierung von Dokumenten auf Basis verteilter Objekte in einer Mehrebenenarchitektur;
15.04.99;15.09.99;1999;intern;Diplom;DE;Erstellen einer Verkehrslärmkarte für das Stadtgebiet Bamberg;
30.04.99;30.09.99;1999;extern;Diplom;DE;Desaster Recovery von WINDOWS NT - Diskussion präventiver Strategien und deren Umsetzung;
04.05.99;04.10.99;1999;intern;Diplom;DE;Entwicklung eines Open GL kompatiblen Treibers für den Grafikchip GLINT MX/Delta für das Betriebssystem Linux;
04.05.99;04.10.99;1999;intern;Diplom;DE;Implementierung eines Systems zur automatischen und halbautomatischen Gewinnung von Unterschriften bei einer Direkt-Bank;
20.05.99;20.10.99;1999;intern;Diplom;DE;Entwurf und Implementierung einer OLE DB-Schnittstelle für Typinformationen in COM-Umgebungen;
20.05.99;20.10.99;1999;intern;Diplom;DE;Methoden des Software Reliability Engineering und deren Implementierung;
30.06.99;30.11.99;1999;intern;Diplom;DE;Aufbau und Test eines Infrarotmikroskops;
01.07.99;30.11.99;1999;intern;Diplom;DE;Die Berechnung der Abscheidung von Aerosolteilchen in Faserfiltermedien aufgrund von Trägheit und Gravitation (neues Zellenmodell);
05.07.99;30.11.99;1999;intern;Diplom;DE;Verwaltung zeitbezogener Daten: Grundlagen und deren Realisierung in SQL-92 und SQL 3;
15.07.99;15.12.99;1999;intern;Diplom;DE;Konzeption, Design und Implementierung einer Portierung von Windows NT nach Windows CE am Beispiel eines Embeddet HMI Systems für Sinumerik 840 D;
16.08.99;16.01.00;1999;intern;Diplom;DE;Konzeption eines vollständig benutzerzentrierten kommerziellen Internetangebotes;
14.09.99;14.02.00;1999;intern;Diplom;DE;Entwicklung einer Anwendung zur Erstellung und Präsentation von Dokumenten auf Basis von Internettechnologie und verteilter Objekte in Java;
14.10.99;14.03.00;2000;extern;Diplom;DE;Untersuchung der Implementierungs- und Realisierungsmöglichkeiten einer WAP-Anwendung;
20.10.99;20.03.00;2000;extern;Diplom;DE;Mental Ray Shader zur realistischen Darstellung der Oberflächenspannung auf mit Flüssigkeit überzogenen Flächen;
22.10.99;22.03.00;2000;intern;Diplom;DE;Konzeption und Realisierung eines Data Warehouse-Ansatzes am Beispiel des Business Information Warehouse der SAP AG;
01.11.99;01.04.00;2000;intern;Diplom;DE;Konzeption und prototypische Umsetzung einer Schnittstelle zur verteilten Simulation dynamischer Produktprozesse auf Basis der High Livel Architecture;
04.11.99;04.04.00;2000;intern;Diplom;DE;Integriertes Domtrollingkonzept für die interne und externe Rechnungslegung bei Energieversorgungsunternehmen als Folge der Liberalisierung der Energieversorgermärkte - Entwicklung und Implementierung;
12.11.99;12.04.00;2000;intern;Diplom;DE;Softwareunterstützte Erzeugung von komplexen, verteilten Simulationsmodellen aus Einzelmodellen auf Basis der HLA;
01.12.99;14.03.99;2000;extern;Diplom;DE;Entwicklung eines Vorgehensmodells für das Management von Projekten in der objektorientierten Software-Entwicklung;
07.12.99;05.05.00;2000;intern;Diplom;DE;Entwurf und Realisierung von Komponenten für graphische Operationen in einem Plotmanagement-System;
09.12.99;09.05.00;2000;intern;Diplom;DE;Entwurf und Realisation einer TAPI-Schnittstelle zur Steuerung einer ISDN-Telekommunikations-Anlage über Ethernet und Demonstration der Funktionsweise anhand einer CTI-Applikation unter LINUX;
23.12.99;23.05.00;2000;intern;Diplom;DE;Analyse und Konzeption von Kommunikationsprozessen in einer Bank im Hinblick auf die Einführung eines Intranets;
10.01.00;13.02.01;2000;intern;Diplom;DE;Auswertung von Stereobildern - Objekterkennung und Szenenvermessung;
20.01.00;26.10.00;2000;intern;Diplom;DE;Entwicklung von Komponentensoftware mit Microsoft COM und der Active Template Library am Beispiel einer verteilten Groupware-Anwendung;
24.03.00;24.08.00;2000;intern;Diplom;DE;Konzeption und Realisierungs internetfähiger Reservierungs-Komponenten am Beispiel eines Kinoverwaltungssystems;
24.03.00;15.12.00;2000;intern;Diplom;DE;Entwicklung eines unternehmensspezifischen Zeiterfassungssystems unter Verwendung von Borland Delphi und Microsoft SQL Server;
28.03.00;28.08.00;2000;extern;Diplom;DE;Einbindung des Internet in den Workflow des mehrspartigen Netzbauabwicklungsprozesses bei einem Energieversorger;
29.03.00;29.08.00;2000;intern;Diplom;DE;Betrachtung des XML-basierten Internet-Objektprotokolls SOAP als Basis für Web-Applikationen der 3. Generation sowie Darstellung anhand eines durchgängigen Beispiels aus der Versicherungsbranche;
31.03.00;15.03.01;2000;intern;Diplom;DE;Konzeption und Implementierung eines komponentenbasierten Robotersimulators;
03.04.00;03.09.00;2000;intern;Diplom;DE;Optimierte Darstellung und Speicherung von Dreiecksnetzen;
19.05.00;19.10.00;2000;intern;Diplom;DE;Konzept zur Einführung eines Dokumentenmanagementsystems für einen internen DV-Dienstleister;
26.05.00;26.10.00;2000;intern;Diplom;DE;Design und Implementierung eines objektorientierten Kommunikations-Framework;
29.06.00;30.09.00;2000;intern;Diplom;DE;Entwurf und Teilrealisierung eines betrieblichen Internet-Informationssystems;
12.07.00;12.12.00;2000;intern;Diplom;DE;Konzept für ein Qualitätsinformationssystem zur Auswertung von technischen Daten mit Hilfe eines Data-Warehouse auf Basis der OLAP-Technologie;
27.07.00;13.03.01;2000;intern;Diplom;DE;Entwicklung und Evaluierung verschiedener Middlewarekonzepte als Simulationsumgebung für GSM (Gloal System for Mobile Communication) - Sprachverarbeitung;
01.08.00;08.01.01;2000;intern;Diplom;DE;Interaktion mit einem Internet-Agenten;
01.08.00;08.01.01;2000;intern;Diplom;DE;Analyse der Methoden des Information Retrieval von Suchmaschinen und prototypische Implementierung geeigneter Anwendungen;
20.09.00;15.12.00;2000;intern;Diplom;DE;Evaluierung der möglichen Integration von SAP Secure Network Communication in die Siemens TranSON Architektur;
22.09.00;19.06.01;2000;intern;Diplom;DE;Entwurf eines Risikomanagementsystems unter besonderer Berücksichtigung der Aggregation von Risiken;
28.09.00;27.01.01;2000;intern;Diplom;DE;Entwicklung von Algorithmen zur Erkennung von Augen in digitalen Bildern;
28.09.00;23.02.01;2000;intern;Diplom;DE;Entwurf und Realisierung eines modularen und interaktiven Bildverarbeitungssystems;
01.10.00;23.02.01;2001;intern;Diplom;EN;Development of a fault tolerant solution for a PC-based Programmable Logic Controller;
04.10.00;01.03.01;2001;intern;Diplom;DE;HyTime-basiertes Link-Management in einem SGML-Content Management-System;
10.10.00;24.07.01;2001;intern;Diplom;DE;Entwicklung einer Ausführungsumgebung von Komponenten in verteilten Systemen;
10.10.00;09.03.01;2001;intern;Diplom;DE;Entwurf und Entwicklung einer XML-basierten Beschreibungssprache für relationale Datenbanken zur parametrisierten automatischen Erzeugung von Web-Eingabemasken;
10.10.00;24.07.01;2001;intern;Diplom;DE;Konzeptionierung und Realisierung einer rückgekoppelten, lernenden Textsuchkomponente;
13.10.00;15.01.01;2001;extern;Diplom;DE;Zusammenführung von theoretischen Informationsmodellen und realem Informationsworkflow und Berücksichtigung vorhandener unternehmerischer Sichten zur Einführung eines Dokumentenmanagementsystems;
14.10.00;14.03.01;2001;extern;Diplom;DE;Optimierung und Weiterentwicklung des Referenz Clock Generators von GSM-Basisstationen;
14.10.00;26.06.01;2001;intern;Diplom;DE;Projektierungstool für die Anzeigensteuerung der Fahrgastinformation;
20.10.00;20.03.01;2001;intern;Diplom;DE;Realisierung eines Workflows für das Bewerbermanagement mit Internet-Technologie;
26.10.00;25.07.01;2001;extern;Diplom;DE;Netz-Erneuerung für die BOSCH-Niederlassung Nürnberg;
30.10.00;29.03.01;2001;extern;Diplom;DE;Dokumentenmanagementsystem für Präsentationen;
31.10.00;30.03.01;2001;extern;Diplom;DE;Entwicklung einer Toolumgebung für eine Hochleistungsmotorsteuerung;
01.11.00;28.02.01;2001;extern;Diplom;DE;Prozessorientiertes Qualitätsmanagement in einem mittelständischen Dienstleistungsunternehmen am Beispiel der DATA INPUT AG;
08.11.00;19.07.01;2001;intern;Diplom;DE;eProcurement-Systeme für KMU-Einsatzszenarien, Technologien und Soft-warekomponenten;
09.11.00;14.03.01;2001;intern;Diplom;EN;Reengineering of a legacy sales information system with respect to Customer Relationship Management (CRM) and the Internet, including an implementation of a certain component;
14.11.00;25.06.01;2001;intern;Diplom;DE;Konzeption und Implementierung eines Web-Portals zur Darstellung aktueller Unternehmenskennzahlen und dessen Integration in die vorhandene Infrastruktur;
23.11.00;23.04.01;2001;intern;Diplom;DE;OBIS - Observation and Information System auf Lotus-Notes-Basis;
30.11.00;25.06.01;2001;extern;Diplom;DE;Konzeption einer User Interface Adaption für mobile Webgeräte;
30.11.00;27.04.01;2001;intern;Diplom;DE;Entwurf und Implementierung eines ISDN-Stacks unter dem Echtzeitbetriebssystem EUROSplus;
01.12.00;27.04.01;2001;intern;Diplom;DE;Konzeption und Design eines graphischen Entwicklungswerkzeugs für internetbasierte Informationssysteme;
20.12.00;16.05.01;2001;extern;Diplom;EN;A generic, computer-based approach to the estimation of asset lifetimes;
10.01.01;03.07.01;2001;extern;Diplom;DE;Ein Einblick in moderne Methoden des Requirements Engineering ;
14.01.01;14.05.01;2001;extern;Diplom;DE;Leitlinien zur innerbetrieblichen Verrechnung der IT-Leistungen in einem Versicherungsunternehmen;
20.02.01;14.03.01;2001;intern;Diplom;EN;Changes of business processes and public presentation within the influence of modern media;
28.02.01;30.01.02;2001;intern;Diplom;DE;Konzeption und Implementierung eines Moduls zur flexiblen Anbindung von Speditionsunternehmen an Internet-Marktplätze.;
21.03.01;13.12.01;2001;intern;Diplom;DE;Evaluierung der Entwicklungswerkzeuge DYMOLA und MODELICA durch beispielhafte Entwicklungen von mechatronischen Systemkomponenten;
21.03.01;18.10.01;2001;intern;Diplom;DE;Werkzeugunterstützte Modellierung von Anlagen mit UML;
27.03.01;01.08.01;2001;intern;Diplom;DE;Ein prototypischer Container für die CEA-Komponenten-Architektur;
30.03.01;29.08.01;2001;intern;Diplom;EN;Design of a customising process and a meta-data model for a key figure-based information system, with focus on the configuration of a key figure model;
01.04.01;22.08.01;2001;intern;Diplom;DE;"Computergestützte Datenerhebung mit dem Internet; Entwicklung eines Front-End-Editors zum Erstellen von Online-Umfragen";
09.04.01;08.01.02;2001;extern;Diplom;DE;Wiederverwendbare Analysemuster auf der Basis natürlich sprachlicher Anforderungen;
11.04.01;22.08.01;2001;intern;Diplom;DE;Vergleichende Studie von Distance-Vector-Routing-Protokollen und Link-State-Routing-Protokollen;
17.04.01;17.09.01;2001;extern;Diplom;DE;"Konzept zur Implementierung einer Schnittstelle zwischen dem<br>Planungstool ""ProPlanner"" und der Arbeitsplan-Datenbank in der <br>Prozessplanung der BMW Group.";
20.04.01;19.09.01;2001;extern;Diplom;DE;Konzept zur Migration von Datenmodellen bei der Firma DATEV in UML-Klassendiagramme und seine Implementierung;
27.04.01;27.09.01;2001;intern;Diplom;DE;Entwurf und Implementierung eines Systems zur Einschreibung zu den Fachwissenschaftlichen Wahlpflichtfächer am Fachbereich unter Benutzung des WWW.;
30.04.01;01.10.01;2001;extern;Diplom;DE;Modellgestützte Analyse und Synthese von Gesichtsbildern;
30.04.01;;2001;intern;Diplom;DE;Extraktion navigationsrelevanter Daten aus vorverarbeiteten<br>Stereobildern mit Hilfe eines simulierten neuronalen Netzes.;
01.05.01;01.10.01;2001;extern;Diplom;DE;Entwurf und Implementierung eines standardisierten Hantierungs-werkzeugs für die Verwaltung von Sortierplänen im Bereich Distributionslogistik;
01.05.01;28.11.01;2001;intern;Diplom;DE;Der Softwareauswahlprozess am Beispiel einer Internet-Suchmaschine mit Detailplanung der Softwareeinführung;
02.05.01;12.09.01;2001;intern;Diplom;DE;Analyse und Neustrukturierung eines Firmen-LANs - Migration von Token Ring zu Switched-Ethernet und Erstellung eines VLAN-Konzepts mit Einbindung in ein Netzwerkmanagementsystem;
02.05.01;01.10.01;2001;intern;Diplom;DE;Unsicherheit und Unschärfe bei Bewertung und Aggregation von Risiken <br>in einem Risikomanagementsystem. Simulationsrechnungen für ein Modell<br>eines produzierenden Unternehmens.;
15.05.01;12.11.01;2001;extern;Diplom;DE;Einführung eines webbasierten Qualitätsmanagementsystems bei <br>einem IT-Dienstleister;
23.05.01;01.10.01;2001;extern;Diplom;DE;XML-Datenhaltungs- und Datenaustauschplattform für das Verlagswesen?;
25.05.01;21.12.01;2001;extern;Diplom;EN;Application of a Web-Controlling Instrument in the Insurance <br>Industry for the Example of Quelle Versicherung;
26.06.01;18.02.02;2001;extern;Diplom;DE;Räumlich verteilte und gleichzeitige Bewertung visualisierter <br>medizinischer Bilddaten. Analyse der Anforderungen, Entwurf und<br>Implementierung eines Prototyps;
11.07.01;;2001;intern;Diplom;DE;Cobol & Objektorientierung - ein Vergleich zwischen objekt-orientierter und prozeduraler Implementierung ;
14.07.01;14.12.01;2001;intern;Diplom;DE;Konzeption und Implementierung einer Architektur zur modularisierten  Daten aus einem OSGi-Server in einem Browser unter Verwendung von XML;
16.07.01;15.02.02;2001;intern;Diplom;DE;Analyse der ISO 9000 ff-Abläufe bei der ISO Software Systeme GmbH und Entwurf einer Web-gestützten Anwendung zu deren Unterstützung;
23.07.01;11.03.02;2001;intern;Diplom;DE;Der Modellbildungsprozess in der Wirtschaftsinformatik: Erkenntnis- theor. Reflexion des Spannungsfeldes zwischen Modell und Realität in ausgewählter Literatur unter besonderer Berücksichtigung des naiven Realismus (Arbeitstitel);
01.08.01;12.12.01;2001;intern;Diplom;DE;Konzeption und Aufbau eines Systems zur Qualitätssicherung in der Softwareentwicklung von Audio-Datenkompressionsverfahren;
13.09.01;04.02.02;2001;extern;Diplom;DE;Konzeption eines pragmatischen Geschäftsprozessmodells für den technischen Vertrieb von IT-Sicherheitslösungen ;
14.09.01;08.02.02;2001;extern;Diplom;DE;Bewertung, Vergleich und Erweiterung von UML-basierten Ansätzen zur objekt-orientierten Modellierung von Echtzeitsystemen.;
01.10.01;27.02.02;2002;intern;Diplom;EN;Concept for an Automated Web-based Customer Relationship Management System for a Web-Design Company. ;
01.10.01;28.02.02;2002;intern;Diplom;DE;Planung und Realisierung eines Internetportals für christl. Jugendarbeit;
11.10.01;07.03.02;2002;intern;Diplom;DE;Analyse, Design und Implementierung eines Werkzeugs zur Modellierung und Erzeugung von Datenbanken unter Verwendung des Entity-Relationship-Modells;
11.10.01;11.03.02;2002;intern;Diplom;EN;Design and Prototyping of a Secure Network File System under Linux on the Basis of Open SSH;
15.10.01;14.03.02;2002;extern;Diplom;DE;Knowledge Management: Theorie, Werkzeuge und Ziele, sowie deren Anwendung für die Wissensbasis eines Software-Hauses;
23.10.01;05.03.02;2002;intern;Diplom;DE;Konzeption und Implementation eines Simulationsmoduls für ein SA/RT-Case-Tool;
24.10.01;21.03.02;2002;intern;Diplom;DE;Realisierungsplattformen für Webservices - Bewertung von Leistungs-umfang und Unterstützung relevanter Technologiestandards;
01.11.01;02.04.02;2002;intern;Diplom;DE;Aufbau,Inbetriebnahme und Test eines netzwerkorientierten Intrusion Detection Systems;
15.11.01;15.04.02;2002;intern;Diplom;DE;Analyse des bestehenden Reportings und Konzeption eines analytischen Informationssystems für das PC-Service-Management in einem EDV-Dienstleistungsunternehmen.;
15.11.01;11.04.02;2002;extern;Diplom;DE;Entwurf und Entwicklung eines Prototyps für ein wissensbasiertes System zur Unterstützung der Konfiguration variantenreicher Büromöbeleinrichtungen;
15.11.01;31.07.02;2002;intern;Diplom;DE;JPEG2000 - Einsatzmöglichkeiten im medizinischen Bereich;
19.11.01;16.04.02;2002;intern;Diplom;DE;Erweiterung der Videocodierung H.263 zur segment- und modellbasierten Kompression bewegter Gesichtsbildfolgen;
27.11.01;18.03.02;2002;intern;Diplom;DE;Erhöhung der Netzwerksicherheit durch den Einsatz von Intrusion Detection Systemen - eine Analyse hinsichtlich Effektivität und Wirtschaftlichkeit;
27.11.01;18.03.02;2002;intern;Diplom;DE;Application Service Providing und daraus resultierende Anforderungen an Service Level Agreements sowie an Konzepte zur Datenhochverfügbarkeit;
13.12.01;13.05.02;2002;intern;Diplom;DE;Realisierung einer Softwareplattform für kundenspezifische Prüfsysteme;
14.12.01;29.04.02;2002;intern;Diplom;DE;Simulation und Entscheidungsfindung - Entwicklung eines Verkehrssimulationssystems mit Simplex III zur Ableitung von mikro- und makroskopischen Entscheidungen;
10.01.02;31.05.02;2002;intern;Diplom;DE;Analogisches Denken als eine mögliche Erkenntnisstrategie zur Modellbildung in der Wirtschaftsinformatik;
10.01.02;22.03.02;2002;extern;Diplom;EN;Testing and Software Rehability with a Special Regard to Component-Based Software;
11.01.02;24.05.02;2002;extern;Diplom;DE;Analyse aktueller Wissensmanagement-Konzepte und Darstellung einer möglichen Umsetzung in der betrieblichen Praxis am Beispiel der Quelle Versicherungen;
11.01.02;12.06.02;2002;intern;Diplom;DE;Grundlagen für ein Konzept zur Einführung von Wissensmanagement in einem Ingenieurbüro zur Verbesserung der Geschäftsprozesse;
14.01.02;14.06.02;2002;intern;Diplom;EN;Enterprise JavaBeans Relationship Service;
30.01.02;12.04.02;2002;intern;Diplom;EN;Knowledge Management;
25.02.02;02.09.02;2002;intern;Diplom;DE;Planung und Programmierung einer hierarchischen Benutzerverwaltung auf Basis eines LDAP-Servers und Bereitsstellung geeigneter Systemschnittstellen;
01.03.02;06.06.02;2002;extern;Diplom;DE;Konzeption und Implementierung eines Java-Programms zur Steuerung der Testumgebung für ein Raumsondenexperiment;
06.03.02;05.08.02;2002;intern;Diplom;DE;Entwicklung eines Linux basierenden Firewall der mit beliebig vielen Partnern kommunizieren kann, welche dynamische IP Adressen verwenden. ;
15.03.02;15.11.02;2002;extern;Diplom;DE;Implementierung eines OPC-Servers unter dem Echtzeitbetriebssystem EUROSplus auf DCOM-Basis;
01.04.02;20.12.02;2002;intern;Diplom;DE;Fachkonzept für die Entwicklung des Programms Kraftfahrzeugsteuererklärung ;
01.04.02;20.12.02;2002;intern;Diplom;DE;Ein EDV-gestütztes Modell zur Unterstützung von Computer Aided Facility Management-Software-Auswahlprozessen;
08.04.02;05.09.02;2002;extern;Diplom;DE;Entwicklung und Pilotierung einer Application Service Providing-Dienstleistung auf Basis der Windows Terminal Server-Technologie bei der DATEV eG;
12.04.02;30.09.02;2002;intern;Diplom;DE;Konzeption und Realisierung einer natürlichsprachlichen Benutzerschnittstelle für ein System zur Entdeckung von Wissen in Datenbanken;
30.04.02;30.09.02;2002;intern;Diplom;DE;Entwicklung einer Empfängersteuerung für digitalen Lang-, Mittel-, Kurzwellenrundfunk;
07.05.02;28.01.03;2002;intern;Diplom;DE;Theoretische Grundlagen und prototypische Implementierung eines anomaliebasierten NIDS;
15.05.02;04.12.02;2002;intern;Diplom;DE;Automatisierung von Unit Tests in der objektorientierten Software-Entwicklung - Eine Fallstudie am Beispiel der Touristik-Software OCEAN -;
15.05.02;11.10.02;2002;intern;Diplom;DE;Forward und Reverse Engineering für Automotive Software unter Verwendung der UML und Java;
28.05.02;27.09.02;2002;intern;Diplom;EN;Analysis, Conception and Implementation of a project planning software based on the ERP-System NAVISION Attain;
28.05.02;30.09.02;2002;intern;Diplom;DE;Erstellung eines Modells von standardisierten CRM-Prozessen in Anlehnung an den Business Development Process nach M. Gerber am Beispiel einer EDV-Firma;
29.05.02;24.01.03;2002;intern;Diplom;EN;Concept of Project Management Software based on the analysis of a generalized Project Management Process.;
19.06.02;12.01.03;2002;intern;Diplom;EN;Conception of a Business Process Modeling Tool with the Focus on Information Management Aspects;
26.06.02;31.10.02;2002;intern;Diplom;DE;Konzeption und Entwicklung eines prototypischen Steuerungssystems für die Überwachung eines international verteilten Produktionssystems;
27.06.02;30.09.02;2002;intern;Diplom;DE;Parallelisierte Lösung von partiellen Differentialgleichungen;
28.06.02;07.01.03;2002;intern;Diplom;DE;Entwicklung einer datenbankbasierten Internet Applikation auf Basis des Oracle Internet-File-System unter Berücksichtigung der Regeln der Informationssicherheit. Analyse der Stärken und Schwachpunkte.;
02.07.02;28.11.02;2002;intern;Diplom;DE;Entwicklung einer Schnittstelle zur Konfiguration eines Datenbanksystems auf Basis einer UML-Datenmodellbeschreibung;
09.07.02;21.11.02;2002;intern;Diplom;DE;Geschäftsprozessoptimierung im Bereich der Rechnungsprüfung bei der Siemens AG ;
15.07.02;12.12.02;2002;extern;Diplom;DE;Application Service Providing (ASP) aus Sicht der DATEV - Geschäftsmodellierung des Einführungsprozesses der Dienstleistung DATEVasp und Ermittlung dazugehörender Kennzahlen zur Messung der Kundenzufriedenheit;
28.08.02;27.01.03;2002;intern;Diplom;EN;Extension of the Imaging & Visualization Toolkit (IVT) for a CT based Colon Polyp Detection Application ;
01.10.02;28.02.03;2003;extern;Diplom;DE;Entwicklung einer Internetapplikation zur Reklamationsbearbeitung für den Einzelhandel unter Verwendung eines LAMP-Systems.(Linux-Apache-MySQL-PHP);
01.10.02;27.02.03;2003;extern;Diplom;DE;Anbindung von Kleinstandorten mit begrenzten Ressourcen an die homogene Windows 2000 PC-Infrastruktur des Siemens Konzerns;
01.10.02;28.02.03;2003;intern;Diplom;DE;Visualisierung von Datenvolumen mit programmierbaren Shadern und Texturen auf PC Hardware;
01.10.02;24.02.03;2003;intern;Diplom;DE;Design und Realisierung eines intelligenten Fachregals zur Unterstützung von Werkern in Montageprozessen;
01.10.02;30.05.03;2003;intern;Diplom;EN;Control and Simulation of Mobile Phone Layer 1 without Layer 3 support;
02.10.02;27.02.03;2003;intern;Diplom;DE;Konzeption und Implementierung eines Registrations-Robot für Internet-Domains;
02.10.02;03.03.03;2003;intern;Diplom;DE;Automatisierte Zuordnung fachbezogener Bewerberprofile zu vorhandenen Stellenprofilen in einer Datenbank;
09.10.02;10.03.03;2003;intern;Diplom;DE;Unterschiede und Gemeinsamkeiten von Wasserzeichenverfahren in verschiedenen Medien;
10.10.02;07.03.03;2003;extern;Diplom;DE;Entwicklung und prototypische Implementierung der zentralen Software-Komponenten eines Akustikmoduls für die akustische und graphische Repräsentation von Signalen eines Körperschallüberwachungssystems.;
14.10.02;24.04.03;2003;intern;Diplom;DE;Konzeption und prototypischer Entwurf einer Web-Applikation zur Produktaktualisierung bei mittelständischen Softwareunternehmen unter Verwendung von Java Servlet und JavaServer Pages Technologien;
15.10.02;25.03.03;2003;intern;Diplom;DE;Konzeption einer integrierten Softwareunterstützung für das Projektmanagement in der Automobilentwicklung am Beispiel des SAP-R/3-Projektsystems;
17.10.02;17.03.03;2003;extern;Diplom;DE;Entwicklung eines Reparatursystems zur automatischen Behebung von zentralen Fehlern eines Linuxsystems.;
17.10.02;17.03.03;2003;intern;Diplom;DE;Untersuchung der Eignung von JAVA für den Einsatz in einem Bildverarbeitungs-System unter Embedded Linux;
21.10.02;28.02.03;2003;intern;Diplom;DE;Verwendung von XML zur Unterstützung von sprachgesteuerten und sprachwiedergebenden Anwendungen für den Pocket PC;
22.10.02;20.03.03;2003;extern;Diplom;DE;Design, Konzeption und Realisierung einer ergonomisch gestalteten WWW-Oberfläche am Beispiel eines Kartenreservierungssystems.;
30.10.02;23.04.03;2003;extern;Diplom;DE;Konzepterstellung und Realisierung einer Einbindung von Linux für IBM Mainframe in den bestehenden Rechenzentrumsbetrieb;
30.10.02;06.03.03;2003;extern;Diplom;DE;Bewertung und praktische Anwendung von Hard- und Softwarelösungen zum Betrieb hochverfügbarer Serversysteme unter Linux und Windows;
30.10.02;06.03.03;2003;intern;Diplom;DE;Entwurf und Implementierung eines standortübergreifenden Kommunikationskonzeptes für den Konzerninternen Informationsaustausch;
30.10.02;25.04.03;2003;intern;Diplom;DE;Evaluation der Sicherheitskriterien für sensible Firmendaten im Internet anhand des Internet-Portals www.logistik.top100.de und Umsetzung einer technischen Lösung zur Reduzierung dieser Gefahren.;
30.10.02;28.03.03;2003;intern;Diplom;DE;Integration eines Bildschirm-Rekorders in eine medizinische Workstation und Bewertung des Ergebnisses anhand des Beispiels der virtuellen Kolonoskopie;
30.10.02;28.05.03;2003;intern;Diplom;DE;Hochsprachen für die Programmierung moderner GPUs (Graphic Processing Units). Analyse ihrer Einsatzmöglichkeiten in der medizinischen Bildverarbeitung anhand beispielhafter Implementierungen ausgewählter Algorithmen.;
01.11.02;28.03.03;2003;intern;Diplom;DE;Untersuchungen zur interaktiven Übertragung komprimierter Bilddaten mit JPEG2000 mittels CORBA;
04.11.02;14.03.03;2003;intern;Diplom;DE;"Implementierung eines Softwaremodells der Übertragungskette beim digitalen Kurzwellenrundfunk ""DRM""";
06.11.02;07.04.03;2003;extern;Diplom;DE;Konzeption einer Anwendung f.d.Ermittlung, zentr.Speicherung u.Veröffentlichung v.Ist-Ertrag-Daten netzgekopp.photovoltaischer (PV) Anl.m.anschl. prototypischer Gestaltung einer Internet-Benutzerschnittstelle f.d.Visualierung der PV-Anl. u. PV-Ist-Erträge;
06.11.02;07.04.03;2003;intern;Diplom;DE;Technische Grundlagen für Performance- und Verfügbarkeitsmanagement in einer Application Service Providing-Realisieerung;
28.11.02;03.04.03;2003;intern;Diplom;DE;Ein generisches Vorgehensmodell für die Spezifikation von Anforderungen an die Benutzerschnittstelle komplexer Systeme;
29.11.02;12.03.03;2003;extern;Diplom;DE;Möglichkeiten der Ingegration der ERP-Systeme SAP R/3 und BaaN IV am Beispiel der Fusion zweier multinationaler mittelständischer Unternehmen.;
01.12.02;31.07.03;2003;intern;Diplom;DE;Realisierung eines Web-Client für Siebel-CRM-Software auf Basis von Java-Technologien;
02.12.02;02.05.03;2003;intern;Diplom;DE;Erstellung eines Verzeichnisdienstes auf LDAP-Basis für<br>die Administration eines Linux-/Unix-Netzes;
02.12.02;02.05.03;2003;intern;Diplom;DE;XML-unterstützte Generierung graphischer Dialogkomponente für Java Applikationen im Bereich Logistik/Lagerhaltung;
03.12.02;05.05.03;2003;extern;Diplom;DE;Durchsatz- und Eignungsvergleich unter Embedded Linux von Sockets, ACE Framework und CORBA als Kommunikationsmechanismen zur Übertragung großer Datenmengen;
06.12.02;14.03.03;2003;extern;Diplom;DE;Konzeption einer integrierten Softwarelösung für die Personalkostenplanung in SAP R/3 am Beispiel der Automobilindustrie;
11.12.02;28.03.03;2003;intern;Diplom;DE;Mehrläufigkeit im praktischen Vergleich auf Basis der aktuellen Technologien von SUN und Microsoft.;
11.12.02;12.03.03;2003;intern;Diplom;DE;Konzepte der Kommunikation und Verteilung;
11.12.02;12.03.03;2003;intern;Diplom;DE;Konzepte der Kommunikation und Verteilung;
12.12.02;18.03.03;2003;intern;Diplom;DE;Entwicklung von Internet- und Intranetanwendungen mit dynamischen Businessgrafiken und Tabellen - Untersuchung und Vergleich von PHP4, Javascript und HTML mit den neuen .NET-Programmiersprachen VB.NET und C#.NET anhand konkreter Anforderungen.;
20.12.02;31.03.03;2003;intern;Diplom;DE;Untersuchungen zu Sicherheitskonzepten für die Kommunikation und Übertragung großer Datenmengen von embedded Multimedia Geräten.;
09.01.03;09.07.03;2003;extern;Diplom;DE;Entwurf und Implementierung einer Systemarchitektur für XML-basiertes Publishing am Beispiel eines Data-Warehouse Systems.;
13.01.03;28.03.03;2003;extern;Diplom;DE;Systemintegrierte Investitionsplanung in der Digitalen Fabrik mit SAP, Delmia und J2EE;
20.01.03;10.06.03;2003;intern;Diplom;DE;Analyse von Verhaltensmustern sowie Entwicklung geeigneter Methoden zur Erkennung und Behandlung von Web-Spidern aus Sicht von Internet-Inhaltsanbietern.;
27.01.03;30.09.03;2003;intern;Diplom;DE;"Untersuchung des Bluetooth-Stack ""BlueZ"" der als Linux-Kernel-Modul realisiert ist und dessen Inbetriebnahme auf einer 80x86 Architektur.<br>";
03.02.03;11.06.03;2003;intern;Diplom;DE;Anwendungsintegration bei Workflow-Management-Systemen;
19.02.03;15.10.03;2003;intern;Diplom;DE;Data Mining und deutsche Verbalmorphologie;
19.03.03;11.12.03;2003;intern;Diplom;DE;Data Mining und russische Verbalmorphologie;
20.03.03;24.07.03;2003;intern;Diplom;DE;Der Markt des Spielwaren-Einzelhandels in Nürnberg ;
27.03.03;19.09.03;2003;extern;Diplom;DE;Prototypische Realisierung eines ActiveX-Control zur Visualisierung eines vorgegebenen Volumenmodelles;
28.03.03;03.09.03;2003;intern;Diplom;DE;Zertifizierung von OLE Compound-Dokumenten und PE-Files mittels digitaler Signaturen. ;
31.03.03;26.11.03;2003;extern;Diplom;DE;Entwurf und Implementation einer IPsec-basierten Absicherung von offenen Netzwerken unter Linux.;
31.03.03;29.08.03;2003;intern;Diplom;DE;M A S T E R A R B E I T :<br><br>Dynamische Speicherstruktur für geometrische 3-dimensionale Objekte und deren hierarchischer Organisation in einem Szenegraphen;
01.04.03;29.08.03;2003;extern;Diplom;DE;Verwendung der 3D-Beschleunigungseinheit moderner Graphikkarten zur hardwarebeschleunigten Berechnung verschiedener Algorithmen in der Bildverarbeitung;
30.04.03;16.01.04;2003;intern;Diplom;DE;Konzeption und Realisierung eines Software-Agenten zum Einholen von Angeboten im Internet mit Verwendung von Branchenwissen ;
01.05.03;02.02.04;2003;intern;Diplom;DE;Multi-Volumen Rendering für medizinische Datensätze;
06.05.03;15.12.03;2003;intern;Diplom;DE;Verteilte Anwendungen auf der Basis Mobiler Agenten;
13.05.03;13.10.03;2003;extern;Diplom;DE;Konzeption und Realisierung eines Unterstützungssystems zum Management kundenspezifischer Konfigurationen von Anwendungssoftware für das Dokumentenmanagement;
23.05.03;20.10.03;2003;intern;Diplom;DE;Entwurf und Implementierung eines abgesicherten zentralen Servers zur Anmeldung und Verwaltung globaler Sessions;
23.05.03;30.09.03;2003;extern;Diplom;DE;Design eines Frameworks zur schnellen Entwicklung von Web-Anwendungen auf Basis des V-ger-Produktservers;
31.05.03;07.01.04;2003;intern;Diplom;DE;Entwicklung eines internetbasierten, datenbankgestützten Business-to-Consumer Portals mittels Techniken der Java2 Enterprise Edition;
01.06.03;07.01.04;2003;intern;Diplom;DE;Konformitätsprüfung von Structured Reports nach dem DICOM-Standard;
04.06.03;04.03.04;2003;extern;Diplom;DE;Bestimmung von wesentlichen Systemqualitätsparametern mit statistischen Analysen auls Patientenbilddaten von Magnetresonanzanlagen;
17.06.03;07.01.04;2003;intern;Diplom;DE;Vergleich der Umsetzung Aspekt-orientierten Programmierens in verschiedenen Frameworks;
11.07.03;30.09.03;2003;intern;Diplom;DE;Objektpersistenz unter Java - Eine Gegenüberstellung aktueller Verfahren am Beispiel des Datenmodells einer Content-Management-Webapplikation;
17.07.03;17.12.03;2003;intern;Diplom;DE;Konzeption und Implementierung eines Rahmenprogramms zur Demonstration von Softcomputingverfahren mit Beispielimplementierungen;
01.08.03;07.01.04;2003;intern;Diplom;DE;Erarbeitung von Richtlinien und Entwicklung eines grundlegenden Frameworks zur komponentenbasierten Softwareentwicklung unter .NET;
08.08.03;07.01.04;2003;extern;Diplom;DE;Untersuchungen und Vergleich verschiedener Echtzeit-Betriebssystem-Implementierungen für den Einsatz im Highspeed-Mulitmedia-Bereich;
01.09.03;01.03.04;2003;extern;Master;EN;Implementation and Evaluation of Pentium 4 - Optimizations in the Audio Codec mp3PRO.;
08.09.03;09.02.04;2003;intern;Diplom;DE;Konzeption und Realisierung einer Lösung zur zuverlässigen Erkennung von Spam-Mails im Emailsystem einer Versicherungsgruppe.;
01.10.03;15.03.04;2004;intern;Diplom;DE;Annuitätentilgung von Darlehen und Renten mit numerischer Berechnung des effektiven Zinssatzes;
01.10.03;26.02.04;2004;intern;Diplom;DE;Konzeption und Realisierung einer Operation- and Maintance-Anwendung zur Visualisierung und Überwachung von Testsystemen der Sigos SITE-Plattform;
02.10.03;12.01.04;2004;intern;Diplom;EN;A Pragmatic Approach to Automation of Office Process and Workflows;
02.10.03;07.01.04;2004;intern;Bachelor;DE;Erstellung einer T9-Worterkennungs-Software für Windows PCs;
10.10.03;16.04.04;2004;intern;Diplom;DE;Enterprise Application Integration mit J2EE und der Java Connector Architecture - Das eFactory Beispiel Delmia PPR-Hub;
10.10.03;08.03.04;2004;extern;Diplom;DE;Konzeption und Implementierung eines XML-basierten Schnittstelle zur Nutzung von Internet-Diensten in einem Workflow-Management-System;
14.10.03;29.04.04;2004;extern;Diplom;DE;Konzeption und prototypische Realisierung eines Frameworks zur Unterstützung der Erzeugung, Installation und Verwaltung von kundenspezifischen Softwarekomponenten ;
16.10.03;17.03.04;2004;extern;Bachelor;DE;Evaluierung der Spezifikation der Business Process Execution Language for Web Services und prototypische Integration in ein Informationsmanagementsystem;
17.10.03;31.03.04;2004;extern;Diplom;DE;Konzept und Implementierung einer Testautomatisierung über die graphische Oberfläche von Qt-basierenden Applikationen.;
23.10.03;22.03.04;2004;extern;Diplom;DE;Entwicklung einer selbst konfigurierbaren Web Applikation für Klein- und Mittelbetriebe zur Erstellung von Dealer-Locator-Solutions;
31.10.03;30.04.04;2004;extern;Master;DE;Konzeption, Machbarkeitsstudie und prototypische Umsetzung eines webbasierten Mitarbeiterprotals zur Personaleinsatzplanung und Zeitwirtschaft;
31.10.03;29.06.04;2004;extern;Diplom;DE;Algorithmen zur Segmentierung der CT-Volumen-Daten von Körpern technischer Werkstoffe aus mehreren Materialien;
01.11.03;02.08.04;2004;intern;Diplom;DE;Entwicklung eines webgestützten Systems zur Evaluation von Lehrveranstaltungen;
03.11.03;11.06.04;2004;extern;Diplom;DE;Ein objektorientierter Ansatz für die Einbindung von Grafiken in Produktdokumentation am Beispiel von Logikdiagrammen;
04.11.03;05.04.04;2004;extern;Diplom;DE;Der sichere PC-Herausforderungen, Chancen und Risiken der Trusted Computing-Initiativen auf den internen PC-Einsatz der DATEV eG;
04.11.03;03.05.04;2004;intern;Master;DE;Entwurf eines Konzepts zur nutzerfreundlichen Verschlüsselung von ISDN-Telefonie;
11.11.03;30.04.04;2004;intern;Diplom;DE;Bewertung und Vergleich alternativer Authentifizierungsmethoden im Bereich der PC-Zugangskontrolle;
14.11.03;14.04.04;2004;intern;Diplom;DE;Eignung internetbasierender Single-Sign-On-Verfahren für die Automatisierungstechnik;
19.11.03;12.03.04;2004;extern;Diplom;DE;M A S T E R A R B E I T :<br>Entwurf und Implementierung eines Frameworks für Profiling- und Performancemessungen mit Hilfe von aspektorientierter Programmierung<br>;
20.11.03;19.04.04;2004;intern;Diplom;DE;Konzeptionierung und Implementierung eines InfoPatz-basierten Sitzungsplaners;
28.11.03;08.04.04;2004;extern;Diplom;DE;Konzeption und Implementierung eines webbasierten Test Suite Servers;
10.12.03;10.05.04;2004;extern;Diplom;DE;Konzeption und Implementierung eines Referenzmodells für ein Wissensportal in Industriebetrieben im Bereich Maschinen- und Anlagenbau.;
12.12.03;12.07.04;2004;extern;Diplom;DE;Entwurf und Entwicklung eines Web-basierenten Taskmanagement-Systems für ein Unternehmen in der Software-Branche;
18.12.03;24.05.04;2004;intern;Diplom;DE;Konzept und Implementierung einer Testautomatisierung über die graphische Benutzeroberfläche von GTK+-basierten Anwendungen unter Linux;
19.12.03;;2004;extern;Diplom;DE;Modellierung ausgewählter Betriebssystemkonzepte am Beispiel Linux mit UML 2.0;
14.01.04;11.06.04;2004;intern;Diplom;DE;Untersuchung zur digitalen Lokalrundfunkversorgung mit Sendern kleiner Leistung im Kurzwellenbereich;
14.01.04;11.06.04;2004;intern;Diplom;DE;Analyse, Modellierung und Implementierung eines regelbasierten Qualitätssicherungssystems für Datenbankschemata auf Basis einer Oracle Datenbank.;
15.01.04;14.06.04;2004;extern;Diplom;DE;Navigation in objektorientierten Datenmodellen mit Hilfe von XPath2-Suchanfragen;
20.01.04;31.03.04;2004;intern;Diplom;DE;Single Sign-On in der Finanzverwaltung. Konzept, Design und prototypische Realisierung einer Single Sign-On Lösung;
01.02.04;01.07.04;2004;extern;Diplom;DE;Entwicklung eines Verfahrens zur Prädiktion von Signalstärken in Gebäuden;
01.02.04;12.08.04;2004;extern;Diplom;DE;Evaluation von Requirements-Engineerings-Ansätzen im Bezug auf spezielle Typen von Systementwicklungsprojekten;
03.02.04;24.06.04;2004;extern;Diplom;DE;Entwurf und Realisierung eines prototypischen Webclients für OPC XML-DA Webservices;
09.02.04;28.05.04;2004;extern;Diplom;DE;Untersuchung und Anwendung von Methoden der Bildverarbeitung für die Erkennung von Psoriasis;
10.02.04;10.09.04;2004;intern;Diplom;DE;Entwurf einer XML-Sprache zur programmiersprachenunabhängigen Formulierung von Algorithmen und einer Transformationskomponente für Java und C++;
05.03.04;03.08.04;2004;intern;Diplom;DE;Design und Entwicklung eines Access Control Mechanismus für E-Commerce Anwendungen mittelsAspect Oriented Programming;
11.03.04;08.06.04;2004;intern;Bachelor;DE;Projektmanagement im öffentlichen Bereich - Von der Konzeption über die Realisierung zu einem Internet-Auftritt für eine Kirchengemeinde;
15.03.04;30.08.04;2004;extern;Diplom;DE;Konzeption und Entwicklung einer Migration der ASP-Technologie für Workflowgestützte Antrags- und Genehmigungsverfahren auf Basis von ASP.Net unter Windows;
16.03.04;10.08.04;2004;extern;Diplom;DE;Umwandlung von EDI-Datenformaten in XML und Erstellung eines entsprechenden Werkzeugs für das DATEV-Programm KanzleiRechnungswesen;
17.03.04;17.08.04;2004;extern;Diplom;DE;Ein ODX-basiertes Diagnosesystem zum Flashen von Steuergeräten im Automobilbereich;
18.03.04;17.08.04;2004;intern;Diplom;EN;A nondeterministic approach to extend the current methods of Software Reliability Engineering to modular and distributed systems via simulation;
22.03.04;20.12.04;2004;intern;Diplom;DE;Entwicklung einer Leitrechner- und Bedienungssoftware für die verteilte Steuerung einer Bahnanlage unter Linux;
22.03.04;20.12.04;2004;intern;Diplom;DE;Entwicklung eines Treibers und der Kommunikation für die verteilte Steuerung einer Bahnanlage unter Linux;
23.03.04;15.06.04;2004;extern;Bachelor;DE;Erstellung einer Funktionsbibliothek für die automatische Benchmark-Analyse der KFZ-Steuergeräteprogrammierung auf Basis der ISO-Protokolle CAN/TP/KWP2000.;
25.03.04;09.09.04;2004;intern;Diplom;DE;Entwurf und Realisierung eines Java-Frameworks für kryptographische Versuche;
25.03.04;28.09.04;2004;intern;Diplom;DE;Entwurf und Realisierung eines Systems zur Durchführung sicherer elektronischer Wahlen mit Java und Open-Source-Werkzeugen;
31.03.04;30.09.04;2004;extern;Diplom;DE;Adaptive Netzwerkstatusüberwachung mit Hilfe von SNMP und NetFlow;
01.04.04;31.08.04;2004;extern;Diplom;DE;Erstellung eines Konzeptes zur Migration der Netzwerkinfrastruktur auf IPv6 im Datacenter Nürnberg;
01.04.04;01.09.04;2004;extern;Diplom;DE;Konzeption und Implementierung eines Referenzmodells für Unternehmensportale bei mittelständischen wissensbasierten Dienstleistungsunternehmen in der IT-Branche mit Schwerpunkt Beratung;
01.04.04;07.09.04;2004;intern;Diplom;DE;Analyse und Klassifizierung verschiedener Arten von Wissenskarten unter den Aspekten Inhalt und Visualisierung, sowie deren Anwendbarkeitsprüfung und prototypische Umsetzung in Bezug auf den Fachbereich Informatik;
01.04.04;18.10.04;2004;extern;Diplom;DE;Portierung eines transaktionssicheren Flash-File-Systems auf QNX und die Verifikation der Transaktionssicherheit durch eine Regressionstestumgebung;
01.04.04;17.09.04;2004;extern;Diplom;DE;Konzeption und Implementierung automatischer Tests für Standard-Softwarekomponenten;
01.04.04;16.08.04;2004;extern;Diplom;DE;Konzept zur Bereitstellung von Informationen zur Steuerung eines Servicerechenzentrums und Basis ITIL;
01.04.04;15.10.04;2004;intern;Diplom;DE;Entwicklung und Implementierung eines intelligenten Assistenten zur Wiederverwendung von Informationen basierend auf der Smart Tag Technolgie;
06.04.04;01.09.04;2004;extern;Bachelor;DE;Dynamische Dokumentengenerierung zur Print-Prozessunterstützung per XSL-FO;
06.04.04;14.10.04;2004;extern;Diplom;DE;Technische Integration von Geschäftsprozessen unter Einbeziehung von Portalsoftware;
07.04.04;10.01.05;2004;extern;Diplom;DE;Benutzerbasierte Zugangskontrolle in lokalen Netzen;
14.04.04;15.02.05;2004;intern;Diplom;DE;Untersuchungen zur Personenzählung auf der Basis von Stereobildverarbeitung und Mustererkennung;
14.04.04;14.01.05;2004;extern;Diplom;DE;Erstellen eines Marketingkonzeptes für das IT-Start-Up Concert;
15.04.04;14.09.04;2004;intern;Diplom;DE;Entwurf und Implementierung erweiterbarer Software zur qualitativen und quantitativen Simulation systemtheoretischer Modelle.;
19.04.04;16.09.04;2004;extern;Diplom;DE;Konzeption und prototypische Implementierung eines Werkzeuges zum Standardisieren und Abgleichen von DATEV-Datenelementen auf Basis von XML;
19.04.04;30.08.04;2004;intern;Diplom;DE;Analyse und Klassifizierung der am deutschen Markt gängigen Dokumentenmanagementsysteme hinsichtlich Funktionsumfang und Technologie;
21.04.04;20.07.04;2004;extern;Bachelor;DE;Konzeption und Entwicklung einer Client-Server basierten Datenbankanwendung zur Unterstützung der administrativen Aufgaben in einer Begutachtungsstelle für Fahreignung;
21.04.04;21.09.04;2004;extern;Diplom;DE;Entwicklung eines softwaregestützten Deploymentprozesses für verteilte Webanwendungen auf Basis von ASP.NET;
26.04.04;24.09.04;2004;intern;Diplom;DE;Multiplattform Implementierung einer Software zur grafischen Echtzeit-Analyse von DVB-Transportströmen;
26.04.04;24.09.04;2004;intern;Diplom;DE;Konzept und Implementierung eines Systems zum Versenden von Mails und der automatisierten Auswertung der Antworten;
28.04.04;28.09.04;2004;extern;Bachelor;DE;Konzeption und Implementierung einer ERP-basierten Materialflussrechnung für die Wertschöpfungskette eines mittelständischen Produktionsunternehmens.;
29.04.04;;2004;intern;Diplom;DE;Konzeption und Implementierung einer Applikation zum Auslesen und Konfigurieren der Registry in den Betriebssystemen Windows 98, Windows 2000 und Windows XP;
30.04.04;;2004;intern;Diplom;DE;Analyse und Implementierung von Verfahren zur Beschreibung zeitbehafteter Systeme mit Petri-Netzen;
03.05.04;30.09.04;2004;intern;Diplom;EN;Neuro linguistic programming in software marketing and software development process;
12.05.04;12.08.04;2004;extern;Bachelor;DE;Konzeption und Realisierung eines SOAP-Routers als Komponente serviceorientierter Architekturen;
12.05.04;10.08.04;2004;intern;Bachelor;DE;State-of-the-Art-Analyse des internationalen Marktes für Softwaresysteme aus dem Bereich Wissensmanagement mmit Untersuchung der zugrundeliegenden Funktionen und anschließender Klassifzierung;
13.05.04;24.09.04;2004;extern;Diplom;DE;Diskrete Ereignissimulation zur Planung von LKW-Leitsystemen: Konzeption und Realisierung eines Prototyps zur Verkehrsflussoptimierung auf einem Werksgelände;
14.05.04;14.02.05;2004;extern;Diplom;DE;Objektrelationales Mapping mit JDO am Beispiel des Bucky-Datenmodells;
18.05.04;18.10.04;2004;extern;Diplom;DE;Konzeption und Realisierung von Programmlogik zur Automatisierung praxisgerechter Qualitätssicherungsmaßnahmen für ein Dokumenten-Management-System;
27.05.04;30.09.04;2004;extern;Diplom;DE;Konzipierung und Implementierung einer Reportengine für die Energiecontrolling-Software InterWatt zur Generierung von Standardberichten in Web- und Windows-Clients;
27.05.04;10.01.05;2004;extern;Diplom;DE;Konzeption und Implementierung der Software für ein Mikrocontrollersystem in der Cryo-Technik zum Einfrieren von lebenden Humanzellen;
01.06.04;10.01.05;2004;intern;Diplom;DE;Konzeption und Implementierung einer plattformunabhängigen Bibliothek zur einfachen Benutzung von Stereoalgorithmen und deren qualitativen Analyse;
01.06.04;10.01.05;2004;intern;Diplom;DE;Konzeption und Implementierung einer plattformunabhängigen grafischen Entwicklungsumgebung für binokulare Algorithmen;
02.06.04;28.10.04;2004;extern;Diplom;DE;Konzeption und Entwicklung eines Monitoring Systems für Netzwerke und verteilte Anwendungen;
07.06.04;03.09.04;2004;intern;Bachelor;DE;Analyse der Funktionalitäten und Leistungsmerkmale am deutschen Markt gängiger Content-Management-Systeme mit Entwurf eines Klassifikationsschemas;
17.06.04;02.09.04;2004;intern;Bachelor;EN;Micropayment Protocols - making small payments on the Internet;
29.06.04;30.09.04;2004;extern;Diplom;DE;Entwurf und Implementierung eines Framework zur sicheren Kommunikation von verteilten Systemen auf Basis von XML;
01.07.04;31.03.05;2004;extern;Diplom;DE;Softwareunterstützung für das Supply-Chain-Management bei einem Unternehmen der Elektroindustrie;
15.07.04;14.01.05;2004;extern;Diplom;DE;Hochverfügbarkeit und Skalierbarkeit von Naming Services auf einer CORBA-Plattform mit 60.000 Endanwendern - Konzept für das Load Balancing und Aufbau einer Testumgebung;
15.07.04;14.02.05;2004;intern;Diplom;DE;Sichere Geschäftsprozesse mit Webservices;
28.07.04;10.01.05;2004;extern;Diplom;DE;Zentrales Management von Intrusion Detection Systemen in segmentierten Netzen mit unterschiedlichen Sicherheitsanforderungen;
01.08.04;15.03.05;2004;intern;Master;DE;Konzeption, Adaption und Einführung einer elektronischen Krankenakte am Beispiel einer Klinik mit Poliklinik;
02.08.04;14.03.05;2004;intern;Diplom;DE;Parallelisierung und Verteilung des Eventsystems eines interaktiven Simulationssystems zur Performanceverbesserung;
02.08.04;29.10.04;2004;extern;Diplom;EN;Conceptual re-disign of an international web-based product information Database (PID) of the company PUMA AG with a focus on user requirements reengineering and business process analysis;
05.08.04;03.02.05;2004;extern;Master;DE;Entwurf und prototypische Implementierung eines EPC-Netzwerks unter Einsatz von mobilen kooperativen Software-Agenten zur Informationssuche;
06.08.04;07.10.04;2004;extern;Bachelor;DE;Erweiterung eines interpreterbasierten Systems um dynamische Elemente;
09.08.04;10.01.05;2004;extern;Diplom;EN;Design and Implementation of a comprehensive tracing-concept for mobile stations based on compiler debugging information;
09.08.04;10.01.05;2004;extern;Diplom;DE;MEDCom - ein System zur Kommunikation, Workflowmonitoring und -unterstützung im medizinischen Umfeld;
13.09.04;;2004;extern;Diplom;DE;Teilautomatisierung des PC-Software-Verteilungsprozesses eines Bankendienstleisters: Automatische Generierung von Software-Profilen und Konfigurationsparametersätzen.;
20.09.04;14.02.05;2004;intern;Diplom;DE;Software-Wartung: Nicht nur ein Problem der Codierung!;
22.09.04;22.02.05;2004;extern;Diplom;DE;Konzeption und Implementierung eines Systems zur Erfassung, Verwaltung und Abrechnung von Feuerwehreinsätzen;
22.09.04;22.02.05;2004;extern;Diplom;DE;Vergleich und Bewertung bestehender Lösungsansätze für einen Persistence Layer und Implementierung einer eigenen Persistenzschicht im .NET-Umfeld;
23.09.04;29.03.05;2004;extern;Diplom;DE;Ausarbeitung eines Wissensmanagement-Konzeptes zur Koordination des Know-hows für das Center of Competence Öl und Gas des Siemens Geschäftsbereichs Automation und Drives;
01.10.04;01.03.05;2005;intern;Diplom;DE;Businessplan für ein IT-Dienstleisungsunternehmen;
01.10.04;25.02.05;2005;extern;Diplom;DE;Konzeptionierung und Implementierung einer TCP/IP Testsuite unt RMOS;
01.10.04;28.02.05;2005;extern;Diplom;DE;Entwurf eines Reisekosten-Workflows in SAP R/3 bei der Audi AG;
01.10.04;28.02.05;2005;extern;Diplom;DE;Entwurf und prototypische Implementierung eines modularen Systems zur interaktiven Computer-assistierten Bildauswertung;
12.10.04;;2005;extern;Diplom;DE;Entwurf von Statistik-Software zur Workflow-Optimierung bei der Siemens AG und Vergleich mit einer Data-Warehouse-basierten Lösung;
14.10.04;14.03.05;2005;intern;Diplom;DE;Hardware / Software - Co Design mit MDA und UML;
15.10.04;02.05.05;2005;intern;Diplom;DE;Optimierung einer Lagerverteilung in einem Hochregallager mit Hilfe evolutionärer Algorithmen in Java;
15.10.04;14.01.05;2005;intern;Bachelor;DE;Strukturierung internetbasierter Human-Resource-Marketplaces;
16.10.04;02.05.05;2005;intern;Diplom;DE;"Untersuchung von Dokument-Informationssystemen unter dem Aspekt ""Benutzerorientierung""  mit besonderem Hinblick auf strukturierte Begriffssysteme";
20.10.04;20.05.05;2005;extern;Diplom;DE;Analyse, Spezifikation und Implementierung einer Konfigurationsmanagement-API für komplexe Datenstrukturen und Integritätsregeln in Logistiksystemen;
26.10.04;15.04.05;2005;extern;Diplom;DE;Ein Vorgehensmodell für das rollenbasierte Berechtigungsmanagement in SAP R/3;
01.11.04;31.03.05;2005;extern;Diplom;DE;Analyse und Vergleich der Anforderungsanalyse nach Volere mit existierenden Prozess-Modellen und prototypische Implementierung eines Requirements Engineering-Tools;
02.11.04;02.05.05;2005;extern;Diplom;DE;Konzeption und Realisierung von Werkzeugen zur Anwendungsentwicklung für ein XML-basierendes Framework auf der Grundlage von Plug-ins für die Entwicklungsumgebung Eclipse;
04.11.04;04.02.05;2005;intern;Bachelor;DE;Vergleich web-basierter Open-Source-Groupware-Lösungen;
04.11.04;04.04.05;2005;extern;Diplom;DE;Leistungsanalyse von Komponenten eines J2EE-Applikationsservers in einer simulierten EAI-Umgebung;
04.11.04;04.04.05;2005;extern;Diplom;EN;Specification and Implementierung of an EAI Framework for a Host Interface Solution in Siemens Logistic Projects containing the preparation for future J2EE architecture;
11.11.04;29.04.05;2005;extern;Diplom;DE;Konzeption und Implementierung einer optimierten Systemínitialisierung für embedded Linux;
15.11.04;15.08.05;2005;extern;Diplom;DE;Entwicklung einer regelbasierten Firewall in einem embedded Linux System;
18.11.04;11.03.05;2005;intern;Diplom;DE;Konzipierung und prototypische Implementierung eines Managementinformationssystems für die Kundendienst-Logistik eines Luft- und Raumfahrtunternehmens;
18.11.04;18.04.05;2005;intern;Diplom;DE;Konzept und Implementierung für einen Rollout von SSO mittels des eToken auf Linux;
25.11.04;22.04.05;2005;extern;Diplom;DE;Vereinfachung eines Software-Entwicklungsprozesses - auf Basis der methodischen Software-Entwicklung inkl. Schätzverfahren - auf die Anforderungen von kleinen und mittelgroßen Projekten und Realisierung eines entsprechenden Tailoring-Werkzeuges;
29.11.04;14.04.05;2005;extern;Diplom;DE;Konzeption und Realisierung eines MDA-basierten Software-Entwicklungsprozesses im J2EE-Umfeld sowie Untersuchung auf Effizienz im realen Unternehmenseinsatz;
01.12.04;02.05.05;2005;extern;Diplom;DE;Analyse, Design und Implementierung einer qualitätssicheren Handschrifterkennung und Validierung am Beispiel von Erfassungsbelegen aus der Produktion;
01.12.04;02.05.05;2005;intern;Diplom;DE;Analyse und Messung der Effizienz von TCP und UPP über Wireless LAN ;
01.12.04;02.05.05;2005;extern;Diplom;DE;Konzeption und Realisierung eines Prototyps zur intranetbasierten Verfolgung von Systemintegrationsprojekten im Medial IT-Markt;
01.12.04;20.05.05;2005;extern;Diplom;DE;Konzeption einer anpassbaren E-Business-Lösung auf der Basis von SAP CRM;
01.12.04;02.05.05;2005;intern;Diplom;DE;Entwicklung und Implementierung eines Funktionsplansystems zur qualitativen Simulation unter besonderer Berücksichtigung von Fuzzy-Logik;
01.12.04;29.04.05;2005;extern;Diplom;DE;Fehlermöglichkeiten- und Einflussanalyse (FMEA) verteilter Datenbanksysteme mit Entwicklung eines Überwachungstools zur Früherkennung von Inkonsistenzen am Beispiel der GfK AG;
13.12.04;20.01.05;2005;intern;Diplom;DE;"Erstellen eines Modells zum ""Künstlichen Leben"", in welchem aus einfachen Bausteinen und deren Zusammenarbeit komplexe Lebewesen entstehen können";
12.01.05;14.03.05;2005;extern;Diplom;DE;Informationssysteme in der Datenproduktion - Analyse und Fachkonzept am Beispiel eines Marktforschungsunternehmens<br>;
14.01.05;14.04.05;2005;intern;Bachelor;DE;Konzeption und Realisierung eines Frameworks für javabasierte Webanwendungen zur automatischen Validierung von Formulareingaben und zur Strukturierung der Webanwendungen nach MVC;
04.02.05;04.07.05;2005;intern;Diplom;DE;Methoden und Strategien zur kundenspezifischen Anpassung von standardisierten ERP-Systemen im Mittelstand;
20.02.05;22.08.05;2005;extern;Master;DE;Konzeption und Realisierung einer JDF-basierten Workflow Integration in der Druckbranche;
25.02.05;21.07.05;2005;extern;Diplom;DE;Wirkungsanalyse von Anforderungsänderungen während des Produktplanungsprozesses: Konzipierung und prototypische Entwicklung eines Simulations- und Optimierungsinstrumentes für einen Automobilhersteller;
01.03.05;27.06.05;2005;extern;Diplom;DE;Untersuchung der Einsatzmöglichkeit von Webservices als Schnittstelle zu SAP R/3 und Implementierung eines Prototypen auf der Basis von NetWeaver für eine Service Applikation;
01.03.05;09.05.05;2005;extern;Diplom;DE;Konvergenz von Sprach- und Datenkommunikation im Application Service Providing am Beispiel DATEVasp;
15.03.05;15.08.05;2005;extern;Diplom;DE;WSDL Compiler zur Web-Service-Erstellung für Automatisierungssysteme;
16.03.05;09.09.05;2005;extern;Diplom;DE;Überwachung und Steuerung der Auslastung von Transportstrecken in automatischen Transportsystemen;
16.03.05;27.09.05;2005;extern;Diplom;DE;Ermittlung logistischer Kennzahlen in automatisierten Logistiksystemen;
17.03.05;01.09.05;2005;extern;Diplom;DE;Kryptographie mit Elliptischen Kurven über Körpern gerader Ordnung für tief eingebettete Systeme;
17.03.05;01.08.05;2005;extern;Diplom;DE;Implementierung einer portierbaren Anwendung zur Nachbildung analoger Video-Matrizen unter Einsatz digitaler Codecs;
18.03.05;18.08.05;2005;intern;Bachelor;DE;Design und Implementierung eines Web-basierten Inventar Managements für den Fachbereich Informatik;
21.03.05;18.08.05;2005;extern;Diplom;DE;Konzeption und Realisierung einer Statistiklösung für eine Online-Agentur;
01.04.05;07.07.05;2005;extern;Bachelor;DE;Design and implementation of a generic flash device driver for cellular phones (Konzeption und Implementierung eines generischen Flash-Treibers für Mobiltelefone);
01.04.05;29.09.05;2005;extern;Diplom;DE;Konzeption und Implementierung eines Dokumentenmanagementsystems in einem mittelständischen Unternehmen der Telekommunikationsbranche mit Anbindung an eine bestehende LAMP Projektdatenbank;
04.04.05;29.09.05;2005;extern;Diplom;DE;Business Intelligence im Service Management;
04.04.05;05.09.05;2005;extern;Diplom;DE;Entwicklung einer XML-basierten Archivlösung für Stücklisten;
05.04.05;15.12.05;2005;extern;Diplom;DE;Prozessmodellierung und -optimierung im Bereich Produktmarketing und Beratung für die Dienstleistung DATEVasp;
05.04.05;08.11.05;2005;intern;Diplom;DE;Ablaufverfolgung und Visualisierung kryptographischer Algorithmen in Maple;
06.04.05;27.09.05;2005;extern;Diplom;DE;Konzeption und Adaption an eine homogene Produktdatenverwaltung für ein Geschäftsgebiet der Siemens AG;
06.04.05;20.10.05;2005;extern;Diplom;DE;Eine Supplier-Relationship-Management-Strategie für mittelständische Unternehmen und ihre Umsetzung in SAP-Szenarien;
07.04.05;16.09.05;2005;extern;Diplom;DE;Hinderniserkennung und Kollisionsvermeidung für einen autonomen Roboter unter Verwendung eines beweglichen Stereokamerasystems;
11.04.05;08.08.05;2005;extern;Diplom;DE;Entwicklung einer PC gestützten Messdatenerfassung für Netzschutzgeräte unter Linux auf der Basis von Messtechnikstandardkomponenten;
11.04.05;16.09.05;2005;extern;Diplom;DE;"Konzeption und Implementierung der Funktionalität Wertarten in der Komponente ""Risk Manager non-life"" der SAP-Versicherungslösung";
12.04.05;12.09.05;2005;extern;Bachelor;EN;Design and Implementation of a prototype for an XML-based feature tracking tool;
12.04.05;30.09.05;2005;extern;Diplom;DE;Design eines Kompressions- und Übertragensverfahrens für Daten in der Polysomnographie;
14.04.05;26.01.06;2005;intern;Diplom;EN;SWIM - Semantic Web Technology based Information Management;
14.04.05;29.09.05;2005;extern;Diplom;DE;Entwicklung eines Steuerungssystems für Kraftfahrzeuge auf der Basis evolutionärer Verfahren - Konzeption, Analyse und Implementierung genetischer und evolutionärer Algorithmen zur Lösung des Einparkproblems;
14.04.05;07.11.05;2005;extern;Diplom;DE;Konzeption und Realisierung eines Plugins zum neurologischen Gesichtsfeldtraining im EvoCare Therapiemanagementsystem<br>;
14.04.05;28.09.05;2005;extern;Diplom;DE;Konzeption und Realisierung eines Frameworks zur Visualisierung von Busaktivitäten im Automobilbereich<br>;
14.04.05;;2005;intern;Diplom;DE;Entwicklung eines Einparksystems für Kraftfahrzeuge auf der Basis evolutionärer Verfahren. Analyse und Umsetzung der Prinzipien des maschinellen Lernens und des Wissenswerten durch genetische Algorithmen am Beispiel einer 3D-Simulation<br>;
14.04.05;27.09.05;2005;extern;Diplom;DE;Konzeption und Implementierung eines Marktabsatzmodells für Prozessvisualisierungs-Software der Siemens AG<br>;
14.04.05;03.11.05;2005;extern;Diplom;DE;Entwurf, Implementierung und Evaluierung von Algorithmen zur Erkennung von Defekten auf unbearbeiteten Oberflächen;
14.04.05;29.09.05;2005;intern;Diplom;DE;Entwicklung eines Steuerungssystems für Kraftfahrzeuge auf der Basis evolutionärer Verfahren. Analyse der genetischen Algorithmen am Beispiel einer Fahrzeugsimulation und Untersuchung der Prinzipien des maschinellen Lernens ;
15.04.05;27.10.05;2005;extern;Diplom;DE;Entwicklung eines intelligenten Web-Portals für einen Gewerbemarktplatz;
15.04.05;30.09.05;2005;extern;Diplom;DE;Implementierung verbesserter und standardisierter Prozesse für Entwicklung, Pflege und Betrieb von IT-Lösungen/Services im Geschäftsbereich Logistics and Assembly Systems der Siemens AG;
15.04.05;30.09.05;2005;intern;Diplom;DE;Berechnung der Pixelfrequenz und deren Visualisierung bei Hochgeschwindigkeitsaufnahmen des Kehlkopfes;
26.04.05;26.09.05;2005;extern;Diplom;DE;Entwicklung einer verteilten Anwendung zur Verwaltung von Servern auf Basis der Eclipse Rich-Client-Platform;
27.04.05;;2005;intern;Bachelor;DE;Unternehmer-Daten-Modell für ein Restaurant-Verwaltungssystem;
29.04.05;28.09.05;2005;intern;Diplom;DE;Konzeption und Entwicklung eines mobilen Büros;
29.04.05;29.09.05;2005;extern;Diplom;DE;Untersuchung und Entwicklung eines Traceability-Konzepts und Teilevaluierung für Großgerätekomponenten im Bereich Siemens Automation and Drives, Large Drives<br>;
29.04.05;28.09.05;2005;intern;Diplom;DE;Konzeption und Entwicklung eines mobilen Büros;
30.04.05;01.08.05;2005;extern;Bachelor;DE;Konzeption und Implementierung einer XML-Schnittstelle zwischen dem Requirements Engineering Verfahren DOORS der Firma Telelogic und anderen Verfahren;
30.04.05;27.09.05;2005;intern;Diplom;DE;Konzeption einer konsistenten mobilen verteilten Datensynchronisationsanwendung für Privatpersonen und KMUs;
02.05.05;15.09.05;2005;extern;Diplom;DE;Integration des MOST-Busses in ein QNX-Neutrino-System mit Performance-Test<br>;
03.05.05;05.12.05;2005;extern;Diplom;DE;Zugriffskontrolle in Webanwendungen: Vom Geschäftsprozess zur Sicherheitspolicy am Beispiel der Energie-Management-Software InterWatt<br>;
09.05.05;08.11.05;2005;intern;Master;DE;Vom Geschäftsprozess zur Sicherheitspolicy;
11.05.05;27.09.05;2005;intern;Diplom;DE;Rückläufiges Register zur griechischen Verbalmorphologie (Aufbereitung mit Data Mining Verfahren)<br>;
23.05.05;24.10.05;2005;extern;Diplom;DE;C-Code Generierung zur automatisierten Ergänzung eines AT Kommandosatzes für einen GSM/GPRS/UMTS Protokollstack;
23.05.05;20.10.05;2005;intern;Diplom;DE;Vernetzung und Verfolgung multimedialer Informationen auf Pocket PCs;
23.05.05;20.10.05;2005;extern;Diplom;DE;Konzeption und Implementierung eines Prozesses zur Projektabwicklung von kundenindividuellen Softwareaufträgen für ein mittelständisches Softwarehaus;
23.05.05;09.09.05;2005;extern;Diplom;DE;Konzeption und Implementierungsansatz einer Scorecard-Lösung für die Zentrale IT der BMW-Group;
25.05.05;;2005;intern;Bachelor;DE;Framework für die Entwicklung sicherer Internet-Anwendungen;
30.05.05;18.11.05;2005;extern;Master;DE;Realisierung einer SAP BW-Lösung für die Einkaufskoordination der Diehl-Gruppe mit den Schwerpunkten Berichtswesen und Qulitätskontrolle.<br>;
30.05.05;28.10.05;2005;extern;Diplom;DE;Konzeption und Implementierung von Java/J2ME/MIDP-Anwendungen zur Gerätebedienung auf Basis von Electronic Device Descriptions (EDD)<br>;
30.05.05;06.10.05;2005;extern;Diplom;DE;Konzeption einer Anwendung zur effektiven Überwachung des SAP APO Core Interface unter Berücksichtigung der organisatorischen Anforderungen eines Industrieunternehmens<br>;
31.05.05;09.02.06;2005;extern;Diplom;DE;Integration des zwischenbetrieblichen Datenaustauschs in eine Produktionsfeuerungs-Software für den Werkzeug- und Formenbau<br>;
01.06.05;27.10.05;2005;intern;Diplom;DE;Qualitative und quantitative Analyse eines als Serien-Parallel Diagramm oder Fehlerbaum modellierten Systems unter Verwendung von farbigen Petri Netzen<br>;
06.06.05;23.12.05;2005;extern;Diplom;DE;Konzeption und Implementierung einer webbasierten Druckerdatenbank mit Schnittstellen zu SAP und Druck-Management-Systemen;
08.06.05;08.09.05;2005;extern;Bachelor;DE;Integration des Transaktions-Monitors CICS (Customer Information Control System) in eine service-orientierte Architektur<br>;
21.06.05;30.09.05;2005;extern;Diplom;DE;Konzeption und Implementierung einer Smartphone-Applikation zum Testen und Überwachen von Mobilfunkservices sowie Integration in das Sigos SITE-System<br>;
27.06.05;28.11.05;2005;intern;Diplom;DE;Entwicklung einer E-learning-Komponente für die Ingenieur-Mathematik;
27.06.05;28.11.05;2005;extern;Diplom;DE;Konzeption und Implementierung eines übergreifenden Rollenmanagements zwischen SAP Web Application Server und SAP Enterprise Portal auf Basis von Web Dynpro, bei der Siemens AG;
27.06.05;30.09.05;2005;intern;Diplom;DE;Analysierung und Bewertung verschiedener Bezahlungsmöglichkeiten aus dem Bereich Micropayment auf ihre Integrationsfähigkeit in eine bestehende Onlinepräsenz<br>;
28.06.05;25.11.05;2005;extern;Diplom;DE;Konzipierung und Implementierung einer Störmeldeverwaltung mit integrierter Bauteilverfolgung bei Siemens TS IS<br>;
29.06.05;;2005;extern;Diplom;DE;Implementierung eines Softwaretools für die Analyse von Digital Cinema Packages;
01.07.05;09.01.06;2005;extern;Diplom;DE;"Anforderungen, Konzept und Realisierung eines Installations- und Änderungsproezesses für das weltweite CAD-Datenmanagementsystem ""Teamcenter""<br>";
07.07.05;30.09.05;2005;extern;Bachelor;DE;Effizienter Einsatz von Capture-Replay-Werkzeugen im Rahmen werkzeuggestützter Softwaretests zur Unterstützung der Qualitätsprüfung<br>;
13.07.05;13.12.05;2005;extern;Diplom;DE;Automatische Analyse von Web-Seiten;
14.07.05;13.12.05;2005;extern;Diplom;DE;Workflow-unterstütztes Prozessmanagement von der Analyse bis zur Implementierung ausgewählter Prozesse am Beispiel der Produktentwicklung für die Automobilindustrie<br>;
15.07.05;;2005;intern;Diplom;DE;Untersuchung der Unabhängigkeit der Anforderungsanalyse von Lösungsmethoden anhand ausgewählter Modellierungsverfahren<br>;
20.07.05;09.01.06;2005;intern;Diplom;DE;Modellierung eines Internetportals zur Erleichterung von Vorgängen im Außenhandel;
26.07.05;09.01.06;2005;extern;Diplom;DE;Konzeption eines Benchmarketingverfahrens für die IT-Abteilungen eines großen Halbleiterherstellers<br>;
27.07.05;23.12.05;2005;extern;Diplom;DE;Konzeption und Realisierung von intelligenten Such-Agenten für rollenbasierte Informationsverwaltung<br>;
29.07.05;09.01.06;2005;extern;Diplom;DE;Analyse sowie Implementierung von Konfigurationen am Beispiel eines Industriebetriebs der Automatisierungsbranche<br>;
03.08.05;01.12.05;2005;intern;Diplom;DE;Untersuchung und Entwicklung von Lösungsansätzen zur Steigerung der Ausdrucksfähigkeit für Wiki-artigen Wissensrepräsentationssystemen<br>;
01.09.05;25.11.05;2005;intern;Bachelor;DE;Grundbegriffe des Data Mining aufbereitet für eine Datenbank-Vorlesung<br>;
01.09.05;01.12.05;2005;extern;Bachelor;DE;"Weiterentwicklung der Machbarkeitsstudie ""MVB-Druckvorschau"" zur Produktionsreife<br>";
01.10.05;03.03.06;2006;extern;Master;DE;Anbindung SAP CRM an das Web-basierte Sales Information System für Opportunities;
01.10.05;24.02.06;2006;extern;Diplom;DE;Entwicklung eines OS-Abstraction-Layers für ein embedded HMI-Framework<br>;
04.10.05;03.03.06;2006;extern;Diplom;DE;Software-Architektur zur Steuerung eines universellen Radio-Tuners - Implementierung am Beispiel eines FM-Tuners mit RDS;
04.10.05;10.05.06;2006;extern;Diplom;EN;Acquisition as well as comparision of the IT architecture and definition of initial IT architecture management processes within Brand Group Financial Services;
04.10.05;24.02.06;2006;extern;Diplom;DE;Definition und Realisierung einer Komponente zur Visualisierung von Ablaufketten (GRAPH)<br>;
07.10.05;;2006;extern;Bachelor;DE;Entwurf und Implementierung eines juristischen Webportals mit administrativen und internen Bereich<br>;
07.10.05;22.12.05;2006;extern;Bachelor;DE;Entwurf und Implementierung eines juristischen Webportals mit administrativen und internen Bereich;
13.10.05;10.03.06;2006;extern;Diplom;DE;Umsetzen einer Softwarelösung zur Ablaufunterstützung und Visualisierung einer portfoliobasierten Bewertungssystematik<br>;
14.10.05;13.03.06;2006;extern;Diplom;DE;Automatisierte Strukturelle Erfassung von Online-Angeboten;
15.10.05;14.03.06;2006;intern;Diplom;DE;Automatisierte Roboterprogrammierung für 3D-Vektorgrafiken;
15.10.05;14.03.06;2006;extern;Diplom;DE;Szenarien zur Wirtschaftsplanung mit SAP R/3 bei der Robert Bosch GmbH;
19.10.05;;2006;intern;Diplom;DE;Erarbeiten und implementieren einer Konfigurationsumgebung für industrielle Bediengeräte unter Verwendung eines embedded Web Servers<br>;
21.10.05;13.03.06;2006;extern;Diplom;DE;Konzeption und Implementierung eines Client-Server-Systems zur Realisierung verteilter Testautomatisierung;
26.10.05;09.06.06;2006;extern;Diplom;DE;Analyse und Optimierung des Geschäftskundenvertriebs eines Telekommunikationsunternehmens;
28.10.05;11.05.06;2006;extern;Diplom;DE;Untersuchung des Geschäftsbereichs Services auf ITIL Konformität bei Faber-Castell Consulting GmbH;
31.10.05;17.03.06;2006;intern;Diplom;DE;Untersuchung und beispielhafte Implementierung der Kommunikation in heterogenen Systemen mit Bluetooth;
03.11.05;29.06.06;2006;extern;Master;DE;Konzeption und Realisierung einer webbasierten Auftragsabwicklung sowie eines Projektcontrollingtools für die strategische Unternehmenführung bei einem internationalen Automobilzulieferer<br>;
03.11.05;13.06.06;2006;intern;Diplom;DE;Multidimensionale handschriftliche Textannotierung auf PPCs;
04.11.05;03.02.06;2006;extern;Bachelor;DE;Konzept zur Realisierung einer verbrauchsabhängigen Verrechnung von Hardware-Ressourcen mit Hilfe der Zonen und des Ressource-Managements von Solaris 10 am Beispiel aTRACKtive Compute- Server<br>;
07.11.05;13.04.06;2006;extern;Diplom;DE;Entwicklung eines DRM geschützten PlugIns für MediaPlayer;
07.11.05;31.03.06;2006;extern;Diplom;DE;Entwicklung und Implementierung eines Konzepts für sicheres Speichern von DRM-Objekten;
11.11.05;13.07.06;2006;extern;Diplom;DE;Konzeption einer Ähnlich- und Gleichteilsuche zur Unterstützung der 3D CAD-Konstruktion bei Siemens A&D LD in Nürnberg;
11.11.05;10.04.06;2006;extern;Diplom;DE;Einsatzmöglichkeiten der Wiki-Technologie im kommerziellen Umfeld - Abgrenzung, Integration und Perspektive;
15.11.05;13.04.06;2006;extern;Diplom;DE;Entwicklung einer Komponente zur Performancesteigerung von PostgreSQL-DBMS;
17.11.05;11.05.06;2006;extern;Master;DE;Beschreibung eines plasmatechnischen Fertigungsprozesses unter Anwendung eines neuronalen Netzwerkes;
30.11.05;27.04.06;2006;extern;Diplom;DE;Sicherheitsbetrachtung mobiler Endgeräte, Anbindung einer DATEV Smartcard unter Windows Mobile und Erstellung eines Konzepts für darauf basierende sichere Internetkommunikation;
01.12.05;13.03.06;2006;intern;Bachelor;EN;Java-based Rule Engines and their Applicability for RDF/S and OWL Knowledge Bases;
01.12.05;02.05.06;2006;extern;Diplom;DE;Technische und ökonomisch sinnvolle Realisierbarkeit der Europäischen Signaturrichtlinie unter Verwendung des OpenPGP Standards (RFC2440)<br>;
01.12.05;02.05.06;2006;extern;Diplom;DE;Ermittlung und Überprüfung spezifischer Begriffe (Konzepte) der Programmiersprache PL/1 aus einer vorher getroffenen Auswahl an PL/1-Programmen;
02.12.05;27.02.06;2006;extern;Bachelor;DE;Entwurf und Implementierung einer Benutzerverwaltung für eine ASP.NET-Webanwendung;
02.12.05;11.05.06;2006;extern;Master;DE;Monitoring- und Reportingmaßnahmen zur Steuerung eines externen IT-Providers auf Basis von ITIL und zu einer effizienten Kommunikationspolitik für Kunden und User;
08.12.05;08.05.06;2006;extern;Diplom;DE;Konzeption und Realisierung eines Berichtsssytems über Kennzahlen aus dem Management eines Softwarelebenszyklus<br>;
12.12.05;12.05.06;2006;intern;Diplom;DE;Bestimmung von Ähnlichkeiten digitaler regionensegmentierter Bilder auf Basis gewichteter räumlicher Beziehungen und ihrer Repräsentation durch Graphen;
16.12.05;14.03.06;2006;extern;Diplom;EN;Service Lifestyle Management with ITIL;
19.12.05;10.03.06;2006;intern;Diplom;DE;Künstliche neuronale Netze mit Analyse der Thematik: Backpropagation Learning;
20.12.05;16.06.06;2006;extern;Master;DE;Evaluierung und konzeptionelle Einbindung internationaler Unternehmensinformationen zur Ausweitung der Geschäftsfelder des DATEV Informationsdienstes;
20.12.05;19.06.06;2006;extern;Diplom;DE;Weiterentwicklung des Software-Entwicklungsprozesses mit CMMI, unter Berücksichtigung der Belange des Konfigurationsmanagements;
22.12.05;30.06.06;2006;intern;Diplom;EN;Data mining and English verb morphology;
22.12.05;14.03.06;2006;extern;Diplom;DE;Entwicklung intelligenter Suchagenten zur Bereitstellung von Ergebnissen einer Intranet-Suchmaschine;
22.12.05;19.05.06;2006;intern;Diplom;DE;Erkenntnistheoretische Grundlagen des Requirements Engineering;
22.12.05;14.03.06;2006;intern;Bachelor;DE;Entwurf und Implementierung eines Programms für die effektive Erfassung handschriftlicher Informationen auf Tablet PCs;
11.01.06;13.03.06;2006;extern;Diplom;DE;Konzeption und Entwicklung eines Marketing Informationssystems am Beispiel der BMW Asia Group;
12.01.06;09.06.06;2006;intern;Diplom;DE;Zuverlässigkeitsbewertung mit Fehlerbäumen und Serien-Parallel-Diagrammen;
13.01.06;06.06.06;2006;extern;Diplom;DE;Konzeption der Schnittstellenarchitektur für die Neuentwicklung eines auf den Mittelstand ausgerichteten ERP-Systems;
13.01.06;13.06.06;2006;extern;Diplom;DE;Möglichkeiten zur wirksamen Eindämmung von Spyware für zukünftige Anwendungszwecke aus Sicht der DATEV e.G.;
01.02.06;02.05.06;2006;intern;Bachelor;DE;Implementierung und Untersuchung einer rundungsarmen Variante des Simplex-Algorithmus;
15.02.06;07.08.06;2006;extern;Diplom;EN;Methods and approaches for improvement of implementation effort estimation of software change requests;
19.02.06;04.09.06;2006;intern;Diplom;DE;XML-basierte Generierung von Benutzeroberflächen mit J2ME;
21.02.06;28.09.06;2006;extern;Diplom;DE;Bewertung von Intrusion Detection Methoden im DataCenter im Hinblick auf Erkennung und Auswirkung von Angriffsmustern;
23.02.06;10.08.06;2006;extern;Diplom;DE;Auswertungen Online, umstellen der Applet-basierten Anwendung auf DHTML;
01.03.06;28.09.06;2006;intern;Diplom;EN;Analysis and evaluation of SAP workflow integration in a multi company system environment with focus on the Electronic Data Interchange processes.;
10.03.06;10.08.06;2006;extern;Diplom;DE;Eingabe von Zählerlisten in InterWatt mit Hilfe von Mobile Devices (PDA);
10.03.06;08.08.06;2006;intern;Diplom;DE;Entwicklung eines Systems zur telemedizinischen Überwachung von kardialen Risikopatienten unter Verwendung drahtloser Sensorik;
17.03.06;04.09.06;2006;extern;Diplom;DE;Echtzeit High Dynamic Range Rendering;
20.03.06;18.08.06;2006;extern;Diplom;DE;Hough-Transformation zu Analyse von Volumen-CT-Daten eines glasfaserverstärkten Kunststoffes;
20.03.06;29.08.06;2006;extern;Diplom;DE;Entwicklung und Validierung eines Proptotypen zur dreidimensionalen Planung von Hüftenprothesen in 2D-Röntgenbildern mit Hilfe von statistischen Knochenmodellen;
22.03.06;15.08.06;2006;extern;Diplom;DE;Analyse und Evaluierung der Rechenleistung des Cell-Prozessors;
27.03.06;18.09.06;2006;extern;Master;DE;Erstellung eines MIS (Management Information System) für IT Kosten Reproting auf Basis eines bei Siemens Medical Solutions eingesetzten Berichtswesens;
28.03.06;21.08.06;2006;extern;Diplom;DE;Ermittlung, Evaluation und Umsetzung von Methoden des Software Engineering zur Performance Analyse am Beispiel einer Oracle-ADF-basierten Anwendung;
30.03.06;29.08.06;2006;intern;Diplom;DE;Konzeption einer Online-Notenauskunft für bayerische Schulen;
30.03.06;01.08.06;2006;extern;Master;DE;Entwurf und prototypische Umsetzung eines Rollenkonzepts für ein Einführungsprojekt zum SAP Enterprise Portal bei einem internationalen Fahrzeugzulieferer;
01.04.06;19.12.06;2006;extern;Diplom;DE;Generierung kundenspezifischer Installationspakete auf Basis einer CMS-basierten Verwaltung von SW-Komponenten und Projektdokumentation;
01.04.06;23.10.06;2006;extern;Diplom;DE;Konzeption und Realisierung eines Frontends zur Steuerung von Vergleichsabläufen in Datenbeständen;
01.04.06;26.09.06;2006;intern;Master;DE;Untersuchung von emergenten Verhalten in einer chemisch evolutionären Umwelt;
03.04.06;04.09.06;2006;extern;Bachelor;DE;Automatische Schnittstellengenerierung aus UML-Modellen im Anwendungsbereich von Prozess-Leitsystemen;
03.04.06;13.10.06;2006;extern;Diplom;DE;Realisierung eines sicheren Sitzungskonzepts für Automatisierungskomponenten auf Basis eines embedded Webservers;
04.04.06;13.10.06;2006;extern;Diplom;DE;Erstellen einer Benutzerverwaltung für ein Software Versionsmanagement-Tool mit Anbindung an Serena ChangeMan Version Manager;
05.04.06;31.08.06;2006;extern;Diplom;EN;Route optimization for multihop radio transmission systems;
05.04.06;28.09.06;2006;extern;Diplom;DE;Konzeption und Implementierung eines graphischen Authoringtools für Digital Cinema Packages;
07.04.06;08.01.07;2006;extern;Diplom;DE;Weiterentwicklung des System- und Netzwerkmonitoring der Dienstleistung DATEVasp.;
07.04.06;05.09.06;2006;intern;Diplom;DE;Konzeption eines Fragebogenkatalogs zur Bedarfsermittlung für ein Wissensmanagement-System mit der Möglichkeit zur unternehmensspezifischen Anpassung;
07.04.06;30.10.06;2006;intern;Diplom;DE;"Konzeption und Entwicklung eines Prototypen für eine ""EDU-Anwendung"" im Fachbereich ""Mathematik 1.-4. Klasse"" mit dem Schwerpunkt ""Stifteingabe""";
10.04.06;06.10.06;2006;extern;Master;DE;Marktanalyse dynamischer Infrastrukturlösungen und Lösungsmöglichkeiten basierend auf Standard-Software;
11.04.06;11.01.07;2006;extern;Diplom;DE;Konzeption und Implementierung eines SQL-Servers für das rationale DBMS tdbengine;
11.04.06;09.01.07;2006;intern;Diplom;DE;Integration von Projektmanagement- und Workflowkomponenten in SPIM, einem Personal Information Manager;
11.04.06;29.09.06;2006;intern;Diplom;DE;IT-Outsourcing - Möglichkeiten, Vorgehensweisen und Grenzen der Fremdvergabe von IT-Leistungen;
11.04.06;22.09.06;2006;extern;Diplom;DE;Augmented Reality - gestützte Verifikation des digitalen Anlagenmodels mit der realen Produktionsanlage;
12.04.06;10.11.06;2006;extern;Diplom;DE;Nutzerfreundlicher Informationszugang durch natürlichsprachige Suchanfragen im Internetportal der Stadt Nürnberg;
12.04.06;24.11.06;2006;extern;Diplom;DE;Inhaltsbezogene Archivierung in Datenbanken;
12.04.06;04.12.06;2006;extern;Diplom;DE;Realisierung eines Benchmarks zur Performancebeurteilung von Prozessorplattformen in der Bahnautomatisierung;
13.04.06;30.11.06;2006;extern;Diplom;DE;Implementierung von Kryptosystemen auf elliptischen Kurven am Beispiel von ECDSA;
27.04.06;29.09.06;2006;extern;Diplom;DE;Konzept zur Einführung eines CRM-Systems in mittelständischen Unternehmen am Beispiel des Produkts Microsoft Dynamics CRM;
28.04.06;28.09.06;2006;intern;Diplom;DE;Entwurf und Entwicklung eines Daytrading-Agents für den deutschen Aktienmarkt;
28.04.06;28.09.06;2006;intern;Master;DE;Konzeption einer Skriptsprache zur Steuerung von Online Befragungen;
02.05.06;30.10.06;2006;intern;Master;EN;Trust and non-traceability in mobile ad-hoc networks;
02.05.06;28.09.06;2006;extern;Diplom;DE;Konzeption und Entwicklung einer Wahllistenverwaltung für BR- und Aufsichtsratswahlen der GfK AG unter besonderen Berücksichtung des Datenschutzes und der Manipulationssicherheit;
04.05.06;02.10.06;2006;extern;Diplom;DE;Analyse und Konzeption einer Projektplanung im Werkzeugbau;
08.05.06;22.09.06;2006;intern;Diplom;DE;Die Geschichte des Parallelrechnens;
12.05.06;05.10.06;2006;extern;Diplom;DE;Flexible Informationsstrukturen auf Basis eines Modells zur Wissenspräsentation am Beispiel einer Ansprechpartnerapplikation;
15.05.06;31.08.06;2006;intern;Diplom;DE;Standardisierungsansätze im IT-Management zur Sicherstellung der Wirtschaftlichkeit in IT-Organisationen;
18.05.06;;2006;intern;Diplom;DE;Theorie der Software-Zuverlässigkeit mit einer praktischen Umsetzung in Maple und Scilab;
23.05.06;23.08.06;2006;extern;Bachelor;DE;Management von hochverfügbaren Diensten am Beispiel einer virtualisierten JAVA/Linux-Appliance;
29.05.06;04.09.06;2006;intern;Diplom;DE;"E-Learning und damit verbundene didaktische Fragestellungen - Erstellung einer Lernsoftware zum Buch ""Stry/Schwenkert: Mathematik Kompakt""";
01.06.06;01.09.06;2006;extern;Bachelor;DE;Konzeption und Implementierung einer datenbankgestützten Webapplikation für das strategische Lieferantenmanagement bei einem internationalen Automobilzulieferer;
01.06.06;30.10.06;2006;extern;Diplom;DE;Untersuchung und Optimierung von Workflow-Prozessen im Umfeld von Steuern- und Rechtsdatenbanken der DATEV e.G.;
01.06.06;28.11.06;2006;extern;Master;DE;Algorithmen zur Bestimmung von Objekteigenschaften in konfigurierbarer Hardware;
08.06.06;08.11.06;2006;extern;Diplom;DE;IT-Management - Erarbeitung und Bewertung von Handlungsalternativen für den Einsatz von Lösungen zur Hardware-Virtualisierung auf Basis einer Anforderungsanalyse;
12.06.06;29.09.06;2006;intern;Diplom;DE;Entwicklung eines Anforderungskataloges und Best Practice für den Einsatz eines Dokumenten-Management-Systems (DMS) für in der öffentlichen Verwaltung an Hand der für Deutschland wichtigen Standardisierungen<br>;
19.06.06;16.02.07;2006;extern;Diplom;DE;Ein Eclipse-basiertes Framework zum Verwalten und Testen von Algorithmen zur Umrechnung von Fahrzeugdiagnoseinformationen;
20.06.06;12.12.06;2006;extern;Master;DE;Implementierung, Vergleich und Bewertung von Zero-Knowledge-Authentifikationsprotokollen in tief eingebetteten Systemen;
21.06.06;21.03.07;2006;intern;Diplom;DE;Konzeption eines Kundenwertmanagements;
21.06.06;;2006;extern;Diplom;DE;Analyse des Softwareentwicklungsprozesses eines mittelständischen ERP-System-Herstellers;
21.06.06;27.11.06;2006;intern;Diplom;DE;Entwicklung eines Geschäftskonzeptes für einen Online-Dichtertreff;
24.06.06;08.01.07;2006;extern;Diplom;DE;Konzeption und Realisierung eines datenbankgestützten Internetauftritts für eine mittelständische Ingenieurgesellschaft unter Verwendung von Open Source Software;
30.06.06;02.10.06;2006;extern;Bachelor;DE;Entwicklung von CAN-Bus-Treibern für Windows und Linux;
03.07.06;02.10.06;2006;intern;Bachelor;EN;Problems Encountered Offshoring IT Services - Why are many IT firms coming back?;
06.07.06;;2006;intern;Diplom;DE;Marktübersicht und Klassifikation aktueller Linux-Distributionen mit Analyse der Einsatzmöglichkeiten;
12.07.06;12.12.06;2006;intern;Diplom;DE;Design einer Grid-Computing-Software sowie Realisierung von Kernfunktionalitäten für eine Linux-Umgebung;
21.08.06;22.01.07;2006;extern;Diplom;EN;Enterprise Application Integration with SAP Exchange Infrastructure 3.0;
12.09.06;12.02.07;2006;extern;Diplom;DE;Entwicklung eines BestPractice-Konzepts zur Einführung und Umsetzung von ITIL im Geschäftsfeld IT-Management der DATEV;
13.09.06;02.03.07;2006;extern;Diplom;DE;Konzeption und Umsetzung eines betriebswirtschaftlichen Kennzahlensystems auf der ERP-Basis Microsoft Dynamics NAV unter Verwendung des SQL-Servers;
14.09.06;14.02.07;2006;extern;Diplom;DE;Schutz von IT-Systemen beim Einsatz mobiler Geräte innerhalb von Unternehmensnetzwerken mit bestehender Client-Security-Software;
15.09.06;13.03.07;2006;extern;Master;DE;Aktuelle Methoden zur Messung des Wertbeitrages der Informatik im Unternehmen und Konzept für eine firmenspezifische Lösung;
29.09.06;01.06.07;2006;extern;Diplom;DE;Softwarezuverlässigkeitsmodelle und deren Einsatz bei der Erstellung von Fehlerprognosen;
01.10.06;27.02.07;2007;extern;Diplom;DE;Implementierung/Evaluierung von Web 2.0 Technologien für einen medizinischen Befundungsarbeitsplatz;
01.10.06;13.03.07;2007;extern;Diplom;DE;Konzeption und Implementierung von Verbindungsaufbaumethoden und Routingalgorithmen für Fahrzeug-zu-Fahrzeug-Netzwerke;
02.10.06;02.03.07;2007;extern;Diplom;DE;Evaluierung und Optimierung eines Ultra-Low-Delay Audiokomprimierungsverfahrens für ARM basierte Prozessarchitekturen;
05.10.06;28.03.07;2007;extern;Diplom;EN;Design and Implementation of an efficient method for the transmission of IEC61850 protocol data via REMPLI Powerline Communication<br>;
05.10.06;12.03.07;2007;extern;Diplom;DE;Anforderungsanalyse, Spezifikation und Umsetzung des ITIL Release-Management-Prozesses auf Basis OMNITRACKER;
11.10.06;11.07.07;2007;extern;Diplom;DE;Konzeption und Implementierung einer datenbankgestützten .NET 2.0 Client-Serveranwendung als Grundlage für die Eröffnung eines Gastronomiebetriebes;
16.10.06;29.05.07;2007;intern;Diplom;DE;Design eines modularen Kommunikationsframeworks und Integration von Bildverarbeitungskomponenten für eine mobile Roboterplattform;
16.10.06;03.07.07;2007;extern;Diplom;DE;Vergleich zweier Verfahren zur Steuerung eines Pick&Place Roboters zum Greifen mittels eines Vision Systems beobachteter, bewegter Roboter;
16.10.06;14.02.07;2007;extern;Diplom;DE;Leistungsfähigkeit und Weiterentwicklung des Qualitätsmanagement-Systems der IT der BMW Group;
16.10.06;16.04.07;2007;intern;Master;DE;Optimierung eines Verfahrens zur 3D-Rekonstruktion mit Hilfe von statistischen Modellen;
17.10.06;17.04.07;2007;intern;Diplom;DE;Indoor-Routenplanung für autonome mobile Roboter in teildynamischen Umgebungen;
17.10.06;14.03.07;2007;extern;Diplom;DE;Konzeption und Teilrealisierung eines Softwaresystems zur Energieoptimierung in der Gebäudeteiltechnik;
18.10.06;18.04.07;2007;extern;Diplom;DE;Konzeption und Implementierung einer modularen Routenplanung für autonome Systeme auf Basis eines hierarchischen Umgebungsmodells;
19.10.06;04.04.07;2007;extern;Master;DE;Aktuelle Formen und Trends im Bereich des Lieferantenmanagements und die Möglichkeit der IT-Unterstützung;
23.10.06;23.03.07;2007;extern;Diplom;DE;"Analyse und Optimierung des Softwareentwicklungslebenszyklus zur unternehmensspezifischen Integration in den ""Visusal Studio 2005 Team Foundation Server"" von Microsoft";
25.10.06;01.08.07;2007;extern;Diplom;EN;Design and Implementation of an Integration between Navigation and Microsoft Project Server for Medium-sized Enterprises;
30.10.06;24.04.07;2007;extern;Diplom;DE;Implementierung der MPEG-4 Avcl H.264 Codierung auf Multiprozessorplattformen;
30.10.06;31.05.07;2007;extern;Diplom;DE;Adaptives Transcoding von JPEG2000-codierten Bildern für RTP-Streaming;
01.11.06;09.05.07;2007;extern;Diplom;DE;Optimierung der Geldbestände für Sparkassen-Filialen und Geldautomaten aufgrund der Vorhersage von Software iCom;
02.11.06;13.03.07;2007;extern;Master;DE;Ein Konzept zur Integration der Windows Workflow Foundation mit dem ERP-System Microsoft Dynamics NAv und seine prototypische Implementierung;
03.11.06;13.03.07;2007;extern;Diplom;DE;Analyse des gesamten IT-Entwicklungsprozesses und Erarbeitung eines Optimierungskonzeptes hierfür hinsichtlich Termin- und Ressourcenplanung für IT-Projekte durch den Einsatz einer durchgängigen Softwarelösung im Projektmanagement<br>;
09.11.06;13.03.07;2007;intern;Diplom;DE;Stochastische Simulation komplexer Systeme in der Theorie mit einer Implementierung in Maple;
10.11.06;;2007;extern;Diplom;DE;Konzeption, Realisierung und Bewertung von Erweiterungen einer Webapplikation für mobile Endgeräte;
15.11.06;16.07.07;2007;intern;Diplom;DE;Inter-Prozess/Inter-OS Kommunikation auf virtuellen Betriebssystemen;
15.11.06;13.03.07;2007;extern;Diplom;DE;Gegenüberstellung des FRU-Prozesses IRS3 und IRSmx1;
21.11.06;09.03.07;2007;extern;Master;DE;Aufbau enes Vertriebscontrollings mit Hilfe von Business-Intelligence Werkzeugen auf Basis von Microsoft CRM;
22.11.06;23.04.07;2007;extern;Diplom;DE;Konzeption eines multidimensionalen Datenmodells für Analysen in einem Date Warehouse;
23.11.06;14.03.07;2007;extern;Diplom;DE;Konzeption der TriBiRe Light, eine Warenwirtschaft für den Fahrradeinzelhandel;
29.11.06;29.05.07;2007;extern;Master;DE;Konzeption und prototypische Implementierung von systemübergreifendem Geschäftsprozessmanagement mit SAP Netweaver XI am Beispiel eines Änderungsprozesses;
30.11.06;30.04.07;2007;extern;Diplom;DE;Softwaregestützte Automatisierung von Geschäftsprozessen am Beispiel eines mittelständischen Unternehmens;
01.12.06;27.04.07;2007;intern;Diplom;DE;Vergleich von Virtualisierungssystemen mit praktischer Untersuchung der Eignung für den Betrieb von Solaris-Gastsystemen;
01.12.06;09.03.07;2007;extern;Diplom;DE;Das Integrationspotenzial drahtloser Sensornetzwerke mit RFID-Middleware: Untersuchung der Realisierbarkeit logistischer Szenarien anhand eines Prototyps;
06.12.06;14.03.07;2007;extern;Diplom;DE;Entwicklung eines Prototypen zur Archivierung für das SAP Business Information Business Warehouse des Siemens AG Bereichs Automation and Drives;
08.12.06;08.05.07;2007;extern;Diplom;DE;Entwurf und Implementierung eines Tagging Systems für den obenSUSE Build Service;
08.12.06;07.05.07;2007;extern;Diplom;DE;Barrierefreie und thesaurusbasierte Suchfunktion für das Webportal der Stadt Nürnberg;
08.12.06;06.03.07;2007;intern;Master;EN;A double helix view on the role of cyclic knowledge gain in information systems anti-aging - Part I: Information systems modification as process of permanent cyclic knowledge gain;
08.12.06;06.03.07;2007;intern;Master;EN;A double helix view on the role of cyclic knowledge gain in information systems anti-aging - Part II: Information systems aging counteracted by a permanent multi-perspective knowledge-gaining-process<br>;
15.12.06;13.03.07;2007;extern;Diplom;DE;Electronic Customer Relationship Management bei MINI Deutschland - Erfolgsfaktoren zur Kundeneroberung im Internet<br>;
18.12.06;14.03.07;2007;extern;Master;EN;Customized implementation of Microsoft SharePoints Services - A solution for global collaboration in a transnational company<br>;
22.12.06;14.03.07;2007;extern;Diplom;DE;Konzeption des weltweiten Einsatzes einer Prüffeldsoftware bei Siemens A&D LD<br>;
22.12.06;30.04.07;2007;intern;Diplom;DE;Domänenspezifische Sprache zur Spezifikation von Zugriffsrechten;
02.01.07;31.05.07;2007;extern;Diplom;DE;Tabellenbasiertes Serialisieren/Deserialisieren von OPC UA Objekten in Embedded Systemen;
04.01.07;25.09.07;2007;intern;Diplom;DE;Software Reliability Engineering - Methoden und deren Anwendung<br>;
08.01.07;14.03.07;2007;extern;Master;DE;Erstellung eines RZ-Controlling-Konzepts für das RZ Nord im Rahmen der IuK-Landesstrategie;
10.01.07;28.09.07;2007;extern;Diplom;DE;Entwicklung eines Parsers und Texteditors für SRGS Gramatiken;
14.01.07;14.03.07;2007;intern;Master;DE;Untersuchung der Problematik von Differenz- und Impact-Analysen in UML-Modellen;
01.02.07;30.07.07;2007;extern;Diplom;DE;Komponentenorientierte Entwicklung graphischer Benutzeroberflächen auf Basis der Eclipse Rich Client Platform (RCP);
05.02.07;16.07.07;2007;extern;Diplom;DE;Prozessanalyse und -optimierung bei der Planung der Prozess- und Informationsmanagement-Aktivitäten am Beispiel von Siemens A&D;
07.02.07;14.05.07;2007;extern;Master;DE;Digitale Wahlen über öffentliche Netze - Untersuchung ausgewählter theoretischer Verfahren und Vorstellung einer praktischen Umsetzung;
08.02.07;01.10.07;2007;extern;Diplom;DE;Linux-basierte Systems Management-Umgebungen zur Installation und Konfiguration von Linux-Betriebssystemen auf Basis des Common Model (CIM);
19.02.07;19.11.08;2007;extern;Diplom;DE;Konzeption und Implementierung einer SAP Web Dynpro Anwendung für das Investitionscontrolling bei Siemens Industry DT LD;
21.02.07;28.09.07;2007;extern;Diplom;DE;Analyse und Optimierung des PLM Prozesses von A&D SD mit den Schwerpunkten Prozessvisualisierung und Toolanbindung<br>;
27.02.07;24.07.07;2007;extern;Diplom;DE;Konzeption und Implementierung eines Messwerkzeuges zur Bewertung der Standardnähe von SAP-Systemen in der BMW-Group;
01.03.07;27.09.07;2007;intern;Diplom;EN;Analysis and implementation of an interface between Motion Capture and Rendering Systems;
02.03.07;02.08.07;2007;extern;Diplom;DE;Entwicklung und Implementierung eines CAN-Treibers für Embedded-Linux auf Basis eines 8- bzw. 32-Bit-RISC-Prozessor;
07.03.07;01.10.07;2007;extern;Diplom;DE;Erfahrungsbasierte Verfeinerung von Umgebungskarten für die Fußgängernavigation;
15.03.07;28.09.07;2007;extern;Diplom;DE;C++-Programmiertechniken für High Performance Computing auf Systemen mit nichteinheitlichem Speicherzugriff unter Verwendung von OpenMP<br>;
16.03.07;20.09.07;2007;extern;Diplom;DE;Evaluierung des SAP Solution Managers als Service Desk und Change Request Tool für die SAP- und Non-SAP-Systeme des Siemens Bereichs I&S;
19.03.07;20.08.07;2007;intern;Diplom;DE;Webbasierte Umsetzung eines Werkzeugs zur Visualisierung und Bearbeitung von Geodaten;
19.03.07;13.07.07;2007;intern;Diplom;DE;Koordinierter Server für Lernsoftware;
20.03.07;20.08.07;2007;extern;Bachelor;DE;Gefährdungen von Webservices und Implementierung von Gegenmaßnahmen;
20.03.07;28.08.07;2007;extern;Master;DE;Zwei-Faktor-Authentifizierung für Maschinensteuerungen;
22.03.07;26.09.07;2007;extern;Diplom;DE;Analyse von verteilten Dateisystemen und Design eines Offline-Dateisystems;
27.03.07;02.08.07;2007;extern;Master;EN;XML Schema based generation of graphical user interfaces with a Qt-based prototype;
28.03.07;25.09.07;2007;extern;Master;DE;SAML-kompatibles Singl-Sign-On-Konzept für Automatisierungsprotokolle;
30.03.07;07.01.08;2007;extern;Diplom;DE;Konzeption und Implementierung eines Prototypen zur Realisierung eines Workflow-Systems im Bereich der Logistikautomatisierung auf Basis der Java Enterprise Edition;
01.04.07;24.09.07;2007;extern;Master;DE;Methoden und Elemente der multidimensionalen Modellierung für Business Intelligence Systeme und deren prototypische Umsetzung in einem Modellierungswerkzeug;
01.04.07;24.09.07;2007;extern;Diplom;EN;Order Process Management with mobile Devices;
01.04.07;28.09.07;2007;extern;Diplom;DE;Modellierung der Produktions-Prozesse in der Leiterplattenbestückung I&S EDM und Effizienzanalyse der gewählten Darstellungen;
04.04.07;07.01.08;2007;extern;Diplom;DE;Plattformunabhängige Konfiguration eines embedded Telekommunikationssystems über ein Web-Interface;
10.04.07;26.06.07;2007;intern;Diplom;DE;Rückläufige Register zur kroatischen Verbalmorphologie - Aufbereitung mit Datenanalyseverfahren der Informatik (Data Mining);
11.04.07;10.09.07;2007;extern;Bachelor;EN;An Eclipse based tool for the visualization of AUTOSAR data structures;
11.04.07;20.12.07;2007;extern;Diplom;DE;Konzeption und Implementierung von Tracing-Mechanismen in einem AUTOSAR-konformen Echtzeitbetriebssystem sowie der Visualisierungs-Möglichkeiten auf einem PC<br>;
12.04.07;11.01.08;2007;intern;Diplom;DE;Konzeption und Entwicklung eines Simulators für Positionsbestimmungssysteme;
12.04.07;20.11.07;2007;intern;Diplom;DE;Konzeption und Implementierung eines Moduls zum Entwurf der Formular-/Workflowlogik im Rahmen einer Tablet-PC-basierenden Anwendung zu Formularverwaltung;
12.04.07;28.09.07;2007;intern;Diplom;DE;Konzeption und Implementierung eines Moduls zur Verwaltung von Kundendaten und abgeschlossenen Formularen im Rahmen einer Tablet-PC-basierenden Anwendung zur Formularverwaltung;
12.04.07;20.11.07;2007;intern;Diplom;DE;Konzeption und Implementierung eines Workflowmanagementmoduls mit integrierter Notizfunktion im Rahmen einer Tablet-PC-basierenden Anwendung zur Formularverwaltung;
12.04.07;26.09.07;2007;extern;Diplom;EN;Comparing SAP XI, Microsoft BizTalk, Web Service and Remote Function Call as Interface Techniques between Microsoft.NET and SAP NetWeaver<br>;
13.04.07;13.01.08;2007;extern;Diplom;DE;Robuste 2D-Objektverfolgung in Verkehrsszenen zur effizeinten Gewinnung von Ground-Truth-Daten für die Bewertung von Fahrerassistenzapplikationen;
13.04.07;28.09.07;2007;intern;Diplom;DE;Ein Maple-Paket zur Nullstellenbestimmung bei Polynomen;
13.04.07;27.09.07;2007;intern;Diplom;DE;Selbstlernende Dokumentanalyse mit Hilfe von Softcomputing-Methoden;
13.04.07;19.10.07;2007;intern;Diplom;DE;Ermittlung der Verbesserungen bei der automatischen optischen Inspektion (AOI) von Leiterplatten durch Einsatz der Farbbildverarbeitung;
15.04.07;01.10.07;2007;intern;Diplom;DE;Entwicklung und Vertifikation von Verfahren zur Mischung von MPEG AAC Bitströmen;
16.04.07;17.09.07;2007;extern;Diplom;DE;Virtuelle SPS in einem eingebetteten System;
20.04.07;01.10.07;2007;extern;Master;DE;Erhöhung der technischen Schnittstellenstabilität durch kontrollierte Evolution von Schnittstellen und Transferobjekten;
24.04.07;24.10.07;2007;intern;Diplom;DE;Geschäftsprozesse als Verhaltensmodelle - Notationen und Verwendungsmöglichkeiten;
27.04.07;25.09.07;2007;intern;Diplom;DE;Erklärte Sicherheitsprofile (ESPE) - Entwicklung einer manipulationssicheren Architektur zur benutzerfreundlichen Beschreibung feingranularer Rechtemengen;
30.04.07;28.09.07;2007;extern;Diplom;DE;Aufbereitung und Verteilung von Anlagen- und Maschinendokumentation für das Internet;
30.04.07;01.10.07;2007;extern;Diplom;DE;Konzeption und Implementierung eines System Tray Clients für die Location Based Service Plattform sleeq;
30.04.07;;2007;intern;Diplom;DE;Implementierung eines Zugriffskontrollmechanismus für Webanwendungen im Spring-Framework mit AOP;
01.05.07;13.09.07;2007;extern;Diplom;DE;Konzeption und Realisierung einer zentralen Logging- und Monitoringkomponente für die verteilte J2EE Architektur einer Direktbank;
02.05.07;04.10.07;2007;extern;Diplom;DE;Weiterentwicklung einer Datenbank für das Projektmanagement bei der manu dextra GmbH und Durchführung einer Machbarkeitsstudie zur Vermarktung;
02.05.07;01.10.07;2007;extern;Diplom;DE;Konzipierung und prototypische Implementierung eines Systems zur Verwaltung, Dokumentation und Kostenüberwachung von Bauvorhaben im Niedrigenergiehausbau;
03.05.07;28.09.07;2007;extern;Diplom;DE;Portierung einer beschreibenden Datenstruktur zur Decodierung von abstrakten Datenbankinhalten sowie Planung und Implementierung der dazugehörigen Services;
07.05.07;13.11.07;2007;extern;Diplom;DE;Entwicklung einer videobasierten Prüfung von Fahrerassistenzsystemen;
07.05.07;06.08.07;2007;intern;Bachelor;DE;Analyse von handschriftlichen Notizen und deren Organisation mit Hilfe eines semantischen Netzes;
16.05.07;16.10.07;2007;extern;Diplom;DE;Automatisierte Outdoor-Datenerfassung und Auswertung für Lokalisierung mittels WLAN-Fingerprint;
24.05.07;27.09.07;2007;extern;Diplom;DE;Konzeption und Realisierung eines Analysesystems auf Basis der OLAP-Technologie zur Auswertung von Nutzungsdaten eines Content Management Systems<br>;
30.05.07;28.09.07;2007;extern;Diplom;DE;Synchronisation von Geschätsprozessmanagement und IT am Beispiel von SAP Solution Manager, ARIS for Net Weaver und RBE Plus bei der Siemens AG<br>;
01.06.07;30.11.07;2007;extern;Master;DE;Optimierung eines bildbasierten Head-Tracking-Systems für virtuell-räumliche Audio-Wiedergabe über Kopfhörer<br>;
01.06.07;02.11.07;2007;extern;Diplom;DE;Individual-Softwareentwicklung zur Organisation, Durchführung und Abrechnung von Kunden-Promotion unter Microsoft.NET 2.0<br>;
05.06.07;30.11.07;2007;extern;Master;DE;Anwenden des A&O-Sicherheitskonzeptes auf Steuerungen und Endgeräte<br>;
05.06.07;01.10.07;2007;extern;Diplom;DE;Evaluierung und wirtschaftliche Analyse von Werkzeugen zum Release-Wechsel von SAP-Systemen<br>;
11.06.07;22.02.08;2007;extern;Diplom;DE;Entwurf und Prototyp eines Remote-Service-Frameworks im Anlagenbereich<br>;
14.06.07;28.09.07;2007;extern;Master;DE;Konzeption und Implementierung einer vollautomatischen Visualisierungslösung in einem Geschäftsprozess-Framework<br>;
19.06.07;19.09.07;2007;intern;Bachelor;DE;Erarbeitung und Implementierung von Features für ein intelligentes computer-gestütztes Papier<br>;
20.06.07;;2007;extern;Diplom;DE;Entwicklung eines Fachkonzeptes zur Verknüpfung und Anzeige von Status- und Alarmmeldungen im Datenverarbeitungszentrum<br>;
20.06.07;14.12.07;2007;extern;Master;DE;Detektion von Gussbauteilfehlstellen mittels 3D-Bildverarbeitung an 3D-Computertomographie-Daten;
21.06.07;21.09.07;2007;extern;Bachelor;DE;Entwicklung eines Fachkonzeptes zur Verknüpfung und Anzeige von Status- und Alarmmeldungen im Datenverarbeitungszentrum<br>;
21.06.07;03.03.08;2007;intern;Master;DE;Produktmarketingstrategien und Technologien im Zeichen vom Web 2.0<br>;
26.06.07;27.09.07;2007;extern;Diplom;DE;Vergleichbare Untersuchung von SAP Business Warehouse und einer Inhouse-Lösung für das Data Warehouse in einem Aufgabengebiet der Bosch Group;
28.06.07;25.09.07;2007;extern;Bachelor;DE;Umstellung des browser-basierten Client-Teils einer J2EE-Applikation auf .NET und deren Integration in eine service-orientierete Architektur<br>;
09.07.07;24.09.07;2007;extern;Bachelor;EN;Enterprise Application Integration;
11.07.07;11.01.08;2007;extern;Master;DE;Verbesserung und Erweiterung des Wissensmanagement-Systems der ISO Software Systeme GmbH<br>;
16.07.07;27.09.07;2007;extern;Diplom;DE;"Konzept eines IT-Services ""Mobile PIM-Daten Synchronisation inkl. Push-Funktionalität"" im Rahmen der IT-Outsourcing Dienstleistung DATEVasp der DATEV eG<br>";
26.07.07;01.10.07;2007;extern;Diplom;DE;Konzept und prototypische Realisierung des IEC 61850 Engineering-Prozesses mit der Windows Workflow Foundation<br>;
27.07.07;01.10.07;2007;extern;Diplom;DE;Entwicklung und Umsetzung eines Konzepts zur Einführung des Office Communications Server 2007 bei Siemens AG A&D<br>;
31.07.07;07.01.08;2007;extern;Diplom;DE;"Entwicklung eines ortsbezogenen Car2Car-Dienstes ""Virtuelles Blaulicht"" für Einsatzfahrzeuge";
01.08.07;21.12.07;2007;intern;Diplom;DE;Automatisierte 3D-Roboterprogrammierung zur Beschriftung von Werkstücken<br>;
02.08.07;01.04.08;2007;intern;Diplom;DE;Untersuchung von Graph-Cut-Algorithmen zur Disparitäts- und Tiefen-Berechnung für die 3D-Rekonstruktion in Multi-Kamera-Systemen<br>;
09.08.07;30.10.07;2007;extern;Diplom;DE;Einführung einer Service-orientierten Architektur (SOA) zur Automatisierung interner Geschäftsprozesse unter Einsatz von Web-Services<br>;
15.08.07;15.04.08;2007;extern;Diplom;DE;Entwurf und Umsetzung einer Modellierungssprache zum Generieren von Testfällen im Automobilbereich<br>;
01.09.07;27.05.08;2007;extern;Diplom;DE;Definition, Entwurf und Realisierung eines webbasierten Systems zur Verwaltung und Ausleihe von Medien;
04.09.07;11.03.08;2007;extern;Diplom;DE;Entwicklung einer graphischen Benutzerführung für eine ophthalmologische Messsoftware auf einem Embedded-System<br>;
05.09.07;23.01.08;2007;intern;Diplom;DE;Softwarearchitektur von Computerspielen;
18.09.07;14.03.08;2007;extern;Master;DE;Untersuchung von Datenhaltungskonzepten für die effiziente Analyse großer Mengen von Betriebsdaten<br>;
24.09.07;25.02.08;2007;intern;Diplom;DE;XML-Formate für zukünftige ortsbezogene Dienste<br>;
01.10.07;10.03.08;2008;extern;Diplom;DE;Überwachung und Parametrierung von Antrieben mit Hilfe von integrierten Web-Services am Beispiel ausgewählter Antriebsfamilien<br>;
01.10.07;13.03.08;2008;extern;Master;EN;Conception and Realization of a Routing Functionality for Manual Warehouses;
11.10.07;11.03.08;2008;extern;Diplom;DE;Konzeption und Durchführung eines Projektes zur Verwaltung kritischer Fertigungsdaten am Beispiel der Steuergeräte Fertigung der Robert Bosch GmbH im Werk Ansbach<br>;
15.10.07;13.03.08;2008;extern;Diplom;DE;Automatische Generierung von Testabläufen für medizinische Geräte aus Use-Case-Beschreibungen;
15.10.07;11.01.08;2008;extern;Bachelor;DE;Konzeption der Zusammenführung von Applikationen zu Unternehmensstrukturen auf Basis von .NET;
15.10.07;28.03.08;2008;extern;Master;DE;Analyse zur Bestimmung geeigneter Untersuchungspartner für die atemkorrelierte Mehrschicht-Spiral-CT;
15.10.07;11.04.08;2008;extern;Master;DE;Entwurf und Entwicklung eines Simulators für das Kommunikationsverhalten von Steuergeräten in Bussystemen<br>;
19.10.07;29.04.08;2008;extern;Diplom;DE;Analyse der SAP ERP Best Practice Geschäftsprozesse für die Geschäftsprozessharmonisierung im Controlling bei der Geschäftseinheit PTD der Siemens AG;
22.10.07;21.07.08;2008;extern;Diplom;DE;Design und Realisierung eines regelbasierten Systems zu Fakturierung projekt- und kundenbezogener Kosten;
25.10.07;17.04.08;2008;extern;Diplom;DE;Ontologiebasierte Verwaltung von Informationsstrukturen - Erstellung, Integration und Pflege am Beispiel Microsoft SharePoint;
26.10.07;14.03.08;2008;extern;Diplom;DE;Erstellung eines Konzepts zum Offshare-Outtasking des Applications Monitoring der Schaeffler KG;
26.10.07;25.07.08;2008;extern;Diplom;DE;Chargenverfolgung mit SAP bei einem weltweit agierenden Automobilzulieferer: Schwachstellenanalyse und Verbesserung von Logistikkprozessen;
01.11.07;02.06.08;2008;intern;Diplom;DE;Online Assessment System für E-Commerce Portale;
01.11.07;10.06.08;2008;intern;Master;DE;Entwicklung eines Erkennungsalgorithmus für DDoS-Angriffe von Botnetzen zur Integration in das Internet-Analyse-System am Beispiel des Storm-Worm;
01.11.07;14.03.08;2008;extern;Diplom;DE;Integration eines ICA-Clients der Firma Citrix sowie Analyse, Evaluierung und Performancevergleich mit weiteren Remote-Protokollen auf Basis der ARM-Plattform;
05.11.07;30.06.08;2008;extern;Diplom;DE;Grafisch-und Skript-gesteuerte Prozessdaten-Simulation und -Auswertung zwecks Verifikation einer programmierbaren Ablaufsteuerung und der dazugehörigen Steuerungsprogramme;
06.11.07;13.06.08;2008;intern;Diplom;DE;Der Betrieb mobiler Geräte in einem selbstkonfigurirenden IPV6-Netzwerk;
06.11.07;16.04.08;2008;extern;Diplom;DE;Untersuchung aktueller Software-Ergonomie-Studien und Erstellung eines Leitfadens zur Entwicklung von zielgruppenorientierter, ergonomischer Webanwendungen;
08.11.07;30.04.08;2008;extern;Master;DE;Systemplattform für Condition-based Monitoring bei Produktionsmaschinen;
09.11.07;08.04.08;2008;extern;Diplom;EN;RFID in mobile environments as a component of Supply Chain Management;
22.11.07;13.03.08;2008;intern;Master;EN;Representation and usage of qualitative similarity in semantic search;
27.11.07;06.05.08;2008;extern;Diplom;DE;Generische Widgeterstellung zum Einbinden in verschiedene Benutzer-erweiterbare Internetplattform;
27.11.07;28.04.08;2008;extern;Diplom;DE;Konzeption und prototypische Implementierung eines workflow-basierten Personalvermittlungsprozesses für Microsoft Office Sharepoint Server und Microsoft Dynamics CRM;
30.11.07;28.04.08;2008;intern;Diplom;DE;Information Retrieval mehrdimensionaler Retrievalobjekte unter Nutzung flexibel integrierbarer Ähnlichkeitsmaße;
04.12.07;14.03.08;2008;extern;Diplom;DE;Analyse und Optimierung der Verteilung von Komponenten in PC basierten Stationsleitsystemen;
05.12.07;05.06.08;2008;extern;Master;DE;Entwicklung eines Replay-Mechanismus für eine Rule-Engine unterstützt durch ein Online-Monitoring-System;
06.12.07;14.03.08;2008;extern;Diplom;DE;Konzeption und Realisierung eines betriebswirtschaftlichen Analysesystems auf der Basis von Microsoft Dynamics AX unter Verwendung des Microsoft SQL-Servers sowie des Cubeware Importers;
17.12.07;14.05.08;2008;extern;Diplom;DE;Evaluierung des End-to-End Management und entsprechender Tools bei Siemens Medical Solutions;
19.12.07;17.06.08;2008;intern;Master;DE;Approximative Lösung des TSP-Problems durch einen erweiterten Partikel-Schwarm Algorithmus (PSO) in Matlab und Vergleich mit einer heuristischen Verarbeitungsweise;
20.12.07;20.05.08;2008;intern;Diplom;DE;Formulierung, Analyse und Überprüfung neuer Software - Zuverlässigkeitsmodelle;
02.01.08;29.09.08;2008;extern;Diplom;DE;Analyse moderner Virtualisierungstechniken und ihr Einsatz in der Medizin;
11.01.08;11.10.08;2008;intern;Master;EN;Semantic Correctness of Compiler Optimizations;
11.01.08;28.04.08;2008;extern;Diplom;DE;Entwicklung eines Konzepts zum Einsatz von Supplier Management im Bereich Outsourcing von Servicedienstleistungen und Anwendung anhand des Einführungsprozesses von DATEVasp compact;
21.01.08;03.07.08;2008;extern;Diplom;DE;Werkzeugunterstützte Optimierung der Übersetzung im Aktualisierungsprozess mehrsprachiger Anwendungen;
01.02.08;30.04.08;2008;extern;Bachelor;DE;Evaluierung der Integrationsmöglichkeiten des neuen elektronischen Handels- und Unternehmensregisters (EHUG) im Geschäftsfeld der DATEV Wissensvermittlung;
11.03.08;13.11.08;2008;intern;Diplom;DE;Konzeption und Realisierung eines Eingabeassistenten für Fehler- und Änderungsmeldungen im Konstruktionsprozess;
25.03.08;07.01.09;2008;extern;Diplom;DE;Aufbau eines PLM-Schowrooms mit Hilfe von UGS Teamcenter zur Darstellung der Optimierungspotentiale durch Produktlebenszyklusmanagement (PLM);
27.03.08;20.06.08;2008;intern;Diplom;DE;Einführung in Navision - Entwurf eines geführten Praktikums;
27.03.08;29.09.08;2008;extern;Diplom;DE;Evaluierung bei der Atos Origin unterstützten Enterprise Content Management-System anhand einer Nutzweranalyse, die auf Basis von spezifischen aus Prozessen resultierenden Kundenanforderungen erstellt sind.;
27.03.08;29.09.08;2008;extern;Diplom;DE;Verfahren zur GPS gestützten Visualisierung von Testfahrten in geographischen Karten im Rahmen der Entwicklung von Mobiltelefonplattformen;
28.03.08;08.12.08;2008;extern;Diplom;DE;Untersuchung der Oberflächenschicht der DATEV-Steuerprogramme für die Migration in eine serviceorientierte Architektur;
01.04.08;14.11.08;2008;intern;Diplom;EN;Visual development of access control policies;
01.04.08;29.09.08;2008;extern;Diplom;DE;Vergleich und Analyse der Einsatzmöglichkeiten von Webservices und Message Queues anhand eines Kurzmitteilungsdienstes einer Webanwendung der Immowelt AG;
01.04.08;15.08.08;2008;extern;Diplom;DE;Konzeption und exemplarische Implementierung eines Generators für Softwaremodule aufbauend auf einem Framework zur Zählerkonfiguration;
01.04.08;30.09.08;2008;extern;Diplom;DE;Implementierung eines modellbasierten 3D-Gesichts-Trackers;
01.04.08;05.12.08;2008;extern;Diplom;DE;Funktionale Modellierung einer automatisierungstechnischen Anlage mit der Microsoft Visual Programming Language VPL;
03.04.08;30.09.08;2008;extern;Diplom;EN;Softwaremanagement of a Linux-based computer as a distribution-independent Service;
03.04.08;04.09.08;2008;intern;Bachelor;DE;Datenbankbasierte Anwendung von Regeln auf einem Data Mining Prozess am Beispiel von natürlich sprachlichen Verbalmorphologien;
03.04.08;30.09.08;2008;extern;Master;DE;Ermittlung einer kostengünstigen Lösung im Bereich Raumautomation unter Verwendung von Siemens EIB/KNX Geräten;
03.04.08;30.09.08;2008;extern;Master;DE;Intranet-Tool zur Sortierung von Detektormodulen eines Computertomographen;
07.04.08;16.06.08;2008;intern;Bachelor;DE;Webbasierte Lernanwendung mit Stifteingabe und Hot-Potatoes als Lernmaterialquelle;
07.04.08;11.09.08;2008;intern;Diplom;DE;Computerunterstütztes Lernen;
08.04.08;19.09.08;2008;extern;Diplom;DE;Entwurf und Implementierung eines Programms zur Steuerung eines Geräts für Tastenbestätigungstests;
10.04.08;30.09.08;2008;extern;Diplom;EN;Virtualization in Wireless Networks;
10.04.08;14.08.08;2008;extern;Diplom;DE;Interaktive Bildfilterung entlang der Herzphase zur kardialen Computertomographie;
10.04.08;26.09.08;2008;extern;Diplom;DE;Analyse, Bewertung und prototypische Umsetzung der Nutzung von TPM (Trusted Platform Modelle) für Kommunikations- und Sicherheitsszenarien in Steuerkanzleien<br>;
10.04.08;14.11.08;2008;intern;Diplom;DE;Business Intelligence und seine Beziehungen zu Data Warehouse, Data Mining und OLAP ;
10.04.08;27.08.08;2008;extern;Diplom;DE;"Untersuchung des ""Software & Systems Process Engineering Metamodel"" auf Praxistauglichkeit anhand der Modellierung eines existierenden Engineering-Prozesses<br><br>";
10.04.08;28.10.08;2008;intern;Diplom;DE;Entwicklung einer browserbasierten eLearning-Software mit Perl;
10.04.08;09.01.09;2008;extern;Diplom;DE;Dynamische Anpassung der Kodierparameter für die IP-basierte Audioübertragung;
11.04.08;30.09.08;2008;extern;Diplom;DE;Optimierung der Integration von Verpackungsmaschinen in Verpackungslinien - Demonstration an einem Demo Modell;
11.04.08;29.09.08;2008;extern;Diplom;DE;"Entwicklung eines Konzepts zur Implementierung einer ""On-Screen-Tastatur"" in Panels und PC basierenden Systemen";
11.04.08;11.09.08;2008;intern;Diplom;DE;Konzeptionierung und Implementierung eines kollaborativen Systems auf Tablet-PC Basis<br><br>;
11.04.08;30.09.08;2008;extern;Diplom;EN;Creation of a mobile phone application for secure voice transmission and reception;
11.04.08;09.01.09;2008;intern;Diplom;DE;Klassifikation von Dateisystemen auf Basis von Ontologien mit Hilfe von Lernalgorithmen;
14.04.08;16.10.08;2008;extern;Diplom;DE;"Konzeption und prototypische Implementierung der Visualisierung von Kennzahlen im ""DATEV Arbeitsplatz""";
14.04.08;14.01.09;2008;extern;Diplom;DE;Konzeption und prototypische Implementierung eines Management-Cockbits für das Kennzahlen-Monitoring in einer Steuerkanzlei;
14.04.08;07.10.08;2008;extern;Diplom;DE;IEEE 802.1X - Port-Based Network Access Control in der Schaeffler Gruppe;
14.04.08;29.09.08;2008;extern;Diplom;DE;Der Prozessnavigator als Entscheidungshilfe im Entwicklungsprozess - Einsatzanalyse in industrieller Umgebung und prototypische Umsetzung eines Teilprozesses mit Evaluierung;
14.04.08;26.09.08;2008;extern;Diplom;DE;Entwicklung und Implementierung eines industriellen Lasersteuersystems, auf Basis einer echtzeitfähigen Schnittstellenkarte;
15.04.08;29.09.08;2008;extern;Diplom;DE;Konzeption und Entwicklung einer datenbankgestützten Internetplattform für modulbasierte Standard- und Spezialanwendungen;
21.04.08;25.09.08;2008;extern;Master;DE;Evaluierung von SAP NetWeaver Master Data Management am Beispiel einer rollenbasierten Berechtigungsverwaltung;
28.04.08;28.10.08;2008;extern;Master;DE;Konzeption einer PLM-Architektur für einen Siemens Geschäftszweig mit Fokus auf dem Produktdatenmanagement;
29.04.08;29.09.08;2008;extern;Diplom;DE;Entwicklung von Verfahren für mobile, Roboter gestützte Röntgencomputertomographen;
30.04.08;24.10.08;2008;extern;Diplom;DE;Automatisches Erstellen von XSLT Skripts für die XHTML Generierung;
30.04.08;29.09.08;2008;extern;Diplom;EN;Extraction and Understanding of Domain Specific Geographical Information in Unstructered Text;
30.04.08;29.09.08;2008;extern;Diplom;DE;Vergleich dreier Entwicklungsumgebungen für die Realisierung von Rich-Clients: Eclipse, NetBeans und .NET;
15.05.08;30.09.08;2008;extern;Diplom;DE;Virtuelle Geldbörse für Schulen auf Smartcard-Basis;
16.05.08;25.09.08;2008;extern;Diplom;DE;Standardisierung der Prozesse für internationale Rollouts von zentralen Client-Server Applikationen am Beispiel SAP-PLM;
20.05.08;30.09.08;2008;intern;Master;EN;Visualization of differences between EMF models;
26.05.08;30.09.08;2008;extern;Diplom;DE;Analyse und Entwicklung eines Unified Remote Service Graphical User Interface zur Steigerung der Bedienbarkeit und der Kundenzufriedenheit innerhalb des Siemens Remote Service<br>;
29.05.08;30.10.08;2008;intern;Diplom;DE;Funktionales Programmieren in C#;
01.06.08;02.09.08;2008;extern;Diplom;DE;Integration von Geschäftsdaten aus Dynamics NAV in den SharePoint-Server;
16.06.08;16.12.08;2008;extern;Master;EN;KPI System for Performance Optimization in Different Airport Baggage Handling Systems;
19.06.08;19.12.08;2008;intern;Master;DE;Reintegration der Dateien in einem Offline-Dateisystem unter Linux mit grafischer Benutzerführung;
25.06.08;17.11.08;2008;extern;Diplom;DE;Konzeption und Implementierung eines Integrationsszenarios für den Datenaustausch von SAP- mit Non-SAP-Systemen unter Verwendung des Microsoft BizTalk Servers in der Siemens AG;
30.06.08;30.09.08;2008;extern;Bachelor;DE;Systemdiagnose in verteilten MES-Systemlandschaften am Beispiel SIMATIC IT;
30.06.08;26.09.08;2008;intern;Bachelor;DE;Entwurf und Implementierung eines MVC-basierten objektorientierten Frameworks mit PHP5;
01.07.08;30.09.08;2008;extern;Bachelor;DE;Elektronische Produktanlage - Bestandsaufnahme von Datenflüssen im PBS-Markt aus Sicht eines mittelständischen Produktionsunternehmen;
17.07.08;30.09.08;2008;intern;Diplom;DE;Konzeption und Realisierung einer ontologiebasierten Kompetenzverwaltung für die Fakultät Informatik;
29.07.08;31.03.09;2008;extern;Diplom;DE;Sicherer Datenverkehr zwischen Steuergeräten auf Basis der Automotive Open System Architecture (AUTOSAR);
26.08.08;27.11.08;2008;extern;Bachelor;DE;Konzeptionierung einer Ressourcenplattform bei der evosoft GmbH;
01.09.08;02.02.09;2008;intern;Diplom;DE;Optimierung des räumlichen Inferenzverfahrens MAP3 und Realisierung als Location Middleware;
01.09.08;30.01.09;2008;extern;Diplom;DE;Konzeptstudie zur Kernelsoftware für SIMATIC-Steuerungen auf Multicore-Prozessoren;
09.09.08;09.02.09;2008;intern;Diplom;DE;Effiziente Implementierung einer feingranularen Zugriffskontrollsprache;
18.09.08;10.04.09;2008;extern;Diplom;DE;Boutiquenkette SOHO: Mode-Marketing in Russland;
29.09.08;02.03.09;2008;extern;Diplom;DE;Modellierung von Dienstleistungsketten bezüglich Planung und Verfolgbarkeit;
30.09.08;27.02.09;2008;extern;Bachelor;DE;Integration einer Hardwareabstraktionsschicht (Fosstrak) in eine existierende RFID-Middleware (SMMART);
30.09.08;27.02.09;2008;intern;Bachelor;DE;Entwurf und Implementierung eines Benutzerverwaltungs-, Bewertungs- und Belohnungssystes zur Unterstützung des computergestützten Lernens;
30.09.08;12.03.09;2008;extern;Diplom;DE;Data Mining im Einzelhandel- Warenkorbanalyse;
30.09.08;03.03.09;2008;extern;Master;EN;Potentials of temporal blocking for stencil-based computations on multi-care Systems;
30.09.08;30.03.09;2008;extern;Master;DE;Konzeptionierung einer Wissensdatenbank zur Speicherung, Analyse und Visualisierung von strategischen Informationen im  medizinischen Umfeld - Anforderungen aus der Sicht der Informationstechnologie;
01.10.08;01.07.09;2009;extern;Diplom;DE;"Integration einer 3D-Ansicht in das Oberleitungsprojektierungsprogramm ""Sicat Master"" mit Hilfe von DirectX 9.0 und C++";
01.10.08;26.02.09;2009;extern;Diplom;DE;Entwicklung eines Frameworkprototypen auf .NET Basis für die Systemautomatisierung;
01.10.08;26.02.09;2009;intern;Diplom;DE;Analyse von mit Geo-Tags versehenen Bilddateien und deren geographische Clusterung;
01.10.08;10.03.09;2009;extern;Diplom;DE;Konzeption und Entwicklung eines regelbasierten Systems zur assistentengestützten Zielgruppenselektion für eine vertriebliche CRM-Komponente;
01.10.08;;2009;extern;Diplom;DE;Limitierung con Risikokennzahlen: Konzeption und prototypische Realisierung im SAP Bank Analyzer;
01.10.08;13.03.09;2009;intern;Diplom;DE;Konzeption und Realisierung eines Geospatial-Add-Ons für SQL;
06.10.08;14.04.09;2009;extern;Diplom;DE;Analyse und Konzeption einer datenbankgestützten Webanwendung zur Effizienzsteigerung des Project Reportings<br>;
08.10.08;09.03.09;2009;intern;Bachelor;DE;Effektives computergestütztes Lernen mit handschriftlichen Eingaben;
08.10.08;08.03.09;2009;intern;Bachelor;DE;Speicherzugriffs-Lokalität in paralellen Programmen mittels Speicher-Temperaturen;
09.10.08;09.03.09;2009;extern;Bachelor;DE;Applikation zur Berechnung von digitalen Filter;
13.10.08;13.03.09;2009;extern;Bachelor;EN;"A feaseability study to integrate a virtual machine on an Infineaon Hardware/Software platform and if feasible an implementation of a ""virtual core"" bundled with an application to proof the concept<br>";
13.10.08;27.02.09;2009;extern;Bachelor;DE;Ablösung des SAP-Formularwesens durch ein kompatibles Output-Management-System für den Pilotstandort Weissenburg der LEONI AG<br><br>;
13.10.08;16.03.09;2009;extern;Diplom;DE;Die Microsoft Windows Workflow Foundation als Basis der IQ-optimize Workflow Eninge - Konzeptionierung und prototypische Implementierung<br>;
13.10.08;13.07.09;2009;extern;Diplom;DE;Abstraktion des Datenbankzugriffes und der Datenschicht einer bestehenden PHP-Applikation;
14.10.08;02.06.09;2009;intern;Diplom;DE;Medienorientierte Benutzeroberfläche zur Literatursuche;
14.10.08;12.03.09;2009;extern;Diplom;DE;Analyse und Konzeption der statistischen Daten des Internetportals Immowelt.de und deren Übertragung in der Immowelt Maklersoftware;
14.10.08;12.03.09;2009;extern;Bachelor;DE;Evaluierung von Einsatzbereichen des Monitoring-Systems Nagios im Unternehmen;
14.10.08;26.02.09;2009;extern;Bachelor;DE;Portierung einer Prozessbeschreibung komplexer IT-Services unter der Berücksichtigung von wechselnden normativen Anforderungen<br>lorarbeit:<br>;
16.10.08;13.03.09;2009;extern;Diplom;DE;Optimierung eines  modellbasierten 3D-Gesichts-Trackers;
16.10.08;03.04.09;2009;extern;Diplom;DE;Automatisiertes Setzen von Referenzpunkten im Gesicht zur Verbesserung von statistischen Modellen;
17.10.08;12.03.09;2009;extern;Bachelor;DE;Desktop-Virtualisierung in der DATEV eG - Untersuchung der Einsatzfähigkeit von Parallels Virtuozzo Containers für den internen Einsatz;
17.10.08;16.03.09;2009;extern;Diplom;DE;Konzeption und Prototyp eines Frameworks zum Erstellen von grafischen Dialoganwendungen für mobile Datenfunkterminals;
20.10.08;29.06.09;2009;extern;Diplom;DE;Entwicklung eines analytischen Verfahrens zur Positionierung von Prozesslogik in dynamischen, verteilten, hierarchischen IT-Netzen<br>;
20.10.08;26.02.09;2009;intern;Bachelor;DE;Komponenten und Konzepte moderner Verkaufplattformen im Internet und ihre marktpsychologischen Wirkungen;
21.10.08;26.02.09;2009;extern;Bachelor;DE;Entwicklung eines Leitfadens zur effizienten Prozessanalyse und -modellierung für die Einführung der elektronischen Vorgangsbearbeitung bei der Stadt Nürnberg<br>;
21.10.08;21.03.09;2009;extern;Bachelor;DE;Prototyp eines AUTOSAR-RTE-Dispatchers für Mehrkernsysteme;
21.10.08;13.03.09;2009;extern;Bachelor;DE;Portierung und Vergleich der Linux-Echtzeiterweiterungen Preempt-RT und Xenomai auf Basis einer ARM926-Plattform;
22.10.08;21.07.09;2009;extern;Diplom;DE;Aufbau eines skalierbaren und hochverfügbaren Content Delivery Network;
23.10.08;05.03.09;2009;intern;Bachelor;DE;Spezifikation einer formalen Sprache zur benutzerfreundlichen Verifikation von FinTs Online Banking Transaktionen;
23.10.08;11.03.09;2009;extern;Diplom;DE;Verteilung automatisierter und manueller Benachrichtigungen über verschiedenste Nachrichtenkanäle mit einer vom Anwender konfigurierbaren Logik;
23.10.08;08.07.09;2009;extern;Diplom;DE;Prozess zur Spezifikation von Zugriffskontrollen in Webanwendungen am Beispiel des Softwareentwicklungsprozesses der Firma e:c:logic ;
23.10.08;14.07.09;2009;extern;Diplom;DE;Instrumentierung und Management einer verteilten Web-Applikation;
24.10.08;16.07.09;2009;extern;Diplom;DE;Konzeption und prototypische Umsetzung der Integration von OMNITRACKER mit Windows SharePoint Services und Microsoft Office SharePoint Server 2007;
27.10.08;27.03.09;2009;extern;Diplom;DE;Entwurf und Implementierung einer realistischen Kreuzungsansicht für ein Navigationssystem basierend auf realen Straßengeometrien;
27.10.08;27.04.09;2009;extern;Master;DE;Analyse, Entwurf und Implementierungvon Verfahren zur Koexistenz paralleler Netze basierend auf der existierenden proprietären Medienzugriffsschicht eines Multi-Hop Sensornetzes;
27.10.08;23.07.09;2009;extern;Diplom;DE;Konzeption einer EDD-Testsuite für Oberflächen- und Grafikelemente;
28.10.08;29.03.09;2009;extern;Diplom;DE;Wertorientierte Kundensegmentierung für eine differenzierte Kundenbearbeitung beim IT-Dienstleister PENTASYS AG;
28.10.08;26.03.09;2009;extern;Diplom;DE;Generische SSL-Hardwarebeschleunigung mit Accelerator Cards unter Linux;
29.10.08;12.03.09;2009;extern;Bachelor;DE;System z Millicode Debugger - Entwicklung eines System z Millcode Debugger Plugins für Eclipse basierend auf einer Anbindung an den existierenden Millicode Emulator;
30.10.08;30.03.09;2009;extern;Bachelor;DE;Software zur Analyse der Schedulability in einem AUTOSAR basierten System;
03.11.08;05.03.09;2009;intern;Bachelor;DE;Analytische Steady-State Auswertung von Deterministisch-Stochastischen Petrinetze (DSPNs);
04.11.08;12.03.09;2009;extern;Diplom;DE;Konzeption und Implementierung einer PowerPC-Peripherie-Komponente in VHDL sowie zugehöriger Linux-Treiber-Software zum Tunneln einer Netzwerkverbindung über Xilinx RocketIO.<br>;
14.11.08;14.04.09;2009;intern;Diplom;DE;Möglichkeiten der Mehrfingerbedienung bei der Dateiverwaltung;
15.11.08;27.03.09;2009;extern;Diplom;DE;Konzeptueller Aufbau einer Adressclusterung und Anwendung verschiedener Clusterungsmethoden;
17.11.08;09.04.09;2009;extern;Diplom;DE;Evaluierung und prototypische Realisierung einer Social CRM und Community Software Plattform auf Basis serviceorientierter Standardsoftware von Oracle;
17.11.08;17.04.09;2009;extern;Diplom;DE;Konzeption und Implementierung eines IT-Systems zur Verwaltung und Bewertung von Kaizen-Maßnahmen bei der Schaeffler Gruppe;
02.12.08;12.03.09;2009;extern;Diplom;EN;Harmonizing and Optimizing Apparel and Footwear Sales Processes for Sporting Goods Industry;
04.12.08;04.03.09;2009;extern;Bachelor;DE;Entwicklung einer parametrierbaren Template-Container-Bibliothek zur Optimierung des Laufzeitverhaltens und des Speicherbedarfs auf eingebetteten Systemen;
09.12.08;09.09.09;2009;extern;Master;DE;Der Einsatz von Open-Source-PACS und Rohdatenkompression in der Mikro-Computertomographie;
12.12.08;14.09.09;2009;intern;Diplom;EN;File System Abstraction for the Semantic Desktop - Path Projection and User Interfaces Concept;
15.12.08;12.03.09;2009;extern;Bachelor;DE;Einführung eines Enterprise Service Bus zur Integration von ECM-Services im Kontext einer service-orientierten Architektur für Finanzdienstleister;
15.12.08;15.09.09;2009;extern;Diplom;DE;Prototypische Entwicklung einer Software zur Erbfolgenbestimmung nach österreichischem Recht;
16.12.08;14.03.09;2009;intern;Bachelor;DE;Verfolgen von Infrarot-Lichtpunkten im dreidimensionalen Raum mit Hilfe mehrerer Wii-Remote;
01.01.09;30.06.09;2009;extern;Diplom;DE;Beschreibung und Optimierung des Siemens-Unternehmensarchitektur-Modells SIEAF;
01.01.09;08.09.09;2009;extern;Diplom;DE;Untersuchung verschiedener Methoden des Softwareenineering am Beispiel des Aufbaus einer Knowledgebase auf Basis von Microsoft Sharepoint-Technologien;
01.01.09;12.06.09;2009;intern;Master;DE;Praktische Bestimmung der Systemkomplexität eines automotiv embedded Echtzeitsystems, anhand von Anforderungen;
30.01.09;30.06.09;2009;extern;Diplom;DE;Bestimmung der optimalen Release-Frequenz in großen Systemlandschaften am Beispiel eines Finanzdienstleisters;
31.01.09;30.06.09;2009;extern;Bachelor;DE;Konzeption eines Tools zur Steuerung des Prozesses Produktdaten-Versorgung;
10.02.09;14.08.09;2009;extern;Diplom;DE;Auswahl einer OLAP-Datenbank für den Aufbau von Planungsanwendungen in mittelständischen Unternehmen;
18.02.09;15.05.09;2009;extern;Bachelor;DE;Konzept zur Integration von projektspezifischem Erfahrungswissen in das Wissensmanagement eines mittelständischen Systemhauses;
24.02.09;24.07.09;2009;extern;Diplom;DE;Entwurf eines Auskunftsportals für Wirtschafts- und Unternehmensdaten und Entwicklung der Marketingstrategie zur Markteinführung;
27.02.09;29.06.09;2009;extern;Diplom;DE;Überblick über Frameworks zur Entwicklung von Webapplikationen mit Schwerpunkt Anwendungssicherheit;
03.03.09;03.09.09;2009;extern;Master;DE;Data Mining zur Merkmalsextraktion aus Positionsdaten;
04.03.09;04.06.09;2009;extern;Bachelor;DE;Konzeption und prototypische Implementierung einer Unternehmensplanungsanwendung für die QUELLE GmbH;
04.03.09;25.09.09;2009;extern;Diplom;DE;Das Produkt-Konfigurationsmanagement als zentrales Element der Software-Integration;
05.03.09;04.12.09;2009;intern;Diplom;DE;Konzeption einer Datenhaltungsschicht für eine Web-Mediengalerie;
09.03.09;14.09.09;2009;extern;Diplom;DE;Entwicklung einer ressourcenoptimierten Nachladestrategie für ortsbezogene Daten auf mobilen Endgeräten;
13.03.09;30.09.09;2009;extern;Master;DE;Softwaregestützte Verwaltung von Benutzern, Rollen und Rechten in der Schaeffler Gruppe;
13.03.09;13.10.09;2009;intern;Master;DE;Design und Development of a Comprehensive Online Marketing Concept für the Movie Platform ohmrolle;
13.03.09;10.12.09;2009;extern;Diplom;DE;Compliance der Infrastruktur im DATEVasp Umfeld;
30.03.09;30.09.09;2009;extern;Master;DE;Machbarkeitsstudie zur Umstellung des IT-Verfahrens COLIBRI von C++ und CORBA nach Java und J2EE;
08.04.09;29.09.09;2009;extern;Master;DE;Untersuchung agiler Projektmanagementmethoden am Beispiel von Scrum und Integration in die Entwicklungsprozesse der up2date solutions GmbH;
30.04.09;31.07.09;2009;intern;Bachelor;DE;Interaktive Formulare am Beispiel eines mobilen Pflegedokumentationsassistenten;
04.05.09;30.09.09;2009;intern;Bachelor;DE;Softwaregestütztes Informationssystem zur Verarbeitung von Lehrveranstaltungsausfällen;
04.05.09;;2009;extern;Master;DE;Konzeption und Realisierung einer vereinheitlichten, SOAP-gestützten Web-Service Schnittstelle durch Zusammenführung verschiedener Web-Services für die KFZ-Versicherungstarifermittlung;
05.05.09;29.09.09;2009;extern;Diplom;DE;Auswertung von SAP Daten unter Microsoft Office Sharepoint Server 2007;
08.05.09;08.08.09;2009;extern;Bachelor;DE;Automatisierte Extraktion von Branchenverzeichniseinträgen aus unstrukturierten Webseiten mit Text-Mining-Verfahren;
08.05.09;30.09.09;2009;intern;Bachelor;DE;Konzeption und Realisierung einer Nahbereichsnavigation eines autonomen mobilen Robots;
11.05.09;11.08.09;2009;extern;Bachelor;DE;Entwicklung und Verifizierung einer CUDA-Testumgebung zur parallelen Berechnung von Korrelationsergebnissen mit Bezug auf Laufzeitmessungen in Lokalisierungssystemen;
01.06.09;31.08.09;2009;intern;Bachelor;DE;Erkennung von Bewegungsmustern mit dem iPhone;
01.06.09;11.02.10;2009;extern;Diplom;DE;Entwurf und Entwicklung eines Service Gateways inklusive Schnittstellenbeschreibung zur herstellerneutralen Kommunikation zwischen Medizingeräten und Facility Management Systemen im Krankenhaus;
03.06.09;29.10.09;2009;extern;Bachelor;DE;Beschaffung und Aufbereitung von Umgebungsinformationen für gewerbliche Immobilienmakler des Internetportals immowelt.de;
12.06.09;29.09.09;2009;intern;Master;DE;Konzeption und Realisierung eines Browser-basierten FAMOS-Eingabeassistenten und Anbindung an Datenbank, ERP und Email<br><br>;
15.06.09;22.03.10;2009;extern;Bachelor;DE;Analyse und Refactoring von PYTHON Programmen;
16.06.09;16.10.09;2009;extern;Bachelor;DE;Analyse und Konzeption eines Tourenplanungssystems für die Lesezirkel-Branche;
16.06.09;15.10.09;2009;extern;Bachelor;DE;Konzeption und Realisierung eines Entscheidungsunterstützungssystems für die Tourenplanung in der Lesezirkel-Branche;
17.06.09;07.01.10;2009;extern;Master;DE;Projektmanagement als Baustein einer integrierten CRM-Applikation - Konzeption und Umsetzung am Beispiel von Microsoft Dynamics CRM 4.0;
30.06.09;30.09.09;2009;extern;Bachelor;EN;Design of a Process Suitable for the Development of Specifications for the Offshore Software Development at DATEV eG for the International Market under Consideration of Agile Methods<br>;
02.07.09;07.01.10;2009;intern;Master;DE;Ein Ansatz zur intuitiven Bedienung des Internets;
14.07.09;14.12.09;2009;extern;Diplom;DE;Modellierung und Messung der Systemleistung eines Prozessors mit XSCALE-Architektur;
20.07.09;20.04.10;2009;intern;Diplom;DE;Ermittlung der 3D-Raumkoordination eines Objektes mit Hilfe eines Stereokamerasystems und Neuronaler Netze;
01.08.09;17.12.09;2009;extern;Bachelor;DE;Konzeptionierung eines Selfserviceportals für die Dienstleistung DATEVasp unter besonderer Berücksichtigung von Sicherheit und Ergonomie;
01.09.09;01.02.10;2009;intern;Diplom;DE;Konzeption und Realisierung einer Positionssensorkorrektur eines autonomen mobilen Robots;
15.09.09;15.02.10;2009;extern;Bachelor;DE;Modellbasierte Entwicklung von Controller-Komponenten für Infotainmentsysteme im Kraftfahrzeug;
29.09.09;01.03.10;2009;extern;Bachelor;DE;Analyse von Monitoring-Lösungen für ERP-Systeme am Beispiel von SAP;
30.09.09;04.03.10;2009;extern;Diplom;DE;Erstellung eines use cases für die Kupplung von e:c:car an externe Systeme;
30.09.09;28.02.10;2009;extern;Diplom;DE;Erstellung von Use Cases für die Kopplung von e:c:car an externe Systeme;
01.10.09;04.01.10;2010;extern;Bachelor;DE;Adaptives Caching auf Smartphones mittels embedded Datenbanken;
01.10.09;14.03.10;2010;extern;Master;DE;Paralleles Programmieren auf Hyprider Hardware: Modelle und Anwendungen;
12.10.09;12.07.10;2010;extern;Diplom;DE;Integration eines Netzwerk-Managements in ein Open Source Trouble-Ticket System;
14.10.09;12.03.10;2010;extern;Bachelor;DE;Entwicklung eines Produktkonfigurators als Rich Internet Application mit Adobe Flex;
14.10.09;14.05.10;2010;extern;Bachelor;DE;Nachkalkulation in der Einzelfertigung - Datenbankbasierte Automatisierung für ein Mittelstandsunternehmen;
15.10.09;12.03.10;2010;intern;Bachelor;DE;Compiler-basierte Verifikation von API Nutzung durch Constraints;
15.10.09;04.03.10;2010;extern;Diplom;DE;Unternehmensplanung mit Microsoft SharePoint - Konzeption und prototypische Realisierung;
16.10.09;08.02.10;2010;extern;Bachelor;DE;Integrationsanalyse der jBPM Workflow Engine in das COI-BusinessFlow System;
21.10.09;15.03.10;2010;extern;Bachelor;DE;Konzipierung und Implementierung der ETL-Prozesse eines Data Warehouses für ein Business Intelligence Systems;
22.10.09;05.03.10;2010;extern;Bachelor;DE;Konzeption der Testdatenbestände und eines Testdatengenerierungs-Werkzeugs für den Stammdatendienst der DATEV eG;
22.10.09;15.03.10;2010;extern;Bachelor;DE;Sentiment Mining: Automatische Auswertung von Kundenrezensionen in Online-Portalen im Bereich Automotive;
22.10.09;05.03.10;2010;extern;Bachelor;DE;Entwicklung eines Gesamtprozesses zur Modellierung, Implementierung, Anwendung und semi-automatischen Anpassung und Erweiterung einer Ontologie;
23.10.09;16.02.10;2010;extern;Bachelor;DE;Einführung eines neuen E-Learning Systems - Von der Analyse des bisherigen Systems bis zur Konzeption einer neuen Lernplattform unter Berücksichtigung des Dateschutzes;
23.10.09;11.03.10;2010;extern;Bachelor;DE;Evaluierung und Analyse potenzieller Single Sign-On-Systeme für das Web-Portal www.immowelt.de unter den Aspekten Wirtschaftlichkeit, Daten- und Zukunftssicherheit;
26.10.09;10.03.10;2010;extern;Bachelor;DE;Konzeption und Implementierung statistischer Auswertungen mit Microsoft SQL Server für Immobiliensoftware der Immowelt AG;
26.10.09;25.03.10;2010;extern;Bachelor;DE;Trade-offs bei der gegenseitigen Abstimmung von Geschäftsprozessen und betrieblicher Software;
26.10.09;25.03.10;2010;extern;Bachelor;DE;Entwicklung einer neuen Startseite für die Demoanwendung der BRANDAD Systems AG, unter Berücksichtigung anerkannter Usability-Richtlinien;
26.10.09;27.04.10;2010;intern;Master;DE;Konzeption und Realisierung einer Reverse Geocoding Plattform;
26.10.09;26.01.10;2010;extern;Bachelor;DE;Entwicklung eines browsergestützten grafischen Programmierinterfaces zur Modellierung von Workflows zur Distribution mittels eines mobilen telemedizinischen Endgeräts;
27.10.09;12.03.10;2010;intern;Bachelor;DE;Entwicklung eines Programms zur Prognose sportlicher Ergebnisse auf Basis von SOAP und C#;
28.10.09;22.03.10;2010;extern;Bachelor;DE;Leitfaden für den Einsatz von ITIL in einem mittelständischen Unternehmen;
30.10.09;30.03.10;2010;extern;Bachelor;EN;Development of Gantt chart application based on AJAX technology;
30.10.09;31.05.10;2010;extern;Bachelor;DE;Management organisationsinterner Terminologien - Ein Beitrag zu Knowledge Management und BI-Governance am Beispiel der Bundesagentur für Arbeit;
30.10.09;25.02.10;2010;extern;Master;DE;Konzeption und Realisierung einer sequenzbezogenen Belieferung (JIS) für die Daimler E-Klasse in China unter Einsatz der Software SAP-ERP 2005;
02.11.09;02.08.10;2010;extern;Diplom;DE;Evaluierung und Optimierung ausgewählter 2D Kompressionsverfahren zur Client/Server-basierten Visualisierung in der medizinischen Bildnachverarbeitung;
03.11.09;03.05.10;2010;intern;Master;DE;Navigation eines Roboters auf der Basis unvollständiger Umgebungsinformationen;
16.11.09;16.02.10;2010;extern;Bachelor;DE;Integration eines Webbrowsers auf low-cost-HMI-Geräten;
19.11.09;30.06.10;2010;extern;Master;DE;Machbarkeitsuntersuchung des Einsatzes von künstlichen neuronalen Netzen im Bereich von Netzwerküberwachung Kapazitätsmanagement;
20.11.09;14.03.10;2010;intern;Diplom;DE;Entwicklung einer datenbankgasierten Webanwendung für die Sprachlerkunde. Verbalformengenerierung in der fortgeschrittenen Rehabilitation;
27.11.09;27.08.10;2010;extern;Diplom;DE;Entwicklung einer BI-Komponente zur Auswertung von Microsoft Navision Kontenschemata für das strategische Management;
02.12.09;02.03.10;2010;intern;Bachelor;DE;Erfolgspotentiale und Herausforderungen durch IT-gestütztes Baucontrolling;
04.12.09;12.03.10;2010;intern;Master;EN;The Key Figure supportedProject Controlling in Construction Firms;
14.12.09;14.03.10;2010;intern;Bachelor;DE;Prognose zur Nachfrage an Geldausgabeautomaten mittels künstlicher neuronaler Netze;
14.12.09;15.03.10;2010;intern;Bachelor;DE;Untersuchung und Bewertung von E-Business-Standards zum Kommunikationsaustausch in der Versicherungswirtschaft;
14.12.09;14.03.10;2010;intern;Bachelor;DE;Entwicklung einer Ontologie als Integrationsschicht zur Anbindung der relationalen Datenbank eines Fakultätsinformationssystems als virtueller RDFGraph;
14.12.09;15.03.10;2010;intern;Bachelor;DE;Entwurf und Realisierung eines Schulungssystems zur Bildbearbeitung mit Operationen im Ortsbereich, im Frequenzbereich und der Modifikation der Grauwerte;
15.12.09;12.03.10;2010;extern;Bachelor;DE;Automatische Bestimmung der Modulationstransferfunktion eilnes röntgenempfindlichen Detektors;
18.12.09;17.05.10;2010;intern;Bachelor;DE;Datenbankbasierte Anwendung zur Unterstützung des strukturierten Anforderungsmanagements im Projektumfeld;
21.12.09;14.05.10;2010;extern;Bachelor;DE;Analyse des Hubschrauber-Dokumentations-Systems (HDS) hinsichtlich Verbesserungspotential sowie Implementierung von Modifikationen zur Prozessoptimierung und Effizienzsteigerung;
23.12.09;12.03.10;2010;extern;Bachelor;DE;Neugestaltung einer Benutzerschnittstelle zur Verwaltung von Ausgabeaufträgen mit SAP Web Dynpro für ABAP;
02.01.10;31.03.10;2010;intern;Bachelor;DE;Effizienzsteigerung des räumlichen Extended Split Index;
01.02.10;29.07.10;2010;extern;Master;DE;Automatische Objektverfolgung in Bildsequenzen für die Filmpostproduktion;
01.02.10;01.05.10;2010;intern;Bachelor;DE;Konzeption eines studiengangunabhängigen DB-basierten Informationssystems für die Vergabe von Studienplätzen in Wahlpflichtfächern an einer Hochschule;
01.02.10;31.07.10;2010;extern;Master;DE;Einsatz von GSM-Endgeräten zur Selbstlokalisierung einschließlich der Untersuchung der Fingerprinting-Methodik auf Eignung;
12.02.10;12.07.10;2010;extern;Diplom;DE;Entwicklung einer GUI-Pattern für Webapplikationen;
18.02.10;22.03.10;2010;intern;Bachelor;DE;Vorteile asynchronischer Verarbeitung von Anfragen in einem Webserver;
25.02.10;25.07.10;2010;intern;Diplom;DE;Multiperspektivische Kategorisierung von Konzepten und Methoden für E-Learning in Lehrveranstaltungen;
01.03.10;31.08.10;2010;extern;Master;DE;Aufbau und Evaluierung eines CAN-Ethernet-Gateways;
11.03.10;10.09.10;2010;extern;Master;DE;Design und Implementierung eines Software Compositons Editors für das EB tresos Studio;
11.03.10;11.08.10;2010;extern;Diplom;DE;Kooperatives Wissensmanagement - Wissensmanagement für die IT eines mittelständischen Unternehmens im Enterprise 2.0;
12.03.10;13.09.10;2010;extern;Master;EN;Feature Scoping Based on Software Product Line Engineering in a Multi-Projekt Environment;
12.03.10;10.09.10;2010;extern;Master;DE;"Comic Map - Konzeption einer schematischen Kartendarstellung für das Navigationssysteme ""street director""";
14.03.10;30.09.10;2010;extern;Diplom;DE;Kostenoptimierung durch Open-Source-Software anhand des Content-Management-Systems eines mittelfränkischen Finanzdienstleisters;
14.03.10;14.09.10;2010;extern;Master;DE;Verbrauchssparende Routen - Effizienzsteigerung im Energieverbrauch durch Optimierung der Routenberechnung in Navigationsgeräten;
15.03.10;15.06.10;2010;extern;Bachelor;DE;Analyse der Leistungsfähigkeit von Grafikkarten für die Implementierung speicherbrandbreitenlastiger Rekonstruktionsalgorithmik in OpenCL;
22.03.10;09.07.10;2010;extern;Bachelor;DE;Automationsschnittstelle für eine integrierte Entwicklungsumgebung basierend auf der Windows Communication Foundation;
31.03.10;31.08.10;2010;extern;Bachelor;DE;Simulation von medizinischen Sensoren und Visualisierung von Systemzuständen in medizinischen embedded Geräten;
01.04.10;30.09.10;2010;extern;Master;DE;Zwei-Faktor User-Authentisierung für Android-Smartphones;
01.04.10;07.09.10;2010;extern;Diplom;DE;Anbindung von Smartphones an das Unternehmen: Machbarkeitsstudie mit besonderem Fokus auf einem integrativen Sicherheitsansatz;
08.04.10;20.08.10;2010;extern;Bachelor;DE;Design und Entwicklung einer abstrakten, objektorientierten Schnittstellenbeschreibungssprache als generischer Input für eine templatebasierte API Codegenerierung für verschiedene Programmiersprachen. ;
08.04.10;08.07.10;2010;intern;Bachelor;DE;"Konzeption und Entwicklung einer Suchfunktion für die Online-Filmeplattform ""ohmrolle"" basierend auf Microsoft Silverlight";
12.04.10;03.10.10;2010;intern;Bachelor;DE;Entwicklung einer Out-of-Browser-Anwendung mit Microsoft Silverlight und Untersuchung der Eigenschaften zu einer nativen Desktop-Anwendung;
12.04.10;12.07.10;2010;intern;Bachelor;DE;"Realisierung von Komponenten einer Webapplikation basierend auf Microsoft Silverlight für die Online-Filmplattform ""ohmrolle"" zur Präsentations von Talents";
14.04.10;14.09.10;2010;extern;Bachelor;DE;Ansichtsabhängiges Umrechnen von Bildern auf Basis von Tiefeninformation;
14.04.10;06.09.10;2010;extern;Diplom;DE;Sensorgestützte Positions- und Lageerkennung eines mobilen Trainingsgerätes;
15.04.10;15.09.10;2010;intern;Bachelor;DE;Corporate Performance Management in kleinen und mittleren Unternehmen;
15.04.10;15.07.10;2010;extern;Bachelor;DE;Framework für kartenbasierte Android-Applikationen;
15.04.10;30.09.10;2010;extern;Bachelor;DE;Automatisierung von Arbeitsabläufen bei der Bildnachbearbeitung in der interventionellen Radiologie;
15.04.10;13.09.10;2010;extern;Bachelor;DE;Konzeption und Realisierung eines Generators für webbasierte interaktive Oberflächen;
16.04.10;30.09.10;2010;extern;Master;DE;Product Information Management System - Entwicklung eines Konzepts zur Integration in ein mittelständisches Produktionsunternehmen;
19.04.10;30.09.10;2010;extern;Master;DE;Automatische Generierung einer übergreifenden Statussicht in einer heterogenen Monitoring-Umgebung;
20.04.10;20.09.10;2010;extern;Diplom;DE;Zusätzliche Anforderungen an ERP-Systeme innerhalb eins multinationalen Konzerns und deren Realisierungsmöglichkeiten;
27.04.10;19.08.10;2010;extern;Bachelor;DE;Planung und Umsetzung einer Funktion zur Graphikausgabe von Messdaten in eine vorhandene Prüfstandsumgebung in der Programmiersprache Python;
27.04.10;27.07.10;2010;extern;Bachelor;DE;CloudIA - Instrumentierung des Social-Network-Gedanken zur Integration von Kunden in Geschäftsprozesse durch die Bearbeitung feingranularer, nicht maschinenlösbarer Aufgaben;
27.04.10;27.07.10;2010;extern;Bachelor;DE;Integration eines Open Source Web-Framework in eine bestehende Basis-Technologie;
29.04.10;29.10.10;2010;extern;Master;DE;Konzeption und Implementierung eines flexiblen und konfigurierbaren Softwareprodukts zur Verteilung von unternehmensinternen Nachrichten nach den Prinzipien agiler Softwareentwicklung;
29.04.10;29.07.10;2010;intern;Bachelor;DE;Erweiterbarer Logikanalysator auf Basis eines Complex Programmable Logic Device mit graphischer Benutzeroberfläche unter Linux;
06.05.10;06.08.10;2010;extern;Bachelor;DE;Datenverwaltung und -auswertung für Monitoring-System Sicat CMS;
10.05.10;10.11.10;2010;intern;Master;DE;Konzeption und Entwicklung einer Komponenten zur automatischen Kartenbeschriftung;
10.05.10;10.08.10;2010;extern;Bachelor;DE;Entwicklung eines Programms in C# zur Administration und Illustration von Relationen zwischen Computer-Hardware und deren Anwendern;
19.05.10;19.08.10;2010;intern;Bachelor;DE;Konzeption und Implementierung einer iPhone-App zum Darstellen und Editieren von Geodaten;
20.05.10;28.09.10;2010;intern;Master;DE;Konzeption und Implementierung einer Business Intelligence Lösung für die Baubranche unter Verwendung von Open Source Software;
25.05.10;24.08.10;2010;intern;Bachelor;DE;Symbolische Suche in großen Geodatenbeständen;
01.06.10;01.09.10;2010;intern;Bachelor;DE;Integration von RDBs zur Population von Ontologien in Protégé;
01.06.10;31.08.10;2010;intern;Bachelor;DE;Marktstudie zur Realisierung eines Dokumentenmanagementsystems mit Open Source Lösungen;
01.06.10;30.09.10;2010;extern;Bachelor;DE;Untersuchung und Bewertung der Möglichkeiten einer fertigungsnahen, automatischen Serienauftragsrückmeldung mit SAP ERP bei der Robert Bosch GmbH;
01.06.10;28.09.10;2010;extern;Master;DE;Konzeption und prototypische Implementierung von Services einer Versicherungssoftware unter Berücksichtigung von branchenspezifischen Kommunikationsstandards;
02.06.10;30.09.10;2010;extern;Diplom;DE;Automatisches Deployment und Monitoring von Microsoft Gruppenrichtlinien im DATEVVasp Umfeld;
14.06.10;08.12.10;2010;extern;Master;DE;Sicherheitskonzept im Umfeld Internet der Dinge für logistische Anwendungen;
17.06.10;16.09.10;2010;extern;Bachelor;DE;Suchmaschinenorientierter Aufbau eines Internet-Reiseführers für ein Ferienportal;
17.06.10;16.09.10;2010;intern;Bachelor;DE;Domänenspezifische Sprache zur Spezifikation von Zugriffsrechten und Generierung parametrierter Datenbank-Views;
30.06.10;30.09.10;2010;extern;Bachelor;DE;Entwicklung eines Auftragsterminals in Microsoft Dynamics AX für automatische und manuelle Abwicklung von asynchron eingehenden Aufträgen;
01.07.10;28.09.10;2010;extern;Bachelor;EN;Color algorithm for a limited gamut LED lighting System;
08.07.10;30.09.10;2010;extern;Bachelor;DE;Betriebsparallele Simulation – Entwicklung eines Verfahrens zur automatisierten Ermittlung stochastischer Einflüsse auf Prozessgüter und darauf basierende Ableitung von Parametern für Komponenten einer Anlagensimulation;
12.07.10;25.09.10;2010;intern;Bachelor;DE;Software-Generator gestützte Portierung von GUI-Artist-Widgets für das Betriebssystem Android;
20.07.10;20.12.10;2010;extern;Bachelor;DE;Ergänzung des Unit Testframes um Performance-Messungen zur Ermittlung des Laufzeitverhaltens ;
26.07.10;28.03.11;2010;extern;Master;DE;Provisioning Adapter für PlateSpin Orchestrator zur Verwaltung von virtuellen Maschinen unter SUSE Linux Enterprise Server für IBM System Z;
29.07.10;18.11.10;2010;intern;Bachelor;DE;Architekturmanagement mit Enterprise Architecture Tools;
31.07.10;31.01.11;2010;intern;Master;DE;Reengineering einer Frameworkarchitektur zur Steuerung von industriellen Röntenanlagen;
03.08.10;03.11.10;2010;extern;Bachelor;DE;Evalurisierung einer Software zur automatischen Testfallgenerierung in der Automobilindustrie: Einsatz von Zustandsübergangsdiagrammen am Hardware in the Loop-Prüfstand;
18.08.10;17.02.11;2010;intern;Master;DE;Usability für Online-Shops;
23.08.10;23.11.10;2010;extern;Bachelor;DE;Prototyping und Analyse des Imports von XML-Dateien nach dem Open-Immo-Standard mit dem Microsoft BizTalk Server 2010;
30.08.10;26.11.10;2010;intern;Bachelor;DE;Web Content Management System für Sportvereine<br><br>;
01.09.10;07.12.10;2010;intern;Bachelor;DE;"Einsatz des Apple iPad im Hochschulbetrieb - Konzeption und Implementierung eines E-Learning Moduls zur Lehrveranstaltung ""Programmieren""";
01.09.10;01.12.10;2010;intern;Bachelor;DE;Evaluierung und Implementierung von Partitionierungsalgorithmen und simulated annealing Algorithmen zur Lösung des dreidimensionalen Packproblems im Kontext des VLSI-Chipplacements;
01.09.10;24.11.10;2010;intern;Bachelor;DE;Evaluierung und Implementierung von floorplanning- und genetischen Algorithmen zur Lösung des 3Dimensionalen Packproblems im Kontext des VLSI-Chipplacements;
20.09.10;20.03.11;2010;intern;Master;EN;Study about the usage and structure of JavaScript in web applications;
20.09.10;20.12.10;2010;extern;Bachelor;DE;Prototypische Realisierung einer applikationsübergreifenden Suchkomponente für das IN-Web-Portal;
01.10.10;28.02.11;2011;extern;Bachelor;DE;Zutrittskontrollierte Besucherführung in Gebäuden mit Smartphones auf Android Basis<br><br>;
01.10.10;14.03.11;2011;extern;Master;EN;Concept for a Virtual Maschine Monitor for an Embedded System;
05.10.10;10.01.11;2011;intern;Bachelor;DE;Automatische Erkennung von Musik-Genres - Schwerpunkt Merkmalsberechnung;
05.10.10;10.01.11;2011;intern;Bachelor;DE;Automatische Erkennung von Musik-Genres - Schwerpunkt Klassifikation;
11.10.10;14.03.11;2011;extern;Bachelor;DE;Entwicklung und Untersuchung einer WLAN-Lokalisierung mit zentraler Positionsbestimmung;
11.10.10;11.03.11;2011;intern;Bachelor;DE;Spielend Lernen;
11.10.10;11.03.11;2011;intern;Bachelor;DE;Konzeption und prototypische Implementierung eines Gedächtnistrainers;
14.10.10;10.03.11;2011;extern;Bachelor;DE;ISO-konforme Prozessoptimierung der Kernprozesse im Leased Line Management bei Telefónica o2 Germany GmbH & Co. OHG;
14.10.10;08.04.11;2011;extern;Bachelor;DE;IT-gestützte Erkennung von Eingangsrechnungen - Praxisorientierte Technologiebewertung zur Entwicklung eines Modellkonzepts am Beispiel der DATEV eG;
14.10.10;08.03.11;2011;extern;Bachelor;DE;Ein Konzept zur Analyse und Visualisierung von Kennzahlen des Änderungsprozesses und dessen prototypische Implementierung bei Siemens Healthcare;
15.10.10;14.04.11;2011;intern;Bachelor;EN;Swarm Intelligence for Natural Language Engineering;
15.10.10;12.01.11;2011;extern;Bachelor;DE;Softwareergonomische Analyse und Redesign von existierenden Benutzerschnittstellen<br><br>;
15.10.10;14.03.11;2011;intern;Bachelor;DE;Dynamische Analyse von Dataraces mit Compilererweiterung für die Sprache X10;
18.10.10;15.03.11;2011;extern;Bachelor;DE;E-Mail-Archivierung als Zusatzdienst für das Dienstleistungsangebot DATEVnet: Machbarkeitsstudie mit besonderem Fokus auf Grundlagen und Integrationsmöglichkeiten;
18.10.10;14.03.11;2011;intern;Bachelor;DE;Notfallortung für Radfahrer;
18.10.10;15.04.11;2011;extern;Master;DE;Zielsystem-seitiger Native Code Compiler für eine Embedded Computer Plattform;
19.10.10;11.03.11;2011;extern;Bachelor;DE;Entwicklung eines projektbezogenen Personalplanungswerkzeugs;
21.10.10;21.04.11;2011;extern;Bachelor;DE;Konzept-Entwicklung zur automatischen Verifikation von 3D-Modellen;
21.10.10;10.03.11;2011;intern;Bachelor;DE;Nicht-formale Methoden bei der Modellierung von Informationssystemen;
22.10.10;14.03.11;2011;extern;Bachelor;DE;Planung, Design und prototypische Implementierung eines Werkzeugs zur Visualisierung von Kommunikationsdaten im Voice-over-IP-Umfeld;
23.10.10;26.04.11;2011;intern;Bachelor;EN;Evaluation of fast data transfer mechanism via PCle within a GPGPU based computation platform for a real-time localization;
25.10.10;18.03.11;2011;extern;Bachelor;DE;Eine Methodik zur Nutzung von IBM-Großrechneranwendungen als Web-Services und ihre prototypische Umsetzung;
25.10.10;25.01.11;2011;intern;Bachelor;DE;Verknüpfung von zusammengehörigen Linienobjekten in Geodatenbeständen;
27.10.10;11.03.11;2011;extern;Bachelor;DE;Zukunftsorientiertes Reporting im N-ENERGIE Konzern: Analyse und Bewertung von BI-Fronted-Tools auf Basis einer Anforderungsbasis;
27.10.10;14.03.11;2011;extern;Bachelor;DE;Performance-Analyse und Optimierung von hochverfügbaren Webseiten am Beispiel von hotel.de;
28.10.10;03.02.11;2011;extern;Bachelor;DE;Analyse verschiedener Kostenkalkulationstools und Empfehlung für das weitere Vorgehen im Outtasking Cente Chemnitz;
28.10.10;28.03.11;2011;extern;Bachelor;DE;Konzeption einer Kollaborationsplattform, in Form eines Microsoft Office Sharepoint Servers, zwischen der Europäischen Kommission und wirtschaftsprüfenden  Verbünden, für die Prüfung der Mittelverwendung des Forschungsrahmenprogramms ;
29.10.10;29.04.11;2011;intern;Bachelor;DE;Überprüfung der Vorhersagegenauigkeit von neuen Software-Zuverlässigkeitsmodellen;
29.10.10;11.03.11;2011;extern;Bachelor;DE;Konzeptionierung einer Portallösung für die Schadensregulierung in der Versicherungsbranche und prototyphaftige Umsetzung auf Basis des IBM WebSphere Portfolios;
29.10.10;29.03.11;2011;extern;Bachelor;DE;Entwurf und Entwicklung einer allgemeinen Software-Komponente zur Ansteuerung verschiedener Kameras;
29.10.10;28.04.11;2011;extern;Bachelor;DE;Redesign einer Open Source Monitoring Umgebung mit Fokus auf die Überwachung von Active Directory Services;
29.10.10;04.03.11;2011;extern;Bachelor;DE;Evaluierung der analytischen Anwendung „IBM Cognos“ zur Unterstützung eines kennzahlengestützten Haushalts- und Liquiditätsmanagements einer gesetzlichen Krankenkasse ;
29.10.10;14.03.11;2011;extern;Bachelor;DE;Entwicklung eines Konzepts zur Qualitätssicherung am Beispiel DATEVasp;
29.10.10;14.03.11;2011;extern;Bachelor;DE;Reorganisation des Anmeldeprozesses für Einspeiser und Konzeption eines SAP NetWeaver Portals mit Einbindung in die Systemlandschaft der N-ERGIE Netz GmbH ;
29.10.10;29.03.11;2011;intern;Bachelor;DE;Verwendung von GPGPU zur Audiobearbeitung in Echtzeit;
29.10.10;11.04.11;2011;intern;Bachelor;DE;Der „Message-Authentication-Mode CMAC“ & der „Authenticated-Encryption-Mode CCM” <br><br>;
29.10.10;14.03.11;2011;extern;Bachelor;DE;Konzipierung und Realsisierung eines Sicherheitskonzeptes;
29.10.10;29.04.11;2011;intern;Bachelor;DE;Integration des File System Cache (FS-Cache) in File System in Userspace (FUSE) im Linux Kernel;
30.10.10;14.03.11;2011;intern;Bachelor;DE;Konstruktion und Implementierung eines autonomen Robotik-Systems mit zwei interagierenden Steuergeräten;
31.10.10;28.04.11;2011;intern;Bachelor;DE;Integration eines Tools zur Modellierung zeitbehafteter Petri-Netze;
31.10.10;10.03.11;2011;intern;Bachelor;DE;Verwendung und Sicherheit von Speichermechanismen in Webbrowsern;
31.10.10;31.03.11;2011;extern;Bachelor;DE;Integration von Web 2.0-Technologien in Eclipse - Analyse und Konzeption am Beispiel von Wiki und Blog<br><br>;
31.10.10;14.03.11;2011;intern;Bachelor;EN;Hierachically Tiled Arrays in X10;
01.11.10;01.02.11;2011;extern;Bachelor;DE;Usability-Konzept für mobile Geschäftsanwendungen am Beispiel eines webbasierten Bestellsystems;
01.11.10;26.01.11;2011;intern;Bachelor;DE;Portierung einer Chipkarten API;
03.11.10;11.03.11;2011;extern;Bachelor;DE;psitrade - eCommerce Erweiterung für das WebCMS Contao;
15.11.10;16.05.11;2011;extern;Bachelor;DE;Entwicklung eines Python System Information API als Object Model Fronted zu C Bibliotheken;
15.11.10;15.02.11;2011;intern;Bachelor;DE;Marketingplan für ein Web-Content-Management-System für Sportvereine;
15.11.10;15.02.11;2011;intern;Bachelor;DE;"Erweiterung des Offline Filesystem (Ohm Filesystem) mit verzögertem Schreiben ""lazy write""";
15.11.10;14.02.11;2011;extern;Bachelor;DE;Analyse und Leistungsbewertung von Integrationsmöglichkeiten der Webanwendung Immowelt i-Tool in ausgewählte Cloud Architekturen;
16.11.10;29.04.11;2011;extern;Bachelor;DE;Entwurf und Implementierung eines allgemeinen Zertifikats-APIs;
17.11.10;17.02.11;2011;intern;Bachelor;DE;"Neugestaltung der Präsentation bisheriger Abschlussarbeiten der ""Ohm-Hochschule - Fakultät Informatik""";
25.11.10;24.02.11;2011;extern;Bachelor;DE;Evaluierung unterschiedlicher Build-Management-Systeme in einer Java-Enterprise-Edition-Umgebung;
28.11.10;26.05.11;2011;extern;Bachelor;DE;Entwicklung eines Systems zur Darstellung von relevanten Informationen eines Real-Time-Locating-System in Form eines Overlay GUI;
29.11.10;25.05.11;2011;extern;Master;DE;Automatisierung von Datenverteilungsaufgaben für ein Werkzeug zur Konstruktion im Anlagenbau;
01.12.10;25.02.11;2011;intern;Bachelor;DE;"Lokalisierung von Software; Fallstudie: Lokalisierung eines Deutschen Produkts für den gehobenen Mode-Handel in Russland";
01.12.10;01.03.11;2011;extern;Bachelor;EN;The Red Sea Dolphin Project - Development of an IT-infrastructure for cetacean research in the Read Sea;
01.12.10;24.02.11;2011;extern;Bachelor;DE;Erstellung eines Systems zur automatischen Analyse und Auswertung von Build-Prozessen;
01.12.10;28.02.11;2011;extern;Bachelor;EN;Spectrum Data Modeler;
01.12.10;01.03.11;2011;intern;Bachelor;DE;Softwareunterstütztes Management von Hard- und Software;
09.12.10;08.03.11;2011;intern;Bachelor;DE;Analyse und Bewertung von Software-Tools für das Wissensmanagement aus dem Open Source-Bereich;
09.12.10;10.03.11;2011;extern;Bachelor;DE;Optimierung des Access Management Prozesses für Softwareapplikationen bei Siemens Healthcare AX IT: Prozessanalyse und Entwicklung eines Soll-Prozesses mit prototypischer Tool-Umsetzung;
10.12.10;14.03.11;2011;extern;Bachelor;DE;Konzeption und prototypische Implementierung eines Bewerberportals auf Basis von Microsoft SharePoint;
15.12.10;15.07.11;2011;intern;Master;EN;Usability of Softwaremetrics to measure the Quality of JavaScript Code;
15.12.10;23.03.11;2011;intern;Bachelor;DE;Türkische Verbalmorphologie und Data Mining;
21.12.10;21.06.11;2011;extern;Master;DE;Implementierung eines Konfigurationstools in C# für die Entwicklung von neuen PROFINET-Geräten auf Basis von PROFINET Development-Kit;
03.01.11;08.04.11;2011;extern;Bachelor;DE;Konzept für ein optimiertes und toolgestütztes Planungs- und Berichtswesen im Testmanagement<br><br>;
10.01.11;18.07.11;2011;extern;Bachelor;DE;Modellierung zur Unterstützung der Entwicklungsarbeiten im Bereich Smart Objects Technologien am Fraunhofer Zentrum für Intelligente Objekte;
17.01.11;17.07.11;2011;extern;Bachelor;DE;Entwicklung einer Datenbankanwendung zur effizienten Abwicklung von Reklamationen;
24.01.11;;2011;intern;Bachelor;DE;Eingebettete Datenbank für Metadaten eines Dateisystems im Offline File System;
27.01.11;31.10.11;2011;extern;Bachelor;DE;Das Modul Bestellwesen in einer Kassen und Warenwirtschaftssoftware. Fachliches Konzept und Entwicklung;
27.01.11;27.07.11;2011;extern;Bachelor;DE;Ein virtuelles Dateisystem zur Diagnose von Kraftfahrzeugen mit Diagnostic-Communication over Internet Protocol<br><br>;
03.02.11;28.07.11;2011;extern;Bachelor;DE;Analyse und Konzeption einer webbasierten Immobilienmakler-Software – Relaunch des Produktes Estate Mobile der Immowelt AG;
14.02.11;30.05.11;2011;intern;Bachelor;DE;Konzeption und Implementierung eines „Online Schwarzen Bretts“ mit Silverlight auf Basis der Serviceorientierten Architekturen;
18.02.11;09.08.11;2011;extern;Bachelor;DE;Eine interaktive Oberfläche zur Darstellung der verschiedenen XML-Standards für Immobilien;
01.03.11;25.08.11;2011;intern;Bachelor;DE;Augmented Reality - Kritische Analyse der Einsatzpotenziale und Marktchancen;
08.03.11;26.08.11;2011;extern;Master;DE;Analyse von Best Practice Ansätzen in der IT zur Einführung eines Qualitätsmanagementsystems nach ISO 9001 und Entwicklung eines für die Siemens AG optimierten Einführungskonzeptes im IT-Bereich der IA unter Berücksichtigung der Siemens Qualitätskriterien;
09.03.11;27.09.11;2011;extern;Bachelor;DE;Automatische Vermessung von Golfschwüngen durch Videoanalyse und Synchronisation mit weiteren Messverfahren;
11.03.11;12.09.11;2011;extern;Master;DE;Portierung des OPC UA Kommunikationsstacks und Implementierung eines OPC UA Servers auf embedded Linux;
14.03.11;14.09.11;2011;extern;Bachelor;DE;Benchmarking von Softwareentwicklungsprozessen, insbesondere Benchmarking der Entwicklung mit Frameworks zur Erstellung graphischer Oberflächen;
15.03.11;15.08.11;2011;extern;Bachelor;DE;Auswahl und Implementierung eines Algorithmus zur Platzierung von WLAN-Access-Points zur Verbesserung einer Fingerprinting-Ortung;
15.03.11;15.08.11;2011;intern;Bachelor;DE;Analyse und Visualisierung von Tracking in Webanwendungen;
15.03.11;26.08.11;2011;extern;Master;DE;Analyse und Auswirkungen der Vollmachtsdatenbank auf die Produktlinie „DATEV Eigenorganisation comfort pro“ durch Konzeption potenzieller Produkt- bzw. Prozessänderungen ;
29.03.11;23.08.11;2011;intern;Bachelor;EN;Global Software Engineering;
30.03.11;29.09.11;2011;intern;Master;DE;Analyse des Einsatzes und der Wirtschaftlichkeit von Open Source Business Intelligence Lösungen in kleinen und mittleren Unternehmen;
30.03.11;29.09.11;2011;extern;Master;DE;Konzeption und Entwicklung eines Standard Data Warehouse für Microsoft ERP-Systeme Navision und Axapta mit dem Focus auf die Finanzbuchhaltung;
31.03.11;27.09.11;2011;extern;Master;DE;Telefonie-Anbindung mit Freisprecheinrichtung auf einer MeeGo Linux Plattform;
01.04.11;21.09.11;2011;extern;Master;DE;"Konzeption von logistischen Assistenzsystemen auf Basis einer EPCIS-Datenbank für den UseCase ""Lange Prozesskette"" im Rahmen des Forschungsprojekts RFID-BASED ATUOMOTIVE NETWORK";
07.04.11;07.09.11;2011;intern;Bachelor;DE;Augmented Reality: Kommerzielle Einsatzmöglichkeiten und Herausforderungen;
08.04.11;08.09.11;2011;extern;Bachelor;DE;Analyse der Informationsflüsse auf Aufzeigen von Optimierungspotentialen im Informationsmanagement eines operational Business Intelligence Systems am Beispiel von „Projekt Cockpit“ der Siemens AG, E F ES (Energy Solutions);
11.04.11;09.09.11;2011;intern;Bachelor;DE;Imitation der Körperhaltung durch einen humanoiden Roboter;
11.04.11;12.09.11;2011;extern;Bachelor;DE;Analyse und Weiterentwicklung von softwaregestützten agilen Prozessen in einem mittelständischen IT-Dienstleistungsunternehmen;
11.04.11;11.09.11;2011;intern;Bachelor;DE;Objektorientierte Prinzipien in Datenbanken: Die objektrelationalen Fähigkeiten von IBM DB2 und Oracle Enterprise;
14.04.11;30.09.11;2011;extern;Master;DE;Konzeption und Entwickklung eines Prototypen zur dreidimensionalen Modellierung und Visualisierung von intralogistischen Anlagen;
15.04.11;15.09.11;2011;intern;Bachelor;DE;Verbindungsplanung im Nahverkehr mit Open-Street-Map-Daten;
15.04.11;15.09.11;2011;extern;Bachelor;DE;Konzeption und Implementierung von Business Rules in ST4 zur semantischen Validierung von Informationsbausteinen;
15.04.11;16.08.11;2011;intern;Bachelor;DE;Konzeption und Entwicklung eines Frameworks zur Anpassung von Datenstrukturen der Standardsoftware Microsoft SharePoint;
18.04.11;09.08.11;2011;extern;Bachelor;DE;Entwicklung einer Smartphone-Anwendung zur Nutzung von Webservices aus dem Hosting-Bereich;
18.04.11;19.09.11;2011;extern;Bachelor;DE;Konzipierung und Prototypische Realisierung einer relationalen SQL-Datenbanklösung inklusive User-Front-End zur Regressabwicklung bei einem Unternehmen der Automobilzulieferbranche;
19.04.11;19.09.11;2011;extern;Bachelor;DE;"Analyse, Design und Implementierung eines Software-Wizards für ein Software Starter Kit der PC-basierten Steuerung  ""Embedded Controller"".";
21.04.11;21.09.11;2011;extern;Bachelor;DE;Hochverfügbare Standortvernetzung mit statischem Routing auf Basis von Open-Source-Software;
28.04.11;28.09.11;2011;extern;Bachelor;DE;Statistische Verfahren und Kenngrößen zur Evaluierung der Performance funkbasierter Lokalisierungssysteme;
28.04.11;28.07.11;2011;extern;Bachelor;DE;Testautomatisierung mit dem DATEV Automation Framework - Integrationsansätze und Übergangslösungen;
29.04.11;29.10.11;2011;intern;Master;DE;Ein Personenverfolgungsmodul für humanoide Roboter;
01.05.11;30.09.11;2011;extern;Diplom;DE;Untersuchung der Schnittstelle zwischen Requierements Management Tools und Testautomatisierung;
01.05.11;28.11.11;2011;extern;Master;DE;Ermittlung der Einsatzpotentiale und -grenzen von Portalen in ERP-Systemen am Beispiel des Geschäftsprozess Verkauf und der Entwicklung eines Prototypen mittels Liferay.;
01.05.11;30.09.11;2011;extern;Bachelor;DE;Strukturierte Integration tabellarischer Unternehmensdaten;
02.05.11;30.09.11;2011;extern;Bachelor;DE;Untersuchung des Total Cost of Ownership Ansatzes beim Einsatz eines SAP Business Intelligence Systems;
02.05.11;;2011;intern;Bachelor;DE;Konzeption und Realisierung eines Konfigurators für Antriebssysteme mit SAP Variantenkonfiguration auf der Grundlage vorhandener Produktkonfigurationen;
02.05.11;29.09.11;2011;extern;Bachelor;DE;Konzeption und Realisierung eines Konfigurators für Antriebssysteme mit SAP Variantenkonfiguration auf der Grundlage vorhandener Produktionsfigurationen;
09.05.11;27.09.11;2011;extern;Master;DE;Konzeption zur Einführung der Module Produktionsplanung und Materialwirtschaft des ERP-Systems Microsoft Dynamics NAV bei einem Produktionsunternehmen;
10.05.11;29.09.11;2011;extern;Bachelor;DE;Implementierung einer Configuration Management Data Base (CMDB) in einem Unternehmen - Machbarkeitsstudie und Wirtschaftlichkeitsrechnung unter Beachtung der Migration bestehender Datenbestände mit DMDB-Relevanz;
11.05.11;11.10.11;2011;intern;Bachelor;DE;Berechnung von kürzesten Wegen unter Berücksichtigung von Flächen;
12.05.11;10.11.11;2011;intern;Master;DE;Marktstudie und Nutzenanalyse von analytischen CRM-Systeme;
21.05.11;21.11.11;2011;intern;Master;DE;Design und Implementierung einer Qt-kompatiblen Audio-Komponente auf Basis von SDL<br>;
25.05.11;27.09.11;2011;intern;Bachelor;DE;Entwicklung einer Online-Marketing Strategie für ein Webportal;
01.06.11;28.09.11;2011;extern;Bachelor;DE;Machbarkeitsanalyse von BPM in KMUs, am Beispiel des Rechnungseingangsprozesses;
15.06.11;30.09.11;2011;extern;Bachelor;DE;Reporting innerhalb von Franchise-Organisationen: Standardisierung von Datenaustauschstrukturen mittels XBRL-Taxonomien;
20.06.11;14.11.11;2011;extern;Bachelor;DE;Prozessanalyse und -modellierung zur Auswahl eines Projektmanagementsystems für technische Dienstleistungen;
26.06.11;26.09.11;2011;extern;Bachelor;DE;Konzeption und Entwicklung eines Trainingsmoduls aus dem Bereich „Siemens Remote Service“<br>für Servicetechniker von medizinischen Anlagen bei der Siemens AG Sektor Healthcare<br>;
21.07.11;20.12.11;2011;intern;Bachelor;DE;Inkrementelles Erzeugen von Proof-Obligations in maschinengestützer, formaler Programmverifikation auf Basis des Hoare-Kalkül und JML;
22.07.11;30.09.11;2011;extern;Bachelor;DE;Entwicklung und Implementierung eines Verfahrens zur automatischen Bestimmung des Abbildungsmaßstabs von Computertomographieaufnahmen;
25.07.11;24.01.12;2011;intern;Master;DE;Entwicklung und Implementierung sinogrammbasierter Korrekturen in der industriellen Computertomographie;
29.07.11;09.01.12;2011;intern;Bachelor;DE;Kahlschlag: Welche Umweltschäden verursacht Werbung im Internet;
29.07.11;29.12.11;2011;extern;Bachelor;DE;Entwicklung und prototypische Umsetzung von Key Performance Indikatoren für ein IT-Infrastruktur-Cockpit;
08.09.11;07.03.12;2011;extern;Master;DE;Fachliche und technische Detaillierung und Dokumentation ausgewählter Kerngeschäftsprozesse eines Online-Versandhandels- Anpassung der IT-Lösung Mail-Order-IT der Firma Prisma informatik GmbH für die Automotive-Branche;
14.09.11;13.03.12;2011;extern;Master;DE;Konzept zur agilen Geschäftsprozessanalyse im Rahmen des Requirements Engineerings in der Marktforschungsbranche;
27.09.11;10.02.12;2011;extern;Master;DE;Konzeption eines Governance Frameworks zur Durchsetzung von IT-Richtlinien im Softwareentwicklungsprozess<br><br>;
28.09.11;28.02.12;2011;extern;Bachelor;DE;Benchmarking von Softwareentwicklungsprozessen. Insbesondere Benchmarking der Entwicklung mit dem Framework für iOS und Android;
01.10.11;10.04.12;2012;extern;Bachelor;DE;Tool zur Optimierung von Testausfallauswahl;
01.10.11;29.02.12;2012;extern;Bachelor;DE;Strategie zur umgebungsabhängigen Auswahl von Referenzpunkten für ein stadtweites WLAN-Fingerprinting Verfahren;
05.10.11;03.04.12;2012;extern;Master;DE;Realisierung einer Audio-Konferenzbrücke mit reduzierter Rechenlast durch Detektion der aktiven Speicher;
06.10.11;06.03.12;2012;extern;Bachelor;DE;Konzeption eines Standardprozesses zur Pflege des Artikelstamms eines internationalen Marktforschungsunternehmens;
06.10.11;06.03.12;2012;intern;Bachelor;DE;Produktions- und Bedarfsplanung bei der Einführung einer neuen Kraftstoffsorte – Erläuterungen und Ausführungen am Beispiel des Benzin-Ethanol-Kraftstoffs E10;
10.10.11;09.03.12;2012;extern;Bachelor;DE;Entwicklung eines generischen Frameworks zur Automatisierung von Komponenten-, System- und Integrationstests;
10.10.11;10.02.12;2012;extern;Bachelor;DE;Erstellung von Berichten im Umnfeld der Verbrauchsabrechnung für Rechenzetrumsleistung - Tagesverarbeitung, Systemzustände und hierarchische Sicht für den Vertrieb;
12.10.11;30.01.12;2012;extern;Bachelor;DE;Vergleich von Theorie und praktischer Umsetzung agiler Softwareentwicklung am Beispiel Agile Core und Agile Plus anhand ausgewählter Projektteams der IBM;
14.10.11;14.03.12;2012;intern;Bachelor;DE;Statistische Analyse und Optimierung von Webseiten;
14.10.11;02.03.12;2012;intern;Bachelor;DE;Analyse der Marketingsituation der Videospielbranche in Deutschland und Konzeption einer Werbekampagne;
17.10.11;13.03.12;2012;extern;Master;DE;Konzeption und Entwicklung einer mobilen Anwendung für die Tourismusbranche;
17.10.11;14.03.12;2012;extern;Bachelor;DE;Konzeption und Entwicklung von SharePoint2010 Templates zur verbesserten Unterstützung von Business Cases;
18.10.11;01.03.12;2012;extern;Bachelor;EN;System and method to generate a physical database design for Netezza parallel database appliance based on queryhistory;
19.10.11;19.03.12;2012;extern;Bachelor;DE;Analyse, Optimierung und Reorganisation von Prozessen am Beispiel der DATEVasp-Projektierung;
19.10.11;12.03.12;2012;extern;Bachelor;DE;Evaluation der verschiedenen Möglichkeiten der Lastermittlung und Prozessverteilung in einem Rechencluster;
20.10.11;14.03.12;2012;extern;Bachelor;DE;Einzug von Consumer Electronic Geräten Geräten in Fahrzeug-Infotainment-Systeme;
21.10.11;21.04.12;2012;intern;Master;DE;Conversion Tracking bei Webanwendungen;
22.10.11;13.03.12;2012;extern;Bachelor;DE;Analyse der Anforderungen und Entwicklung eines Prototypen für einen mobilen Zugang zum Siemens Industry Internet;
24.10.11;14.03.12;2012;extern;Bachelor;DE;Entwurf und Implementierung der Prozessvisualisierung einer Biogasanlage;
25.10.11;24.04.12;2012;extern;Master;DE;Konzeption zur Portierung einer bestehenden Webseite auf mobile Endgeräte;
28.10.11;28.03.12;2012;extern;Bachelor;DE;Analyse und Bewertung von Methoden zur fachlichen Entwicklung einer IT-Anwendungsarchitektur am Beispiel der DATEV eG;
28.10.11;13.03.12;2012;extern;Bachelor;DE;Konzeption und Implementierung einer Suchmaschinenoptimierung durch Web-Widgets am Beispiel der Immowelt AG;
31.10.11;21.02.12;2012;extern;Bachelor;DE;Entwicklung einer Kommunikations- und Darstellungssoftware für ein UNIX-basiertes SCADA-System der Netz- und Stationsleittechnik auf der Plattform Android;
01.11.11;29.02.12;2012;intern;Bachelor;DE;Synergiepotenzial zwischen SOA und SaaS im Kontext der Anforderungen an ein ERP-System<br><br>;
02.11.11;03.05.12;2012;extern;Master;DE;Spezifikation und Komplexitätsbewertung von Produktlinien;
02.11.11;06.03.12;2012;extern;Bachelor;DE;Analyse eines Frameworks zur graphischen Modellierung im Produktdatenmanagement;
02.11.11;08.03.12;2012;extern;Bachelor;DE;Qualitätsmangement im Requirements Engineering - Entwicklung eines innovativen QS-Prozesses bei der SOPHIST GmbH;
03.11.11;03.05.12;2012;extern;Master;DE;Fachkonzept und IT-Konzept einer Scannerkassen-Software. Detaillierung der branchenübergreifenden POS-Basisfunktionalitäten und der Schnittstelle zum ERP-System „MS Dynamics NAV“;
03.11.11;29.03.12;2012;extern;Bachelor;DE;Konzeption und Realisierung einer mobilen Lohnerfassung für die Baubranche;
07.11.11;13.03.12;2012;intern;Bachelor;DE;Internes IT-Marketing - Übersicht über genutzte und ungenutzte Potenziale der absatzpolitischen Instrumente;
09.11.11;04.04.12;2012;extern;Bachelor;DE;Dynamischer Test der Software-Schnittstellenkomponenten in KFZ-Steuerelektronik;
14.11.11;14.03.12;2012;extern;Bachelor;DE;Übertragung großer Datenmengen in einer Service-orientierten Architektur;
14.11.11;14.03.12;2012;intern;Bachelor;DE;Parallelisierung endlicher Automaten am Beispiel XML Scanner/Tokenizer;
14.11.11;13.03.12;2012;extern;Bachelor;DE;Redesign einer Wörterbuch-Webanwendung mit gleichzeitiger Portierung von Java nach .NET;
15.11.11;14.03.12;2012;extern;Bachelor;DE;Entwurf eines IEC62304-konformen agilen Medizintechnik-Entwicklungsprozesses unter Verwendung des Prozessframework Scrum;
17.11.11;29.02.12;2012;extern;Bachelor;DE;Neukonzeption und -entwicklung einer HR Geschäftsanwendung;
18.11.11;16.04.12;2012;intern;Bachelor;DE;Imitation menschlicher Bewegungsabläufe durch einen humanoiden Roboter unter Einsatz einer Tiefensensorkamera;
22.11.11;21.04.12;2012;extern;Bachelor;DE;Optimierung der Arbeitsplanung von mobilen Pflegediensten durch automatische Erstellung von Leistungsnachweisen;
24.11.11;12.04.12;2012;intern;Bachelor;DE;Die Erschließung zukunftsorientierter Geschäftsfelder durch Anwendung von E-Business in verschiedenen Branchen;
24.11.11;20.04.12;2012;extern;Bachelor;DE;Konzeption, Modellierung und Implementierung eines Business Intelligence Prototyps im Bereich Road-Services der Spedition Geis;
01.12.11;29.05.12;2012;extern;Master;DE;Implementierung und Evaluierung eines TCP/IP-Stapels mit IPv6-Unterstützung auf einem Embedded-Gerät;
01.12.11;31.05.12;2012;extern;Master;EN;Future concepts for smart and scalable access to digital media content in global companies;
01.12.11;30.04.12;2012;intern;Bachelor;DE;Entwicklung einer effizienteren Texteingabe für Smartphones;
01.12.11;12.03.12;2012;extern;Bachelor;DE;Proof of Concept: Aufbau eines Stateless IPv4/IPc6 Address Translators (IVI) für die Kommunikation vom IPv4-basierten Internet-Clients mit IPv6-only Services;
01.12.11;13.03.12;2012;extern;Master;DE;Einführung eines ESB-Systems bei einem Versandhändler am Beispiel der Kommunikation zwischen Onlineshop und ERP/CRM System.;
05.12.11;30.04.12;2012;extern;Bachelor;EN;User Experience - Analytics for Business Software;
06.12.11;14.03.12;2012;extern;Bachelor;DE;Prototyp eines Kfz-Infotainment-Systems auf GENIVI-Basis auf einer embedded Plattform;
06.12.11;05.03.12;2012;extern;Bachelor;DE;Analyse und Bewertung von Replikationsstrategien für eine hochskalierbare Active Directory Lightweight Directory Services (AD LDS) Umgebung;
08.12.11;14.03.12;2012;extern;Bachelor;DE;Konzeption softwaregestützter Prozessoptimierung des Projekt- und Multiprojektmanagements bei hotel.de.;
09.12.11;14.03.12;2012;extern;Master;DE;Konzept und prototypische Implementierung einer Business Intelligence-Standardlösung;
15.12.11;15.05.12;2012;extern;Bachelor;DE;Untersuchung der möglichen Einflussmöglichkeiten und Auswirkungen auf die Performance der DATEV-Anwendungen durch das Anbringen der Codesignatur;
15.12.11;15.05.12;2012;intern;Bachelor;DE;SEO als Marketinginstrument für eine Unternehmensbertung;
15.12.11;13.06.12;2012;extern;Master;DE;Entwicklung und Implementierung einer Softwareanwendung für die Thermographieprüfung an LEDs und Wafern;
16.12.11;15.06.12;2012;extern;Master;DE;Integration mobiler HTML-5-Anwendungen bei der DATEV eG<br><br>;
20.12.11;05.05.12;2012;intern;Bachelor;EN;Autonomously detecting an picking up scattered objects: design and implementation of a module for humanoid robots<br><br>;
20.12.11;01.06.12;2012;extern;Master;DE;Serious Gaming - Konzeptionelle Entwicklung und prototypische Umsetzung eines Lernspiels zur Vermittlung von ausgewählten COBIT-Inhalten anhand eines lerntheoretischen Ansatzes<br><br>;
20.12.11;20.05.12;2012;extern;Bachelor;DE;Automatisierte Erzeugung. Verteilung und Installation von Linux-Images in virtualisierte Umgebungen<br><br>;
21.12.11;18.06.12;2012;extern;Bachelor;DE;Aufbau von Testumgebungen für automatisierte Tests in verteilten Szenarien<br>;
21.12.11;21.05.12;2012;extern;Bachelor;DE;Evaluation von Test-Tools für ASP.NET MVC3 Anwendungen bei hotel.de<br>;
22.12.11;20.07.12;2012;extern;Master;DE;Konzeption und Realisierung einer Standard Berichtslösung und eines Kenntzahl-Cockpits für die Versandhandelsbranche<br><br>;
13.01.12;12.06.12;2012;extern;Bachelor;DE;Konzipierung und Realisierung einer Client-Server-Datenbanklösung inklusive User-Front-End zur Haushaltsstrukturprüfung von Kommunen;
16.01.12;14.03.12;2012;extern;Bachelor;DE;Analyse, Erweiterung und Optimierung eines verteilten Test-Mangement-Systems in einem akkreditierten Prüflabor;
19.01.12;03.09.12;2012;extern;Master;DE;Entwicklung einer standardisierten Controllinglösung für kleine und mittelständische Unternehmen;
19.01.12;19.07.12;2012;extern;Master;DE;Webanwendung und iPhone App für den mobilen Zugriff auf das Störungsmanagementsystem einer EAM-Applikation;
01.02.12;31.05.12;2012;extern;Bachelor;DE;Projektmanagement - Symbiose zwischen klassischen Projektmanagement und agilen Methoden von Scrum;
01.02.12;29.06.12;2012;extern;Bachelor;DE;HTML-5 Anwendungen: Nutzung der offline Storage;
08.02.12;06.06.12;2012;intern;Bachelor;DE;Analyse von Race Conditions in WebSeiten;
17.02.12;17.07.12;2012;extern;Bachelor;DE;Konzeption und Implementierung einer Infrastruktur zur Übertragung und Speicherung großer Mengen von Sensodaten;
20.02.12;20.07.12;2012;extern;Bachelor;DE;Analyse und Erweiterung eines Projekt-Management Tools;
01.03.12;31.07.12;2012;extern;Bachelor;DE;Entwicklung einer modularen Medienverwaltung für DCPs;
13.03.12;21.08.12;2012;intern;Bachelor;DE;Potenziale einer Data-Warehous basierten Unternehmensplanung;
15.03.12;09.08.12;2012;extern;Bachelor;DE;Entwicklung einer Software zur Generierung von interaktiven Diagrammen;
15.03.12;03.08.12;2012;extern;Bachelor;DE;Konzeption einer Festfallverwaltung für Siemens-Anlagen - Bedien- und Beobachtungsanlagen;
15.03.12;27.07.12;2012;extern;Bachelor;DE;Automatisierte Erkennung von Tracking im Web;
15.03.12;05.09.12;2012;extern;Master;DE;Evaluation von Wettbewerbsvorteilen für die Brand Community myAudi durch die Nutzung von telemetrischen Diensten;
19.03.12;16.08.12;2012;extern;Bachelor;DE;Discovery, Monitoring und Statusvisualisierung in einer komplexen Multi-Vendor-Loadbalancer-Umgebung;
19.03.12;18.08.12;2012;extern;Bachelor;DE;Konzeption und Implementierung einer Schnittstelle zwischen dem Immowelt i-Tool und Microsoft Office 365 Cloudlösung;
20.03.12;18.09.12;2012;intern;Master;DE;Konzeption und Realisierung einer textuellen und räumlichen Suche von Geo-Objekten auf Smart-Phones;
20.03.12;20.08.12;2012;intern;Bachelor;DE;Zugriffsbeschränkungen für Webapplikationen mit Parameterized Views in einer PostreSQL-Datenbank;
22.03.12;11.07.12;2012;intern;Bachelor;DE;Programmierung eines Steuerungsmoduls für den humanoiden Roboter Nao zur Durchführung gezielter Minigolfschläge;
23.03.12;07.09.12;2012;extern;Master;DE;Manuelle und automatisierte Tests mobiler Anwendungen für Smartphones und Tablet-Computer - Herangehensweisen, Herausforderungen und Unterschiede zu herkömmlichen Tests.“<br>;
26.03.12;27.08.12;2012;intern;Bachelor;DE;Konzeption und Implementierung eines interaktiven Szenarios mit einem humanoiden Roboter;
27.03.12;27.08.12;2012;intern;Bachelor;DE;Softwarezuverlässigkeit - Parameterschätzung und Überprüfung der Vorhersagegenauigkeit bei Vorliegen gruppierter Daten;
30.03.12;21.08.12;2012;intern;Bachelor;DE;Generierung von Flächen aus einzelnen Linienobjekten in Geodatenbeständen;
30.03.12;30.09.12;2012;extern;Master;DE;Berechnung von kürzesten Wegen unter Berücksichtigung von Flächen;
30.03.12;30.08.12;2012;intern;Bachelor;DE;IT-Leistungsverrechnung - Aufgaben, Methoden und Entwicklungen<br><br>;
30.03.12;28.09.12;2012;extern;Bachelor;DE;Entwurf und Implementierung eines Tools zur Migration von Datenbeständen nach DATEV-DMS<br><br>;
30.03.12;30.09.12;2012;extern;Master;DE;Sichere (secure) elektrische Ladesäule<br><br>;
30.03.12;28.09.12;2012;extern;Master;DE;Modellierung von Geschäftsprozessen in Steuerkanzleien mit DATEV-Software - Integration der BPMN in die Workflow-Umgebung DATEV ProCheck pro-<br><br>;
01.04.12;29.08.12;2012;extern;Bachelor;DE;Entwicklung und Anwendung eines Prozessmodells für Aufwandssmimulation in der Forschung und Entwicklung;
01.04.12;27.09.12;2012;extern;Master;DE;Konzeption eines Systems zum standardisierten Entwurf von Prozessmodellen in Fachabteilungen - Analyse und Design des MID Prozess Engineering Frameworks -<br><br>;
01.04.12;19.09.12;2012;extern;Master;DE;Entwicklung eines modularen Vorgehensmodells zur Einführung von Wissensmanagement - Modellentwicklung auf Basis aktueller Literatur und empirischen Umsetzungsverfahren der IPI GmbH<br><br>;
01.04.12;24.09.12;2012;extern;Master;DE;Analyse des Planungsprozesses bei Siemens Healthcare und Evaluierung von Planungswerkzeugen;
01.04.12;24.09.12;2012;extern;Master;DE;Erarbeitung eines Konzepts zur Sicherstellung der nachhaltigen Datenqualität im zentralen Enterprise Architecture Repository bei Siemens<br><br> <br><br>;
01.04.12;31.08.12;2012;extern;Bachelor;DE;Bereitstellung eines E-Shops für mobile Endgeräte;
01.04.12;20.09.12;2012;extern;Master;DE;Serviceorientierte Client-Architektur mit HTML5 - Konzeption und prototypische Realisierung am Beispiel der Online-Anwendung Belege der DATEV eG<br><br>;
01.04.12;30.08.12;2012;extern;Bachelor;DE;Selfservice-Toolset zur Administration von Cisco-Komponenten im WAN-Bereich;
02.04.12;20.08.12;2012;extern;Bachelor;DE;"Integration von Risikomanagementaspekten in die Geschäftsprozessmodellierung mit ""Innovator für Business Analysts""<br><br>";
02.04.12;27.09.12;2012;extern;Master;DE;Entwurf und Implementierung eines CA-Webservices in C#;
02.04.12;30.08.12;2012;extern;Bachelor;DE;Bewertung und Konzeption des Demand-Portfolio-Managements bei der Siemens AG, I IA IT und Einsatz einer unterstützenden BI-Software am Beispiel von QlikView.<br><br>;
04.04.12;25.09.12;2012;extern;Bachelor;DE;Ermittlung und Analyse der Bedarfsanforderungen eines mittelständischen Unternehmens an ein SAP CATS Modul;
12.04.12;12.09.12;2012;intern;Bachelor;DE;studierBar - Entwicklung einer App für das Schülermarketing;
12.04.12;12.09.12;2012;intern;Bachelor;DE;Anwendung von Methoden des Requirements Engineering für BI Systeme an Hochschulen<br><br><br><br>;
12.04.12;12.09.12;2012;extern;Bachelor;DE;Design und Implementierung eines Frameworks zur effizienten Konsolidierung von Testergebnissen in der Automobilindustrie;
15.04.12;15.10.12;2012;intern;Master;EN;Combinatorial problem solving and optimization on GPUs;
16.04.12;21.08.12;2012;extern;Master;DE;Variantenkonfiguration mit produktionssynchronen Abrufen am Beispiel Johnson Controls;
16.04.12;15.10.12;2012;extern;Master;DE;Kryptographischer Coprozessor für Automatisierungssysteme;
16.04.12;14.09.12;2012;extern;Bachelor;EN;Gamification in a B2B Environment - How to make it fun working with business intelligence data on an mobile app.;
17.04.12;17.09.12;2012;extern;Bachelor;DE;Konzeption und prototypische Realisierung eines Testframeworks für eine Medizinsoftware;
18.04.12;14.09.12;2012;extern;Bachelor;DE;Prozessmodellierung zur Abteilung von Anforderungen an ein technisches Assistenzsystem für die Betreuung alter Menschen;
19.04.12;19.09.12;2012;extern;Bachelor;DE;Konzeption und prototypische Umsetzung einer datenbankbasierten Applikation zur Produktklassifizierung und Auswertung betriebswirtschaftlicher Kennzahlen bei der GfK<br><br>;
19.04.12;17.09.12;2012;extern;Bachelor;DE;Analysieren, manipulieren und visualisieren von Stammdaten für Planungszwecke<br><br>;
20.04.12;20.10.12;2012;extern;Master;DE;Konzeption und Realisierung eines Reporting Cockpits im Service Level Management der DATEV eG;
20.04.12;28.09.12;2012;extern;Master;DE;Konzipierung und prototypische Realisierung zentraler OLAP-Funktionen für mobile Endgeräte am Beispiel der Online-Datensicherung für Systempartner der DATEV eG;
23.04.12;22.10.12;2012;intern;Master;DE;Perspektivabhängige 3D-Darstellung mittels Kopf-Tracking und Stereoskopie;
23.04.12;21.09.12;2012;extern;Bachelor;DE;Integration und Evaluierung eines Usability-Prozesses in einen SCRUM-orientierten SW-Entwicklungsprozess;
26.04.12;26.09.12;2012;intern;Bachelor;DE;Berechnung von Isochronen auf Straßennetzen;
27.04.12;20.08.12;2012;extern;Bachelor;DE;Konzeption und Realisierung einer IT-Lösung zur Unterstützung der Prozesse des IT-Projektportfoliomanagements<br><br> <br><br>;
30.04.12;26.09.12;2012;extern;Bachelor;DE;Automatisiertes Extrahieren von Informationenüber virtuelle Maschinen aus Hypervisoren;
30.04.12;27.09.12;2012;extern;Bachelor;DE;Einführung und Analyse eines Business Intelligence Prozessmodells in dem Microsoft Sharepoint Server (MOSS) basierten Business Process Management-Modells Project4Sure (P4S);
30.04.12;28.09.12;2012;extern;Bachelor;DE;Automatisierte Messwerte Analyse;
30.04.12;28.09.12;2012;extern;Bachelor;DE;Analyse und Optimierung der Erstellung von Gehaltsdatenauswertungen auf dem IBM Mainframe der DATEV eG;
30.04.12;30.09.12;2012;extern;Bachelor;DE;Implementierung eines Dokumentenmanagementsystems für die zentrale Bereitstellung von Unternehmensrichtlinien und -prozeduren bei adidas AG;
01.05.12;01.10.12;2012;intern;Diplom;DE;Algorithmus zur Lokalisierung von Mustern in diskreten Audiosignalen;
01.05.12;26.09.12;2012;extern;Bachelor;DE;Modellierung und Implementierung der Projektmanagement-bezogenen Geschäftsprozesse der mediendesign AG;
01.05.12;27.09.12;2012;intern;Master;DE;Von der Anforderung hin zur qualitativen Software - Ein Ansatz zur Umwandlung von Anforderungen in Testfälle;
01.05.12;27.06.12;2012;extern;Bachelor;DE;Möglichkeiten und Nutzen für Auswerteapplikationen für Vicos RCS am praktischen Beispiel;
01.05.12;28.09.12;2012;extern;Bachelor;DE;Effiziente Implementierung der AUTOSAR Festpunktarithmetik Bibliothek ;
02.05.12;20.09.12;2012;extern;Bachelor;DE;Optimierung von verteilten Ereignisverarbeitungssystemen durch Umverteilung von Ereignis-Detektoren zur Laufzeit;
02.05.12;28.09.12;2012;extern;Master;DE;Design und Implementierung eines Konfigurations- und Diagnose-Proxy-Servers für eingebettete Systeme;
02.05.12;31.10.12;2012;extern;Master;DE;Konzeption und Implementierung einer komplexen HTML-Dokumentanzeige unter Verwendung von Entwurfsmustern für JavaSkript;
02.05.12;02.10.12;2012;extern;Bachelor;DE;Einsatz von Heimautomatisierung im häuslichen Umfeld für ein längeres selbstbestimmtes Leben;
15.05.12;;2012;extern;Master;DE;Entwicklung eines standardisierten Vorgehensmodells zur Anforderung für eine Anforderungsanalyse für eine Postaleinführung am Beispiel eines Energieversorgers;
15.05.12;25.09.12;2012;extern;Master;DE;Entwicklung eines standardiesierten Vorgehensmodells zur Anforderungsanalyse für eine Portaleinführung am Beispiel eines Energieversorgers;
18.05.12;26.09.12;2012;extern;Bachelor;DE;Planung, Programmierung und Implementierung einer Kommunikationskomponente für eine Pateientenunterstützungssoftware und Bewertung der Nützlichkeit dieser Software als Organisationshilfe im medizinischen Bereich;
20.05.12;20.11.12;2012;extern;Master;DE;"Entwicklung und Implementierung eines Befragungssystems für ""Car Clinics"" unter besonderer Berücksichtigung von mobilen Client Systemen";
21.05.12;18.10.12;2012;extern;Bachelor;DE;Auswahl und Implementierung eines Echtzeit-Betriebssystems für Libelium Waspmote Sensorknoten;
21.05.12;01.10.12;2012;extern;Bachelor;DE;Erarbeitung eines Konzepts zur Integration der Finanzsysteme einer deutschen Konzerntochter an den amerikanischen Mutterkonzern;
22.05.12;28.09.12;2012;intern;Bachelor;DE;Automatisches Lokalisieren und Annäherung an im freien Raum platzierte Objekte mit einem humanoiden Roboter;
30.05.12;;2012;intern;Bachelor;DE;Transskriptions- und Transrationsmethode vom arabischen ins lateinische Alphabet;
31.05.12;30.11.12;2012;extern;Master;DE;Entwurf eines Augmented Reality Toolkits für Windows Phone und die Verwendung in einer Demonstrations-Applikation;
01.06.12;02.11.12;2012;extern;Bachelor;DE;Sensobasierte Modellerstellung für die Simulation von industriellen Roboteranwendungen mit dem Microsoft Robotics Developer Studio;
04.06.12;28.09.12;2012;intern;Bachelor;DE;Indoor-Selbstlokalisierung eines autonomen Quadrocopters mit Methoden der Bildverarbeitung;
04.06.12;04.11.12;2012;intern;Bachelor;DE;Stand und Vision der Anwendungen des Semantic Web und deren betriebswirtschaftlicher Bedeutung - speziell Ontologien;
05.06.12;27.09.12;2012;extern;Bachelor;DE;Konzeption und Realisierung einer kundenspezifischen Verpackungsdatenbank für einen mittelständischen Automobilzulieferer;
14.06.12;;2012;intern;Bachelor;DE;Controlling und Monitoringwerkzeuge für Social Media Aktivitäten in der Unternehmenskommunikation;
21.06.12;20.11.12;2012;extern;Bachelor;EN;Analysis of the impact of Smart Home Applicances in combination with Photovoltaic Systems on monetary benefits and CO2-Emission for private households;
27.06.12;26.11.12;2012;extern;Bachelor;DE;Analyse und Konzeption eines Systems zur Verwaltung von Web-Hosting-Kunden auf Basis von MVC;
27.06.12;30.09.12;2012;extern;Bachelor;DE;Entwicklung einer universellen Eingabemaske für modellzentriertes Testen mit Interface zu verschiedenen UML-Werkzeugen;
29.06.12;29.12.12;2012;intern;Master;DE;Konzept und Implementierung eines Prototypen zur Verbesserung des Trendidentifikationsprozesses;
01.07.12;07.02.13;2012;extern;Master;DE;Mehrwert durch Multi-Touch-Anwendungen im Geschäftsfeld Steuern der DATEV eG;
13.07.12;12.12.12;2012;extern;Bachelor;DE;Entwicklung einer Android App zur Visualisierung von Sensordaten;
13.07.12;10.12.12;2012;extern;Bachelor;DE;Projektmanagement in Großunternehmen: Konzeption und prototypische Anwendung eines Pre-Project-Checks für die EBH GmbH;
17.07.12;17.01.13;2012;extern;Master;DE;"Evaluierung des SIMD Instruction Sets im Dual ARM Cortex A9 (""NEON Extensions"")";
18.07.12;18.12.12;2012;intern;Bachelor;DE;Soziale Plattform für einen Hobby-Feuerwerk-Club;
20.07.12;31.10.12;2012;extern;Bachelor;DE;Konzeption und Implementierung einer auf XSL-Templates basierenden Dokumentaufbereitung für unterschiedliche Endgeräte;
24.07.12;21.12.12;2012;intern;Bachelor;DE;Graphische Modellierung von Sicherheitsanforderungen in Geschäftsprozessen zur feingranularen Autorisierung in Webdatenbanken;
31.07.12;07.01.13;2012;extern;Bachelor;DE;Optimierung der Projektmanagementstrukturen im Bereich Consulting bei der DATEV eG;
01.08.12;02.11.12;2012;extern;Bachelor;DE;Entwicklung und Implementierung eines Vorgehens zur Auswertung thermographischer Aufnahmen von Mikrochips;
29.08.12;15.01.13;2012;extern;Bachelor;DE;Evaluierung der Rechtsvorschriften für einen Webauftritt am Beispiel einer Praxis für Coaching und Psychotherapie;
01.09.12;25.02.13;2012;extern;Bachelor;DE;Entwicklung eines Verfahrens zur Verzögerungs- und Genauigkeitsmessung von Head- und Facetracking Systemen;
14.09.12;13.03.13;2012;extern;Master;DE;Analyse und Konzeption einer Client-Virtualisierungslösung für das Landratsamt Fürth;
14.09.12;14.02.13;2012;extern;Bachelor;DE;Entwicklung eines Vorgehensmodells zur Pflichtenhefterstellung sowie von Pflichtenhefttemplates für ein mittelständisches Softwareentwicklungsunternehmen;
15.09.12;07.03.13;2012;extern;Master;DE;Entwicklung und Implementierung eines Kalibrierverfahrens für robotergestützte Computertomographiesysteme auf Basis von Röntgenprojekten;
17.09.12;14.02.13;2012;extern;Bachelor;DE;Erstellen eines Postprocessors für den Cause & Effect Editor;
26.09.12;14.03.13;2012;extern;Master;DE;Ausarbeitung einer BI-Strategie für ein mittelständisches Unternehmen auf Microsoft SQL Server 2012 unter Berücksichtigung von In-Memory- und OLAP-Verfahren;
28.09.12;28.03.13;2012;extern;Master;DE;Realisierung eines Softwaresystems zur Datenerfassung und Speicherung von Messwerten aus PV-Kraftwerken mit variabel konfigurierbaren Hardwareschnittstellen<br><br>;
28.09.12;06.03.13;2012;extern;Master;DE;Business Reporting einer Geschäftseinheit auf Basis von SAP BW - Evaluierung und Optmierung der Prozesse und Harmonisierung des Reportings;
01.10.12;13.03.13;2013;extern;Master;DE;Erkennung und Modellierung von Fahrbahnrändern für Straßen ohne Spurmarkierungen;
01.10.12;28.02.13;2013;extern;Bachelor;DE;Entwicklung und Implementierung eines Frameworks für dynamische Tests eingebetteter Software auf einer Zielplattform;
01.10.12;01.03.13;2013;extern;Bachelor;DE;Eine Windows 8-Anwendung für die gestengesteuerte Erstellung von Teilnehmerlisten;
01.10.12;01.03.13;2013;extern;Bachelor;DE;3D-Visualisierung von überlappenden Materialien bei der Reifenfertigung;
01.10.12;01.03.13;2013;extern;Bachelor;DE;"Konzeption und Implementierung eines Prozesses zur Erkennung von ""Megatrends"" im Rahmen des Innovationsmanagement im Bereich Business Development der DATEV e.G.";
01.10.12;18.02.13;2013;intern;Bachelor;DE;Implementierung eines Dateisystems und einer RAM-Disk für das Betriebssystem ULIX;
01.10.12;01.03.13;2013;intern;Bachelor;DE;Implementierung eines ELF-Programm-Loaders für das Betriebssystem ULIX;
01.10.12;01.03.13;2013;intern;Bachelor;DE;Evaluieren von Modellierungsmöglichkeiten für vorhandenen STEP7-Code und Beispielimplementierung mit C#;
05.10.12;05.03.13;2013;intern;Bachelor;DE;Evaluation von CRM Systemen: CRM for free: Was leisten Open Source CRM Systeme?;
08.10.12;05.03.13;2013;intern;Bachelor;DE;Warum scheitern CRM Projekte in der Praxis?;
09.10.12;09.03.13;2013;extern;Bachelor;DE;Konzeption und Implementierung einer projektübergreifenden Personaleinsatzplanung;
09.10.12;05.03.13;2013;intern;Bachelor;DE;Erkennung und Digitalisierung von Noten mit iOS und der iPad-Kamera;
10.10.12;08.03.13;2013;intern;Bachelor;DE;Konzeption und Realisierung eines Verfahrens für eine automatische Silbentrennung deutscher Wörter;
11.10.12;11.03.13;2013;extern;Bachelor;EN;3D Game Engine Comparison Educational Purpose;
12.10.12;12.03.13;2013;extern;Bachelor;DE;Analyse der Nutzung des Moduls Tectura Project bei der Firma Semikron Elektronik GmbH & Co. KG und Erstellung einer strategischen Handlungsempfehlung zur weiteren Implementierung;
12.10.12;08.03.13;2013;intern;Bachelor;EN;Design and Development of a Social Network Platform for Sports;
12.10.12;28.02.13;2013;extern;Bachelor;DE;Definition und Umsetzung eines Daten- und Anwendungsmodells zur Erfassung und Auswertung regional agierender Ressourcen zur Optimierung des Reportings, Siemens I IA AS;
12.10.12;12.03.13;2013;extern;Bachelor;DE;Ausarbeiten eines Vergleichs moderner Echtzeitsysteme und Anfertigen von geeigneten Referenzimplementierungen;
14.10.12;12.03.13;2013;extern;Bachelor;DE;Entwicklung einer E-Learning-Umgebung für den Siemens Healthcare Sektor AX;
14.10.12;14.03.13;2013;extern;Bachelor;DE;Konzeption und Entwicklung eines Intranet-Tools zur Verwaltung von Stammdaten;
15.10.12;14.03.13;2013;intern;Bachelor;DE;Konzeption und Entwicklung eines Werkzeugs zur Aktualisierung einer mobilen Zählererfassungssoftware;
15.10.12;11.04.13;2013;intern;Master;DE;Evaluierung und Implementierung eines Konzeptes für die autonome Orientierung eines humanoiden Roboters anhand potentieller Warnzeichen oder Gefahrensituationen;
15.10.12;14.03.13;2013;extern;Bachelor;DE;Erstellung eines Architektur Models für TenneT in Verbindung mit der Darstellung von Businessreport- und Technology Map für die Bereiche Netzführung sowie Energiedatenmanagement und Forderungsmanagement;
15.10.12;13.03.13;2013;extern;Bachelor;DE;Konzeption und Realisierung eines Informationsportals für Gewerbeimmobiliensuchende und -makler;
15.10.12;14.03.13;2013;extern;Bachelor;DE;Warteschlangenmodellierung zur Performancesimulation von Storage Systemen;
15.10.12;15.03.13;2013;intern;Bachelor;DE;Webanwendung für generatives Layout-Design;
15.10.12;14.03.13;2013;extern;Diplom;DE;Untersuchung und Realisierung der Synchronisation einer unternehmens- und anwendungsspez. zentralen SQL-Datenbank über verschiedene verteilte Standorte;
15.10.12;07.03.13;2013;extern;Bachelor;DE;Konzeption und Umsetzung der Migration von IT News Blog in Share Point 2010;
16.10.12;11.03.13;2013;extern;Bachelor;DE;Konzeption, Entwurf und Implementierung eines Visualisierungstools zu Veranschaulichung von Protokolldateien;
18.10.12;18.03.13;2013;extern;Bachelor;DE;Untersuchung der Machbarkeit und Entwicklung von Einsatzmöglichkeiten von Windows Metro Style Anwendungen für Labormanagementsysteme;
19.10.12;13.03.13;2013;extern;Bachelor;DE;Interaktive Restaurantsoftware auf Basis einer Windows 8 App;
24.10.12;14.03.13;2013;extern;Bachelor;DE;Test einer komplexen Korrekturkette zur Verbesserung von CT Rekonstruktionen;
26.10.12;14.03.13;2013;extern;Bachelor;DE;Evaluierung von Applikationsentwicklung mittels Metro-Design am Beispiel eines Radiology Information System;
26.10.12;13.03.13;2013;extern;Bachelor;DE;Konzept zur Einführung eines IT-basierten Flächenmanagementsystems bei der PUMA SE unter Berücksichtigung betriebswirtschaftlicher und strategischer Aspekte;
26.10.12;02.04.13;2013;intern;Bachelor;DE;"Entwicklung einer einfach konfigurierbaren interaktiven Side-Scroller-Umgebung nach dem ""Jump and Run""-Spielprinzip";
26.10.12;25.03.13;2013;extern;Bachelor;DE;Konzeptionierung systemübergreifender Workflows auf Basis von Microsoft SharePoint 2010, Nintex Workflow 2010 und Microsoft Dynamics NAV 2013;
26.10.12;14.03.13;2013;extern;Bachelor;DE;Entwicklung eines Systemprozesses für die automatisierte Bereitstellung und interne Abrechnung von virtuellen Testumgebungen für die DATEV eG;
26.10.12;14.03.13;2013;extern;Bachelor;DE;Konzeption von Performance-Metriken für das Project Office im Rahmen des Account Portfolio Managements bei der IBM Deutschland GmbH;
31.10.12;27.03.13;2013;extern;Bachelor;DE;Konzeption und Implementierung einer neuen Software für eine Messanlage zur Verbesserung der Produktqualität und zur Erweiterung der vorhandenen Funktionen;
01.11.12;26.03.13;2013;intern;Bachelor;DE;Interaktive Segmentierung von CT-Volumendatensätzen von Museumsexponaten;
01.11.12;14.03.13;2013;extern;Bachelor;DE;Bedienung eines 3D-Objekts via Multitouch Display;
01.11.12;13.03.13;2013;intern;Bachelor;DE;Klassifikation und Bewertung von Web 2.0 Anwendungen in Marketing und Vertrieb;
02.11.12;02.04.13;2013;intern;Bachelor;DE;Data Mining und türkische Verbalmorphologie - Morphologische Analyse der verneinten, fragenden und fragend-verneinten Verbalformen mit farbcodierter Darstellung der Morpheusstrukturen;
02.11.12;02.04.13;2013;extern;Bachelor;DE;Konfiguration, Anpassung und Erweiterung der Visualisierungsschnittstelle einer Geschäftsprozessplattform am Beispiel Omnitracker;
06.11.12;14.03.13;2013;extern;Bachelor;DE;Datenbankmodell für ein drahtloses Sensornetz basiertes Überwachungssystem für logistische Prozesse;
07.11.12;14.03.13;2013;extern;Bachelor;DE;Verfahren zur Korrektur von Kreisringartefakten in der Röntgen-Computertomographie;
14.11.12;14.03.13;2013;extern;Bachelor;EN;Continous Integration in Embedded-Systems;
15.11.12;14.03.13;2013;intern;Bachelor;DE;Social Semantic Web - Zusammenführen von Social WEb Anwendungen mit Semantic Web Technologien und Erstellung eines Social Semantic Wikis;
15.11.12;15.04.13;2013;extern;Bachelor;DE;Entwicklung einer Entscheidungsvorlage inklusive Wirtschaftlichkeitsbetrachtung für die zukünftige Gestaltung der IT Systemlandschaft im Bereich Konzernkonsolidierung eines Energiedienstleisters;
15.11.12;14.03.13;2013;extern;Bachelor;DE;Integration von Supportprozessen in ein Liferay Service Portal bei einem Automobilhersteller;
15.11.12;15.04.13;2013;extern;Bachelor;DE;Realisierung eines Datenworkflows für die lokale Bereitstellung von in der Cloud erstellten Befundungsergebnisse für Ärzte in einer medizinischen Einrichtung;
20.11.12;20.04.13;2013;intern;Bachelor;DE;Entwurf und Implementierung einer Echtzeitanalyse von Twitter;
20.11.12;;2013;intern;Bachelor;DE;Entwurf und Implementation einer Echtzeit-Analyse von Twitter-Nachrichten;
22.11.12;14.02.13;2013;extern;Bachelor;DE;Besondere Herausforderungen der digitalen Forensik auf SmartPhones;
22.11.12;22.04.13;2013;extern;Bachelor;DE;Analyse und Verbesserung der Supportprozesse bei einem mittelständischen ERP-Anbieter;
22.11.12;14.03.13;2013;extern;Bachelor;DE;Implementierung und Zertifizierung eines Qualitätsmanagementsystems für ein IT-Systemhaus nach DIN EN ISO 9001:2008;
27.11.12;11.04.13;2013;extern;Bachelor;DE;Pseudonymisierung der medizinischen Bilddaten zur regulatorisch konformen Übertragung über öffentliches Internet in ein Data Center;
29.11.12;18.04.13;2013;extern;Master;EN;"Lock removal via ""Smart Scheduling""";
29.11.12;14.03.13;2013;extern;Bachelor;DE;Evaluierung verschiedener Software Development Kits zur Entwicklung plattformunabhängiger Anwendungen für mobile Geräte;
29.11.12;18.03.13;2013;extern;Bachelor;DE;Mobile Transaktionen mit SAP ERP zur Unterstützung der Logistik - Konzeption und beispielhafte Umsetzung mit ITSmobile und Web Dynpro;
30.11.12;18.04.13;2013;extern;Bachelor;DE;Self-Service BI Visualisirungswerkzeuge: Vergleichende Tools Evaluierung und Machbarkeitsanalyse bei Siemens Energy;
30.11.12;;2013;intern;Bachelor;DE;Zeitlicher Abgleich zwischen dem Audiosignal und den Noten eines instrumentalen Musikstücks;
01.12.12;30.04.13;2013;extern;Bachelor;DE;Konzeptionierung und Implementierung eines Systemkonfigurationswerkzeuges für ein funkbasiertes Lokalisierungssystem;
05.12.12;05.06.13;2013;extern;Master;DE;Konzept zur automatisierten Reduzierung des Straßennetzes für eine Navigationssoftware;
05.12.12;08.03.13;2013;intern;Bachelor;DE;Customer Relationship Management: Konzepte, Technologie und Trends;
11.12.12;10.05.13;2013;extern;Bachelor;DE;Marktanalyse für den Einsatz von PC-based Produktion in der Gebäudeautomatisierung;
11.12.12;08.04.13;2013;extern;Bachelor;DE;Evaluierung und prototypische Realisierung einer Plattform zur Speicherung und Verwaltung von Know-How;
12.12.12;14.03.13;2013;extern;Bachelor;DE;Enterprise Architecture Management bei der TenneT TSO GmbH;
15.12.12;14.06.13;2013;extern;Master;DE;Konzeption und Implementierung eines Profile-Serviced im Umfeld von HMI / SCADA Runtime Innovation Line;
18.12.12;18.05.13;2013;extern;Bachelor;DE;Aufbau einer Hadoop-Umgebung zur Analyse von Massendaten eines Onlineshops;
21.12.12;16.05.13;2013;intern;Bachelor;EN;Comparison of Mobile Technology Applications in Germany and Korea;
01.01.13;26.06.13;2013;extern;Master;DE;Entwicklung einer Verfahrensweise für die Erstellung von 3D-Unternehmenspräsentationen für 3D-Bildschirme ohne Brille;
01.01.13;30.06.13;2013;intern;Master;DE;Evaluierung verschiedener Verfahren für die performante Abfrage von Massendaten am Beispiel eines Online-Werbeservice;
01.01.13;31.07.13;2013;extern;Bachelor;DE;Konzeption eines grafischen Instrumentations-Clusters auf einem NVIDIA Tegra 2 Prozessor unter Verwendung des NVIDIA Composter Studios;
10.01.13;14.03.13;2013;extern;Bachelor;DE;Plattformübergreifende Synchronisierung von Daten und Kollaboration am Beispiel der Anwendung Owncloud unter besonderer Beachtung von Datensicherheit;
23.01.13;14.03.13;2013;intern;Bachelor;DE;Die Entwicklung des Versandhandels und die Auswirkungen des E-Commerce auf traditionelle Versandhandelsunternehmen;
05.02.13;14.03.13;2013;extern;Bachelor;DE;Web-basierte Versionsverwaltung für die revisionssichere Speicherung von Designdokumenten mit Hilfe des express-Frameworks;
15.02.13;23.05.13;2013;extern;Bachelor;DE;Entwickeln eines Oberflächen-Designers inkl. optimierter grafischer Benutzeroberflächen für eine Cdn/Lin-Busanalyse-Applikation;
18.02.13;18.07.13;2013;extern;Bachelor;DE;Konzept für eine automatisierte stabile Berechnung der Verfügbarkeit für die Produkte DATEVcloud Software und DATEVasp.;
01.03.13;08.09.13;2013;intern;Bachelor;DE;"Leitfaden für SQL-Übungen als Bestandteil eines Hochschul-Kurses ""Datenbanken""";
11.03.13;15.07.13;2013;extern;Bachelor;DE;Einführung eines Warenwirtschaftssystems bei einem mittelständischen Anlagenbauunternehmen in der Rohrsanierungsbranche;
11.03.13;11.08.13;2013;intern;Bachelor;DE;Entwurf und Implementierung eines Systems zum Austausch von Aufgaben und Lösungen während einer Lehrveranstaltung;
12.03.13;12.08.13;2013;extern;Bachelor;DE;Analyse und Definition von Anforderungen zur Auswahl eines Frameworks für die Entwicklung einer generischen Webapplikation im Versicherungsumfeld;
14.03.13;09.08.13;2013;extern;Bachelor;DE;Entwicklung einer webbasierten Zeiterfassung mit Datenaustausch mit einem Kanzleinetzwerk;
14.03.13;14.08.13;2013;intern;Bachelor;DE;Entwicklung und Realisierung einer Applikation für das Erstellen von Sendungen für ein Webradio;
15.03.13;15.07.13;2013;extern;Bachelor;DE;Die Bedeutung von Soft Skills im Prozess der Softwareentwicklung mit agilen Verfahren;
18.03.13;28.06.13;2013;extern;Bachelor;DE;Untersuchung des Einsatzes semantischer Technologien im E-Business - Ist-Analyse und Forschungsgebiete;
01.04.13;28.08.13;2013;extern;Bachelor;DE;Usability Engineering für die bestehende Energiecontrolling-Software IngSoft InterWatt mittels Erstellung eines Aufgabenmodells und einiger Prototypen, so dass sie die aus der Implementierung der ISO 50001 .....;
01.04.13;26.08.13;2013;extern;Bachelor;DE;"Konzeption und prototypische Realisierung eines Plugin-Konzepts für WPF Anwendungen auf Basis von MEF unter Berücksichtigung des MVVM Patterns am Beispiel des Redaktionswerkezugs ""DFacto"" der DATEV eG <br><br>";
01.04.13;01.09.13;2013;extern;Bachelor;DE;Erstellung einer Datenaufzeichnungs- und Darstellungskomponente für Daten einer SPS;
01.04.13;30.09.13;2013;extern;Bachelor;DE;Erschließung von Erfolgspotenzialen bei Projektabwicklungsprozessen durch Lean Management;
01.04.13;31.08.13;2013;extern;Bachelor;DE;Untersuchen der Möglichkeiten von IntelliTrace für die Reproduktion von Fehlern in einer Anwendung;
02.04.13;30.08.13;2013;extern;Bachelor;DE;Entwicklung einer dynamischen Kommunikationsschnittstelle in einem Hardware/Software Co-Simulationssystem;
03.04.13;02.09.13;2013;intern;Bachelor;DE;Punktmerkmalsverfahren zur Kollisionsvermeidung beim Quadrocopter;
10.04.13;10.10.13;2013;extern;Master;DE;Erkennung und Vermeidung von Hindernissen in der Flugbahn eines autonomen Quadrocopters mittels optischem Fluss;
15.04.13;15.09.13;2013;extern;Bachelor;DE;Anforderungsanalyse und Neuentwicklung einer Software zur Auswertung und Visualisierung von statistischen Daten am Beispiel des Importvorgangs von Immobiliendaten;
15.04.13;16.09.13;2013;extern;Bachelor;DE;Echtzeitkorrektur des Rolling-Shutter-Effekts in Videostreams einer Quadrocopter-Bordkamera;
17.04.13;17.09.13;2013;extern;Bachelor;DE;Entwicklung eines UML-Profils für EAST-ADL in Rational Rhapsody;
18.04.13;08.08.13;2013;extern;Bachelor;DE;Entwicklung von Handlungsempfehlungen zur Optimierung eines Applikationsportfolios im Bereich Offer-Management;
18.04.13;18.09.13;2013;extern;Bachelor;DE;Entwicklung eines Vendor-Managed-Inventory-Systems mit Anbindung an Microsoft Dynamics NAV;
18.04.13;18.09.13;2013;extern;Bachelor;DE;Vergleich von In-Memory und relationalen Datenbanksystemen in Anwendungen der DATEV;
22.04.13;22.10.13;2013;extern;Master;DE;Agile Programmiersprachen - Analyse und Bestimmung der Agilitätsfaktoren von Programmiersprachen und deren Übertragbarkeit auf klassische Sprachen;
23.04.13;23.09.13;2013;extern;Bachelor;DE;Patterns in Web-Anwendungen mit JavaScript;
25.04.13;01.08.13;2013;extern;Bachelor;DE;Möglichkeiten und Grenzen agiler Entwicklung von technischen Dokumentationen in einem Softwareunternehmen;
30.04.13;30.09.13;2013;extern;Bachelor;DE;Rekursive Virtualisierung - Stand der Technik und Möglichkeiten;
01.05.13;30.09.13;2013;intern;Bachelor;DE;Aufbau einer flexiblen Virtual-Reality-Lösung für die Visualisierung von Punktwolken und CAD-Modellen;
03.05.13;23.09.13;2013;extern;Bachelor;DE;Konzeption und Umsetzung einer Kartographieanwendung durch einen Quadrocopter;
10.05.13;10.10.13;2013;extern;Bachelor;DE;Evaluierung der Zertifizierungsmöglichkeiten eines innovativen Smartphone-Bezahlsystems sowie die Analyse der Markt- und Vertriebsfähigkeit;
13.05.13;12.11.13;2013;extern;Master;DE;Konzeption und Entwicklung einer Scripting-gestützten Softwareanwendung zur Vereinheitlichung logisch unabhängiger, fachlich zusammengehöriger Systeme am Beispiel eines länderübegreifenden Lohnabrechnungssystems;
15.05.13;15.11.13;2013;extern;Master;DE;Konzept und Umsetzung eines Programmes zur Nutzung des Microsoft KINECT Sensors zur Erfassung der Handbewegungen eines Werkers;
15.05.13;15.10.13;2013;extern;Bachelor;DE;Aufbauz eines RDF-Stores als semantische Komponente der Intranetsuchmaschine für die Fakultät Informatik;
15.05.13;14.10.13;2013;extern;Bachelor;DE;Konzeption und Entwicklung eines Softwareprototypen für die CIV-Methodik;
20.05.13;30.09.13;2013;extern;Bachelor;DE;Konzeption und prototypische Realisierung eines IT-Infrastruktur-Monitoring-Frameworks, angepasst an die Bedürfnisse von Anwendungsentwicklern im Umfeld eines ausgelagerten IT-Infrastruktur-Betriebs am Beispiel der Siemens AG<br><br>;
22.05.13;18.10.13;2013;extern;Bachelor;DE;Restrukturierung eines auf Microsoft SharePoint Services basierenden Intranetportal bei Siemens Healthcare;
24.05.13;22.10.13;2013;extern;Bachelor;DE;Einbindung von juristischem Content in eine Kanzleiorganisationssoftware für Rechtsanwälte;
24.05.13;23.10.13;2013;extern;Bachelor;DE;Marktanalyse von Software-Ressourcen für das Ideenmanagement der Siemens AG;
03.06.13;31.10.13;2013;extern;Bachelor;DE;Weiterentwicklung eines Eclipse-RCP basierten Editors zur Steuergerätedatenbeschreibung im Hinblick auf Bedienerfreundlichkeit und Eingabe-Effizienz<br><br>;
04.06.13;31.10.13;2013;extern;Bachelor;DE;Formularerstellung aus SAP ERP bei der MAN Truck & Bus AG - Untersuchung alternativer Drucksysteme;
12.06.13;12.08.13;2013;extern;Bachelor;DE;Duale Proxy Appliance zur feingranularen Zugriffskontrolle in Webanwendungen;
17.06.13;15.11.13;2013;extern;Bachelor;DE;Anbindung vorhandener Software an das Ausstellungs-Management- & Tagging-System und Erweitern der Foyer-Ausstellung mit zusätzlichen Exponaten.<br>;
28.06.13;28.12.13;2013;extern;Master;DE;Analyse, Konzeption und Implementierung einer domainspezifischen Methode zur automatisierten Lagerstammdatengenerierung bei der Dematic GmbH;
01.07.13;20.12.13;2013;extern;Master;DE;Automatisierte Co-Simulation und Simulationsdatenmanagement im PLM-System Teamcenter unter Verwendung des Functional Mock-up Interface;
01.07.13;29.11.13;2013;extern;Bachelor;DE;Modern User Interface Devices - Möglichkeiten eines effizienten und sinnvollen Einsatzes der Kinect in Business-Anwendungen;
02.07.13;02.12.13;2013;extern;Bachelor;DE;Unterstützung des Änderungsmanagements bei agilen IT-Projekten;
23.07.13;07.01.14;2013;extern;Bachelor;DE;Entwicklung eines Konfigurationsschlüsselkonzeptes und einer Anlagenkonfigurations-Software zur automatisierten Verarbeitung von ERP-Daten (Stücklisten)<br><br>;
25.07.13;07.01.14;2013;extern;Bachelor;DE;Entwicklung einer 3D-Objekterkennung zur Bestimmung der Bauteillage in einem Greifsystem auf der Basis von Partikelverdichtung als Eingangsdaten für die Movelt! Bewegungsplanung;
26.07.13;07.01.14;2013;extern;Bachelor;DE;Evaluierung und Umsetzung eines SOA Management Konzepts mit Fokus auf Service-Governance und Service Life Cycle bei Cortal Consors S.A.<br><br>;
29.07.13;07.01.14;2013;extern;Bachelor;DE;Erweiterte Klassifikation in Hörgeräten durch Georeferenzierung mit mobilen Endgeräten;
01.08.13;07.01.14;2013;extern;Bachelor;DE;Kameragestützte Erkennung eines Quadocopterlandeplatzes in verschiedenen Freiheitsgraden<br><br> <br>;
01.08.13;07.01.14;2013;extern;Bachelor;DE;Erweiterung des Treibers eines virtuellen Dateisystems für skalierbare Medien um die Funktionalität eines parametierbaren Dateiaufrufes am Beispiel von JPEG 2000;
07.08.13;07.01.14;2013;extern;Bachelor;DE;Konzeption und Entwiclung einer Java-Anwendung zum Erkennen von Zyklen in Baubarkeitsregeln für Fahrzeuge mit Mitteln der Graphentheorie<br><br>;
19.08.13;20.01.14;2013;extern;Bachelor;DE;Parallele, fehlertolerante Programmierung unter Anwendung von Design Pattern in Erlang/OTP;
19.08.13;17.01.14;2013;extern;Bachelor;DE;Untersuchungen zu den Testanforderungen von AUTOSAR und Erarbeitung eines Testkonzepts;
21.08.13;21.01.14;2013;extern;Bachelor;DE;Konzeption und Implementierung der Visualisierung eines fachlichen Datenmodells im Bereich der Arbeitsvermittlung;
31.08.13;30.01.14;2013;extern;Bachelor;DE;Analyse, Optimierung und Konzeption des Angebotsmanagement-Prozesses der evosoft GmbH;
01.09.13;13.01.14;2013;extern;Bachelor;DE;Implementierung eines echtzeitfähigen Feature-Extraction-Algorithmus aus Livebilddaten auf der ARM-i.MX6-Architektur für ein Medizingerät;
01.09.13;02.12.13;2013;extern;Bachelor;DE;"Konzeption und Prototypisierung zum Thema Gewinnung und Analyse von Nutzungsdaten mit Hilfe von ""Runtime Intelligence""";
01.09.13;;2013;extern;Bachelor;DE;Analyse und Evaluation verschiedener Dokumentenmanagementsysteme zur Schaffung einer einheitlichen Archivschnittstelle;
01.09.13;20.01.14;2013;extern;Bachelor;DE;Serverseitige Verwaltung von Spielzuständen für geräteübergreifende, asynchrone Spielkonzepte;
02.09.13;27.02.14;2013;extern;Master;DE;Optimierung der Produktstammdatenversorgung einer weltweiten E-Commerce Lösung für Industrie Produkte mit der Technologieplattform SAP HANA;
02.09.13;02.02.14;2013;extern;Bachelor;DE;Konzeption und Implementierung eines Werkzeugs zum Vergleich von Performancetestergebnissen;
10.09.13;22.04.14;2013;extern;Bachelor;EN;Viral Marketing;
10.09.13;10.02.14;2013;extern;Bachelor;DE;Konzeptionelle Untersuchung des SAP Business Process Exception Managements in Verbindung mit dem SAP Common Layer für den Einsatz bei einem Energieversorgungsunternehmen;
11.09.13;28.04.14;2013;extern;Bachelor;DE;Aufbau eines Frameworks für die Testautomatisierung der Softwarekomponenten eines UNIX-basierten SCADA-Systems;
13.09.13;13.02.14;2013;extern;Bachelor;DE;Software Projektcontrolling basierend auf Requirementanalysen;
15.09.13;31.01.14;2013;extern;Bachelor;DE;Marktüberblick, Evaluation und Erstellung eines Showcases zur Datenerfassung mit einem digitalen Stift;
16.09.13;15.01.14;2013;extern;Bachelor;DE;Entwicklung eines NFC Reader Modules;
18.09.13;18.02.14;2013;extern;Bachelor;DE;Konzeption und Entwicklung einer plattformunabhängigen HTML5-Desktop-Application für die Office Fitness Solutions GmbH;
19.09.13;16.01.14;2013;extern;Master;DE;Web 2.0 im Peronalbereich - Analyse und Klassifizierung der Einsatzpotenziale von Web 2.0 Anwendungen in Unternehmen;
19.09.13;19.02.14;2013;extern;Bachelor;DE;Realisierung einer Webanwendung zur datenbankgestützten Konfiguration eines Clusters von Java-Standalone-Anwendungen;
20.09.13;20.02.14;2013;extern;Bachelor;DE;Technische Evaluierung und prototypische Realisierung einer unternehmensinternen Plattform zur Speicherung und Verwaltung von Wissen;
24.09.13;24.02.14;2013;extern;Bachelor;DE;Konzeption und Realisierung eines Stellen- und Informationsportals als Smartphone Applikation für die evosoft GmbH<br><br>;
01.10.13;30.06.14;2014;extern;Master;DE;Entwicklung einer interaktiven Webapplikation für die Verwaltung von Spielern, Mannschaften und Wettbewerben sowie die Verarbeitung und Visualisierung von Statistiken eines Multiplayer-Online-Spiels mit Ruby on Rails und jQuery;
01.10.13;01.03.14;2014;extern;Bachelor;DE;Implementierung des FAT-Dateisystems für das Lehrbetriebssystem ULIX;
01.10.13;04.02.14;2014;extern;Bachelor;DE;Untersuchung möglicher Fehlerquellen bei der Änderung von Netzwerk-Hardware und Entwicklung eines vereinfachten Change-Management-Systems;
01.10.13;28.02.14;2014;extern;Bachelor;DE;Entwicklung eines Prototypen für eine Augmented-Reality Applikation zur Unterstützung der Bedienung von Alltagsgeräten an ausgewählten Beispielen;
01.10.13;25.02.14;2014;extern;Bachelor;DE;Prototypische Implementierung einer interaktiven Geschäftsgrafik für die Simulation betriebswirtschaftlicher Szenarios am Beispiel des DATEV Controllingreports mobil;
01.10.13;27.02.14;2014;extern;Bachelor;DE;Ein browserbasiertes Dashboard zur dynamischen Datenvisualisierung im Innovationsmanagement;
01.10.13;28.02.14;2014;extern;Bachelor;DE;Analyse des Anforderungsmanagements der DATEV eG und konzeptionelle Erweiterung um übergreifende Prozesse;
01.10.13;07.02.14;2014;extern;Bachelor;DE;Ankopplung einer Softwareplattform für Bioprozessentwicklung mit OPC DA;
01.10.13;26.02.14;2014;extern;Bachelor;DE;Konzeption und Implementierung eine Infoscreens zur Darstellung von Projektinformationen einer Entwicklungsabteilung;
01.10.13;28.02.14;2014;extern;Bachelor;DE;Prozedurale Modellierung und Constraint-Programmierung zur Generierung von dreidimensionalen Objekten;
01.10.13;31.01.14;2014;extern;Bachelor;DE;Konzeption und Einsatz einer Hybrid IAAS Cloud mit OpenStock auf SUSE Linux Enterprise Server<br><br>;
01.10.13;19.02.14;2014;extern;Bachelor;DE;Anforderungsanalyse, Konzeption und Implementierung einer webbasierten Software zur Verarbeitung von Dokumenten;
01.10.13;24.01.14;2014;extern;Bachelor;DE;Variantenkonfiguration im Spannungsfeld von Betriebswirtschaft (ERP) und Technik (PLM);
01.10.13;28.02.14;2014;extern;Bachelor;DE;Konzeption und Entwicklung einer Plattformübergreifenden Web-Applikation zur Erfassung und Visualisierung der persönlichen Gemütslage anhand einer parallel geführten Nutzerstudie;
01.10.13;28.02.14;2014;extern;Bachelor;DE;Konzeption und Implementierung eines skalierfähigen Server-Backends für eine Web-Anwendung unter Auswahl einer passenden Cloud-Plattform;
04.10.13;03.03.14;2014;extern;Bachelor;DE;"Umsetzung von ""point&click"" Aufgaben zur 3D-Volumenmanipulation mit Leap Motion im klinischen Umfeld der Angiographie";
04.10.13;28.02.14;2014;extern;Bachelor;DE;Oberflächen-, Benutzer- und Bedienkonzepte für einen XML-Editor in der Windows 8 Desktop- und Tablet-Umgebung bei der Fa. SCHEMA;
07.10.13;31.01.14;2014;extern;Bachelor;DE;Konzeption und Umsetzung eines BI-Workflows auf Basis der Microsoft BI Lösung (SSIS, SSAS, SSRS);
08.10.13;07.03.14;2014;extern;Bachelor;DE;Bewertung und prototypische Umsetzung semantischer Datenmodelle für Customer-Relationship-Management-Systeme;
10.10.13;10.03.14;2014;extern;Bachelor;DE;Portable Browser-Integration und Sicherheitsdemo für das Nürnberger Anti-Phisching Device;
10.10.13;;2014;extern;Bachelor;DE;Entwicklung einer Client-Sever Applikation zur Filespace-Kostenreduzierung;
10.10.13;07.03.14;2014;extern;Bachelor;DE;Entwicklung einer Client-Server Applikation zur Filespace-Kostenreduzierung;
11.10.13;31.01.14;2014;extern;Bachelor;DE;Automatisierter Test einer betriebswirtschaftlichen Anwendungssoftware - Konzipierung, Entwiclung und Implementierung eines neuen Softwaretestverfahrens bei der DATEV eG;
11.10.13;30.01.14;2014;extern;Bachelor;DE;Analyse, Konzeption und Implementierung eines Tools zur Messung der Auslastung eines Materialflusssystems bei der Dematic GmbH<br><br>;
14.10.13;14.02.14;2014;extern;Bachelor;DE;Entwurf eines Konzepts zur Einbindung eines sozialen Netzwerks in die Personalverwaltung;
14.10.13;14.03.14;2014;extern;Bachelor;DE;Entwicklung einer Beschreibungssprache für skalierbare Medien;
14.10.13;14.03.14;2014;extern;Bachelor;DE;Responsive Webdesign: Herausforderungen, Technologiebewertung und praktische Anwendung;
14.10.13;12.03.14;2014;extern;Bachelor;DE;DATEVcloud Software und DATEVasp Self Service Application für mobile Endgeräte Evaluation verschiedener Entwicklungsansätze mit anschließendem Proof of Concept<br><br>;
15.10.13;15.03.14;2014;extern;Bachelor;DE;Einsatz von Werkzeugen für das Windows-Rechtemanagement in der DATEV eG;
15.10.13;;2014;extern;Bachelor;DE;Konzeption und prototypische Implementierung einer Smartphone-App für SIMATIC B.Data;
15.10.13;12.02.14;2014;extern;Bachelor;DE;Konzeption und Implementierung einer Prüf- und Analysesoftware für einen Schubstangenantrieb;
15.10.13;13.03.14;2014;extern;Bachelor;DE;Konzeption und prototypische Umsetzung einer Smartphone App für SIMATIC B.Data;
16.10.13;14.03.14;2014;extern;Bachelor;DE;Entwicklung einer Web-Applikation mit RESTful Web-Services zur Übertragung, Konfiguration und Auswertung von Fitbit-Sensordaten;
17.10.13;12.03.14;2014;extern;Bachelor;DE;Analyse und Konzeption einer mobilen Makler-Applikation zur Unterstützung im täglichen Geschäft;
18.10.13;04.03.14;2014;extern;Bachelor;DE;Automatisierung der Bereitstellung von thematischen Karten im DATEV-Intranet;
21.10.13;20.03.14;2014;extern;Bachelor;DE;Konzeption einer sicheren Speicherung von Kreditkarteninformationen auf einem Smartphone im Rahmen von Mobile Payment;
22.10.13;22.03.14;2014;extern;Bachelor;DE;Entwicklung einer autonomen, mobilen Anwendung zum Auffinden von Produkten in Regalen von Einzelhandelsgeschäften;
22.10.13;06.03.14;2014;extern;Bachelor;DE;Entwicklung dynamischer Algorithmen zur Erkennung von Web-Tracking auf Basis von Benutzer-Domain-Interaktionen;
24.10.13;14.03.14;2014;extern;Bachelor;DE;Analyse und Erweiterung der SAP-ATP-Verfügbarkeitsprüfung bei der Firma Fackelmann GmbH & Co. KG;
24.10.13;29.01.14;2014;extern;Bachelor;DE;Evaluierung von ausgewählten Tools zur Prozesssimulation von Beispielprozessen;
25.10.13;21.03.14;2014;extern;Bachelor;DE;Behandlung komplexer Abbiegesituation in der Routenplanung;
25.10.13;21.03.14;2014;extern;Bachelor;DE;Machbarkeitsstudie zur HTML5-Migration eines Java-basierten Planungstools;
28.10.13;28.07.14;2014;extern;Master;EN;Debug and Trace using Logic Analyzers in AUTOSAR;
28.10.13;12.03.14;2014;extern;Bachelor;DE;Wie Web 2.0 das Wissensmanagement verändert;
29.10.13;27.03.14;2014;extern;Bachelor;DE;Bereitstellung von Verlaufsdaten und Auswertungen im SelfService-Portal und DATEVasp und DATEVcloud Software zur Nutzung auf mobilen Endgeräten;
29.10.13;27.03.14;2014;extern;Bachelor;DE;"Entwicklung eines Frameworks für Multiagentensysteme zur Verwendung in industriellen Fertigungsnetzen nach dem Konzept ""Industrie 4.0"" und Evaluation eines Prototyps für einen Modellaufbau";
29.10.13;31.01.14;2014;extern;Bachelor;DE;Konzeption und Implementierung eines Online-Echtzeit-Strategie-Spiels für iOS;
30.10.13;14.06.14;2014;extern;Bachelor;DE;Entwicklung einer hardwarenahen µ-Controller-Software zur Steuerung und Modulation eines Bakensenders über ein proprietäres Protokoll und Webinterface<br><br>;
31.10.13;28.03.14;2014;extern;Bachelor;DE;Schemaänderungen im laufenden Betrieb;
01.11.13;19.02.14;2014;extern;Bachelor;DE;Entwurf und prototypische Entwicklung eines Werkzeugs zur Arbeitsplanerstellung mit Hilfe von genetischen Verfahren;
01.11.13;27.05.14;2014;extern;Master;DE;Hochskalierbare Single-page Applications;
01.11.13;01.04.14;2014;extern;Bachelor;DE;Konzeption und Realisierung eines Monitoring-Systems für spezifische unternehmenskritische Abläufe der DATEV eG;
01.11.13;03.03.14;2014;extern;Bachelor;DE;Möglichkeiten und Grenzen bei der Portierung interaktiver C++ Multimediaanwendungen zu Webanwendungen<br><br><br><br>;
01.11.13;01.04.14;2014;extern;Bachelor;DE;HTML5 Alternativen zur Ablösung von Flash-Inhalten;
04.11.13;21.03.14;2014;extern;Bachelor;DE;Analyse von Self-Service-Funktionalitäten im Bereich Business Intelligence exemplarisch dargestellt anhand des Microsoft SQL Servers 2012;
04.11.13;14.03.14;2014;extern;Bachelor;DE;Möglichkeiten des Einsatzes eines semantischen Desktops an Hochschulen;
05.11.13;12.03.14;2014;extern;Bachelor;DE;Evaluierung einer ganzheitlichen und modellgetriebenen Business Analyse Plattform und Konzeption zugehöriger Prozesse bei der DATEV eG;
08.11.13;07.04.14;2014;extern;Bachelor;DE;Entwicklung einer Single-page Web Application zur Erstellung und Auswertung von Umfragen;
12.11.13;27.01.14;2014;extern;Bachelor;DE;Entwicklung einer Wissensbasis zur Unterstützung eines agilen Projektmanagements anhand eines Fallbeispiels;
12.11.13;14.03.14;2014;extern;Bachelor;DE;Speicherung großer Geodaten-Bestände in NO-SQL-Datenbanken;
14.11.13;14.03.14;2014;extern;Bachelor;DE;Modellierung und Implementierung eines Automotive Steuergeräts mit EAST-ADL und AUTOSAR;
15.11.13;15.04.14;2014;extern;Bachelor;DE;Technologien und Umsetzung des WYSIWYG Ansatzes für WCMS;
18.11.13;17.04.14;2014;extern;Bachelor;DE;Technische und Kognitive Optimierungsansätze für WPF-Oberflächen;
22.11.13;18.06.14;2014;extern;Master;DE;Konzeption und Umsetzung von strategischen und operative Internet-Marketing-Maßnahmen für den Onlineshop www.vorlagen.de - Schwerpunkt Suchmaschinenmarketing (SEM);
25.11.13;28.04.14;2014;extern;Bachelor;DE;Konzeption und Entwicklung einer Softwarekomponente für eine Mobileplattform zur lokalen Suche von Geo-Objekten;
26.11.13;14.03.14;2014;extern;Bachelor;DE;Erstellung eines Regelwerks für das Requirements Engineering in Business Intelligence-Projekten bei mittelständischen Unternehmen;
27.11.13;14.03.14;2014;extern;Bachelor;DE;Spezifische Qualitätssicherungsmaßnahmen bei der Entwicklung verteilter Anwendungen im .NET-Umfeld der DATEV eG<br><br> <br>;
02.12.13;02.05.14;2014;extern;Bachelor;DE;Umsetzung einer grafischen Nutzerschnittstelle zur interaktiven Steuerung des örtlichen Höreindrucks in einer Audiokonferenz;
05.12.13;02.05.14;2014;extern;Bachelor;DE;Automatische Annotierung geografischer Objekte in Texten;
05.12.13;05.09.14;2014;extern;Master;DE;Keyword-basierter Zugriff auf RDF-basierte semantische Datenbanken;
13.12.13;12.05.14;2014;extern;Bachelor;DE;Realisierung einer Geodatensuche mit Lucene;
16.12.13;16.05.14;2014;extern;Bachelor;DE;Automatische Kartenbeschriftung von Linien- und Flächenobjekten;
07.01.14;07.06.14;2014;extern;Bachelor;DE;Vollautomatische Bereitstellung virtueller Maschinen im Umfeld VMware aus der Verwaltungsdatenbank heraus;
14.01.14;14.05.14;2014;extern;Bachelor;DE;Konzeption und prototypische Implementierung einer<br>plattformunabhängigen Client-Schnittstelle im Bereich<br>der Zählerverwaltung und Verbrauchsdatenerfassung;
10.02.14;08.07.14;2014;extern;Bachelor;DE;Automatisiertes Testen und Bewerten von GUI Oberflächen;
14.02.14;14.07.14;2014;extern;Bachelor;DE;Konzeption der Vorgehensweise eines Anbieters von Unternehmenssoftware im Rahmen der Softwareinführungen in kleinen und mittelständischen Unternehmen;
17.02.14;15.07.14;2014;extern;Bachelor;DE;Koroutinen in modernen Programmiersprachen;
26.02.14;30.09.14;2014;extern;Master;EN;Augmented reality in Kindergarten-Challenges and possibilities of object recognition in games for preschool children;
27.02.14;23.07.14;2014;extern;Bachelor;DE;Gamification mit Hilfe der E-learning Plattform MOODLE an der TH Nürnberg;
28.02.14;28.07.14;2014;extern;Bachelor;DE;Kennzahlengestütztes Projekt-Controlling für Supply Chains in der Bauindustrie;
01.03.14;31.07.14;2014;extern;Bachelor;EN;Behavior-Based Web User Identification: An Experimental Approach for Pointing Devices;
01.03.14;01.08.14;2014;extern;Bachelor;DE;Erweiterung der Eingabewerkzeuge des radiologischen Arbeitsplatzes um ein Multi-Touch-Tablet;
01.03.14;31.07.14;2014;extern;Bachelor;DE;Evaluation der Einsatzmöglichkeiten einer an ein Prüfgerät angebundenen Datenbrille und prototypische Implementierung einer Applikation für ein Einsatzszenario ;
05.03.14;01.08.14;2014;extern;Bachelor;DE;Vom statischen Intranet zu einer interaktiven Social Media Plattform bei der DATEV eG;
06.03.14;10.07.14;2014;extern;Bachelor;DE;Konzeptionierung und prototypische Entwicklung eines Self Service BI Werkzeuges für die Inhalte eines DATEV Cockpits;
10.03.14;10.08.14;2014;extern;Bachelor;DE;Vorstudie zu einem Migrationsprojekt bezüglich Frontend-Tools im SAP Umfeld bei der Bundesagentur für Arbeit;
13.03.14;13.08.14;2014;extern;Bachelor;DE;Konzeption und Prototyp zur Aufbereitung von Prozesskennzahlen für das Service Level Management im Rahmen des IT Controlling bei DATEV;
14.03.14;14.08.14;2014;extern;Bachelor;DE;Analyse, Modellierung und Implementierung eines Workflows für die Aufwandsschätzung von IT-Systementwicklungsfragen;
15.03.14;15.08.14;2014;extern;Bachelor;DE;Implementierung von Algorithmen der kooperativen Spieltheorie;
15.03.14;13.08.14;2014;extern;Bachelor;DE;Konzeption und Implementierung einer mobilen Anwendung zur Verdeutlichung von baulichen und sozialen Teilhabe-Barrieren, denen Rollstuhlfahrer gegenüber stehen;
15.03.14;15.08.14;2014;extern;Bachelor;DE;Quantitativer Vergleich von Echtzeitbetriebssystemen;
15.03.14;03.07.14;2014;extern;Bachelor;DE;Kritische Analyse und Erweiterung der DB-basierten Korrespondenzverwaltung bei der N-Ergie - Methodenreflexion, -anwendung und -evaluation in den einzelnen Projektphasen;
17.03.14;17.08.15;2014;extern;Bachelor;DE;Aufbau einer Umgebung für funktionale Tests und Lasttests für einen REST-basierten Web Client;
17.03.14;20.06.14;2014;extern;Bachelor;DE;Entwurf eines Konzepts zum Aufbau einer IT-Community zum Thema - Application Lifecycle Management;
17.03.14;28.07.14;2014;extern;Bachelor;DE;Mitarbeiter-Demographie in Abhängigkeit vom Software-Lifecycle an einem Beispiel bei der Siemens AG;
17.03.14;17.08.14;2014;extern;Bachelor;DE;Evaluierung der Werkzeuge zur Unterstützung in agilen Projekten mit Schwerpunkt Anforderungsmanagement;
18.03.14;27.06.14;2014;extern;Bachelor;DE;Konzeption und Realisierung einer auf Cross-Synthese basierenden iPhone-Applikation zum Sound-Design<br><br><br><br>;
19.03.14;18.07.14;2014;extern;Bachelor;DE;Frühneuzeitliche und heutige Buchhaltung im Vergleich - Die Geschäftsvorfälle bei Heinrich Schreiber (Nürnberg 1521) und ihre Aufbereitung für ein Datenbank-basiertes IT-System<br><br>;
21.03.14;20.08.14;2014;extern;Bachelor;DE;Entwicklung einer Meta-Suchmaschine für 3D-Modelle mit automatisierter Weiterverarbeitung der Suchresultate für den 3D-Druck<br><br> <br>;
25.03.14;03.07.14;2014;extern;Bachelor;EN;State-of-the-Art: Mobile CRM;
26.03.14;26.08.14;2014;extern;Bachelor;DE;Erweiterung der infoteam Software Plattform um eine wiederverwendbare Schnittstelle, mit der Daten auf mobilen Endgeräten angezeigt werden können;
31.03.14;27.08.14;2014;extern;Bachelor;DE;Technische Evaluierung mehrerer java-basierter WCMS zur Konzeption und Entwicklung einer Unternehmenswebseite;
01.04.14;15.08.14;2014;extern;Bachelor;DE;Evaluierung und Konzeptionierung der Einführung eines homogenen Incident-Management-Systems in ein bestehendes globales IT-Service Angebot;
01.04.14;01.09.14;2014;extern;Bachelor;DE;Entwurf, Implementierung und Test einer Kalibrierstufe für Trägerphasenmesswerte in einem Lokalisierungssystem;
01.04.14;01.09.14;2014;extern;Bachelor;DE;Supplier Relationship Management (SRM): Evaluation der Einsatzpotentiale des Lieferantenmanagements für die Baubranche;
02.04.14;24.07.14;2014;extern;Bachelor;DE;Erweiterung von interaktiven Webanwendungen um Funktionalitäten zur Unterstützung von mobilen Endgeräten und beispielhafte Durchführung anhand eines Urlaubsplanungstools;
03.04.14;03.09.14;2014;extern;Bachelor;DE;Konzeption und prototypische Realisierung einer mobilen Website der Fakultät Informatik;
08.04.14;08.09.14;2014;extern;Bachelor;DE;Konzeption und Implementierung einer Sprache zur Beschreibung von Oberflächen und Abläufen eines generischen Anwendungsdienstes;
08.04.14;23.07.14;2014;extern;Bachelor;DE;Multidimensionale Daten und ihre Besonderheiten am Beispiel von Microsoft SQL Server und Analysis Services - Struktur, Entwicklung und Analyse;
09.04.14;;2014;extern;Bachelor;DE;Realisierung eines FlexRay Clusters;
09.04.14;;2014;extern;Bachelor;DE;Entwicklung einer OCR-Applikation zur Erfassung von Belegen auf mobilen Endgeräten für das Unternehmen DATEV eG;
09.04.14;09.09.14;2014;extern;Bachelor;DE;Smartphone Anwendung zur auditiven Unterstützung blinder Menschen bei der Erkundung von taktilen Karten;
10.04.14;10.07.14;2014;extern;Bachelor;DE;Konzeption und Implementierung eines Assistenten zur Erstellng von Templates für die E-Learning Plattform Moodle;
14.04.14;31.07.14;2014;extern;Bachelor;DE;Juristische und technische Beurteilung von Datenschutz und Datensicherheit in produzierenden Unternehmen - Ein Beratungsleitfaden für DATEV-Consulting<br><br>;
15.04.14;15.09.14;2014;extern;Bachelor;DE;Analyse und Darstellung von Verbesserungspotentialen in einer systemübergreifenden Werksberichterstattung bei Siemens Industry Automation;
16.04.14;01.12.14;2014;extern;Master;DE;Softwareentwicklungsprozess der DATEV DMS Posteingangsassistenen: Analyse und Optimierung der Qualitätssicherungsmaßnahmen;
24.04.14;01.09.14;2014;extern;Bachelor;DE;"Implementierung einer Ethernet-basierten Kommunikationsschnittstelle für das ""embedded system"" eines Medizingerätes";
25.04.14;25.09.14;2014;extern;Bachelor;DE;Konzeptionierung und Realisierung einer Wissensbasis für Sharepoint 2013 Entwickler bei Siemens Energy;
01.05.14;07.01.15;2014;extern;Master;EN;Vision-based Object Tracking Using an Unmanned Aerial Vehicle;
01.05.14;30.09.14;2014;extern;Bachelor;DE;Evaluation von HTML5/CSS3 zur plattformübergreifenden Gestaltung und Entwicklung im Web;
02.05.14;15.08.14;2014;extern;Bachelor;DE;Konzept der Überleitung vom Produktmanagementsystem PLM@IEC auf das Projektmanagementsystem PM(i)@IEC;
02.05.14;30.09.14;2014;extern;Bachelor;DE;Konzeption und prototypische Implementierung eines webbasierten Kundengeschenke-Portals für kleine und mittelständische Unternehmen;
05.05.14;05.01.15;2014;extern;Master;DE;Konzeption und Realisierung einer multimodalen Routenplanung;
05.05.14;06.10.14;2014;extern;Bachelor;DE;Entwurf und Implementierung eines Algorithmus zur individuellen Optimierung des Lernerfolges in einer eLearning-Plattform;
06.05.14;;2014;extern;Bachelor;DE;Linguistische Analyse von DATEV Servicewesen zur Herausarbeitung von Wissenskonzepten unter Verwendung der Beschreibungssprache Salsa;
06.05.14;06.10.14;2014;extern;Bachelor;DE;Traceability in der Model Driven Architecture;
09.05.14;28.11.14;2014;extern;Master;DE;"Konzept zur Einführung des Vertriebssystems ""Global Logistics Ordering Information System Automotive and Accounting"" im Musterbau bei der Robert Bosch GmbH in Nürnberg";
13.05.14;10.10.14;2014;extern;Bachelor;DE;Konzeption und Prototypisierung eines Reportingsystems für Refurbished Systems;
14.05.14;23.12.14;2014;extern;Bachelor;DE;Neuerungen in der Welt des Datenaustauschs: SEPA, ELSTER, eBilanz;
14.05.14;29.10.14;2014;extern;Bachelor;DE;Konzeption eines Lagerhaltungssystems für Kleinunternehmen und Entwicklung der grafischen Benutzeroberfläche;
15.05.14;13.10.14;2014;extern;Bachelor;DE;Anforderungsanalyse und Evaluierung geeigneter Technologien für die visuelle Darstellung von Objektstrukturen;
22.05.14;21.10.14;2014;extern;Bachelor;DE;Unit-Testing in modernen Front-End-Anwendungen am Beispel des DATEV Controllingreport mobil;
22.05.14;30.09.14;2014;extern;Bachelor;DE;Analyse der Nutzung von Thesauren in Suchmaschinen und exemplarische Einbindung in die Fakultätssuchmaschine;
28.05.14;27.01.15;2014;extern;Master;DE;Benutzeroptimiertes Suchen in heterogenen Datenbeständen;
02.06.14;31.10.14;2014;extern;Bachelor;DE;Interaktive Verbesserung von Tiefenkarten zur Qualitätsverbesserung im Rendering;
02.06.14;02.11.14;2014;extern;Bachelor;DE;Analyse, Konzept und Implementierung einer Prototypen zur Pfaderkennung von C# Programmtext;
03.06.14;15.01.15;2014;extern;Master;EN;Conception and development of a KPI reporting in context of T-innovation management at Siemens Energy;
09.06.14;03.11.14;2014;extern;Bachelor;DE;Analyse bestehender Sicherheitsalgorithmen auf Basis des UDS Protokolls und Implementierung performanter Sicherheitsalgorithmen für Mikrocontroller von Bremssteuergeräten;
10.06.14;03.11.14;2014;extern;Bachelor;DE;Evaluation des Potentials von Cloud Computing für die industrielle Computertomographie;
11.06.14;11.11.14;2014;extern;Bachelor;DE;Konzeption und Entwicklung einer mobilen Applikation als Erweiterung eines ERP-Systems;
12.06.14;10.12.14;2014;extern;Bachelor;DE;Erweiterung der E-learning-Plattform Moodle um Aufgaben mit 3D-Modellen aus dem Bereich Maschinenbau;
17.06.14;31.07.14;2014;extern;Bachelor;DE;Anforderungsanalyse und prototypische Implementierung einer Rollout- und Schulungsdatenbank;
18.06.14;14.11.14;2014;extern;Bachelor;DE;Einsatz von Weblogs zur Unterstützung der Kommunikation zwischen Betreuer und Studierendem während einer Abschlussarbeit;
23.06.14;23.11.14;2014;extern;Bachelor;DE;Portierung einer webbasierten Geschäftsanwendung auf mobile Endgeräte - Konzeption und prototypische Implementierung;
27.06.14;27.10.14;2014;extern;Master;DE;Business Process Monitoring für Kernprozesse bei der Schaeffler-Gruppe - Konzeption, prototypische Umsetzung und Bewertung;
27.06.14;16.01.15;2014;extern;Master;DE;Erstellung eines Schulungskonzeptes zur Einführung eines ERP-Systems für KMU am Beispiel der Firma Pollin Electronic GmbH;
01.07.14;02.03.15;2014;extern;Master;DE;Einsatzmöglichkeiten der automatisierten Analyse von Artefakten und Metadaten aus Softgwareprojekten zur Unterstützung der Wartbarkeits- <br>optimierung langlebiger Softwaresysteme der DATEV eG;
02.07.14;02.12.14;2014;extern;Bachelor;DE;Extraktion und Persistierung von Metadaten aus DATEV Servicewissen zur Verbesserung der semantischen Suche mit Hilfe der Programmiersprache LUA;
16.07.14;31.10.14;2014;extern;Bachelor;DE;Erstellung einer Benutzeroberfläche zur beispielhaften Ansteuerung einer Automatisierungssoftware am Beispiel von TIA Portal Openness;
21.07.14;20.12.14;2014;extern;Bachelor;DE;Analyse, Auswahl und Optimierung eines visuellen Datenbanken Query-Builders für Führungskräfte mit dessen beispielhafter Implementierung;
21.07.14;;2014;extern;Bachelor;DE;Prototypische Umsetzung der Stammdatenversorgung einer weltweiten E-Commerce Lösung mit der Technologieplattform SAP HANA;
22.07.14;22.12.14;2014;extern;Bachelor;DE;Konzeption, Umsetzung und Controlling der Migration einer Webpräsenz<br>unter besonderer Berücksichtigung von SEO;
24.07.14;22.12.14;2014;extern;Bachelor;DE;Automatisierung und Optimierung der Journal Entry Tests der Jahresabschlussprüfung bei der Rödl & Partner GmbH;
01.08.14;31.12.14;2014;extern;Bachelor;DE;Überführung einer objektorientierten zu einer relationalen Datenbank - Evaluation, Konzeption und Umsetzung anhand des Softwareprodukts distribution.list;
01.08.14;30.03.15;2014;extern;Master;DE;Handgestenerkennung zur Interaktion mit Webanwendungen unter Einsatz moderner Webtechnologien;
01.08.14;07.01.15;2014;extern;Bachelor;DE;Mobile Zeiterfassung für das Projektmanagement mit Liferay ;
05.08.14;10.11.14;2014;extern;Bachelor;DE;Automatisierung der Bereitstellung fachlicher Web Services aus einem Kernbankensystem;
18.08.14;16.01.15;2014;extern;Bachelor;DE;Analyse und Bewertung von Strategien zur Implementierung einer Cloud-Plattform für Customizing-Lösungen im Bereich Personalwirtschaftssysteme;
01.09.14;28.01.15;2014;extern;Bachelor;DE;Entwicklung einer flexibel einsetzbaren Ansteuereinheit für LED-Leuchtmittel ;
01.09.14;30.01.15;2014;extern;Bachelor;DE;Konzeption und Entwicklung einer Web-Oberfläche zur Erfassung und Visualisierung  fachlicher Kompetenzen,  anhand einer parallel geführten Nutzerbefragung<br><br>;
01.09.14;;2014;extern;Bachelor;DE;Analyse der neuen Programmiersprache Swift mit Identifikation neuer<br>Programmierkonzepte gegenüber bekannten Sprachen und Zukunftsprognose in<br>Hinsicht auf Nützlichkeit, Sicherheit und Performance im Kontext der Platformen<br>iOS und OS X.<br>;
01.09.14;30.01.15;2014;extern;Bachelor;DE;Konzeption und Entwicklung einer Anwendung zur Verwaltung von team- und mitarbeiterübergreifenden Fachkompetenzen zur Ermittlung des Weiterbildungsbedarfs für die Firma;
01.09.14;31.01.15;2014;extern;Bachelor;EN;Virtual Reality Software - A Comparison ;
08.09.14;08.05.15;2014;extern;Master;DE;Integration neuer Software innerhalb existierender IT-Strukturen am Beispiel eines Skillmanagementtools;
12.09.14;;2014;extern;Bachelor;DE;Partikelschwarm-Algorithmen - Konzeption und Realsierung einer Anwendung zur Optimierung;
15.09.14;15.05.15;2014;extern;Master;DE;Einsatzmöglichkeiten und Chancen von Business Activity und Complex Event Processing in Unternehmen der Logistikbranche;
15.09.14;30.01.15;2014;extern;Bachelor;EN;Conception and prototypical implementation of a performance scorecard for PLM Solution Engineering at Siemens AG;
01.10.14;20.02.15;2015;extern;Bachelor;DE;Entwickeln einer Web-basierten App für Embedded Geräte;
01.10.14;02.03.15;2015;extern;Bachelor;DE;Berechnung der Tabulatur aus dem Audiosignal einer Gitarrenaufnahme;
01.10.14;30.01.15;2015;extern;Bachelor;DE;Auswahl und Einführung eines Produktdatenmanagement-Systems in einem mittelständischen Unternehmen;
01.10.14;13.02.15;2015;extern;Bachelor;DE;Konzeption und Entwicklung von agilen Deployment-Prozessen für DB-Code bei der ING-DiBa AG;
01.10.14;01.03.15;2015;extern;Bachelor;DE;Konzeption und Entwicklung einer Microsoft.NET Framework-Anwendung<br>zum Management eines verteilt gespeicherten Kundendatenpools.;
01.10.14;27.02.15;2015;extern;Bachelor;DE;Entwicklung eines Datenrouting-Services für das Energiemanagementframework OGEMA 2.0;
01.10.14;27.02.15;2015;extern;Bachelor;DE;Implementierung und Evaluierung einer WebRTC-basierten Videokonferenz;
01.10.14;26.02.15;2015;extern;Bachelor;DE;Ermittlung, Vergleich und Bewertung von Frameworks für Web Apps als Alternative zu nativen Apps anhand einer Beispielanwendung der Versicherungsbranche;
01.10.14;29.01.15;2015;extern;Bachelor;DE;Anbindung einer Laborautomatisierungssoftware an die iLAB-Plattform via des Kommunikationsstandards SiLA;
01.10.14;20.02.15;2015;extern;Bachelor;DE;Implementierung einer prototypischen Anwendung auf Basis des iMED Web Service Hosts in der iMED Softwareplattform;
01.10.14;02.03.15;2015;extern;Bachelor;DE;Konzeption und Realisierung eines Tools für kollaborative Vorlesungsmitschriften unter Ausnutzung gerätespezifischer Eingabeverfahren;
01.10.14;02.03.15;2015;extern;Bachelor;DE;Konzeption und Implementierung einer Low-Level Sprachsteuerung auf mobilen Android-Geräten;
02.10.14;;2015;extern;Bachelor;DE;Entwicklung einer App zur Korrektur individueller Rot-Grün-Farbsehschwächen;
02.10.14;27.02.15;2015;extern;Bachelor;DE;Visualisierung proprietärer Prozessdaten mit Prognose des Prozessverlaufs und prototypischer Umsetzung;
06.10.14;29.01.15;2015;extern;Bachelor;EN;Tool Support for Organizing an Open Source Conference - Examination <br>of the Practicability of Predictive Analytics;
06.10.14;05.03.15;2015;extern;Bachelor;DE;Analyse und Implementierung des DANE-Protokolls für EXIM;
06.10.14;06.03.15;2015;extern;Bachelor;DE;Konzeption und Entwicklung einer Standort-basierten Werbeplattform für mobile Endgeräte auf Basis eines Systems zur lokalisierten Anzeige von Produkten;
09.10.14;06.03.15;2015;extern;Bachelor;DE;Konzeption und Realisierung einer Ausführungsplanerstellung für eine räumlich/symbolische Suchumgebung;
10.10.14;09.03.15;2015;extern;Bachelor;DE;Musikerkennungssoftware: Stand der Technik und vergleichende Evaluierung;
10.10.14;02.02.15;2015;extern;Bachelor;EN;Scene extraction by means of a Pan-Tilt-Zoom-camera;
13.10.14;;2015;extern;Bachelor;DE;Entwicklung einer Benutzerschnittstelle eines Eclipse-basierten Plugins zur Optimierung von automobilen Steuergerätearchitekturen;
15.10.14;16.03.15;2015;extern;Bachelor;DE;Konzeption und Implementierung einer Komponente zum Import relationaler Datenbankstrukturen in smartfacts;
15.10.14;12.03.15;2015;extern;Bachelor;DE;Konzeption und Entwicklung eines Global Data Dictionaries zur Nachvollziehbarkeit von Datenstrukturänderungen im Mainframeumfeld der Datev eG;
15.10.14;13.03.15;2015;extern;Bachelor;DE;Konzeption, Implementierung und Evaluation einer HTML5-basierten Loopstation zur Nutzung mit Saiteninstrumenten;
16.10.14;18.02.15;2015;extern;Bachelor;DE;"Edition der Aufgabenstellungen aus Anton Neudörffers ""Grosser Arithmetic"" (~1610). Materialerschließung als Beitrag zum diachron-<br>intermedialen Wissensmanagement";
16.10.14;30.01.15;2015;extern;Bachelor;DE;Softwaregestützte Entscheidungshilfe für Planungsänderungen durch Auswertung von hierarchisch priorisierten Arbeitsaufgaben bei der Datev eG;
16.10.14;04.12.14;2015;extern;Bachelor;DE;Architektur dynamischer Single-Page-Applications;
16.10.14;09.02.15;2015;extern;Bachelor;DE;Konzeption und Implementierung eines Android-Clients zur Darstellung von personalisierbaren Echtzeitinformationen für Studierende der TH Nürnberg Georg Simon Ohm;
16.10.14;16.03.15;2015;extern;Bachelor;DE;Konzeption und Implementierung eines Softwaresystems zur Visualisierung und Analyse von Algorithmen in Graphen;
16.10.14;16.03.15;2015;extern;Bachelor;DE;Modellierung von Geschäftsprozessen in einer Standardnotation und prototypischer Import in ein IT-Service-Management-Tool;
16.10.14;13.03.15;2015;extern;Bachelor;DE;Erstellung und Konzeption einer flexiblen Datenschnittstelle zur Integration von Sensornetzen in das Internet of Things;
20.10.14;20.03.15;2015;extern;Bachelor;DE;Entwicklung eines Web-Portals zum zentralen Versand von institutsspezifischen Brief- und Vertragsdokumenten;
20.10.14;13.03.15;2015;extern;Bachelor;DE;Entwicklung eines arbeitsplangestützten Reportings zur Optimierung der KVP (Kontinuierlicher Verbesserungsprozess)- Arbeit;
22.10.14;13.03.15;2015;extern;Bachelor;DE;Mehrkernfähige Konfiguration von Telekommunikationseinrichtungen durch modellbasierte Abhängigkeiten;
23.10.14;16.03.15;2015;extern;Bachelor;DE;Möglichkeiten der Datenanalyse bei einem mittelständischen Softwarehersteller;
23.10.14;05.02.15;2015;extern;Bachelor;DE;Konzeption und prototypische Entwicklung eines wissensbasierten Systems zur Unterstützung der normierten Erfassung von Kunden-<br>Interaktionen am Service Desk des Produktbereichs der DATEV eG ;
24.10.14;16.03.15;2015;extern;Bachelor;DE;Auswahl und prototypische Implementierung einer Einsatzplanungssoftware für den Ausbildungsbereich der DATEV eG;
24.10.14;13.03.15;2015;extern;Bachelor;DE;Konzeption und prototypische Realisierung eines Werkzeugs für den länderübergreifenden Datentransfer zwischen Lohnabrechnungssystemen bei der DATEV eG;
27.10.14;26.03.15;2015;extern;Bachelor;DE;Einführung von Agilität;
01.11.14;16.03.15;2015;extern;Bachelor;DE;Implementierung einer intelligenten Walk-Away App. zur Steuerung von Laborgeräten mit SILA;
01.11.14;30.06.15;2015;extern;Master;DE;Kalibrierung von Panorama-Endoskopen;
03.11.14;01.04.15;2015;extern;Bachelor;DE;Konzeption und Realisierung des §21-Anzeigeprogramms getAEB mit Fokus auf die Entwicklung einer modularen Softwarearchitektur unter Verwendung geeigneter Patterns und Clean Code;
04.11.14;04.04.15;2015;extern;Bachelor;DE;Action Script zu Java Script Compiler ;
04.11.14;01.04.15;2015;extern;Bachelor;DE;Entwurf und Implementierung eines Projekt-Dashboards für ein Softwareunternehmen;
06.11.14;25.06.15;2015;extern;Master;DE;Evaluierung und Bewertung von Identity-Management-Architekturen in Hinblick auf Federated Identity-Management;
07.11.14;02.04.15;2015;extern;Bachelor;DE;Automatisiertes OnDemand-Provisioning von Testumgebungen in einer Private Cloud unter Einsatz von vCloud Automation Center;
10.11.14;30.01.15;2015;extern;Bachelor;DE;Analyse und Optimierung von Reports in einem Betrieb und Aufzeigen der Abbildungsmöglichkeiten in ein DWH;
10.11.14;10.04.15;2015;extern;Bachelor;DE;Prototypische Entwicklung eines Snapshoting-Tools zur Softwarequalitätssicherung ;
11.11.14;23.02.15;2015;extern;Bachelor;DE;"""Loss Prevention"" - Entwicklung von webbasierten Berichten zur Analyse von potentiellen Manipulationen im Retail-Sektor";
12.11.14;26.02.15;2015;extern;Bachelor;DE;Konzeption und prototypische Implementierung eines Performance Cockpits ;
13.11.14;07.04.15;2015;extern;Bachelor;DE;Implementierung eines Cross-Bilateralen-Filters für lichtfeldbasierte Tiefenkartendaten;
17.11.14;16.04.15;2015;extern;Bachelor;DE;Konzeption und Realisierung einer generischen Web-Benutzeroberfläche zur Planung von Arbeitsabläufen;
17.11.14;15.04.15;2015;extern;Bachelor;DE;Nutzung von Inter-Tag-Entfernungsmessung in der RTLS-basierten Ortung;
17.11.14;16.04.15;2015;extern;Bachelor;DE;Portierung und Schnittstellenkonzeption/-Implementierung einer Applikation zur Steuergerätediagnose;
20.11.14;12.03.15;2015;extern;Bachelor;DE;Unterstützung von logistischen Prozessen mit Hilfe von Smart Glasses<br>und Mustererkennung ;
24.11.14;01.02.15;2015;extern;Bachelor;DE;Business Intelligence in einem mittelständischen Unternehmen - Eine Fallstudie ;
24.11.14;;2015;extern;Bachelor;DE;Semantische Technologien im Wissensmanagement - Einsatzmöglichkeiten, Umsetzung in die Praxis und strategische Ausrichtung;
26.11.14;24.04.15;2015;extern;Bachelor;DE;Technische Entwicklung, Vorteile und Risiken des Cloud Computings aus unternehmerischem und technischem Blickpunkt.;
01.12.14;30.04.15;2015;extern;Bachelor;DE;"Konzeption und prototypische Entwicklung einer Klassenbibliothek für das Android-Betriebssystem für den Zugriff auf die Umfrage-Plattform ""Limesurvey""";
01.12.14;15.09.15;2015;extern;Master;DE;Konzeption, Design und Entwicklung einer nativen Adroid-App für mobile Endgeräte basierend auf der Umfrage-Plattform Limesurvey zur Anzeige von Antworten und Statistiken von Studiengangtests ;
09.12.14;09.08.15;2015;extern;Master;DE;Best Practice für die Integration einer toolgestützten Codeanalyse mit dem Fokus Wartbarkeit und Codequalität;
15.12.14;14.08.15;2015;extern;Master;DE;Portierung und Evaluation von Algorithmen zur WLAN-basierten Richtungs- und Positionsbestimmung;
16.12.14;14.08.15;2015;extern;Master;DE;Konzeption, Realisierung und Einführung der IT-gestützten Kommissionierung im Online-Modehandel;
17.12.14;15.05.15;2015;extern;Bachelor;DE;Analyse der techn. Aspekte an die Mehrsprachigkeit von IT-Applikationen zur Unterstützung von Geschäftsprozessen (Schwerpunkt PLM- und SCM-Prozesse) sowie Erarbeitung von Lösungskonzepten unter der Berücksichtigung von wirtschaftl. Einflussfaktoren;
17.12.14;17.05.15;2015;extern;Bachelor;DE;Prototypische Implementierung eines Space Colonization Algorithmus in einer 3D-Engine;
17.12.14;14.08.15;2015;extern;Master;DE;Optimierung von Modellen maschineller Lernverfahren im Rahmen eines Big Data Projektes zur Betrugsanzeigenerkennung;
18.12.14;13.03.15;2015;extern;Bachelor;DE;Agiles IT-Management;
18.12.14;18.05.15;2015;extern;Bachelor;DE;Konzeption einer Recommendation-Engine mittels ausgewählter Data-Mining Algorithmen;
22.12.14;02.04.15;2015;extern;Bachelor;DE;Fahrzeugflottensimulation als Dienst;
23.12.14;;2015;extern;Bachelor;DE;Einsatz von Data-Mining-Verfahren zur Entscheidungsunterstützung im BPM am Beispiel von Adaptive-Case-Management-Szenarium;
15.01.15;12.06.15;2015;extern;Bachelor;DE;Untersuchung der Dienstgüte von Audio-Streaming in Mobilfunknetzen bei Bitraten unter 32 kbps;
23.01.15;19.06.15;2015;extern;Bachelor;EN;Design and Development of a Web-Based Interface for a Mobile Digital Storytelling System;
03.02.15;02.07.15;2015;extern;Bachelor;DE;Konzeption und Entwicklung einer dynamisch erzeugten Konfigurationsoberfläche für Funk- und Ortungstechnologien bei Fraunhofer;
03.02.15;08.06.15;2015;extern;Bachelor;EN;Implementation of Pipes for the Ulix Operating System;
05.02.15;07.09.15;2015;extern;Master;DE;Entwicklung einer 3D-Multitouchoberfläche auf Basis des Fused Deposition Modeling 3D-Druckverfahrens;
05.02.15;09.09.15;2015;extern;Master;DE;Analyse und Optimierung des Incident Management Prozesses bei einem mittelständischen Unternehmen;
12.02.15;13.06.15;2015;extern;Bachelor;DE;Konzeption und Implementierung einer Report-Software zur Analyse des Nutzungsverhaltens von CAD-Software bei der Robert Bosch GmbH;
12.02.15;12.10.15;2015;extern;Master;DE;Konzepterstellung und prototypische Entwicklung für die Siemens interne Kommunikation im Kontext Enterprise Architecture Management in einer global agierenden Abteilung;
18.02.15;18.08.15;2015;extern;Master;DE;Schutz kompilierter Binärpakete vor Dekompilierung und Manipulation;
26.02.15;23.10.15;2015;extern;Master;DE;Automatisiertes Testen von mobilen Applikationen;
01.03.15;01.08.15;2015;extern;Bachelor;DE;Konzeptionierung und Realisierung eines Konfigurations-Tools für die Echtzeit-Middleware Gamma V;
01.03.15;22.07.15;2015;extern;Bachelor;DE;Service Design und Service Transition in der IV-Abteilung am Klinikum Nürnberg;
02.03.15;30.07.15;2015;extern;Bachelor;DE;Konzeption und prototypische Realisierung einer graphischen, workflowbasierten Steuerungs- und Überwachungsanwendung für ein Datenübermittlungssystem.;
05.03.15;05.08.15;2015;extern;Bachelor;DE;Big Data Analysen in der Cloud;
12.03.15;28.09.15;2015;extern;Master;DE;Konzeption und Implementierung eines Reputationssystems für ein soziales Netzwerk im Umfeld der Lehre;
12.03.15;11.08.15;2015;extern;Bachelor;DE;Konzeption und prototypische Implementierung einer challengebasierten Bucketlist;
15.03.15;15.08.15;2015;extern;Bachelor;DE;Plattformunabhängige Softwareentwicklung für mobile Endgeräte;
15.03.15;14.08.15;2015;extern;Bachelor;DE;Evaluierung und Bewertung von Methoden des Information Retrievals   zur Berechnung von Code Metriken am Beispiel vom Quellcode der DATEV;
16.03.15;17.08.15;2015;extern;Bachelor;DE;Implementierung eines Verfahrens zur Nachbearbeitung von zusammengesetzten Projektionen in der industriellen röntgen Radioskopie;
17.03.15;17.08.15;2015;extern;Bachelor;DE;Entwicklung einer prototypischen Tastatur für eine runde Smartwatsch auf Basis von Android Wear;
17.03.15;17.08.15;2015;extern;Bachelor;DE;Verschiedene Wege der Integration von MongoDB in Liferay Applikationen;
18.03.15;20.08.15;2015;extern;Bachelor;DE;Mittel zur Verbesserung der Umgangsformen in sozialen Netzwerken mit Fokus auf Methoden der Gamification;
23.03.15;23.11.15;2015;extern;Master;DE;Industrie4.0:Agentenbasierte Modellierung industrieller Fertigungsnetze;
24.03.15;18.08.15;2015;extern;Bachelor;DE;Konzeption und prototypische Implementierung zur Erneuerung des Kassensystems einer ERP-Software;
25.03.15;14.08.15;2015;extern;Bachelor;DE;Analyse und Verbesserung von Usability und Design bei ERP-Systemen anhand der Software v. Soft der Firma GmbH & Co. KG;
26.03.15;;2015;extern;Bachelor;DE;"Verhaltensanalyse von ""Parallelität in Parallelität""";
26.03.15;20.11.15;2015;extern;Master;DE;Entwicklung eines sicheren Session- und Access-Managements für eine verteilte Anwendung;
30.03.15;24.08.15;2015;extern;Bachelor;DE;Analyse des Einflusses von Bewertungsportalen, Communities und Foren auf das Kaufverhalten;
30.03.15;27.08.15;2015;extern;Bachelor;DE;Konzeption und Entwicklung eines Fax-Anzeige Controls für SFF-Dateien in DATEVnet pro Fax noch CAPI;
31.03.15;31.08.15;2015;extern;Bachelor;DE;Planung, Analyse und Entwurf eines skalierbaren und modularen Automaten für die Erfassung von verteilten Daten unter Berücksichtigung sicherheitstechnischer Rahmenbedingungen;
01.04.15;31.08.15;2015;extern;Bachelor;DE;Vergleichende Studie zur Eignung von durch 3D-Druck erstellten optischen Markern;
01.04.15;31.08.15;2015;extern;Bachelor;DE;Entwicklung einer mobilen App, zur Fernsteuerung einer .NET Applikation über Netzwerk (WLAN);
01.04.15;01.09.15;2015;extern;Bachelor;DE;Erstellung und inkrementelle Erweiterung zufallsgenerierter Höhenkarten unter Berücksichtigung geomorphographischer Eigenschaften ;
01.04.15;17.08.15;2015;extern;Bachelor;DE;Relevanz und Auswirkungen der professionellen IT auf den Geschäftserfolg von Social Entrepreneurship am Beispiel der Helden Gesucht gGmbH;
01.04.15;07.09.15;2015;extern;Master;DE;Konzeption und Implementierung einer rechnergestützten Qualitätskontrolle studentischer Beiträge im Kontext kollaborativen e-Learnings;
01.04.15;31.08.15;2015;extern;Bachelor;DE;Ein Geschwindigkeitsassistenzsystem mit automatischer Verkehrszeichenerkennung für das iPhone;
01.04.15;31.08.15;2015;extern;Bachelor;EN;Optical Music Recognition for Mobile Devices;
01.04.15;31.08.15;2015;extern;Bachelor;DE;Fahrzeugdiagnose und -Service mittels mobiler Consumer-Endgeräte;
02.04.15;31.08.15;2015;extern;Bachelor;DE;Simulation und Steuerung von Bahnbewegungen einer Kugel mit Hilfe von Softcomputing Verfahren und einer Physik Engine.;
07.04.15;;2015;extern;Bachelor;DE;3D-Objekt-Erkennung durch einen autonomen, mobilen Roboter;
08.04.15;04.09.15;2015;extern;Bachelor;DE;Abbilden des Scrum Prozesses auf die Anforderungen des Automotive SPICE  Standards;
09.04.15;18.08.15;2015;extern;Bachelor;DE;Komparative Studie zur Lesbarkeit taktiler Ausdrucke von Schrift, Symbolen, Graphiken und taktiler Karten;
09.04.15;09.09.15;2015;extern;Bachelor;DE;Konzeption und Implementierung von TAG s in einem Verwaltungstool für medizinische Testbilder;
09.04.15;09.09.15;2015;extern;Bachelor;DE;Entwicklung eines plattformübergreifenden Werkzeugs zur kollaborativen Echtzeit-Generierung von Mindmaps;
13.04.15;;2015;extern;Bachelor;DE;"Konzeption und prototypische Realisierung eines Software-Werkzeugkastens zur Generierung praxisnaher Testdaten für die DATEV-on-premise-Komponente ""Zentrale Stammdaten""";
15.04.15;24.09.15;2015;extern;Master;DE;Analyse, Design und Implementierung von generischen Business Intelligence-Auswertungen mit QlikSense basierend auf Microfsoft Dynamics NAV;
17.04.15;18.08.15;2015;extern;Bachelor;DE;Dashboards im Krankenhaus. Analyse und Konzeption eines Dashboards für radiologische Abteilungen im Krankenhaus;
17.04.15;17.09.15;2015;extern;Bachelor;DE;Benutzerfreundliche Buchungs- und Transaktionskonzepte für mobile Consumer-Endgeräte;
20.04.15;21.09.15;2015;extern;Bachelor;DE;Webbasierte Interaktion zwischen Smartphone und Public Display zur Verbesserung des Einkaufserlebnisses;
20.04.15;02.11.15;2015;extern;Bachelor;DE;Untersuchung der Güte der Klassifikation von User-Based Collaborative Filtering am Beispiel des MovieLens-Datensatzes;
22.04.15;22.09.15;2015;extern;Bachelor;DE;Analyse des Einflusses von sozialen Medien auf das Kaufverhalten am Beispiel der deutschen Buchbranche;
22.04.15;22.12.15;2015;extern;Master;DE;Prototypische Implementierung eines Frameworks zur Kennzahlenanalyse eines Content-Management-Systems;
23.04.15;15.10.15;2015;extern;Master;DE;Konzeption und Realisierung der Migration einer BI-Applikation am Beispiel von SAP BW nach SAP BW on HANA bei einem führenden Automobilhersteller;
23.04.15;21.09.15;2015;extern;Bachelor;DE;Analyse und Weiterentwicklung eines Business Intelligence Systems für ein mittelständisches Unternehmen;
24.04.15;07.01.16;2015;extern;Master;DE;Machbarkeitsstudie zur Evaluierung und Bewertung der Java-Basistechnologie für ein komplexes und laufzeitintensives Netz der DATEV-Rechnungsschreibung;
24.04.15;23.09.15;2015;extern;Bachelor;DE;Konzeption und Entwicklung eines Verfahrens zur Earned Value Analyse in agilen Festpreisprojekten;
24.04.15;28.08.15;2015;extern;Master;DE;"Konzeption und prototypische Entwicklung eines Brettspiels zur interaktiven Gestaltung der Lehrveranstaltung ""Wissensmanagement"" mittels Gamification";
27.04.15;14.08.15;2015;extern;Bachelor;DE;Entwurf und Implementierung einer Kommunikationsschnittstelle zwischen einem sozialen Netzwerk und einer Jobbörse;
28.04.15;28.09.15;2015;extern;Bachelor;DE;Konzeption und prototypische Umsetzung einer Skript-Sprache für Autoren von interaktiven Spielbüchern;
29.04.15;06.08.15;2015;extern;Bachelor;DE;Kritische Auseinandersetzung mit der Knowledge Modeling an Description Language und Anwendung auf einen geeigneten Prozess;
30.04.15;30.09.16;2015;extern;Bachelor;DE;Konzeption und Realisierung einer Webservice-Anbindung zum automatisierten Datenaustausch zwischen einem ERP-System und E-Commerce-Plattformen;
30.04.15;30.09.15;2015;extern;Bachelor;DE;Realisierung einer Android-App zur Unterstützung der Orientierung blinder Menschen;
30.04.15;30.09.15;2015;extern;Bachelor;DE;Routenoptimierung von öffentlichen Verkehrsmitteln mit Hilfe von Softcomputingmethoden;
30.04.15;30.09.15;2015;extern;Bachelor;DE;Konzeption und Realisierung eines generischen Filters für Webservices am Beispiel des DATEV Schnittstellensystems Pro<br><br>;
30.04.15;18.08.15;2015;extern;Bachelor;DE;Workflow-Management-Systeme für digitale Formulare;
01.05.15;18.12.15;2015;extern;Master;DE;Rekonstruktion der Gesamtansicht eines großflächigen Photovoltaik-Freiflächenanlage aus Multicopter-Videoaufnahmen;
04.05.15;01.10.15;2015;extern;Bachelor;DE;Internationalisierung der HomeRun-Umgebung<br><br>;
08.05.15;08.10.15;2015;extern;Bachelor;DE;Entwurf und prototypische Entwicklung einer intelligenten und vielseitigen Assistenzanwendung für den <br>Einsatz im privaten und geschäftlichen Alltag<br>;
12.05.15;;2015;extern;Bachelor;DE;Ermittlung und Analysierung bestimmter Zielgruppenraster und deren dazugehörigen Gamification Patterns<br>;
12.05.15;12.10.15;2015;extern;Bachelor;DE;Entwurf und Implementierung einer Smartwatch-/Smartphone-Anwendung zur Trainingskontrolle;
13.05.15;19.08.15;2015;extern;Bachelor;DE;Peer-to-Peer-Netze jenseits des Filesharing: Entwicklung und Potenziale.;
13.05.15;13.10.15;2015;extern;Bachelor;DE;Online Marketing mit Schwerpunkt Search Engine Optimization auf Basis eines Content Management Systems für ein Unternehmen in der Finanz- und Versicherungsbranche ;
15.05.15;11.08.15;2015;extern;Bachelor;DE;Entwicklung eines Handlungsleitfadens zur Erstellung einer adressatengerechten Softwaredokumentation<br>;
18.05.15;18.01.16;2015;extern;Master;DE;Konzeption, Design und Entwicklung einer nativen Android-App für Zugriff, Bearbeitung und Auswertung von Online Self Assessments (OSAs) des OSA-Portals der TH Nürnberg;
18.05.15;02.12.15;2015;extern;Master;DE;Konzeption und Umsetzung eines Kennzahlensystems im Bereich Business Intelligence auf Basis des ERP Systems Microsoft Dynamics NAV unter der Verwendung der Technologie des Microsoft SQL Servers 2014;
01.06.15;29.10.15;2015;extern;Bachelor;DE;Computer Supported Cooperaive Work - Aufbau eines digitalen Arbeitsplatzes in SharePoint, der in den Niederlassungen einer mittelständischen Firma weltweit nutzbar ist.;
01.06.15;01.02.16;2015;extern;Master;DE;Cloud-basierte Kurvenwarnung;
01.06.15;07.01.16;2015;extern;Master;EN;Organizational Learning Measured By Social Network Analysis ;
03.06.15;02.11.15;2015;extern;Bachelor;DE;Konzeption und Entwicklung einer Applikation für den Austausch von Kunden- und Bestelldaten zwischen E-Commerce-System OXID und E-Mail-Marketingplattform<br><br><br>;
11.06.15;10.02.16;2015;extern;Master;DE;Systematischer Vergleich der Extraktionsstrategien aus SAP Business Warehouse zur Visualisierung und Aufbereitung der Daten mit Hilfe alternativer Analyse-Frontend-Systeme.;
12.06.15;08.02.16;2015;extern;Master;DE;Definition und Entwicklung einer kennzahlenbasierten Business Intelligence Architektur unter Verwendung des In-Memory Technologie des SQL-Servers 2014;
30.06.15;14.03.16;2015;extern;Master;DE;Konzeption einer mobilen Anwendung für das Frachtenbenchmarking in der Chemielogistik bei der Fraunhofer-Arbeitsgruppe für Supply Chain Services;
01.07.15;;2015;extern;Bachelor;DE;Anonymisierung von Gesichtern in Videos;
23.07.15;23.12.15;2015;extern;Bachelor;DE;Automatisierte Analyse von Systemdaten für das In-Memory-Datenbanksystem EXASolution;
27.07.15;24.03.16;2015;extern;Master;DE;Entwicklung eines Eclipse-Plugins zur Analyse von EAST-ADL-Modellen im Hinblick auf empirisch erhobene Qualitätskriterien<br><br>;
31.07.15;16.11.15;2015;extern;Bachelor;EN;Modern Front End Development for Web Applications illustrated by UniCoach;
03.08.15;01.04.16;2015;extern;Master;DE;Entwicklung eines visuellen Zwei-Punkte-Kommunikationsprotokolls für Endbenutzergeräte;
03.08.15;21.12.15;2015;extern;Bachelor;DE;Entwurf und Bewertung einer generischen hoch skalierbaren strombasierten Monitoring Plattform;
04.08.15;;2015;extern;Bachelor;DE;Kinect One zur Beobachtung des Kundenverhaltens;
10.08.15;11.03.16;2015;extern;Master;DE;Inkrementelle Restrukturierung der Software-Architektur einer Lagecy-Anwendung im laufenden Betrieb;
11.08.15;11.01.16;2015;extern;Bachelor;DE;Das Internet der Dinge im Umfeld der privaten Nutzung - Marktanalyse und Zukunftsprognose;
13.08.15;13.01.16;2015;extern;Bachelor;DE;Konzeption und prototypische Umsetzung einer Client-Server-Architektur für die Datenübertragung von Augumented Reality Daten zwischen Webserver und iOS App;
01.09.15;28.01.16;2015;extern;Bachelor;DE;Entwicklung eines Metadaten-Codegenerators zur automatischen Erstellung von Auswertungsprogrammen für IBM Mainframes;
01.09.15;29.01.16;2015;extern;Bachelor;DE;Architekturkonzept und Prototyp zur Visualisierung von Automaten aus der theoretischen Informatik;
01.09.15;01.02.16;2015;extern;Bachelor;DE;Entwicklung eines gestenunterstützten natürlichsprachlichen Dialogs mit einem humanoiden Roboter;
01.09.15;29.01.16;2015;extern;Bachelor;DE;Konzeption und Implementierung eines webbasierten Systems zur Steuerung von Batch-Prozessen;
01.09.15;28.01.16;2015;extern;Bachelor;DE;Physically-based Shading mit Web GL;
01.09.15;28.01.16;2015;extern;Bachelor;DE;Analyse und Vergleich von Garbage Collection Algorithmen für C++;
01.09.15;25.02.16;2015;extern;Bachelor;DE;Verwaltung von RDF-Graphen mittels non-RDF-Graphdatenbanken;
01.09.15;29.01.16;2015;extern;Bachelor;DE;Prototypische Realisierung einer Plattform zur organisatorischen Wissensmanagement und Vorbereitung des Einsatzes automatischer Analyse-Methoden;
04.09.15;11.12.15;2015;extern;Bachelor;DE;Konzeption und prototypische Realisierung eines Datenqualitätstools für das Dokumentenmanagementsystem der DATEV eG<br><br>;
07.09.15;28.01.16;2015;extern;Bachelor;DE;Entwicklung einer effizienten Vorgehensweise zur Analyse technischer Schulden des Software-Produkts „Zahlungsverkehr on premise“ der DATEV eG unter Verwendung von Architekturanalysewerkzeugen;
07.09.15;05.02.16;2015;extern;Bachelor;DE;Entwicklung und Evaluation einer Benutzerschnittstelle für blinde Menschen zur Bedienung von 3D-Druck-Software;
08.09.15;08.02.16;2015;extern;Bachelor;DE;Implementierung und Weiterentwicklung von Algorithmen der Spieltheorie auf der Basis von Algorithmen des Operations Research;
14.09.15;;2015;extern;Bachelor;DE;Prototypische Entwicklung einer Benutzerschnittstelle zur Visualisierung mehrdimensionaler, komplexer Daten bei der Optimierungsanalyse von EAST-ADL Architekturen;
14.09.15;15.02.16;2015;extern;Bachelor;DE;Konzeption und Realisierung einer Desktop-Virtualisierung im Umfeld der bayerischen Staatsbauverwaltung,;
15.09.15;29.01.16;2015;extern;Bachelor;DE;"Entwurf von IT-Architektur Modellierungsrichtlinien im Kontext der Architekturbeschreibungssprache ArchiMate®"" ";
18.09.15;07.01.16;2015;extern;Bachelor;DE;Prozessmanagement in einem mittelständischen IT-Unternehmen;
21.09.15;19.05.16;2015;extern;Master;DE;Entwicklung und Implementierung eines Gamification-Konzepts am Beispiel einer Webseite zur Vereinsorganisation;
23.09.15;22.01.16;2015;extern;Bachelor;DE;Konzeption und Realisierung eines Front-End Wechsels für ein Kanzlei Management-System;
28.09.15;26.02.16;2015;extern;Bachelor;DE;Neuronale Netze<br>Analyse und Design zur Bewertung von Fußballspielern<br>;
30.09.15;29.02.16;2015;extern;Bachelor;DE;Anonymisierung von Autokennzeichen in Videostreams;
01.10.15;29.02.16;2016;extern;Bachelor;DE;Einsatz von Redfish zur Administration virtueller Maschinen;
01.10.15;29.01.16;2016;extern;Bachelor;DE;HMI-Testautomatisierung in der Fahrzeugentwicklung;
01.10.15;01.03.16;2016;extern;Bachelor;DE;Entfernungsbasierte Detailgradsteuerung von punktbasierten Modellen durch den binären Raumpartionierungsalgorithmus;
01.10.15;26.02.16;2016;extern;Bachelor;DE;Beschleunigung der Visualisierung wasserbaulicher Simulationen durch Gitterreduktionsverfahren;
01.10.15;01.03.16;2016;extern;Bachelor;EN;Automatic classification of defects in photovoltaic modules using electroluminescence imaging;
01.10.15;29.02.16;2016;extern;Bachelor;DE;Erkennung von Bäumen in Farbbildern mit neuronalen Netzen;
01.10.15;29.02.16;2016;extern;Bachelor;DE;"Konzeption und Projektkoordination für die Ablösung der DATEV ""ASP Datenbank""";
01.10.15;01.03.16;2016;extern;Bachelor;DE;Konzeption und Prototyping einer 2D/3D-Visualisierungskomponente zur Anzeige von Voxel-, Oberflächen- und Textdaten<br><br>;
01.10.15;24.02.16;2016;extern;Bachelor;DE;Konzeption und Realisierung einer vereinheitlichten Kollaborationsplattform auf Basis von MS Exchange im Bankenumfeld;
02.10.15;29.04.16;2016;extern;Master;DE;Untersuchung von Apple HTTP Live Streaming für AAC-basierte Musik-Streaming Dienste<br><br>;
05.10.15;05.03.16;2016;extern;Bachelor;DE;"""Entwicklung einer prototypischen AUTOSAR Implementierung für ein autonom fahrendes Modellfahrzeug"" ";
05.10.15;05.06.16;2016;extern;Master;DE;Adaptive und geräteübergreifende Anwendungsentwicklung im Umfeld von Industrie 4.0;
05.10.15;02.03.16;2016;extern;Bachelor;DE;Entwicklung einer generischen Vorgehensweise zur Härtung von IT-Serversystemen;
05.10.15;02.06.16;2016;extern;Master;DE;Entwurf und Entwicklung einer mobilen Gamification-Lösung für Städtetouren;
06.10.15;22.01.16;2016;extern;Bachelor;DE;Fachliche Konzeption der automatisierten Zuordnung von Kreditkarten- sowie PayPal-Zahlungen zu Ausgangsrechnungen im Rahmen des SaaS-Projekts bei DATEV eG;
06.10.15;03.03.16;2016;extern;Bachelor;DE;Konzept zur Überprüfung von On-Premise-Produkten zu einer 3-Tier-Architektur am Beispiel der Expertisen-und Gestaltungssysteme der DATEV eG;
07.10.15;01.03.16;2016;extern;Bachelor;DE;Konzeption eines Customer-Relationship Management Prozesses für einen Online-Stellenmarkt;
08.10.15;29.01.16;2016;extern;Bachelor;DE;Werbestrategien im Zeitalter der Blogger und Online Shops-Klassisches Onlinemarketing oder Social Payments;
08.10.15;07.03.16;2016;extern;Bachelor;DE;Analyse einer bestehenden Hochverfügbarkeitslösung für Linux-Systeme sowie Evaluierung und Test von Alternativen;
09.10.15;25.02.16;2016;extern;Bachelor;DE;Konzeption und Implementierung einer weiterentwickelten Testautomatisierungssoftware bei der DATEV eG;
09.10.15;08.06.16;2016;extern;Master;DE;Konzeption und Mechanismen zur Prüfung der Plausibilität der Umsatzsteuervoranmeldung auf Basis einer mobilen Applikation im Auftrag der DATEV eG;
10.10.15;10.06.16;2016;extern;Bachelor;DE;Erkennung von Personen(Full Body Detection) in Videoaufnahmen eines Quadrocopters;
12.10.15;11.02.16;2016;extern;Bachelor;EN;Efficient software image distribution in a chassis-based network switch;
12.10.15;14.03.16;2016;extern;Bachelor;DE;Konzeption und Integration eines Single-Page-Application-Designs in eine native Android-Anwendung;
12.10.15;11.03.16;2016;extern;Bachelor;DE;Analyse und Erweiterung eines Trackingsystems für Vergleichsrechner im Internet und Mobile-Apps;
12.10.15;28.01.16;2016;extern;Bachelor;DE;Konzeption und Implementierung eines Tools zur Verwaltung von ARIS-Skripten mit Apache Subversion ;
12.10.15;;2016;extern;Bachelor;DE;Konzeption und Implementierung von Usage Tracking in einer Messsoftware;
13.10.15;04.02.16;2016;extern;Bachelor;DE;Konzeption, Entwicklung und Evaluation eines Entscheidungsverfahrens zur Festlegung geeigneter Testmethoden für UI-Tests im agilen Softwareentwicklungsumfeld bei DATEV eG;
14.10.15;13.06.16;2016;extern;Master;DE;Definition eines Standards zur Modellierung des Softwareentwicklungsprozesses von DATEV Unternehmen online und eine darauf basierende Optimierung ausgewählter Teilprozesse;
15.10.15;10.03.16;2016;extern;Bachelor;DE;Entwurf einer Applikationsserver-Architektur für das CRM System CAJAC;
15.10.15;14.03.16;2016;extern;Bachelor;DE;Evaluation relationaler und NoSQL Datenbanken hinsichtlich eines CMS mit prototypischer Implementierung für eine Kirchengemeinde;
15.10.15;14.03.16;2016;extern;Bachelor;DE;Entwicklung einer Verarbeitungskette für Echtzeitfeedback im Training;
19.10.15;11.04.16;2016;extern;Bachelor;DE;Analyse und Konzeption einer Kundenverwaltung;
19.10.15;03.03.16;2016;extern;Bachelor;DE;Entwurf und prototypische Implementierung eines ELN auf Basis des iLAB-Frameworks;
20.10.15;20.03.16;2016;extern;Bachelor;DE;Echtzeitrendering von analytischen Flächenlichtquellen;
21.10.15;08.03.16;2016;extern;Bachelor;DE;Analyse und Konzeption eines effektiven Datenmanagements bei der N-ERGIE AG am Beispiel des Netzanschlussprozesses;
22.10.15;03.03.16;2016;extern;Bachelor;DE;Konzeption und Realisierung eines webbasierten Big Data Dashboards für Immowelt AG;
22.10.15;22.03.16;2016;extern;Bachelor;DE;Konzeption und Entwicklung eines Fehlerberichts- und Feedbacksystems für eine Anwendungssoftware für Industrie- und Handelskammern;
22.10.15;14.03.16;2016;extern;Bachelor;DE;Konzeption und prototypische Entwicklung eines webbasierten Dashboards für das Monitoring lungendiagnostischer Geräte;
22.10.15;24.02.16;2016;extern;Bachelor;DE;Untersuchung zur Performancesteigerung der Pakethistorie durch Nutzung eines NoSQL – Datenbanksystem;
26.10.15;24.06.16;2016;extern;Master;DE;Evaluation gängiger Lösungen zum Management und zur Analyse von Logdaten;
26.10.15;29.03.16;2016;extern;Bachelor;DE;Entwicklung einer Fluent API zur Kommunikation mit dem RESTful Webservice DATEVconnect;
26.10.15;14.03.16;2016;extern;Bachelor;DE;Konzeption und Implementierung einer Datenvirtualisierungslösung für Testdaten zur Unterstützung des Testprozesses von medizinischen Bildsystemen;
26.10.15;25.03.16;2016;extern;Bachelor;DE;Evaluation moderner Skalierungsmethoden von Webservices am Beispiel von Media Asset Management mit Node.js und NoSQL;
27.10.15;10.03.16;2016;extern;Bachelor;DE;Auswahl und prototypische Einführung einer Service-Management-Software für die IT-Abteilung eines international tätigen Industrieunternehmens.;
27.10.15;18.04.16;2016;extern;Bachelor;DE;Monitoring strengvertraulicher Daten am Beispiel eines Versicherungsunternehmen;
28.10.15;;2016;extern;Bachelor;DE;Ein spielerischer Ansatz zur Modellierung und Analyse von Klanglandschaften;
28.10.15;28.06.16;2016;extern;Master;DE;Konzeption und Entwicklung eines Analysesystems zur Bewertung von Versicherungsrisiken in Abhängigkeit von Fahrzeugausstattungen“;
29.10.15;14.03.16;2016;extern;Bachelor;DE;Entwicklung einer skalierbaren Serverarchitektur zur Jobsteuerung bei der Siemens AG“;
30.10.15;14.03.16;2016;extern;Bachelor;DE;Entwicklung und Umsetzung eines Tools zur automatisierten Angebotserstellung für automobile Elektronikprodukte;
01.11.15;01.04.16;2016;extern;Bachelor;DE;Bewertung von Bildverarbeitungsmethoden für den automatischen Test von Navigationskartendarstellungen;
01.11.15;01.02.16;2016;extern;Bachelor;DE;Evaluierung verschiedener Caching-Strategien und prototypische Implementierung in Online-Anwendungen. ;
01.11.15;31.03.16;2016;extern;Bachelor;DE;Analyse des Umgangs mit nicht-quantifizierbaren Größen bei der Kostenplanung;
01.11.15;29.06.16;2016;extern;Master;DE;Automatische Erkennung von Quadrocopter-Landeplätzen mittels künstlicher neuronaler Netze;
01.11.15;22.04.16;2016;extern;Master;DE;Entwicklung eines fachlichen Rollenkonzepts und Prozessmodells für die Self-Service-BI-Lösung der Carl Zeiss SMT GmbH;
02.11.15;31.03.16;2016;extern;Bachelor;DE;Portierung und Weiterentwicklung des „Levelgraph“-Verfahrens;
02.11.15;29.03.16;2016;extern;Bachelor;DE;Evaluierung einer Business Process Transformation in einer Geschäftsverwaltung mihilfe agiler Methoden;
06.11.15;04.04.16;2016;extern;Bachelor;DE;Konzept zur automatisierten Mustererkennung in Fahrzeug-Flottendaten;
06.11.15;06.04.16;2016;extern;Bachelor;DE;Parallelisieren von Schwarmalgorithmen bei der Erzeugung von Tiefenkarten auf Stereobildern;
06.11.15;14.03.16;2016;extern;Bachelor;DE;Berechnung einer 3D-Hinderniskarte auf einem autonomen, mobilen Roboter;
09.11.15;14.03.16;2016;extern;Bachelor;DE;"Analyse und Konzeption einer ""Do-it-your-self"" Internet Plattform für Heimtextilien mit Anbindung von E-Commerce";
10.11.15;;2016;extern;Master;DE;Entwicklung eines Prototypen für die Exploration des Entwurfsraumes EAST-ADL-basierter Steuergerätearchitekturen für die Verwendung in Optimierungsanalysen (Student der Fakultät EFI);
12.11.15;12.04.16;2016;extern;Bachelor;DE;Konzeption und Realisierung eines generischen Clients für den geräteunabhängigen Zugang zu Datenquellen im ERP-Umfeld;
18.11.15;18.04.16;2016;extern;Bachelor;DE;Optimierung eines Dokumentenmanagementsystems zur Erfüllung der regulatorischen Anforderungen in der Medizintechnikindustrie;
18.11.15;17.07.16;2016;extern;Master;DE;Automatische Formularauswertung mit Hilfe von Bildverarbeitungsverfahren, OCR-,und OMR-Algorithmen;
23.11.15;31.03.16;2016;extern;Bachelor;DE;Einführung von SharePoint in einem mittelständischen Unternehmen;
23.11.15;22.04.16;2016;extern;Bachelor;DE;Design einer mobilen Lösung auf Basis einer bestehenden Rich Client Applikation im Bereich CRM;
24.11.15;29.04.16;2016;extern;Bachelor;DE;Implementierung und Evaluation von Remeshing-Operatoren hinsichtlich Boolescher-Algorithmik auf Dreiecksnetzen;
25.11.15;14.03.16;2016;extern;Bachelor;DE;Auswahl und Evaluierung einer Learning Analytics-Software für die Technische Hochschule Nürnberg;
26.11.15;14.03.16;2016;extern;Master;DE;Prozessoptimierung und Handlungsempfehlung für das interne Enterprise IT Architecture Management bei Siemens;
01.12.15;02.11.16;2016;extern;Master;EN;Immersion-optimized sensor fusion for low-cost realtime locating systems in VR applications;
02.12.15;14.03.16;2016;extern;Bachelor;DE;Analyse, Konzeption und Realisierung von Business Intelligence Dashboards im Bereich Einkauf mit QlikView basierend auf Microsoft Dynamics NAV;
07.12.15;14.03.16;2016;extern;Bachelor;DE;"Kompatibilitätsanalyse des BI-Ansatzes ""IFS Applications"" der Fa. IFS mit klassischen BI-Ansätzen der Fa. syscon unter Betrachtung des Bereichs ""Sales""";
11.12.15;04.05.16;2016;extern;Bachelor;DE;Konzeption und prototypische Implementierung eines Social Intranets zur Verbesserung der Informationsprozesse bei der IHK Nürnberg für Mittelfranken;
17.12.15;10.05.16;2016;extern;Bachelor;DE;Technische und wirtschaftliche Evaluation von Konzepten zur Hochverfügbarkeit durch Virtualisierung;
22.12.15;02.03.16;2016;extern;Bachelor;DE;Johan Gotlibs Einführung in die Buchhaltung Edition und Kommentar zu Geschäftsvorfällen;
04.01.16;10.08.16;2016;extern;Bachelor;DE;Evaluation der Verwendung von Use Case 2.0 vs. Impact-/Story Mapping in einem Redesign-Projekt unter Einsatz der agilen Methode Scrum;
08.01.16;08.06.16;2016;extern;Bachelor;DE;Konzeption und prototypische Realisierung einer automatisierten Konfigurationsverteilung und -verwaltung für Netzwerkkomponenten bei der Firma HUK-COBURG;
11.01.16;09.06.16;2016;extern;Bachelor;DE;Integration eines Moduls zur Named-Entity-Recognition in die Suchmaschine der Fakultät Informatik;
11.01.16;13.06.16;2016;extern;Bachelor;DE;Analyse zur Leistungserhöhung im Umfeld von Produktstammdaten-Projekten der BMW Group;
13.01.16;23.05.16;2016;extern;Bachelor;DE;Ein evolutionäres Verfahren für Echtzeitscheduling auf einen Multikernprozessor;
18.01.16;01.09.16;2016;extern;Master;DE;Entwicklung und Evaluierung von Geschäftsmodellen zur kommerziellen Nutzung von Gamification;
18.01.16;17.06.16;2016;extern;Bachelor;DE;Dokumentation eines IT Servicekataloges mit OBASMI;
26.01.16;06.06.16;2016;extern;Bachelor;EN;Conception and Implementation of Penetration Tests in EBDiri-go;
01.02.16;13.07.16;2016;intern;Master;DE;Virales Marketing via Social Media;
17.02.16;17.10.16;2016;extern;Master;DE;Evaluation der NB-IoT-Technik im Bezug auf spezifische Anforderungen von IoT- und M2M-Anwendungsszenarien ;
18.02.16;01.08.16;2016;extern;Bachelor;DE;Entwicklung eines Next Generation IT-Outsourcing-Konzepts für Großunternehmen;
01.03.16;31.07.16;2016;extern;Bachelor;DE;Konzept und Realisierung der DRG-Eingruppierungsanzeige mit Fokus  auf die Entwicklung einer modularen Softwarearchitektur und Clean Code;
01.03.16;11.10.16;2016;extern;Master;DE;Analyse und Anwendung von Business Intelligence Reifegradmodellen am Beispiel der DATEV eG;
08.03.16;08.11.16;2016;extern;Master;DE;Untersuchung der Eignung von Ameisenalgorithmen für die Routenermittlung autonomer Flugobjekte;
09.03.16;01.08.16;2016;extern;Bachelor;DE;Konzeption und prototypische Implementierung einer Notizverwaltungsanwendung für Entwickler;
09.03.16;09.08.16;2016;extern;Bachelor;DE;"Untersuchung der Auswirkungen von Ausfällen abhängiger Applikationen und Schnittstellen in der Test- und Entwicklungsumgebung für das Verfahren ""Virtueller Arbeitsmarkt"" der Bundesagentur für Arbeit";
14.03.16;15.08.16;2016;extern;Bachelor;DE;Homecare „Fall Detection“ mit einem Wearable;
14.03.16;08.12.16;2016;extern;Master;DE;Methodische Unterstützung von agilem Projektmanagement nach dem Vorgehensmodell Scrum mit dem Kollaborationswerkzeug Microsoft SharePoint; 
15.03.16;15.11.16;2016;intern;Master;DE;Erzeugung eines animierten Gesichtes auf Basis einer einzelnen Aufnahme;
15.03.16;15.11.16;2016;intern;Master;DE;Automatische Flugrouten-Planung und Steuerung eines Multicopters über einer Photovoltaik-Freiflächenanlage anhand von Video-Bildern;
15.03.16;12.08.16;2016;intern;Bachelor;DE;Entwicklung einer Simulationsumgebung für kooperierende Industrieroboter;
15.03.16;08.08.16;2016;extern;Bachelor;DE;Analyse und Vergleich von Clean-Code-Regeln und Sprachfeatures in C# auf ihre Performance;
15.03.16;15.08.16;2016;extern;Bachelor;DE;Konception und prototypische Implementierung eines Informationsdisplay-Systems;
16.03.16;16.10.16;2016;extern;Bachelor;EN;Biometric User Identification through Smartphones;
16.03.16;12.08.16;2016;extern;Bachelor;DE;Speicherverwaltung in Swift: Low-Level-Analyse der ARC- und Copy-on-Write-Implementierungen;
16.03.16;16.08.16;2016;extern;Bachelor;DE;Studie zur mentalen Rotation von 3D gedruckten Brailleschriftzügen;
16.03.16;12.08.16;2016;extern;Bachelor;DE;Entwicklung eines Dashboards zur Visualisierung von Gerätenutzungsdaten der Siemens Healthcare GmbH;
16.03.16;16.08.16;2016;extern;Bachelor;DE;Bedienkonzept und Evaluierung zur barrierefreien, grafischen Modellierung mit Innovator für motorisch eingeschränkte Anwender;
16.03.16;29.07.16;2016;extern;Bachelor;DE;Entwicklung und Umsetzung eines Konzeptes zur Verbalisierung von Kartenausschnitten für blinde Menschen;
17.03.16;26.10.16;2016;extern;Master;DE;Virtuelle Absicherung von Fahrerassistenzsystemen anhand von Machine Learning basierten Simulationsmodellen<br><br>;
17.03.16;14.07.16;2016;extern;Bachelor;DE;Erweiterung eines Web-Content-Management-Systems mit semantischen Technologien am Beispiel von WordPress;
18.03.16;;2016;extern;Bachelor;DE;Offline Map-Matching mit Hilfe von Multi-Routing;
18.03.16;18.08.16;2016;intern;Bachelor;DE;Entwicklung eines Vertriebskonzepts mit Hilfe eines Multi Channel Ansatzes für ein Unternehmen der Nahrungs- und Genussmittelindustrie;
21.03.16;18.08.16;2016;extern;Bachelor;DE;Implementierung einer Smartphone-Applikation zur Erkennung von Fußgängerampeln als Unterstützung für Menschen mit Sehbehinderung ;
21.03.16;18.11.16;2016;extern;Master;DE;Konzeption und Realisierung einer Sensornetz-basierten, intelligenten Gebäudeüberwachung.;
22.03.16;19.08.16;2016;extern;Bachelor;DE;"Optimierung des Team- und Projektu&#776;bergreifenden agilen Softwareentwicklungsprozess und Evaluation durch geeignete Kennzahlen zur Qualitätsmessung bei der esolutions GmbH";
23.03.16;22.08.16;2016;intern;Bachelor;DE;Prototypische Entwicklung einer Augmented Reality Applikation mit Beamer Smartphone in Verbindung mit Indoor-Positionsbestimmung;
29.03.16;25.11.16;2016;extern;Master;DE;Untersuchung und Realisierung eines Konzepts zur Bereitstellung von Web-basierten Diensten für IOT Geräte durch einen IOT-Plattformanbieter<br>;
30.03.16;26.08.16;2016;extern;Bachelor;DE;SCCM 2012 - Software Center  Design und Implementierung eines Application-Management Systems;
31.03.16;30.08.16;2016;extern;Bachelor;DE;Weiterentwicklung einer Projektmethodik auf Basis von PRINCE 2 für IT-Projekte der Leoni AG;
01.04.16;28.11.16;2016;extern;Master;DE;Industrie 4.0 in der Automobil- und Fertigungsindustrie Entwicklung und Integration eines Bedien- und Visualisierungskonzepts für eine Endmontagelinie;
01.04.16;25.11.16;2016;extern;Master;DE;Anwendung von MQTT als Schnittstelle zwischen Teilnehmern zukünftiger Smart Grid Szenarien;
01.04.16;18.08.16;2016;extern;Bachelor;DE;Konzeption, Implementierung und Inbetriebnahme eines elektromischen Fahrtenbuchs auf Basis einer Telematik und Back-End Lösung von Continental Engineering Services;
01.04.16;31.08.16;2016;intern;Bachelor;DE;Interaktion mit einem Public Display und prototypische Umsetzung mit Hilfe des CMS WordPress;
01.04.16;01.09.16;2016;extern;Bachelor;DE;Konzeption und Entwicklung einer kollaborativen Auftragsverwaltung bei Telefónica Germany;
01.04.16;31.08.16;2016;intern;Bachelor;DE;Evaluation des Content-Management-Systems Wordpress hinsichtlich seiner Eignung als Plattform für Crowdsourcing Anwendungen;
01.04.16;22.08.16;2016;extern;Bachelor;DE;Konzeptionierung und Implementierung der 3D-Modelierung von CAD-Daten in einem Bosch-Viewer;
01.04.16;01.09.16;2016;intern;Bachelor;DE;Prototyp eines Personal-Food-Management-Systems;
04.04.16;02.09.16;2016;intern;Bachelor;DE;Platform as a Service: Marktanalyse und Einsatz in der Praxis;
04.04.16;04.09.16;2016;extern;Bachelor;DE;Erschließung von Erfolgspotentialen mithilfe des Team Foundation Server durch werkzeuggestützte Vorbereitung für ein DATEV Freigabegespräch.;
04.04.16;30.08.16;2016;intern;Bachelor;DE;Analyse und Optimierung potentieller Prozesse der Ausgabestelle IssWas e. V. ;
06.04.16;18.08.16;2016;extern;Bachelor;DE;Konzeption und prototypische Realisierung eines modularen Tools zur automatisierten Konfiguration von Anwendungstestsystemen;
08.04.16;07.09.16;2016;extern;Bachelor;DE;Erstellung eines Soll-Konzeptes zur Optimierung des internen Materialflusses für die Produktionsversorgung in einem international tätigen Unternehmen der Elektrotechnik;
08.04.16;08.09.16;2016;extern;Bachelor;DE;Konzeption und prototypische Implementierung eines Geotainment-Systems für Langstreckenzüge;
12.04.16;09.09.16;2016;intern;Bachelor;DE;Evolution und Potenzial verteilter synchroner Kommunikations- und Kollaborationssysteme;
14.04.16;07.09.16;2016;intern;Bachelor;DE;Eye Tracking in der Datenanalyse zur Optimierung von Blended Learning-Systemen;
15.04.16;;2016;intern;Bachelor;DE;Konzeption einer Internetplattform zum Crowdsourcing von Haushaltsbesorgungen;
15.04.16;15.09.16;2016;intern;Bachelor;DE;Umsetzung eines Monitoring Systems mit Icinga2 zur Realisierung einer automobilen Telematik;
15.04.16;;2016;intern;Bachelor;DE;Texturbasiertes Volume-Rendering auf mobilen Endgeräten;
19.04.16;16.12.16;2016;intern;Master;DE;Tensorfaktorisierung als Ansatz für Empfehlungssysteme;
21.04.16;21.12.16;2016;extern;Master;DE;Konzeption und prototypische Implementierung der Positionsrechnung in funkbasierten Lokalisierungssystemen;
21.04.16;21.09.16;2016;intern;Bachelor;DE;Modellierung von Texten mit Rekurrenten Neuronalen Netzwerken;
22.04.16;12.12.16;2016;intern;Master;DE;Umsetzung eines Verfahrens zur simultanen Lokalisierung und Kartenerstellung auf einem autonomen, mobilen Roboter; 
25.04.16;22.12.16;2016;extern;Master;DE;Planung, Konzeption und Entwicklung eines Moduls zum zentralen und asynchronen Logging im Content-Management-Umfeld;
25.04.16;23.09.16;2016;intern;Bachelor;DE;Entwicklung eines Overlay-Dateisystems für das Lehrbetriebssystem Ulix mit Literate Programming;
27.04.16;27.09.16;2016;intern;Bachelor;DE;Merkmalbasierte Analyse und Klassifikation von Musik mit selbstorganisierenden Karten;
28.04.16;28.09.16;2016;extern;Bachelor;DE;Marktpreismodellierung eines Produktportfolios der Siemens AG mit Hilfe von Machine Learning-Algorithmen;
28.04.16;05.08.16;2016;extern;Bachelor;DE;Konzeption der DATEV-Online-Anwendung Drucker-Scanner-Analyse mit einer dokumentenbasierten NoSQL-Datenbank;
28.04.16;26.09.16;2016;extern;Bachelor;DE;Neukonzeption und prototypische Implementierung der Inputverarbeitung als Service;
29.04.16;29.09.16;2016;intern;Bachelor;DE;"Evaluation der Performance des Audiocodecs ""Opus"" für IP-basierte Audiokonferenzanwendungen";
29.04.16;29.09.16;2016;extern;Bachelor;DE;Analyse und Bewertung der Social-Gaming-Plattform ELO;
01.05.16;22.12.16;2016;extern;Master;DE;Konzeption und Entwurf eines Systems zur Organisation des Wissensmanagements der Markt- und Wettbewerbsbeobachtung der DATEV eG;
01.05.16;09.01.17;2016;extern;Master;DE;Konzeption und prototypische Implementierung einer analytischen Marktfor-schungsplattform basierend auf Apache Spark; 
01.05.16;09.01.17;2016;extern;Master;DE;Konzeption und Implementierung eines mehrbenutzer-basierten Zugriffssystems für das Energiemanagementsystem OGEMA;
02.05.16;30.09.16;2016;extern;Bachelor;DE;Automatische Suche von Bibliotheksabhängigkeiten in einer großen Codebasis;
02.05.16;14.11.16;2016;intern;Master;DE;Produkt-Monitoring in sozialen Medien;
04.05.16;04.10.16;2016;extern;Bachelor;DE;Der Einsatz von User Centered Design zur Evaluierung der neugestalteten Oberfläche eines auf den Mittelstand ausgerichteten ERP-Systems;
04.05.16;09.01.17;2016;intern;Master;DE;Evaluation von Markov Random Walk als Empfehlungsalgorithmus anhand unterschiedlicher Metriken;
06.05.16;06.10.16;2016;intern;Bachelor;DE;Entwicklung einer Online-Navigationskomponente;
12.05.16;11.10.16;2016;intern;Bachelor;DE;Integration einer vektorbasierten Beschriftungskomponente in einen Kartendienst;
12.05.16;12.10.16;2016;intern;Bachelor;DE;Zuverlässige Anonymisierung von Gesichtern in Video-Dateien;
15.05.16;29.08.16;2016;extern;Bachelor;DE;Punktbasiertes Rendering von virtuell fotografierten Szenen aus einer Game-Engine;
18.05.16;11.11.16;2016;intern;Bachelor;DE;Konzeption und Implementierung eines Print@Home-Ticketabgleichs über mehrere Kassenstationen;
18.05.16;18.10.16;2016;intern;Bachelor;DE;Veränderungen von Prozessen durch Industrie 4.0 und deren Implikationen für das Wissensmanagement;
20.05.16;20.10.16;2016;intern;Bachelor;DE;Techniken für die Darstellung angereicherter ineraktiver Geschichten;
23.05.16;20.10.16;2016;extern;Bachelor;DE;Verbesserung der Qualität und Effizienz von regelgestützter Codierung durch automatische Analyse;
25.05.16;25.10.16;2016;intern;Bachelor;DE;Evaluation verschiedener Simulations-Softwareprodukte für den Einsatz in Lehrveranstaltungen;
27.05.16;05.12.16;2016;intern;Bachelor;DE;Erarbeitung eines Konzepts für eine effiziente Datenanalyse der Hochschule-Jobbörse Nürnberg;
30.05.16;31.01.17;2016;intern;Master;DE;Entwurf und Implementierung einer Plattform zum Austausch und Abspielen von Audio-Dateien auf Basis moderner JavaScript Frameworks und Amazon Web Services;
01.06.16;27.10.16;2016;extern;Bachelor;DE;Konzeption und prototypische Realisierung einer WebGL Applikation zur Gewährleistung der physischen Sicherheit in einem leittechnischen Cyber-Sicherheitsmodell;
01.06.16;18.01.17;2016;intern;Master;DE;Human Information Behavior - Ausgewählte Aspekte des State of the Art;
03.06.16;30.09.16;2016;extern;Bachelor;DE;Strukturierter Vergleich ausgewählter JavaScript Frameworks für Webentwicklung im Gesundheitswesen: Eine Fallstudie am Beispiel der kubus-IT.;
09.06.16;21.11.16;2016;intern;Bachelor;DE;Konzeption und Weiterentwicklung des Ohmquiz anhand von Gamification;
01.07.16;17.11.16;2016;intern;Bachelor;DE;Entwicklung einer strukturierten Abfragesprache für eine symbolisch-räumliche Suche;
04.07.16;03.03.17;2016;extern;Master;DE;Evaluierung und prototypische Umsetzung von Sensoren und Dashboards mit deren relevanten, zielgruppenorientierten technischen Indikatoren und KPIs mit einer Handlungsempfehlung in Kooperation mit der DATEV;
13.07.16;24.10.16;2016;intern;Bachelor;DE;Evaluierung und Bewertung von Visualisierung-Frameworks zur Darstellung von mehrdimensionalen Fuzzy-Planungsmodellen in Webanwendugen;
15.07.16;15.12.16;2016;extern;Bachelor;DE;Evaluierung und Konzeption eines Self-Service Business Intelligence Ansatzes für ein mittelständisches Unternehmen unter der Verwendung von Reporting Services auf Basis des Microsoft SQL Servers 2016;
15.07.16;08.12.16;2016;intern;Bachelor;DE;Entwicklungskorridore des Wissensmanagements in der Industrie 4.0;
20.07.16;20.12.16;2016;intern;Bachelor;DE;Anwendung von Big Data Systemen (Vorschlagssystem) im Vertrieb von Vollsortiment-Supermärkten. Wie kann man dort Big Data Systeme sinnvoll einsetzen? Welche Chancen und Risiken gibt es? Welche rechtlichen bzw. ethischen Aspekte sollten berücksichtigt werd;
20.07.16;22.02.17;2016;intern;Master;DE;Vergleich der Empfehlungsqualität von Markov Random Walk und Collaborative Filtering;
27.07.16;09.01.17;2016;extern;Bachelor;DE;Duplikaterkennung von Fehlerberichten an einem zentralen Fehlermanagementsystem; 
28.07.16;28.03.17;2016;extern;Master;DE;Untersuchung und Konzeption des Einsatzes von Cyber-Physischen Systemen am Montageband;Im Fokus dieser Arbeit steht der Einsatz von Cyber-Physischen Systemen in der Montage. Cyber-Physische Systeme gewinnen in den aktuellen Entwicklungen der Industrie 4.0 eine immer wichtigere Rolle. Ihr Einsatz soll dazu dienen, virtuelle und reale Welt zu vernetzen, um speziell in der Montage manuelle und starre Prozesse zu flexibilisieren und automatisieren. In Kooperation mit der Fraunhofer-Arbeitsgruppe für Supply-Chain Services SCS wird erfasst inwieweit deutsche Unternehmen Cyber-Physische Systeme bereits in ihren Produktionen einsetzen. Weiterhin sollen Herausforderungen und Chancen untersucht werden, die sich dabei ergeben sowie Anforderungen der Unternehmen an Cyber-Physische Systeme im Allgemeinen sowie an ein ideales Cyber-Physisches System im Speziellen. Die Informationsgewinnung erfolgt zunächst über die Durchführung einer Literaturrecherche, um die Sicht der gegenwärtigen Theorie zu erfassen. Als Gegenstück zur Theorie wird die Praxis anhand von Expertenbefragungen untersucht und die Ergebnisse der Gespräche nach der Methodik nach Mayring analysiert und ausgewertet <br>(vgl. [Ma16, S.114?121]). Diese Auswertung dient dazu, Theorie und Praxis abzugleichen und auf Basis dessen ein ideales Cyber-Physisches System zu konzipieren. Das Ergebnis dieser Arbeit soll den aktuellen Status-Quo des Einsatzes von Cyber-Physischen Systemen in der Montage wiederspiegeln.<br>
01.08.16;30.03.17;2016;extern;Master;DE;Konzeption eines idealen Continuous Integration Prozesses zur Unterstützung der CAE-Softwareentwicklung;
01.08.16;31.03.17;2016;intern;Master;DE;Objekterkennung mit Convolutional Neural Networks auf Basis von TensorFlow und iOS.;Im Rahmen dieser Masterthesis wird die Klassifikation von Objekten, explizit von Verkehrszeichen, mithilfe von Convolutional Neural Networks behandelt. In diesem Zusammenhang wird das Convolutional Neural Network unter Anwendung der Software-Bibliothek TensorFlow entwickelt. Das zur Verkehrszeichenerkennung entwickelte Netzwerk wird in ein bestehendes Geschwindigkeitsassistenzsystem, welches auf einem Smartphone betrieben wird, integriert. Die einführenden Kapitel geben einen Überblick über den aktuellen Stand der Technik und erläutern den Aufbau und die Funktionsweise von Convolutional Neural Networks. Um ein besseres Verständnis für Convolutional Neural Networks zu schaffen, werden zunächst die theoretischen Grundlagen der künstlichen neuronalen Netzwerke genannt. Anschließend werden die verwendeten Hardware- und Software-Komponenten vorgestellt und ein Bezug zu deren Relevanz geschaffen. Die Implementierung des Modells mithilfe von TensorFlow, sowie die prototypische Erweiterung der bestehenden Anwendung wird daraufhin dargelegt. In den nachfolgenden Kapiteln wird auf die Evaluierung des Convolutional Neural Networks, sowie auf bestehende Optimierungs- und Erweiterungsmöglichkeiten eingegangen. Abschließend wird ein Resümee über das entstandene Netzwerk und dessen Klassifikationsrate, sowohl unter TensorFlow als auch unter iOS, gegeben.
18.08.16;16.01.17;2016;extern;Bachelor;DE;Analyse und Optimierung der internen IT-Leistungsverrechnung der GfK SE mit Fokus auf der Kostentransparenz(Bill of IT);
01.09.16;01.02.17;2016;extern;Bachelor;DE;CT-basiertes virtuelles Fräsen in Knochen für das Training von Cochlea Implantationen;
01.09.16;01.02.17;2016;extern;Bachelor;DE;Konzept und Implementierung einer Quiz-Anwendung zur unternehmensinternen Wissensvermittlung; 
01.09.16;01.03.17;2016;intern;Bachelor;DE;Umsetzung von strategischen Einkaufskonzepten in bestehenden Softwarewerkzeugen. Analyse und Gestaltungsempfehlung;
13.09.16;10.02.17;2016;intern;Bachelor;DE;Analyse des Stands der Technik und Evaluierung der IT-Security im vernetzten Fahrzeug;
14.09.16;13.03.17;2016;extern;Master;DE;Konzept zur Einführung von Agilität im Softwareentwicklungsprozess der Abteilung fachlichen Verarbeitung von Lohn im Rechenzentrum der Datev e.G.; 
15.09.16;14.02.17;2016;extern;Bachelor;DE;Konzeption zur Digitalisierung des Auftragsmanagements einer Firma im Eventbereich;
19.09.16;19.02.17;2016;intern;Bachelor;DE;Teil-automatisierte Erstellung und interaktives Rendering von bildbasierten 3D-Szenen aus 2D-Panoramabildern;
23.09.16;22.02.17;2016;extern;Bachelor;DE;Konzept zur Betriebsdatenerfassung bei Protoform; 
28.09.16;30.01.17;2016;extern;Bachelor;DE;Konzipierung und Implementierung eines cloudbasierten Mitteilungssystems;
29.09.16;06.02.17;2016;extern;Bachelor;DE;Entwicklung eines Systems zur Echtzeitüberwachung von Statistikdaten in der Fertigung;
01.10.16;01.03.17;2017;intern;Bachelor;DE;Gesichtsdetektion in Bildern mit Convolutional Neural Networks;
01.10.16;22.02.17;2017;extern;Bachelor;DE;Graphvisualisierung von Abhängigkeiten zwischen IT-Betriebsmitteln einer IT-Landschaft;
01.10.16;18.01.17;2017;extern;Bachelor;DE;Konzeption und prototypische Implementierung eines automatisierten Applikationsdeployments am Beispiel der Bundesagentur für Arbeit;
01.10.16;13.02.17;2017;intern;Bachelor;DE;Evaluierung und Bewertung von technischen Lösungen zur Darstellung von ortsbezogenen Daten in einer mobilen Social-Media-Anwendung<br><br>;
01.10.16;28.02.17;2017;extern;Bachelor;DE;Weiterentwicklung des Projektprozesses der mediendesign AG, Abgleich und Verbesserung anhand eines Reifegradmodells;
01.10.16;27.02.17;2017;extern;Bachelor;DE;Einsatz von Text Mining zur Unterstützung automatisierter E-Mail-Verarbeitung in der Sparda-Datenverarbeitung eG;
01.10.16;24.02.17;2017;intern;Bachelor;DE;C++ und Rust: Ein Vergleich zweier Programmiersprachen mit Fokus auf Zwischencode und dessen Analyse;
03.10.16;31.01.17;2017;extern;Bachelor;DE;Konzeption und prototypische Implementierung der Migration von Prozessinstanzen einer BPMN Engine auf ein neues Prozessmodell;
04.10.16;16.12.16;2017;extern;Bachelor;DE;Analyse von Technologien zur Desktopbereitstellung - Entwicklung eines zukunftsorientierten Konzepts<br>;Viele Unternehmen verfügen über etablierte Desktopbereitstellungs-Lösungen. Doch besitzen die klassischen Konzepte die Fähigkeit auch Anforderungen an einen Future Workplace zu erfüllen?<br>Die prognostizierte, zunehmende Verbreitung von mobilen Endgeräten im Unternehmensumfeld ist ein Beispiel für einen aktuellen Treiber der Veränderung des Arbeitsplatzes. Diese Veränderung führt zwangsläufig zu einer Neuausrichtung der Desktop-Verwaltung. Deswegen werden neue gnerische Konzepte benötigt, die es Mitarbeitern ermöglichen endgeräte-, zeit- und ortsunabhängig auf Unternehmensressourcen zuzugreifen.<br>Die Bachelorarbeit liefert einen Überblick über die erwarteten Veränderungen und bietet Lösungsvorschläge zur Auswahl geeigneter Desktopbereitstellungs-Varianten. Nach wissenschaftlicher Ausarbeitung des Themas wird ein Future Workplace konzeptionell entwickelt.
04.10.16;;2017;extern;Bachelor;DE;Entwicklung einer Universal-Grammatik für einen konfigurierbaren Parser;
04.10.16;03.03.17;2017;intern;Bachelor;DE;Prototypische Thesaurusintegration in die Solr-basierte Suchmaschine der Fakultät Informatik <br><br>;
05.10.16;28.02.17;2017;extern;Bachelor;DE;Analyse, Konzeption und prototypische Realisierung eines Plug - Ins für Microsoft Dynamics CRM Online zur Integration von Qlik Sense;
05.10.16;02.06.17;2017;extern;Master;DE;Konzeption und Implementierung einer mobilen Anwendung zur optischen Erfassung von Zählerinformationen;"Ziel der Masterarbeit ist es, eine mobile Anwendung zur optischen Erfassung von Zählerinformationen zu konzeptionieren und Implementieren. Dafür sollen Zählerinformationen, wie z. B. Identifikationsnummer und Zählerstand, optisch erfasst und verarbeitet werden. Des Weiteren soll es möglich sein, der Erfassungssoftware IZAR@MOBILE ein Foto vom Einbauort des entsprechenden Zählers zuzuordnen. Nachdem alle relevanten Daten aufgenommen sind, werden sie an die zentrale Erfassungs- und Auswertungssoftware IZAR@NET verschlüsselt übertragen. Dabei ist IZAR@MOBILE eine Software, die eine einfache und wirtschaftliche Auslesung von Funkzählern über mobile Endgeräte ermöglicht. Für die Verwaltung der einzelnen Zähler wird die IZAR@NET verwendet. Zuletzt soll eine Marktanalyse für verschiedene Länder über die aktuelle Verteilung von ""intelligenten Messsystemen"" und ""konventionellen Zählern"" durchgeführt werden. Zusätzlich zu der Marktanalyse soll eine Analyse über die ökonomische Verwendung der oben genannten Features durchgeführt werden."
05.10.16;31.01.17;2017;extern;Bachelor;DE;Erstellung eines Konzepts zur Sicherung der Web Application Security eines Online-Bankings auf Basis von AngularJS;
05.10.16;;2017;intern;Bachelor;DE;Detektion von Autos in Bildern mit Convolutional Neural Networks ;
05.10.16;30.01.17;2017;extern;Bachelor;DE;Analyse und Verbesserung des Wissensmanagements in einem speziellen Softwareentwicklungsprozess;
06.10.16;;2017;extern;Bachelor;DE;Konzeptionierung und Implementierung eines Systems zum End-to-End-Monitoring des Authentisierungsverfahrens SmartLogin der DATEV eG;
06.10.16;21.02.17;2017;extern;Bachelor;DE;Erstellen und Visualisieren einer System- und Datenlandschaft für eine HDP-Produktionslinie ; 
06.10.16;06.03.17;2017;intern;Bachelor;DE;Anforderungen an das Wissensmanagement in der Aus- und Weiterbildung durch Industrie 4.0<br><br>;
06.10.16;20.02.17;2017;extern;Bachelor;DE;Konzeption und prototypische Umsetzung einer Infrastruktur zum automatisierten Zertifikatsaustausch;
06.10.16;;2017;extern;Bachelor;DE;Konzeptionierung einer prozessbeschleunigenden Software-Lösung für eine automatische, regelbasierte Auswertung von Ergebnissen aus automatisierten Softwaretests;
07.10.16;03.03.17;2017;extern;Bachelor;DE;Evaluierung Graph-orientierter Datenbanken bei der Verwaltung von Geschäftsbeziehungen zwischen Unternehmen.;
10.10.16;25.01.17;2017;extern;Bachelor;DE;Konzeptionierung und Realisierung einer Anwendung zur Konfiguration der DATEV DMS-Arbeitsplatzintegration;Das Ziel dieser Bachelorarbeit ist die Konzeption und Entwicklung einer datenbankgestützten Anwendung, welche Änderungen an der Konfiguration der DMS-Arbeitsplatzintegration jederzeit und problemlos ermöglicht. Um dieses Ziel zu erfüllen, erfolgte im ersten Schritt die Ist-Analyse. Diese schloss die Beschreibung der Ausgangssituation mit ein.<br>Des Weiteren wurde das Thema DMS-Arbeitsplatzintegration genaue beleuchtet sowie das bestehende Datenbankmodell vorgestellt und analysiert.<br>Basierend auf den gewonnenen Erkenntnissen wurden anwendungsspezifische Anforderungen erarbeitet und definiert.<br>Auf dieser Grundlage konnte entsprechend den DATEV-Richtlinien eine Anwendung konzipiert werden.<br>Als Nächstes wurde die Anwendung gemäß der gegebenen Technologieleitlinie realisiert.<br>Die während dieser Abschlussarbeit entwickelte Anwendung wird zukünftig in der Customizing Abteilung der DATEV eingesetzt und hat sich somit in der Praxis als erfolgreich erwiesen. Auf diese Weise konnte die Erfüllung der gestellten Anforderungen sowie die Richtigkeit und Tragfähigkeit des Konzepts bestätigt werden.
10.10.16;10.03.17;2017;intern;Bachelor;DE;Vergleichende Studie zu Greif- und Bewegungsaufgaben in der HTC Vive Virtual Reality Umgebung;
12.10.16;14.03.17;2017;extern;Master;DE;Erstellung eines Konzepts für priviligierte IT-Berechtigungen und Administrationsrechte - allgemein und anhand einer Fallstudie bei der N-Ergie AG Nürnberg;
12.10.16;09.03.17;2017;extern;Bachelor;DE;Konzeption einer Einführung von Software Asset Management in einem mittelständischem Verlag und Evaluation geeigneter Tools;
13.10.16;13.03.17;2017;intern;Bachelor;DE;Veränderung von Produkt- und Methodenwissen durch Industrie 4.0;
13.10.16;13.03.17;2017;extern;Bachelor;EN;Optimized Multideep Storage Heuristic;
14.10.16;14.03.17;2017;intern;Bachelor;EN;Deep Residual Network  ;
14.10.16;13.03.17;2017;extern;Bachelor;DE;Evaluierung einer Plattform zur Automatisierung der Konfiguration von Server-Management-Controllern;
14.10.16;13.03.17;2017;extern;Bachelor;DE;Entwicklung eines individualisierten Burndown-Dashboards zur Überwachung des Projektfortschritts in der agilen Entwicklung bei der Bundesagentur für Arbeit;
14.10.16;13.03.17;2017;intern;Bachelor;DE;Entwicklung einer Bahnregulierung für einen autonomen, mobilen Roboter;Die Bachelorarbeit befasst sich mit der Entwicklung einer Bahnregulierung für einen autonomen, mobilen und radgetriebenen Roboter, den Carbot. Der Carbot-Roboter und dessen Simulationsumgebung sind Entwicklungen von Prof. Dr. Jörg Roth an der Technischen Hochschule Nürnberg. Der Roboter verfügt über Funktionen zur Selbstlokalisierung, Erkennung von Hindernissen und Kollisionen auf Basis von Sensordaten sowie zur Planung von<br>Routen und Bahnen. Die kontrollierte Bewegung des Roboters wird über ein Antriebs- und Bewegungsmodell realisiert.<br>Das derzeitige Problem ist der Verlust von Traktion bei Fortbewegung des Roboters auf nicht idealem Untergrund und die damit verbundene Abweichung beim Abfahren geplanter Fahrbahnen. In dieser Arbeit wird ein Verfahren vorgestellt, das diese Diskrepanz erkennt, auswertet und den Roboter sanft auf die geplante Bahn zurückführt. Die Realisierung eines Prototypen erfolgte in der Carbot-Umgebung.
14.10.16;;2017;extern;Bachelor;DE;Analyse und Konzeption eines Auswertungsprozesses der CRM-Daten bei der DATEV eG und eine prototypische Implementierung auf Basis SAP Lumira;
15.10.16;15.03.17;2017;intern;Bachelor;DE;Objekterkennung mit Convolutional Neural Networks auf Basis von Tensorflow;
15.10.16;19.06.17;2017;extern;Master;DE;RFID-Landmarken basierte Selbstlokalisierung und gleichzeitige Warenortung;In this thesis the feasibility of replacing the positioning, done by a real-time locating system, in an existing RTLS based RFID goods-tracking system, with SLAM is studied. The system consists of a forklift whose position can be obtained via a RTLS. Attached to the forklift is a RFID-reader and a linear-antenna-array, which can determine the angle between RFID-tagged goods and the forklift. By combining both systems the goods in warehouse can be localized. The RTLS can be replaced by using the RFID-tags as landmarks for a SLAM algorithm. The major challenges are unmonitored changes by the staff who often uses a pallet jack for rearranging wares which cause the attached landmarks to change their position and cause an erroneous position estimation of the forklift. The SLAM algorithms FastSLAM and FastSLAM2.0 weres used.Techniques for detecting non-static landmarks were studied and the SLAM Algorithms were extended with a method for detecting changes in the landmark environment. Despite worsening the forklift position accuracy most landmark position changes could be successfully detected. Additionally an integration of the carrier phase shift, that is detected by RFIDantennas into the SLAM-Filter was investigated. Despite yielding comparable results with existing techniques during a static evaluation it failed to improve the localization accuracy when integrated into the SLAM-Filter.
17.10.16;17.03.17;2017;intern;Bachelor;DE;Entwicklung einer vektorbasierten Navigationskomponente für einen autonomen, mobilen Roboter;An der Technischen Hochschule Nürnberg existiert ein autonomer, mobiler Roboter. Für diesen soll eine vektorbasierte Navigationskomponente entwickelt werden. Es wurde sich hierbei für einen<br>Voronoi-Diagramm Ansatz entschieden. Die Kanten eines solchen Voronoi-Diagramms mussten durch ein entwickeltes Verfahren für navigatorische Zwecke nutzbar gemacht werden. Diese Kanten eines modifizierten Voronoi-Diagramms galt es in eine Graph-Repräsentation umzuwandeln. Anschließend musste noch mittels einer vorzunehmenden A *-Algorithmus Implementation der kürzeste Weg von einem Start zu einem Zielknoten gefunden werden.
17.10.16;31.01.17;2017;extern;Bachelor;DE;Entwicklung einer webbasierten Simulationsumgebung für Hardware-Ereignisse im Umfeld von Strahlungskontaminations-Messsystemen;Die Bachelorarbeit befasst sich mit der Entwicklung einer Simulationsumgebung, die es ermöglicht, über eine webbasierte Oberfläche digitale Signale zu erzeugen und zu verarbeiten. Dabei ist es möglich, Abhängigkeiten zwischen eingehenden und ausgehenden Signalen zu berücksichtigen. <br>Für die Entwicklung der Simulationsumgebung wurden Komponenten evaluiert, um alle Anforderungen umsetzen zu können. Hierbei wurden potenzielle Hardwarekomponenten betrachtet, anschließend Python Web Frameworks verglichen, eine geeignete Datenbank gewählt und eine passende Library zur Ansteuerung der Hardware-Schnittstelle evaluiert. Die Evaluierung ergab, dass der Raspberry Pi 3 Model B als Hardwarekomponente, das Python Web Framework Django, die Datenbank SQLite und die RPi.GPIO Library zur Ansteuerung der GPIO-Schnittstellen des Raspberry Pi am besten geeignet sind.<br>Um den digitalen Datenaustausch zwischen dem Raspberry Pi 3 Model B und der Mess- und Steuerungseinheit zu ermöglichen, wurde ein Konzept entworfen, das Inkompatibilitäten zwischen den Schnittstellen ausgleicht.
17.10.16;16.06.17;2017;extern;Master;DE;Umsetzung eines TTCN-3 Interpreters für den Einsatz im Automobilsektor;Im Bereich der Automatisierung von Softwaretests, unter Verwendung von Hardware in the Loop-Testsystemen, kommt die Testing and Test Control Notation Version 3 (TTCN-3) als standardisierte Testsprache zum Einsatz. Diese Sprache stammt ursprünglich aus dem Telekommunikationsbereich. Im Rahmen des ProTecT-Forschungsprojektes (Förderkennzeichen: KF21397041150) wurde der Einsatz dieser Testsprache im Automobil-Bereich geprüft. Dabei wurde im Vorfeld dieser Arbeit ein TTCN-3-Interpreter in Python implementiert. <br><br>Im Rahmen dieser Abschlussarbeit wurde die Debug-Funktionalität für den TTCN-3-Interpreter für eine Erweiterung der Testmöglichkeiten ergänzt. Weiterhin war die Performance des TTCN-3-Interpreters zu untersuchen und gegebenenfalls zu optimieren. Ziel war die Vervollständigung des TTCN-3-Interpreters für den Einsatz in Software-Testprojekten. Die im Rahmen des ProTecT-Forschungsprojektes eingeführte TTCN-3-Testsprache im Automobilsektor über den Ansatz eines Interpreters wurde durch diese Arbeit entscheidend vorangetrieben. Durch die Umsetzung des Debuggers in dieser Arbeit können Fehler früh im Entwicklungsprozess erkannt und behoben werden.<br>
19.10.16;20.03.17;2017;intern;Bachelor;DE;Vergleich der Modellierung mit Graphdatenbanken und Ontologien anhand einer Fallstudie;Durch die immer weiter steigende Digitalisierung unserer Welt werden immer mehr Da-ten erfasst und gespeichert. Fast keine Anwendung in der Informatik funktioniert noch ohne eine Datenbank. Vor allem in Suchmaschinen oder sozialen Netzwerken spielen Graphdatenbanken eine große Rolle. Deshalb werden diese in dieser Arbeit genauer erklärt. Das Pendant zu den Graphdatenbanken aus dem Bereich der Wissensrepräsenta-tion bilden die Ontologien. Die intelligente Datenverarbeitung wird in aktuellen Infor-mationssystemen immer wichtiger. Daher bilden Ontologien den zweiten Schwerpunkt dieser Abschlussarbeit. Abschließend werden beide Technologien in einer Fallstudie gegenübergestellt.
20.10.16;25.04.17;2017;intern;Bachelor;DE;Webstatistik-abhängige, dynamische Bannererstellung aus verschiedenen Firmenlogos von Kunden der Hochschul-Jobbörse der TH;
20.10.16;20.03.17;2017;intern;Bachelor;DE;Sentiment Analyse von Kundenreviews aus einem sozialen Netzwerk zur Produktverbesserung eines ausgewählten Streaming Dienstes;Das Ziel der vorliegenden Bachelorarbeit ist es, aus Nutzerkommentaren Verbesserungsvorschläge für die Angebote des Streaming Dienstes Netflix zu gewinnen sowie die Erkenntnis über die Zufriedenheit der Kunden über das Angebot. Dies geschieht durch eine Sentiment Analyse, bei der die Bewertungen als erstes in die Kategorien ?positiv?, ?negativ? und ?neutral? aufgeteilt werden. Danach werden Produktverbesserungenvorschläge der Kunden sowie der Beliebtheitsgrad des Produktes herausgefiltert. Dies hat den Zweck herauszufinden, was dem Kunden an dem Produkt mehr zusagen würde und ob dieses Produkt überhaupt genutzt wird. Wenn nicht, kann der Grund dafür durch die Produktverbesserungsvorschläge erschlossen werden und an einer Verbesserung gearbeitet werden. Auch soll die Analyse dabei helfen herauszufinden, wie hoch der Benutzungsgrad in einer bestimmten Zeitspanne war, um Trends ablesen zu können. 
20.10.16;;2017;intern;Bachelor;DE;SRM- und CRM-Systeme: Funktionaler Vergleich von Beziehungsmanagementsoftware: was können SRM-Systeme von CRM-Systemen übernehmen?;
20.10.16;16.03.17;2017;extern;Bachelor;DE;Automatisierung des Freigabe- und Buchungsprozesses für Eingangsrechnungen in einem ERP-System;Das Ziel dieser Arbeit ist es, den Prozess der Erfassung bzw. Genehmigung von Eingangsrechnungen im Rahmen des ERP-Systems Microsoft Dynamics NAV zu optimieren. Dabei werden zunächst die bereits vorhandenen Prozesse in Micrcsoft Dynamics NAV unter der Berücksichtigung von Kundenanforderungen untersucht. Da der Genehmigungsprozess zu unflexibel und nicht auf den jeweiligen Kunden zuschneidbar ist, wurden nachfolgend die bereits auf dem Markt vorhandenen Lösungen von anderen Partnern bzgl. ihrer Nutzbarkeit analysiert. Die KUMAVISION AG verfügt derzeit über keine eigene Lösung in diesem Bereich, deshalb soll das Potential einer neu entwickelten Lösung in Betracht gezogen werden. Nach einer näheren Analyse der Eignung einer solchen Eigenentwicklung und der bereits vorhandenen Module, wird im Rahmen einer Evaluierung der direkte Vergleich gezogen und als Resultat eine Einsatzempfehlung gegeben. Da in vielen Fällen eine Eigenentwicklung sinnvoll erscheint, wird für diese abschließend eine fachliche Spezifikation ausgearbeitet.
21.10.16;18.01.17;2017;extern;Bachelor;DE;Konzeption und prototypische Entwicklung einer Pick-by-Light-Emulationssoftware bei der Dematic GmbH;
21.10.16;19.09.17;2017;extern;Master;DE;Konzeption und Entwicklung eines REST-basierten Microservices zur Behandlung von Autorisierungs- und Authentifizierungsanfragen im Rahmen der Rechenzentrumskommunikation der DATEV eG;Das Ziel der vorliegenden Masterarbeit ist die Konzeption und Entwicklung eines REST-basierten Microservice, der als Ansprechpartner für Nutzungs- und Zugangskontrollfragen bisheriger verteilter Berechtigungskonzepte des DATEV Anwendungsumfeldes zusammenführt und innerhalb eines zentralen Rechteservice bereitstellt. Hierfür wird nach Klärung grundlegender Begrifflichkeiten und Durchführung einer Anforderungsanalyse die Fragestellung erörtert, wie die Softwarearchitektur des Microservice aufgebaut sein kann, die eine möglichst lose Anbindung an diese in existierenden Fremdsystemen abgebildeten Berechtigungskonzepte ermöglicht. Zu diesem Zweck werden nach Erörterung etablierter Entwurfsprinzipien im Rahmen einer szenariobasierten Architekturbewertung unter Berücksichtigung innerhalb der Anforderungsanalyse definierten Qualitätsszenarien hierarchische Architekturmuster auf ihre Tauglichkeit zur zielführenden Umsetzung bewertet. Basierend aus hieraus gewonnen Erkenntnissen wird der Architekturentwurf in Anlehnung an einen schalenorientierten Architekturansatz konzipiert. Unter Berücksichtigung technologischer Rahmenbedingungen wird eine Technologieanalyse durchgeführt, in welcher Technologiekomponenten erörtert und evaluiert werden, mit welchen der konzipierte Architekturentwurf umsetzbar ist. Abschließend wird der Microservice unter Anwendung des konzipierten Architekturentwurfes sowie den evaluierten Technologiekomponenten in der Form eines Machbarkeitsnachweises umgesetzt.
25.10.16;23.03.17;2017;extern;Bachelor;DE;Certificate Transparency: Beschreibung, Implementierung und Einsatz in einer real existierenden Public Key Infrastruktur;
25.10.16;14.03.17;2017;extern;Bachelor;DE;Analyse und Vergleich von Caching-Algorithmen einer Information Retrieval-Anwendung mit asymmetrischer Anfragenverteilung;
26.10.16;10.02.17;2017;extern;Bachelor;DE;Empfehlung für eine Make-or-Buy Entscheidung eines Werkzeugs zur Gestaltung von Rechnungsformularen im Rahmen der Neuentwicklung der Rechnungsschreibung bei DATEV eG;
26.10.16;24.02.17;2017;extern;Master;DE;Liquiditätsermittlung bei Mittelständlern und Steuerberatern: Teilkonzeption und prototypische Implementierung in einer Mandanten-Software der DATEV eG;
26.10.16;03.03.17;2017;extern;Bachelor;DE;Erstellung eines Prototyps für die automatisierte Java-Aktualisierung in einer modularen Systemlandschaft;
27.10.16;24.03.17;2017;extern;Bachelor;DE;Entwicklung eines Echtzeitdownloads zur Erweiterung laufender Anlagen;Mit dem Prozessleitsystem von ProLeiT ist es zu jedem Zeitpunkt möglich eine Anlage zu erweitern. Diese Eigenschaft zieht sich durch nahezu alle Produkte des Prozessleitsystems. Einzige Ausnahme bildet das Produkt Plant Batch iT. Hier werden spezielle Batch iT Objekte und Anlagenparameter benötigt und mit einem separaten Download in die Steuerung übertragen. Dieser Download kann nicht durchgeführt werden, während eine Charge in der Steuerung bearbeitet wird. <br>Mit der vorliegenden Bachelorarbeit wird dieser Download untersucht, um herauszufinden, warum er nicht durchgeführt werden kann, wenn eine Charge in der Steuerung bearbeitet wird. Außerdem wird untersucht, warum die Steuerung gestoppt und neu gestartet werden muss, wenn sich Datenbausteine der Anlage geändert haben. Hierbei werden der Code des PCs und der Code der Steuerung analysiert. Das Prozessleitsystem wird analysiert, um herauszufinden, wann es erlaubt ist, Batch iT Objekte zu aktualisieren und wann eine Änderung zu einem Fehler in der Anlage führen würde.<br>Mit den gesammelten Informationen werden zwei neue Downloads konzeptioniert, um Änderungen während der Produktion zu ermöglichen. Bei der Konzeption wird speziell darauf eingegangen, worauf im Umgang mit Echtzeitsystemen zu achten ist. Anschließend werden die beiden Downloads sowohl für den PC als auch für die Steuerung umgesetzt. Hierbei kommen die Sprachen C#, C++ und Anweisungsliste zum Einsatz.<br>
27.10.16;;2017;intern;Bachelor;DE;Entwicklung und responsive Umsetzung des Moduls „Stellensuche“ der Hochschul-Jobbörse der TH Nürnberg mit anschließendem Usability-Test;
27.10.16;13.01.17;2017;extern;Bachelor;DE;Integration und Bewertung von Messdaten aus Lasermessungen für die Fahrdrahtlage;
27.10.16;22.02.17;2017;intern;Bachelor;DE;Analyse von Lösungen für die Re-Zertifizierung des Qualitätsmanagementsystems in einem mittelständischen Unternehmen;
31.10.16;24.03.17;2017;extern;Bachelor;DE;Vergleich von Anbietern cloudgestützter Datenauswertungstools zur Analyse von Monitoringdaten im Rahmen eines SaaS-Angebotes;
31.10.16;31.03.17;2017;extern;Bachelor;DE;Sichere Datenübertragung von externen Datenträgern in Firmen-Netzwerke;Mitarbeiter von Firmen bekommen des Öfteren externe Datenträger, sei es von Kunden oder Werbegeschenke auf Messen. Auf diesen kann sich leicht Schadsoftware befinden und so bei Benutzung an Firmenrechner großen Schaden anrichten. Deswegen müssen externe Datenträger vor der Benutzung von einer zentralen Stelle geprüft und freigegeben werden. Dieser Prozess kann in der DATEV bis zu drei Tagen dauern. Der Prozess soll nun durch ein System beschleunigt und verbessert werden. Ziel der Bachelorarbeit ist es, ein System zu entwickeln, welches Daten von externen Datenträger sicher (unter dem Aspekt Security) und schnell in ein Firmennetzwerk transportieren kann.
31.10.16;30.03.17;2017;intern;Bachelor;DE;Implementierung einer Überführung eines multi-kriteriellen (nicht-)linearen ganzzahligen Programms in Standard-Eingabeformate für Optimierungssolver;Diese Arbeit ist Teil eines Lösungsansatzes zur system-basierten Optimierung von Software-Architekturen. Um aus einer solchen Software-Architektur optimierungs-relevante Elemente zu erhalten, bedarf es einer standardisierten Architekturbeschreibungssprache. Hierzu bietet sich die EAST-ADL an, eine Architekturbeschreibungssprache, die vorwiegend in der Automobilbranche Anwendung findet. Mithilfe der EAST-ADL können ganze System-Produktlinien, in Form von hierarchisch, strukturierten Features-Modellen, abgebildet werden. Durch Modellierung von Features und den zugehörigen Eigenschaften entsteht ein multikriterielles, lineares oder nichtlineares Programm. Dieses Programm kann in der vorliegenden Form von Optimierungswerkzeugen nicht aufgelöst werden. Moderne Optimierungswerkzeuge lesen und verarbeiten lediglich Standardeingabeformate von algebraischen Modellierungssprachen, die der mathematischen Notation nahe kommen. Aus diesem Grund wird ein Überführungsmechanismus benötigt, welcher diese Umformung durchführt. <br>Auf Basis einer variantenreichen EAST-ADL Beispiel-Architektur werden die optimierungs-relevanten Elemente erzeugt und veranschaulicht. Alle möglichen Ausprägungen dieser Elemente bilden die Argumentationsgrundlage zur Evaluierung der Standardeingabeformate. Das Ergebnis der Evaluierung wird anschließend als Modellgenerator, zur Überführung der optimierungs-relevanten Elemente, in Form einer Software implementiert. <br>
31.10.16;;2017;extern;Master;DE;Datengetriebene Optimierung von Fertigungsprozessen zur Kostenoptimierung;
01.11.16;01.03.17;2017;intern;Bachelor;EN;Machine Learning for Algorithmic Trading:<br>Using Neural Networks for Time Series Analysis of Stock Market Data;
02.11.16;03.07.17;2017;intern;Master;DE;Entwicklung und prototypische Realisierung einer Microservice-Referenzarchitektur zur Einbettung von Spielelementen in Webseiten;Im Rahmen dieser Masterarbeit wird ein Konzept entwickelt, welches die Gamification von Webseiten ermöglicht. Für die Integration, einer auf dem Konzept basierenden Implementierung in die Webseite, sind kaum Änderungen an dieser nötig. Das Hinzufügen und Entfernen von Mustern ist mit wenigen Schritten möglich. Ein einmal hinzugefügtes Muster kann zudem mit einem Klick ein- oder ausgeschaltet werden.<br><br>Die Muster werden hierfür als eigenständige Microservices implementiert. Für die Webseite bieten sie eine REST-Schnittstelle an. REST ist eine engere Definition von HTTP, welches das Hauptkommunikationsprotokoll des Internets ist.<br><br>Die Kommunikation mit anderen Microservices erfolgt über einen Messaging-Server. Für die Übersetzung der Nutzerdaten der Webseite und die Gewährleistung der Sicherheit im Gamification-System wird ein zentraler Microservice genutzt. Dieser implementiert kein Muster, sondern dient zum einen als Anticorruption Layer und kümmert sich zum anderen um die Autorisierung und Authentifizierung der Nutzer. Des Weiteren dient er als zentraler Eintrittspunkt in das Gamification-System. Über ihn werden die Muster-Microservices in die Webseite eingebunden.<br><br>Durch die Realisierung eines Prototyps wird die Architektur praktisch umgesetzt.
02.11.16;29.03.17;2017;extern;Bachelor;DE;Übermittlung von schützenswerten Dokumenten in einem mittelständischen Produktionsbetrieb am Beispiel der Firma Rhodius;Die Arbeit befasst sich mit dem Austausch von schützenswerten Dokumenten in einem mittelständischen Produktionsbetrieb.<br><br>Einleitend werden für die Thematik relevante Grundlagen des Datenschutzes sowie zur Geheimhaltung von Betriebs- und Geschäftsgeheimnissen behandelt. Weiter werden Anforderungen allgemein, als auch an konkerten Übermittlungsverfahren diskutiert.<br><br>Im Zweiten Teil wird eine Fallstudie bei der Firma RHODIUS durchgeführt. Hierzu werden zuerst alle relevanten Informationen zu Dokumenten und Übermittlungsverfahren zusammengetragen und anschließend mit Hilfe vorheriger Grundlagen analysiert und bewertet.<br><br>Abschließend wird aufgezeigt, wie andere Unternehmen Defizite bei der Übermittlung von schützenswerten Dokumenten festestellen und bewerten können.
02.11.16;;2017;intern;Bachelor;DE;Medizinische Bildverarbeitung auf mobilen Endgeräten;
03.11.16;01.03.17;2017;intern;Bachelor;DE;Untersuchung und Evaluation der Usability im E-Commerce unter Einsatz eines Eye-Tracking-Systems am Beispiel von Onlinereiseportalen;
03.11.16;04.04.17;2017;extern;Bachelor;DE;Entwicklung intuitiver Interaktionsmöglichkeiten für die graphischen Auswertungen in der Software IngSoft InterWatt;?Intuitive Interaktion? gewinnt in den letzten Jahren als Qualitätsmerkmal von Soft-ware immer mehr an Bedeutung, dies gilt auch für die Energiemanagementsoftware IngSoft InterWatt. In der vorliegenden Bachelorarbeit wird zunächst auf die Bedeu-tung von intuitiver Interaktion und deren Merkmale eingegangen. Anschließend werden Vorgehensmodelle vorgestellt, die die Entwicklung von intuitiv bedienbarer Software sicherstellen sollen. Basierend auf diesen Erkenntnissen werden die beste-henden Interaktionsformen in den graphischen Auswertungen von IngSoft InterWatt optimiert und weitere Interaktionsmöglichkeiten umgesetzt. Abschließend werden Testverfahren aufgezeigt, die Probleme bei der Bedienung der Software im laufen-den Entwicklungsprozess aufzeigen und somit die Möglichkeit bieten, diese frühzei-tig zu beheben.
03.11.16;;2017;intern;Bachelor;DE;Aktuelle Trends im IT-Offshoring und Reshoring;
04.11.16;14.03.17;2017;intern;Bachelor;DE;Analyse von Rahmenbedingungen bei der Entwicklung von eGovernment-Software innerhalb öffentlicher Behörden und privater Dienstleister und deren Implikation auf Software-Entwicklung und Projektmanagement;
08.11.16;30.06.17;2017;intern;Master;DE;Prototypische Entwicklung einer Android App für ortsbasierte Dienste für mobiles Bezahlen in Stadien;Die Masterthesis bearbeitet die Thematik des mobilen Bezahlens in Stadien mit<br>Mehrwertdiensten unter Android. Sie besteht im Wesentlichen aus zwei Teilen.<br>Zunächst soll der Markt in Deutschland hinsichtlich anderer Applikationen, die<br>das mobile Bezahlen ermöglichen, untersucht und die generelle Verbreitung<br>dieser Bezahlmethode beleuchtet werden. Anschließend wird der Fokus auf das<br>Stadion und dessen Stakeholder gesetzt. Eine Analyse wird Aufschluss darüber<br>geben, inwiefern im Umfeld des Stadions die Bereitschaft bzw. die Infrastruktur<br>gegeben ist, um ein derartiges System einführen zu können.<br>Im zweiten Teil der Masterthesis wird auf Basis der Ergebnisse des ersten Teils<br>ein Konzept erstellt. In diesem werden u. a. Anforderungen definiert, anhand<br>derer die entsprechenden Technologien bewertet werden, um diese umsetzen<br>zu können. Abschließend wird eine Applikation entwickelt, in der die Anforderungen mit Hilfe der evaluierten Technologien realisiert werden. Diese wird im<br>Stadionumfeld das mobile Bezahlen ermöglichen und Mehrwertdienste bereitstellen
08.11.16;14.03.17;2017;intern;Bachelor;DE;Studie zu Extraktion von Richtungsinformationen aus kapazitiven Bildern zur Multitouch-Interaktionen auf mobilen Endgeräten;
09.11.16;10.07.17;2017;extern;Master;DE;Die Konzeption und Validierung eines Entscheidungsmodells zur bedarfsorientierten Auswahl eines Datenbanksystems anhand einer prototypischen Implementierung einer Datenhaltungsschicht für ein Massendatenübermittlungssystem.;"Die ""Datenübermittlung"" der DATEV eG sendet elektronische Meldungen an externe Kommunikationspartner (Banken, Finanzverwaltung, etc.) und holt Rückmeldungen für Steuerberater und Mandanten ab. Die Datenbestände liegen dabei aktuell im DATEV-Rechenzentrum auf einer VSAM-Datensammlung. Das Team möchte auf moderne Datenbanksysteme wechseln. Dabei stellt sich die Frage anhand welcher Entscheidungskriterien soll das bestmögliche Datenbanksystem ausgewählt werden. Die Masterarbeit umfasst die Konzeption und Validierung eines universell einsetzbaren Entscheidungsmodelles zur Auswahl geeigneter Datenbanksysteme. Mithilfe einer prototypischen Implementierung einer Datenhaltungsschicht für ein Massendatenübermittlungssystem soll das Entscheidungsmodell validiert werden. Die Validierung dessen stellt dabei keine allgemeingültige Aussage über das Entscheidungsmodell auf. Vielmehr dient die Validierung als Indikation, dass Anhand dieses Modells eine Entscheidung getroffen werden kann."
10.11.16;07.04.17;2017;extern;Bachelor;DE;Konzeption eines Proof of Concept-Modells für einen internationalen Softwarehersteller von In-Memory-Datenbanken.;Ein Proof of Concept ist für viele Unternehmen der erste Schritt, wenn es um die Evaluierung passender Software geht. Dabei ist es vor allem wichtig, dass die geprüfte Lösung richtig eingesetzt und integriert wird. <br>Im Zuge der Bachelorarbeit wird deshalb für einen Softwarehersteller einer In-Memory-Datenbank ein Modell für einen durchgeführten Proof of Concept erarbeitet. Im Vordergrund steht dabei die Analyse der einzelnen Elemente eines Proof of Concept, sowie die Gestaltung möglicher Anwendungsfälle. Zu den betrachteten Bestandteilen gehört beispielsweise die Auswahl eines passenden Datenbankschemas oder das Erstellen von Methoden zur Performancemessung. <br>Das Muster soll als Grundlage für Vertriebspartner sowie Mitarbeiter verwendet werden und über das User-Portal zur Verfügung gestellt werden.<br>
11.11.16;11.04.17;2017;extern;Bachelor;DE;Beurteilung des Betriebsprüfungsrisikos anhand einer E-Bilanz: Konzeption und prototypische Realisierung eines Prüf- und Hinweissystems bei der DATEV eG;Seit spätestens 2013 sind bilanzierende Unternehmen verpflichtet ihre Jahresabschlussdaten elektronisch an das Finanzamt zu übermitteln. Durch eine automatisierte Analyse der gewonnenen Daten soll auch die Auswahl der Unternehmen für eine Betriebsprüfung seitens der Finanzverwaltung erheblich vereinfacht werden.<br>Das Ziel der Bachelorarbeit ist die prototypische Realisierung eines Prüf- und Hinweissystems. Das System soll dem Anwender auf Basis einer E-Bilanz Hinweise geben, ob infolge bestimmter Konstellationen ein erhöhtes Betriebsprüfungsrisiko bei einem Unternehmen vorliegt. Dazu nimmt der Prototyp eine E-Bilanz entgegen und führt darauf Analysen auf Basis von Experten entwickelten Risikofaktoren durch. Durch die Ausgabe der Prüfungsergebnisse wird der Anwender über die potenziellen Risikofaktoren informiert. <br>Der Prototyp dient als Vorstudie für eine spätere Implementierung.<br>
11.11.16;11.04.17;2017;extern;Bachelor;DE;Arbeitsplatz 4.0 und digitales Arbeiten: Anforderungen an die IT-Landschaft einer Direktbank beim Transformationsprozess zum Digital Workspace;Im Rahmen der Digitalisierung der Arbeitswelt soll bei einer Direktbank die Flexibilisierung von Arbeitsorten, Arbeitsmitteln sowie Arbeitszeiten erfolgen.<br>Das Ziel der Bachelorarbeit ist es, die Anforderungen an digitales Arbeiten und die dafür erforderliche technische und organisatorische Infrastruktur darzustellen. Hierfür sollen einzelne IT-Lösungen evaluiert und am Ende im Rahmen einer ganzheitlichen Systemlandschaft vorgestellt werden. Im Fokus stehen vor allem die Strategie einer individuellen und adäquaten Mitarbeiter-Cloud, die Sicherstellung von reibungslosen und ortsunabhängigen Zusammenarbeitsmöglichkeiten und die Einführung von Unified-Communications-Lösungen. Des Weiteren sollen zur Ergänzung der Thematik Umsetzungen des Digital Workspace am Beispiel ausgewählter Unternehmen  vorgestellt sowie die psychologischen Anforderungen, Chancen und Risiken durch digitales Arbeiten betrachtet werden.
14.11.16;14.07.17;2017;extern;Master;DE;Evaluierung und Vergleich von Verfahren für einen Realtime-Recommendation Service ;Im Rahmen dieser Arbeit wurde ein Verfahren für einen Realtime-Recommendation Service in Zusammenarbeit mit dem Big Data Team der Immowelt AG entwickelt. Ziel dieser Entwicklung war es, neue Objektangebote in Echtzeit an passende Benutzer vermitteln zu können. Hierdurch sollten Benutzer noch schneller für sie passende Objektangebote empfohlen bekommen, als es bisher der Fall war. <br>Zu diesem Zweck wurde nach einer Analyse der Anforderungen und Ziele ein Ansatz über ähnliche Objektangebote gewählt. Hierbei werden Objektangebote ermittelt, welche zu einem neuen Objektangebot ähnlich sind. Zu den ähnlichen Objektangeboten wiederrum werden Benutzer ermittelt, die ein hohes Interesse an diesen gezeigt haben. Dies folgt der Annahme, dass Benutzer, welche ein großes Interesse an den ähnlichen Objekten zeigen, auch an dem neuen Objektangebot ein hohes Interesse zeigen werden. <br><br>Um ähnliche Objektangebote möglichst performant und zuverlässig ermitteln zu können, wurden verschiedene Ähnlichkeits- und Distanzmaße auf ihre Verwendbarkeit, sowie ihre Performance hin untersucht. Ebenso sind die Erkenntnisse, wie die Ausgangsdaten für möglichst gute Ergebnisse vorverarbeitet werden müssen, sowie die Auswahl der geeigneten Attribute dargestellt. Um den gewählten Ansatz kritisch zu hinterfragen, sind andere Ansätze dargestellt und werden mit dem gewählten Ansatz verglichen.<br>
16.11.16;15.04.17;2017;extern;Bachelor;DE;Evaluierung und Analyse von CRM Systemen in einem KMU;Die effiziente Analyse und Verwaltung von Kundendaten gewinnt für kleine und mittelständische Unternehmen (KMU) zunehmend an Bedeutung. Die Kundenbeziehung kann auf diese Weise positiv beeinflusst werden und dies spiegelt sich mit steigendem Absatz wieder.<br>Im Rahmen der Arbeit wird nach einer geeigneten Softwareunterstützung für das Verwalten und Analysieren der Kundendaten für die KMU geforscht. Im Zuge der Evaluierung werden verschiedene Open Source und kommerzielle CRM-Systeme miteinander verglichen.<br>Dabei sollen unter anderem die firmeninternen Prozesse berücksichtigt werden. Des Weiteren sind wichtige Auswahlkriterien in Bezug auf die Funktionalität und die Beschaffenheit vom Unternehmen vorgegeben.<br>
16.11.16;14.03.17;2017;extern;Bachelor;DE;Konzeption und Evaluation einer Wissensdatenbank für das modellbasierte FM: Ermittlung der Nutzungskosten in der Entwicklung eines Gebäudes;
24.11.16;10.04.17;2017;extern;Bachelor;DE;Integration von Product Lifecycle Management und Application Lifecycle Management am Beispiel der Softwareprodukte Teamcenter PLM und Polarion ALM;Das  Ziel  der  vorliegenden  Bachelorarbeit  ist  es,  die  beiden  Systeme  Teamcenter <br>PLM  und  Polarion  ALM  miteinander  zu  integrieren.  Hierfür  wird  in  erster  Linie <br>deutlich  gemacht,  wie  die  beiden  Konzepte  PLM  und  ALM  zu  verstehen  sind  und <br>welche  Rolle  sie  in  der  technisch  fortgeschrittenen  und  automatisierten  Welt  der <br>Produktentwicklung  einnehmen.  Es  wird  außerdem  aufgezeigt,  wie  sich  diese <br>Konzepte  unterscheiden  und  wie  sie  voneinander  profitieren  können,  woraus <br>Ansatzpunkte für eine erfolgreiche Integration der beiden Systeme abgeleitet werden <br>können.  Als  nächstes  wird  der  Wunsch  des  Auftraggebers  nach  dem  Ausbau  des <br>Prozessverständnisses im Bereich PLM-ALM erfüllt. Hierfür werden ein spezifischer <br>Prozess  und  eine  Reihe  von  unterstützenden  Prozessen  konzipiert,  welche  den <br>Informationsaustausch zwischen den beiden Systemen wiedergeben. Da sich diese <br>Prozesse  dank  der  Workflow-Designer  in  die  beiden  Systeme  aufnehmen  lassen, <br>wird  auf  diese  bei  der  Integration  Bezug  genommen.  So  lässt  sich  der <br>Datenaustausch  zwischen  den  beiden  Systemen  nach  dem  gewünschten  Schema <br>gestalten.  
25.11.16;21.04.17;2017;extern;Bachelor;DE; Evaluierung von Apache Flink und Apache Spark im Kontext der Echtzeitanalyse von Weblogdaten auf Fraud bei der ING-DiBa AG.<br><br>;Fraud und Betrüge über digitale Dienste sind für Finanzinstitute ein ernstes Problem. <br>Im Zuge des Wandels der Bankenlandschaft werden digitale Dienste in Zukunft weiter<br>in den Vordergrund für Banken rücken. Banken möchten hier so schnell wie möglich betrügerische<br>Transaktionen stoppen können, um Kundenauswirkungen oder finanziellen Schäden der Bank<br>und des Kunden entegegenzuwirken. Eine maschinelle Analyse von Transaktionsdaten ist hierbei<br>aufgrund der Menge an Daten unerlässlich. <br>Diese Arbeit beschäftigt sich mit der Analyse von Logdaten<br>aus dem Online Banking der ING-DiBa AG und wie eine Frauderkennung mithilfe der Big Data<br>Streaming APIs Apache Flink und Apache Spark ermöglicht werden könnte. Elementar ist hierbei<br>die Implementation von Session Windows durch die genannten Applikationen. Es wird zunächst<br>ein Überblick über nötige Kenntnisse für Big-Data-Systeme geschaffen und Fraud im Kontext<br>der ING-DiBa AG spezifiziert, bevor ein Beweis der Umsetzungsfähigkeit der beiden Frameworks<br>betrachtet wird. Darüber hinaus wird ein Vorschlag zur Visualisierung der Daten in Echtzeit<br>gegeben, und vorgestellt wie ein produktiver Aufbau eines Systems aussehen könnte. Die Evaluation<br>wurde mit einem Benchmark und verschiedener Konfigurationen von Multi-Node Clustern durchgeführt,<br>wobei Apache Flink schneller Abschnitt als Apache Spark.
29.11.16;28.04.17;2017;extern;Bachelor;DE;Optimierte Verteilung von Speisen auf genormte Behälter in Großküchen;Während in der Logistikbranche Algorithmen zur Verteilung von Paketen in zum Beispiel<br>LKW-Anhänger zur Optimierung und Kosteneinsparung zum Alltag gehören, ist es in<br>Großküchen, wenn es darum geht Lebensmittel in genormte Gastro-Behälter optimiert<br>und kostensparend zu transportieren ein Fremdwort. Im Rahmen dieser Bachelorarbeit,<br>wird ein Algorithmus entwickelt und implementiert, der die Verteilung von Speisen aus<br>Großküchen auf unterschiedlich genormte Gastro-Behälter (DIN EN 631 oder DIN 66075)<br>optimiert. Da es sich hierbei um ein kombinatorisches Optimierungsproblem handelt wird<br>als Basis hierfür das Bin-Packing-Problem herangezogen und analysiert. Es stellt sich heraus,<br>dass der Approximationsalgorithmus ?Best-Fit-Decreasing? für das weitere Vorgehen<br>sich am besten eignet. Dieser wird aufgrund der entsprechenden Bedingungen im realen<br>Anwendungsfall in Großküchen modifiziert. Die anschließende Analyse zeigt die Merkmale<br>zur Optimierung der Verteilung der Speisen über die Behälter auf. Aus den gewonnenen<br>Erkenntnissen der theoretischen Untersuchungen wird der Algorithmus formuliert und<br>implementiert. Zur weiteren Verbesserung der Verteilung als auch der Kostensenkung<br>im Laufe des Einsatzes des Algorithmus im Großküchen wird ein Empfehlungssystem<br>ausgearbeitet und ebenfalls zum Algorithmus implementiert. Damit die Ergebnisse des<br>erarbeiteten Algorithmus rational bewertet werden können, wird eine Gütefunktion, die<br>zur Bewertung der mehreren Lösungen, die der Algorithmus liefe
01.12.16;02.05.17;2017;intern;Bachelor;DE;Johan Gotliebs Einführung in die Buchhaltung Edition und Kommentar zu den Geschäftsvorfällen (Faktorbuchhaltung); 
01.12.16;14.03.17;2017;extern;Bachelor;DE;Abbilden der Lizenzierungskette in IngSoft InterWatt von der Angebotserstellung bis zur Abrechnung und prototypische Konzeption eines datenbankgestützten Anwendungssystems zur Lizenzverwaltung;
06.12.16;08.05.17;2017;intern;Bachelor;DE;Extraktion von 2d-Features aus Punktwolken;Durch Auswertung von optischen Signalen werden Hindernisse erkannt und in Punktwolken dargestellt. Für höhere Funktionen, beispielsweise die Klassifikation von Objekten ist diese Darstellung ungeeignet, da sie auf einem zu niedrigen Niveau befindet. In dieser Arbeit sollen die Hindernispunkte zu höherwertigen Objekten zusammengefasst werden. Solche Objekte werden auch Features genannt. Damit ist eine einfachere Repräsentation der Umwelt möglich. In dieser Arbeit sollen mindestens linienförmige Objekte und gekrümmte Objekte als Features extrahiert werden. Die Arbeit soll auf 2D-Daten operieren. Teil der Arbeit ist eine Recherche über existierende Arbeiten. Basierend auf dem Recherche-Ergebnis soll ein Ansatz für die Carbot-Umgebung realisiert und bewertet werden.
08.12.16;08.08.17;2017;extern;Master;DE;Kontextsensitive Navigationsstrukturen in Content Delivery Portalen;
15.12.16;15.05.17;2017;extern;Bachelor;DE;Entwurf und Implementierung einer Softwarelösung zur Sammlung und Analyse von Kundendaten am Beispiel einer Messanwendung zur Qualitätssicherung von Röntgenanlagen;
15.12.16;15.05.17;2017;extern;Bachelor;DE;Erweiterung eines XML-Diff-Algorithmus unter Berücksichtigung eines RELAX NG-Schemas ;In der vorliegenden Arbeit war das Ziel, einen XML-Diff-Algorithmus so zu erweitern<br>dass es zusätzlich ein RELAX NG (Regular Language for XML New Generation) Schema<br>berücksichtigt. Des Weiteren sollte ein Prototyp in der Programmiersprache Python<br>implementiert werden, um ein bestehendes XML-Diff-Programm mit einem RELAX NG<br>Schema zu ergänzen. Es sollte untersucht werden, welche Eigenschaften eines RELAX NG<br>Schemas für einen XML-Diff-Algorithmus ausgenutzt werden können, um dessen Ausgabe<br>zu optimieren. Die Ergebnisse zeigten, dass Standardwerte in Attributen einen Einfluss<br>auf die Ausgabe eines XML-Diff-Algorithmus haben, wenn diese im Diff eingefügt oder<br>gelöscht werden. Als zu untersuchender XML-Diff-Algorithmus wurde der Fast Match Edit<br>Script (FMES)-Algorithmus ausgewählt. Hierzu wurde ein Konzept zur Erweiterung der<br>Insert- und Delete-Phase des FMES-Algorithmus erstellt und dies in einem Prototypen<br>implementiert. Eine Fallstudie hat gezeigt, dass der Prototyp erfolgreich falsche Ausgaben<br>in der XML-Diff-Ausgabe ignoriert hat.<br>Diese Bachelorarbeit ist für Studierende in Fachrichtung Informatik wie auch für Personen<br>von Interesse, die ihre XML-Dokumente mit einem RELAX NG Schema strukturieren.
20.12.16;14.03.17;2017;extern;Bachelor;DE;" Konzeption und Realisierung einer Schnittstelle zum kontextbezogenen Aufruf des Programms ""Elektronische Übermittlung Einspruch "" in der DATEV eG"; 
09.01.17;09.06.17;2017;extern;Bachelor;DE;Effiziente Voxelisierung von Dreiecksnetzen;In dieser Arbeit wird ein Algorithmus zur Umwandlung von Dreiecksnetzen in Voxelvolumen<br>entwickelt. Dieser kann sowohl eine Oberflächen- als auch eine solide<br>Voxelisierung (engl. Surface / Solid Voxelization) des Netzes erstellen. Hierfür wird<br>ein dünner Abschnitt schichtweise entlang einer Achsenrichtung durch das Dreiecksnetz<br>verschoben. Dieser Abschnitt dient als Sichtbereich für einen OpenGLViewport,<br>dessen Frame Buffer ausgelesen und die Pixel-Farbwerte in Voxel umgewandelt<br>werden. Der Algorithmus ist in OpenGL 3.3.0 implementiert und wird<br>anhand verschiedener Dreiecksnetzdatensätze evaluiert.
30.01.17;28.09.17;2017;extern;Master;DE;Verbesserung der Gestaltung des konzerninternen Berichtswesen in einem Umfeld am Beispiel der Siemens AG; 
01.02.17;29.09.17;2017;extern;Master;DE; Risikomanagement in der IT-Dienstleistungsbranche im Kontext der aktuellen Marktsituation;Risiken besitzen eine ambivalente Bedeutung für Unternehmen, da sie einerseits durch die verbundenen Chancen den Fortschrittbestand sichern und andererseits im Schadensfall unter Umständen die Unternehmensexistenz gefährden. Die IT-Lösungsbranche steht neben den alltäglichen Unternehmensrisiken durch Trends wie Cloud Computing unter steigendem Wettbewerbs- bzw. Preisdruck. Die Arbeit hat die Untersuchung der Auswirkungen der aktuellen Entwicklungen auf Risikomanagementprozesse bei IT-Lösungsanbietern zum Ziel. Der Fokus liegt dabei auf dem Angebotsprozess. Zentrale Fragestellung ist, ob und ferner wie bei IT-Lösungsanbietern der Umgang mit Risikofaktoren durch die Marktsituation beeinflusst wird. Die Untersuchung im Rahmen der Arbeit erfolgt in Kooperation mit der DXC Technology Group durch einen ethnographischen Ansatz und stellt fest, dass das in den Angebotsprozess integrierte Risikomanagement insbesondere durch die Neufassung der Delegation of Authority zukunftsweisend implementiert ist. Nichtsdestotrotz lassen die Erkenntnisse insbesondere im Hinblick auf die Erfassung unscharfer Risikofaktoren erkennen. Die Arbeit schlägt ein in den Angebotsprozess integriertes regelbasiertes Fuzzy-Expertensystem zur Risikobeurteilung und weiterhin zur Entscheidungsunterstützung hinsichtlich Verkaufstransaktionen vor.
01.02.17;29.09.17;2017;extern;Master;DE; Training eines automatischen Spracherkenners mit Hilfe neuronaler Netze und Integration in ein Dialogsystem;Die Firma Elektrobit Automotive GmbH entwickelt die Software EB GUIDE zur Modellierung von grafischen Benutzerschnittstellen. Durch die Erweiterung EB GUIDE Speech Extension gibt es zusätzlich die Möglichkeit der Modellierung von Sprachdialogen in EB GUIDE.<br>In dieser Arbeit sollen mit Hilfe eines Spracherkennungs-Toolkits akustische Modelle und Sprachmodelle unter Einsatz von neuronalen Netzen trainiert werden und in das Tool als zusätzlicher Spracherkenner integriert werden. Ziel ist es, für einen vorhandenen Trainingskorpus und ein domänenspezifisches Vokabular eine möglichst geringe Wortfehlerrate zu erzielen bzw. durch eine geeignete Abbildung der erkannten Phrasen auf Kommandos die Fehlerrate auf Dialogschrittebene zu minimieren. Darüber hinaus soll der Spracherkenner in eine vorhandene Softwarearchitektur integriert werden.
03.02.17;02.10.17;2017;intern;Master;DE;Erkennung von Liniennummer und Fahrtziel von Stadtbussen mittels Smartphone-Kamera zur Unterstützung von Sehbehinderten; 
14.02.17;14.07.17;2017;intern;Bachelor;DE;Konzeption und Entwicklung einer effizienten Datenstruktur für Punktwolken;Ziel dieser Bachelorarbeit ist es, eine Datenstruktur zu entwickeln, die einen zeitlich effizienten Zugriff auf eine zweidimensionale Punktwolke ermöglicht. Im Rahmen dieser Arbeit soll zunächst die aktuelle Verfahrensweise analysiert und anschließend alternative Strukturen recherchiert werden. Die zu entwickelnde Datenstruktur soll anschließend in die Carbot-Umgebung integriert werden. Hierbei sollen geometrische Anfragen, wie z.B. die Suche nach den nächst gelegenen Punkten innerhalb der Punktwolke oder die Suche nach Punkten innerhalb eines Rechtecks beantwortet werden können. Um effiziente geometrische Anfragen zu ermöglichen, ist eine räumliche Indizierung der Punktwolke notwendig. Datenstrukturen für Punktwolken werden in der Carbot-Umgebung für eine Vielzahl von Software-Komponenten benötigt. Eine mögliche Effizienzsteigerung wird abschließend, anhand typischer Aufgaben der Carbot-Umgebung, analysiert und ausgewertet.
20.02.17;19.10.17;2017;intern;Master;DE;Konzeption und prototypische Implementierung einer E-Learning Plattform für Data Science;Innerhalb der Masterthesis soll die Thematik eines E-Learning Einsatzes, innerhalb einer Hochschulvorlesung, im Themenumfeld Data Science behandelt werden. Die Arbeit besteht aus vier Teilen.<br><br>Im ersten Teil werden die Grundlagen von Data Science und E-Learning behandelt. Im Data Science Teil werden zudem Prozesse für die Umsetzung von Data Science Projekten, sowie einige Analysemodelle vorgestellt. Der E-Learning Teil behandelt Didaktik Grundlagen und stellt einige Module für eine Umsetzung vor. Abschließend werden Evaluationskriterien und -methoden vorgestellt, für die Überprüfung eines erfolgreichen Einsatzes.<br><br>Im zweiten Teil werden Data Science E-Learning Plattformen verglichen. Hierfür wird ein Scoring Model, mit unterschiedlichen Kriterien, erstellt. Zudem werden sechs E-Learning Plattformen für Data Science vorgestellt und bewertet.<br><br>Der dritte Teil behandelt die Erstellung eines Konzeptes für den Einsatz. Erst wird die Plattformauswahl, auf Basis des Plattformvergleiches, getroffen. Anschließend wird ein Didaktik Konzept für die Umsetzung auf der gewählten Plattform erstellt. Außerdem wird auf die Bestandteile der Umsetzung eingegangen. Darunter sind die einzelnen Kapitel, sowie die Evaluierung des Lernerfolgs, zu verstehen.<br><br>Im letzten Teil der Arbeit wird auf die prototypische Implementierung der Plattform eingegangen. Von der Installation der Plattform bis zur Bedienung dieser. Ebenso die Erstellung der einzelnen Kapitel wird näher erläutert.
23.02.17;23.10.17;2017;extern;Master;DE;Konzipierung eines Reifegradmodels für Wissensmanagement nach dem ISO 33000 Standard;"Untersuchung und Analyse der Kernbegriffe ""Daten"", ""Information"", ""Wissen"" und ""Wissensmanagement"". Anschließende Definition der Begriffe für die komplette Ausarbeitung.<br>Untersuchung und Analyse ausgewählter Prozess- und Wissensmanagementmodelle mit anschließender Reflexion der Ergebnisse.<br>Konzipierung eines Reifegradmodells für Wissensmanagement nach dem ISO/IEC 330XX Standard.<br>"
01.03.17;02.08.17;2017;intern;Master;DE;Entwurf und prototypische Entwicklung eines natürlichen Dialogsystems im Kontext von Unterhaltung, Websuche und E-Commerce;Der natürliche Dialog ist ein einfach zu lernender und barrierefreier Weg, ein System zu bedienen. Dialogsysteme, auch Konversationsagenten genannt, finden seit Jahren in verschiedenen Formen in den unterschiedlichsten Bereichen Anwendung. <br>Um den Nutzern ein möglichst positives Nutzungserlebnis (UX) zu ermöglichen, soll ein Dialog natürlich wirken. Menschen lernen relativ früh, mit ihrer Umwelt zu kommunizieren und haben dadurch jahrelange Erfahrung mit Dialogen. Sie bemerken sehr schnell, wenn ein Dialog unnatürlich verläuft. <br>Viele Dialogsysteme versorgen den Nutzer mit Informationen, diese basieren auf Daten. Die Quelle dieser Daten kann eine Datenbank, allerdings auch eine Sammlung unstrukturierter Daten (z. B. Text) sein. Um dem Nutzer die gewünschten Daten zu liefern, muss die Anfrage des Nutzers in eine Abfrage (Query) umgewandelt werden. Je konkreter diese Abfrage ist und je genauer sie mit der Intention des Nutzers übereinstimmt, desto hilfreicher ist die Ant-wort des Systems an den Nutzer. <br>Damit ein Dialogsystem Nachfragen eines Nutzers beantworten kann, benötigt es Antworten in Form von Informationen, die als strukturierte Daten abrufbar sein müssen.<br>Eine große Sammlung an Informationen befindet sich in Form von unstrukturierten Daten (Text) auf Webseiten und elektronischen Dokumenten im Internet. Um diese Daten in eine strukturierte Form zu überführen, werden Methoden aus der Computerlinguistik (CL) auf Texte angewendet, welche von Webseiten extrahiert wurden.<br>
01.03.17;31.07.17;2017;intern;Bachelor;DE;Ein Ansatz zur Steigerung der Aussagekraft von Online-Bewertungen von Grafiken<br>;Die vorliegende Bachelorarbeit beschäftigt sich damit, Möglichkeiten zu ermitteln um den Informationsgehalt und die Qualität von Bewertungen von Grafiken zu erhöhen. Hierzu wurde die Hypothese aufgestellt, dass durch den Einsatz eines mehrdimensionalen Bewertungssystems, eine Steigerung der Bewertungsqualität zu erwarten ist. Um die Hypothese zu überprüfen wurde eine Evaluation durchgeführt, die ein mehrdimensionales mit einem eindimensionalen Bewertungssystem vergleicht. Die Evaluation wurde von ausgewählten Testpersonen ausgeführt, die beide Bewertungssysteme unter bestimmten Vorgaben genutzt haben. Anschließend wurden die Testpersonen einer Befragung unterzogen. Anhand der gewonnenen Daten kann durch den Einsatz eines mehrdimensionalen Bewertungssystems eine Erhöhung der Qualität nachgewiesen werden, welche allerdings durch die kleine Stichprobe eher als Tendenz gewertet werden kann.
01.03.17;01.11.17;2017;intern;Master;DE;Generative Adversarial Networks zur Manipulation von Bildern;"Diese Masterarbeit befasst sich mit einem neuartigen Ansatz im Bereich des maschinellen<br>Lernens, welcher von einem Forscherteam um I. Goodfellow im Jahre 2014 vorgestellt<br>wurde. Der dabei veröffentlichte Ansatz der ""Generative Adversarial Networks"" (kurz<br>GANs) ist dazu in der Lage, den Aufbau und die Struktur von komplexen Elementen<br>aus großen Datenbanken unbeaufsichtigt zu erlernen. Da die Verteilung von Bildern aus<br>großen Datenbanken bisher kaum zu erlernen war, sind GANs durch diese Eigenschaft<br>besonders in der Forschung im Bereich der Bildverarbeitung sehr populär. Dies führte<br>bereits zu einem enormen Schub an Veröffentlichungen und somit auch zu neuen Ein-<br>satzgebieten im Bereich der Bildverarbeitung. Erlernen GANs beispielsweise den Aufbau<br>und die Struktur von Gesichter in einer Gesichts-Datenbank, so kann dieses Wissen<br>anschließend dazu eingesetzt werden, um neue Gesichter zu generieren oder realistische<br>Manipulationen an Gesichts-Attributen durchzuführen.<br>Ziel dieser Arbeit ist es daher ein fundiertes Grundwissen über die Technik der GANs<br>zu vermitteln, einen Überblick über die aktuellen Einsatzbereiche der GANs im Bereich<br>der Bildverarbeitung zu liefern sowie die Umsetzung und Evaluierung der GANs in<br>den Bereichen der Super-Resolution und der Transformation von Häuser-Skizzen in<br>Häuser-Fotos."
01.03.17;27.10.17;2017;extern;Master;DE;Gestenerkennung und virtuelle Eingabemöglichkeiten mittels Myo-Armband in labor- und medizintechnischen Umgebungen;Durch ein EMG-Armband ist es möglich Muskelbewegungen, welche durch Gesten mit der Hand, dem Arm oder auch bei Fingerbewegungen auftreten, zu erfassen. Hierdurch kann eine Anwendung realisiert werden, die ohne Berührungen mit Standard-Eingabegeräten auskommt. Ein äußerst interessanter Anwendungsfall ist hierbei die Verwendung bei Computersystemen in Reinräumen oder ähnlich stark hygienisch reglementierten Standorten, bei denen darauf Wert gelegt wird, möglichst wenige Oberflächen mit den Händen berühren zu müssen. Im Speziellen können dies labor- oder medizintechnische Umgebungen sein. Dieses Konzept wird hierbei anhand eines exemplarischen Showcases in Zusammenarbeit mit der infoteam Software AG umgesetzt.
01.03.17;01.11.17;2017;intern;Master;DE;Entwicklung einer OpenCL-Implementierung für die VideoCore IV GPU des Raspberry Pi;Die VideoCore IV GPU der Raspberry Pi Modelle besitzt im Vergleich zu den Host-CPUs eine sehr viel höhere Rechenleistung. Diese bleibt in vielen Einsatzgebieten von Raspberry Pi größtenteils ungenutzt, da es keine einfach zu verwendende Programmiersprache und Schnittstelle gibt, mit deren Hilfe die GPU für nicht-grafische Anwendungen verwendet werden kann.<br>In dieser Arbeit wird eine OpenCL-Implementierung für die VideoCore IV GPU erstellt, die es ermöglicht, nicht-grafische Berechnungen auf der GPU auszuführen. Implementiert werden die OpenCL-Laufzeitbibliothek für den hostseitigen Zugriff, ein Compiler zum Umwandeln von OpenCL C-Quellcode in Maschinencode und die GPU-seitige Standardbibliothek mit häufig verwendeten Funktionen. Für die Teile dieser Arbeit werden die relevanten Ausschnitte der Vorgaben durch den OpenCL-Standard sowie deren Umsetzung beschrieben, wobei auf interessante Teilbereiche und Problemlösungen besonders eingegangen wird.<br>Anhand von vorhandenen Anwendungen wird gezeigt, dass die entstandenen Implementierung bereits erfolgreich auf OpenCL basierende Programme ausführen kann und wie weit sie für einen produktiven Einsatz geeignet ist.<br>Ebenso wird aufgezeigt, dass diese Implementierung bei rechenaufwendigen Aufgaben die Performance der Host-CPUs weit übertrifft sowie in welchen Fällen die Host-CPU eine bessere Performance bietet.
01.03.17;31.08.17;2017;extern;Bachelor;DE;Evaluation von Methoden zur transparenten Bereitstellung von Daten aus Datenbanken mit unterschiedlichen Schemata;Diese Bachelorarbeit befasst sich mit der Evaluation und prototypischen Implementierung von Verfahren, mit denen einer Anwendung die Daten aus mehreren MySQL-Datenbanken bereitgestellt werden können.<br><br>Als Anwendungsfall wird dabei eine PHP-Software betrachtet die bisher nur auf eine der Datenbanken zugreift. Aus Anwendungssicht soll sich dies nicht ändern. Eine Modifikation des Quellcodes der Anwendung sowie deren Datenbankabfragen soll nicht vorgenommen werden.<br><br>Die Datenbanken haben einen teils unterschiedlichen, teils redundanten Datenbestand sowie historisch gewachsene und voneinander abweichende Schemata.<br><br>In der Bachelorarbeit werden mehrere Softwaresysteme auf die Erfüllung der oben genannten Anforderungen überprüft sowie ein Konzept für die Integration der Daten erarbeitet. <br><br>Als geeignet stellt sich Software heraus, die über Fähigkeiten aus den Bereichen Data Virtualization sowie Data Federation verfügt.<br><br>Für das Konzept zur Datenintegration wird je ein Prototyp mit der Software PostgreSQL und teiid erstellt.
01.03.17;31.07.17;2017;extern;Bachelor;DE;Wissensmanagement im Wealth Management einer international agierenden Großbank;Ziel dieser Arbeit ist der prototypische Aufbau eines Wissensmanagementsystems, das als Alternative zur jetzigen suboptimalen Kommunikation eingesetzt werden kann. Durchgeführt wurde die Arbeit zusammen mit dem Geschäftsbereich Wealth Management der BNP Paribas. Dieser Bereich bietet Vermögensberatung und -verwaltung für vermögende Privatkunden an.<br>Durch die aktuelle Verbreitung von Informationen besteht ein hohes Risiko, dass neue Mitarbeiter Prozesse falsch ausführen. Dadurch können sich im Banking-Bereich Verstöße gegen das Aufsichtsrecht ergeben. Diese Problematik verschärft sich durch das starke, dynamische Mitarbeiterwachstum der Abteilung, sowie der schnellen Veränderung der regulatorischen Rahmenbedingungen, insbesondere in der Vermögensberatung.<br>Mithilfe eines Wissensmanagementsystems soll es allen Mitarbeitern des Geschäftsbereichs Wealth Management möglich sein, jederzeit die für sie relevanten Informationen einsehen zu können, um die Fehlerquote auf ein Mindestmaß zu reduzieren und die Qualität der Kundenberatung zu Erhöhen. <br>Es werden aktuelle Kommunikationswege analysiert und ein Soll-Konzept erstellt. Des Weiteren wird zum einen der Ist- und Soll-Zustand modelliert und verglichen, zum anderen wird der aktuelle Beratungsprozess modelliert. Basierend auf den gewonnenen Erkenntnissen wird das erstellte Konzept in einer prototypischen Lösung umgesetzt.
06.03.17;07.08.17;2017;extern;Bachelor;DE;Sicherstellung der einheitlichen Auskunftsfähigkeit des Onsite Supportes.;Thema der Arbeit:<br>Sicherstellung der einheitlichen Auskunftsfähigkeit des Onsite Supportes<br><br>Zusammenfassung der Arbeit:<br>Ziel dieser Bachelorarbeit ist es, die Auskunftsfähigkeit des Onsite Support (Service Desk von Siemens Healthineers Erlangen) versuchen mit geeigneten Vorschlägen zu verbessern bzw. zu vereinheitlichen. Im Rahmen der Abschlussarbeit wird eine Bewertung, durch systematische Gegenüberstellungen der aktuell eingesetzten Kommunikations- und Informationswerkzeuge für die Eignung der einheitlichen Auskunftsfähigkeit, durchgeführt. Ferner ist ein wichtiger Untersuchungsgegenstand der Arbeit die gründliche Analyse des Soll-Zustandes und Informationsbedarfes des Onsite Supportes und der beteiligten Geschäftsbereiche, mittels (qualitativer) Interviews. Als Abschluss werden drei unterschiedliche Vorschläge gezeigt, welche die Auskunftsfähigkeit vereinheitlichen könnten. Die Einführung eines Geschäftsprozesses, die Reduktion des E-Mail-Verkehrs und die Kombination von Enterprise Social Software ergeben die vorgeschlagenen Möglichkeiten.
09.03.17;06.11.17;2017;extern;Master;DE;Real-Time Data Streaming - prototypischer Vergleich von technischen Lösungen;Diese Master Thesis dient zur Durchführung eines prototypischen Vergleichs von Stream Processing Frameworks. Dieser soll genutzt werden, Auswahlprozesse eines solchen Frameworks transparent zu machen und eine objektive Auswahl im Rahmen einer Entscheidungsfindung zu treffen. Im Rahmen dessen werden im ersten Abschnitt der Arbeit grundlegende Begriffe wie Streaming Daten, Eventzeit und Pattern der Verarbeitung vorgestellt und architektonische Hintergründe beschrieben. Grundlage des prototypischen Vergleichs bilden eine Auswahl von beschriebenen Stream Processing Frameworks. Zum Zweck einer näheren und detaillierteren Betrachtung werden im Folgenden die Frameworks Spark Streaming, Flink und aufgrund von betrieblichen Vorgaben Informatica Intelligent Streaming ausgewählt. Ein konzeptioneller Entwurf einer sogenannten Real-Time Streaming Architektur wird im Anschluss an den Auswahlprozess genutzt, um eine optimale Implementierung der ausgewählten Frameworks zu gewährleisten.<br>Im Weiteren beschreibt diese Arbeit den konzeptionellen Vorgang zur Erstellung einer Bewertungsmatrix, welche eine Evaluierung von Stream Processing Frameworks gewährleistet. Mit Hilfe dieser und der Breitstellung einer Real-Time Streaming Architektur wird in Folge dessen der prototypische Vergleich durchgeführt und die Ergebnisse evaluiert und vorgestellt. Ein Fazit und Ausblick auf mögliche weiterführende Arbeiten und die Entwicklung von Data Streaming in den nächsten Jahren bilden den Abschluss der Arbeit.
10.03.17;09.08.17;2017;intern;Bachelor;DE;Konzeption und Implementierung einer Softwarelösung zur Planung und Durchführung von Handballturnieren;In dieser Arbeit wurde untersucht, wie eine softwareseitige Hilfestellung für die Planung und Durchführung von Beachhandball-Turnieren bei einem Nürnberger Sportverein gewährleistet werden kann. Hierfür sind eine Ist- und Schwachstellenanalyse durchgeführt und ein Anforderungskatalog erstellt worden. Die Arbeit besteht aus einem fachlichen Konzept, welches die die zum Einsatz einer solchen Software relevanten Features aufzeigt und erklärt. Zusätzlich wurde untersucht, wie eine Softwarelösung durch beratende Komponenten über ein obligatorisches Maß hinaus nützlich sein kann. Auch wurde der Versuch unternommen, die konzipierte Softwarelösung zu implementieren und die hierfür eingesetzten Technologien und Methoden ausführlich dokumentiert. 
13.03.17;13.08.17;2017;intern;Bachelor;DE;Analyse der Programmiersprache Go;Go ist eine Programmiersprache die vom Unternehmen Google Inc. entworfen wurde, um dessen Probleme im Entwicklungsprozess zu lösen. In dieser Arbeit soll die Programmiersprache Go analysiert werden. Hierfür wird eine Auflistung ausgewählter Features aufgestellt, welche für einer genaueren Analyse vorgesehen sind. Anschließend erfolgt eine Gegenüberstellung der Einträge mit vergleichbaren Features anderer Programmiersprachen, um konzeptionelle und inhaltliche Unterschiede herauszuarbeiten. Zusätzlich wird beschrieben, wie sich konzeptionelle Unterschiede verschiedener Sprachen auf die Architektur der mit Go entwickelten Software auswirken. Bei ausgewählten Features wird genauer auf die konkrete Implementierung eingegangen. Der Schwerpunkt soll auf Nebenläufigkeit und die Speicherverwaltung von Go gelegt werden.
13.03.17;10.08.17;2017;extern;Bachelor;DE;Software Architektur zur Entwicklung von Cross-Plattform Casual Games;Im Rahmen der Arbeit soll eine Software Architektur entstehen, welche auf die verschiedenen Bereiche bei der Erstellung von Cross-Plattform Games eingeht. Die Bereiche unterteilen sich in den Plattform unabhängigen Teil und die von der jeweiligen Plattform abhängigen Teile. Hierfür eignet sich Beispielsweise das Model-View-ViewModel Modell (kurz MVVM). Ziel ist eine Software Architektur und Plattform Spezifische Templates, mit deren Hilfe Entwickler direkt mit der Entwicklung der Spiele beginnen können, ohne erst die Grundlagen schaffen zu müssen.
15.03.17;14.08.17;2017;extern;Bachelor;DE;Entwicklung eines Verfahrens zur Risikoanalyse nach DSGVO im Hinblick auf Rechte und Freiheiten der Betroffenen;Im Mai 2018 wird die am 27. April 2016 durch das Europäische Parlament und dem Europäischen Rat verabschiedete Verordnung 2016/679 zum Schutz der natürlichen Personen bei der Verarbeitung personenbezogener Daten, zum freien Datenverkehr und zur Aufhebung der Richtlinie 95/46/EG (DSGVO) wirksam. Ziel dieser Verordnung ist es, den Datenverkehr in Europa zu vereinfachen und einen Schutz zu schaffen, durch den die Verarbeitung personenbezogener Daten europaweit harmonisiert wird.<br>Ein wesentlicher Teilaspekt der DSGVO sind die Anforderungen an die Risikoanalyse, die den Schutzbedarf bei der Verarbeitung personenbezogener Daten klassifizieren soll.<br>Diese sollen im Rahmen dieser Bachelorarbeit ausgearbeit und mittels einer Software-Lösung für eine Risikoanalyse, Risikobewertung und zur Einhaltung der gesetzlich vorgeschriebenen Nachweispflichten abgebildet werden.
15.03.17;15.08.17;2017;intern;Bachelor;DE;Positionsbestimmung unter Einsatz von Isovist-Merkmalen;Bei dem Carbot handelt es sich um einen autonomen, mobilen Roboter, der eine Plattform zur Entwicklung von Verfahren und Algorithmen im Bereich autonome Robotik bietet. Zu der Hardwareausstattung des Carbots gehört ein 360°-Laserscanner, welcher die Entfernung zu Objekten misst, wie auch eine Ultraschall-basierte Hinderniserkennung.<br><br>Im Carbot-Projekt soll ein Verfahren zur Positionsbestimmung anhand von ermittelten Isovist-Merkmalen entwickelt werden und als optionale Softwarekomponente im Carbot integriert und bewertet werden.<br><br>Dazu gehört zum einen die Recherche über bestehende Ansätze zur Positionsbestimmung, die Auswahl sinnvoller Isovist-Merkmale und die Realisierung der Merkmalsextraktion anhand der gelieferten Daten des 360°-Laserscanners.<br><br>Bei der Umsetzung soll auf Basis der extrahierten Merkmale ein Fingerprint gebildet werden, um die Position des Carbots zu bestimmen.
15.03.17;15.08.17;2017;intern;Bachelor;DE;Analyse von inkrementellen, rasterbasierten<br>Navigationsverfahren für autonome, mobile Roboter;Für den Carbot existiert die Navigationskomponente GAA (Grid-based A* Advanced), die eine Punkt-zu-Punkt-Wegeplanung vorbei an Hindernissen durchführt. In dynamischen Umgebungen ändert sich die wahrgenommene Umwelt ständig, alleine schon dadurch, dass während der Fahrt neue Hindernisse erfasst werden (z.B. weil sie in den Sichtbereich der Kamera kommen). Klassische A*-Ansätze müssen bei Änderung der Hinderniskarte die Planung komplett neu durchführen. Im Gegensatz dazu versuchen inkrementelle Ansätze soviel wie möglich aus einer alten Planung wiederzuverwenden und berechnen eine neue Route auf der Basis der inkrementellen Änderungen. Das kann Ressourcen schonen, allerdings ist die Planung komplexer. In dieser Arbeit sollen in der Literatur beschriebene inkrementelle Ansätze (z.B. D*, Focussed D*, D* Lite) analysiert und teilweise implementiert werden. Eine Auswertung soll diese dann mit nicht-inkrementellen Ansätzen (A* oder GAA) vergleichen.
15.03.17;15.08.17;2017;intern;Bachelor;DE;Konzept und Implementierung der Simulation grundlegender Smart-Home-Konzepte;Im Rahmen dieser Arbeit wird ein Prototyp entwickelt und beurteilt. Thema ist das Feld Heimautomatisierung, mit einer Zielgruppe von wenig technik-affinen Nutzern. Ziel des Prototyps ist es, interaktiv zu veranschaulichen worauf es bei Smart Homes und insbesondere der Heimautomatisierung ankommt. Dazu wird dazu zusätzlich eine Nutzerstudie durchgeführt. Es werden Designentscheidungen und Vorgehensweise erörtert und die Ergebnisse einer eigenen Bewertung sowie die Ergebnisse und Anregungen aus der Nutzerstudie diskutiert. Der entstandene Prototyp wurde von den Nutzern positiv entgegengenommen und könnte eine gute Basis für eine Weiterentwicklung bzw. einen zweiten Prototyp dienen.
15.03.17;15.08.17;2017;intern;Bachelor;DE;Konzept und Umsetzung eines Wordpress Auftritts der Hochschul-Jobbörse; 
18.03.17;18.08.17;2017;extern;Bachelor;DE;Erkennung von Zählerständen statischer Verbrauchszähler mittels einer mobilen Applikation;"Die vorliegende Bachelorarbeit beschäftigt sich mit der automatischen Mustererkennung und Auswertung der Zählerstände von statischen Gas- und Stromzählern mit Hilfe einer Smartphone Applikation. Durch verschiedenste Störfaktoren, wie z.B. Lichtverhältnisse oder Typenvielfalt der Zähler, ist das manuelle Ablesen der Zählerstände langsam und fehleranfällig. Hier wäre eine schnelle, genaue und automatisierte Erfassung der Zählerstände von großem Nutzen. Einerseits für die Energieversorger durch Kosteneinsparung, andererseits für Privatpersonen durch eine einfache Überwachung des Verbrauchs.<br>Ziel ist es die Zählerstände zu erkennen, eine einfache Handhabung der Applikation zu erreichen, die fehlerrelevanten Faktoren zu präzisieren und mögliche Lösungen zu skizzieren. In Zusammenarbeit mit den Stadtwerken Erlangen AG und der Firma Method Park soll eine mobile Softwareanwendung entworfen und implementiert werden. Sie soll auf den vorhandenen Bibliotheken ""OpenCV"", für die Bildverarbeitung, und ""Tesseract"", für die Texterkennung, basieren.<br>Als Ergebnis sollen die Bildverarbeitungsschritte aufgezeigt sein, die zur möglichst besten Texterkennung benötigt werden. Außerdem sollen die am häufigsten in der Praxis vorkommenden Störfaktoren mit Hilfe der Applikation sowie mögliche Lösungsansätze zur Behebung dieser erarbeitet werden. Diese Arbeit soll durch die automatisierte Erkennung von Zählerständen einen Beitrag für den Bereich der zukunftsweisenden Heimautomatisierung leisten."
18.03.17;16.08.17;2017;extern;Bachelor;DE;Neukonzeption und -implementierung einer bestehenden Client-Server-Anwendung mit aktuellen Web-Technologien<br>;Diese Arbeit befasst sich mit der Neu- bzw. Weiterentwicklung einer bestehenden Client-Server-Anwendung mit aktuellen Web-Technologien. Als Anwendungsfall dient hier die Zeiterfassungs-Anwendung der Firma mediendesign AG. Ziel soll es sein diese Anwendung für die Mitarbeiter mobil nutzbar zu machen, also primär für Android- und iOS-Geräte. Hierfür sollen Abwägungen getroffen werden, welche der derzeit gängigen oder auch der neuesten Web-Technologien sich am Besten dafür eignen. Dabei werden unter Anderen die Kosten und die User Experience der zur Verfügung stehenden Techniken eine Rolle spielen. Mit der ausgewählten Technologie soll die Anwendung dann implementiert und evaluiert werden. Hierbei stehen eine bessere Usability der Anwendung und eine mögliche Zeitersparnis bei der Nutzung im Vordergrund.
21.03.17;17.11.17;2017;extern;Master;DE;Inhalts- und Stimmungsanalyse von Kundenfeedback im Automotiveumfeld;"Diese Arbeit beschreibt eine Vorgehensweise zur Analyse von Feedback-Daten für den Bereich der Text-Kategorisierung in Bezug auf Stimmung und Inhalt, mit einem Vergleich von unterschiedlichen Lösungen aus dem ""as-a-Service""- und Open-Source-Bereich. Die Feedback-Daten sind auf die Automotive-Domäne ausgelegt und werden im Zuge von Natural-Language-Processing-Schritten aufbereitet und jeweils als Ganzes analysiert. Das Trainieren eigener Modelle erfolgte mit unterschiedlichsten Datensätzen, wovon einer nur Automotive-Themen behandelt. Durch das Fehlen von Trainingsdaten im Bereich der Inhaltsanalyse wurden Bootstraping-Methoden und Semi-Supervised-Learning-Algorithmen exploriert, um durch die Hinzunahme von nicht gelabelten Daten einen möglichst guten Klassifikator zu erzeugen. Alle Lösungen wurden sowohl anhand der Feedback-Daten über die Metriken Accuracy, Precision und Recall, als auch über unterschiedliche Eigenschaften wie z.B. den verwendeten Algorithmen, Kosten, Lizenzen und Sprachunterstützungen verglichen. Am Ende wird ein mögliches Konzept anhand einer Lösung dargestellt."
21.03.17;18.08.17;2017;extern;Bachelor;DE;Prozessoptimierung der Wareneingangserfassung und Kontrolle in der Entsorgungswirtschaft am Beispiel der GfM Gruppe und Ihrer Unternehmen;Die Arbeit beschäftigt sich auf Grundlage des Kreislaufwirtschaftsgesetzes im Allgemeinen mit dem Wareneingang in der Entsorgungswirtschaft und im speziellen mit den Schwachstellen und dem Ziel der daraus resultierenden Optimierungsmöglichkeiten.<br><br>Bei der Beschreibung und Analyse der Teilschritte Erfassung, Kontrolle und Dokumentation des Wareneingangsprozesses in einem Unternehmen werden gängige Methoden aus der Fachliteratur angeführt. Nach der Analyse der Ist-Situation bei der GfM Gruppe werden Schwachstellen ermittelt und in Korrelation mit den bereits angeführten Methoden gesetzt.<br><br>Anhand der aussagekräftigen Bewertungen der Methoden in Bezug auf die erarbeiteten Kriterien und analysierten Schwachstellen durch die Nutzung von Scoring-Modellen, wird eine konkrete Handlungsempfehlung erarbeitet. Dabei ergibt sich, dass sowohl Optimierungspotenziale möglich sind, aber auch teilweise durch vorherrschende Rahmenbedingungen verhindert werden. Durch eine anschließende prototypische Entwicklung dieser Empfehlung in Form eines webbasierten IT-Systems wird das zuvor erarbeitete technische Konzept umgesetzt. Auch mögliche weitere Integrationsansätze werden dabei exemplarisch dargestellt.<br><br>Durch das prototypische System ist ein anschließender direkter Vergleich mit der bisherigen Situation im Wareneingang der GfM Gruppe möglich und belegte, dass erhebliche zeitliche Einsparungen durch eine Prozessoptimierung im Wareneingang realisierbar sind.
21.03.17;21.08.17;2017;extern;Bachelor;DE;Dynamisch generierte SQL-Abfragen auf die nicht-relationale Mainframe-Datenbank Adabas: Prototypische Realisierung und Performanzanalyse;
22.03.17;18.08.17;2017;extern;Bachelor;DE;Konzeption und Entwicklung eines Dashboards zur Visualisierung von Protokollbäumen bei Siemens Healthcare;Kurzzusammenfassung<br>Die vorliegende Arbeit befasst sich mit der Konzeption und Entwicklung eines Dashboards zur dynamischen Visualisierung von Protokollbäumen bei Siemens Healthcare GmbH.<br>Den Hauptteil dieser Arbeit bildet ein Vergleich der Levenshtein Distanz, Jaro Distanz, Longest Common Subsequence und Longest Common Substring Algorithmen für Zeichenkettenvergleiche. Ziel hierbei ist es diese Algorithmen zu klassifizieren und zu vergleichen, um den geeignetsten Algorithmus für Vergleichsanalysen zu finden. Ein weiterer Fokus liegt auf der Suche nach Implementierungsmöglichkeiten des ausgewählten Algorithmus für eine dynamische Ausführung spontaner Benutzerabfragen. <br>Im praktischen Teil dieser Abschlussarbeit wurde ein Dashboard im Business Intelligence Tool QlikView implementiert. Nach einer Ausgangssituationsanalyse wurden zunächst die Anforderungen festgelegt, die im Dashboard erfüllt werden sollten. Um die benötigten Daten zu integrieren, wurde ein ETL-Prozess verwendet. Für benutzerfreundliche Datenauswertungen wurden verschiedene Visualisierungsmöglichkeiten in das Dashboard eingesetzt.<br>
22.03.17;22.08.17;2017;intern;Bachelor;DE;Maschinelles Lernverfahren zur Strukturierung von Stellenanzeigen;Diese Arbeit ist eine Bachelorarbeit über das Thema: Maschinelles Lernverfahren zur Strukturierung von Stellenanzeigen. Zuerst wird im ersten Kapitel das Thema eingeleitet. Dabei wird die Motivation erläutert und das Ziel der Arbeit festgehalten. Der Aufbau der Arbeit wird angesprochen und Voraussetzungen zum Verständnis dieser werden spezifiziert. Im nächsten Kapitel wird das Anwendungsszenario beschrieben. Darin wird der Ablauf wiedergegeben, der notwendig ist, damit Unternehmen ihre Stellenanzeigen bei der Hochschuljobbörse einstellen können. Außerdem wird auf das Datenbankschema eingegangen in dem die Stellenanzeigen und Zusatzinformationen in der Datenbank abgespeichert werden. Anwendungsbeispiele, die das Einsetzen von maschinellen Lernverfahren rechtfertigen, werden auch erläutert. Das dritte Kapitel handelt von verschiedenen Grundlagen des maschinellen Lernens. Sowohl, regelbasierte Lernverfahren, als auch maschinelle Lernverfahren sind enthalten. Im vierten Kapitel werden Ansätze aufgelistet, die in der Literatur beschrieben sind, um ähnliche Problemstellungen zu lösen. Kapitel fünf beschreibt eigene Ansätze der Problemstellung und das sechste Kapitel somit auch Software, die dabei eingesetzt wurde. Zu guter Letzt wird eine Evaluierung durchgeführt und ein Ausblick gegeben.
22.03.17;22.11.17;2017;extern;Master;DE;Untersuchung verschiedener BYOD-Szenarien in einem mittelständischen Betrieb mit anschließendem Umsetzungsvorschlag;Heutzutage wird der Ruf nach modernen Arbeitskonzepte, die flexibles und mobiles Arbeiten ermöglichen, immer lauter. Diese können beispielhaft durch den Einsatz mobiler Endgeräte ermöglicht werden. Dabei können die Geräte nach diversen Szenarien im Unternehmen eingesetzt werden. Im Rahmen dieser Masterarbeit kommt es zu einer Betrachtung der verschiedenen BYOD-Szenarien in einem mittelständischen Betrieb. Dabei werden rechtliche Aspekte und organisatorische Aufwände der unterschiedlichen Szenarien untersucht sowie eine Nutzungs- und Kostenbetrachtung durchgeführt, deren Ergebnisse in eine Nutzwertanalyse einfließen. Auf Basis der so erlangten Erkenntnisse erfolgt ein Umsetzungsvorschlag sowohl für die IT- als auch für die Personalabteilung der N-ERGIE IT GmbH.
24.03.17;21.08.17;2017;extern;Bachelor;DE;Prototypische  Implementierung eines Kennzahlensystems zur Verbesserung der Unternehmensziele bei der Siemens AG;Eine systematische Verknüpfung von Kennzahlen in ein Kennzahlensystem. <br>In Zukunft soll das Kennzahlensystem helfen Probleme rechtzeitig zu erkennen. Die Ergebnisse aus<br>denn Kennzahlen sollen dann als Grundlage für strategische Entscheidungen<br>dienen. Dies könnte besonders wichtig werden für zukünftige Verhandlungen um<br>Ziele und Sollvorgaben. Aufgrund starker Konkurrenz werden in Zukunft neue<br>Vorgaben vom Management zur Reduzierung der Kosten und der Durchlaufzeit<br>entstehen. Somit wird durch das Kennzahlensystem eine Grundlage geschaffen<br>um in den Fertigungsschritten Chancen und Gefahren zu erkennen.<br>Ein weiteres Ziel der Einführung eines Kennzahlensystems soll die Standardisie-<br>rung von Kennzahlen sein. Die Vorgaben und Daten sollen klar vordefiniert sein.<br>Dadurch soll die Anzahl der Auswertungen und die Interpretationsmöglichkeiten<br>minimiert werden.
28.03.17;21.07.17;2017;extern;Bachelor;DE;Auswahl und Einführung eines externen Online-Portals für Veranstaltungsbuchungen mit Anbindung an SAP;Die vorliegende Bachelorarbeit behandelt die Auswahl und Einführung eines Portals für Veranstaltungsbuchungen für die Firma DATEV eG. Hierzu wird in dieser Arbeit zunächst ein allgemeines Verständnis für die sogenannte MICE-Branche und MICE-Portale geschaffen und anschließend anhand der Anforderungen der DATEV eG ein passender Anbieter für ein Online-Portal gesucht. Ein wichtiger Bestandteil der Analyse der angebotenen Portale war außerdem das Thema Datenschutz und wie die Anbieter den Datenschutz sicherstellen. Nach der Auswahl eines passenden Anbieters wurde das MICE-Portal an die SAP-Systeme der Firma DATEV angebunden und ein Genehmigungswork?ow implementiert. Ziel dabei war ein einheitlicher Bescha?ungsprozess von Veranstaltungen unter Einhaltung der Bescha?ungskompetenzen der Veranstaltungsplaner.
29.03.17;28.08.17;2017;intern;Bachelor;DE;Modulares Konzept und Umsetzung von Videoanleitungen für Inserenten der Hochschuljobbörse;Im Rahmen dieser Bachelorarbeit wird ein modulares Konzept für die Erstellung von Videotutorials erarbeitet. Diese werden für die Firmenkunden der Hochschul-Jobbörse erstellt. Weiterhin soll das Konzept in einem ersten Testlauf umgesetzt werden.<br><br>Zunächst werden die Problemstellung und Zielsetzung der Bachelorarbeit erörtert.<br><br>Danach werden die zugehörigen Anforderungen diskutiert. Hier werden die Grundbegriffe definiert und erläutert. Danach werden abschließend noch die funktionalen und qualitativen Anforderungen erarbeitet. <br><br>Die Analyse von verwandten Werken wird im Anschluss durchgeführt. Diese umfassen Videoformate von Konkurrenten und explizite Videotutorials.<br><br>Daraufhin befasst sich diese Bachelorarbeit mit den Bestandteilen des modularen Konzepts im Rahmen der Videotutorials. Hier werden die Elemente für die Audio- und Videomaterialien analysiert. Eine weitere Thematik ist die Präsentation der Information.<br><br>Danach wird die erste Umsetzung des modularen Konzeptes abgehandelt. Zunächst werden die Design Entwürfe erörtert und danach die einzelnen Schritte der Umsetzung diskutiert.<br><br>Abschließend wird ein Fazit gezogen. Dieses beinhaltet die Zielerreichung und Grenzen, sowie einen Ausblick.
30.03.17;30.08.17;2017;extern;Bachelor;DE;Prototypische Entwicklung eines analytischen Modells für die Klassifizierung und Vorhersage von Bestellabbrüchen;Nicht immer gelingt der Verkauf eines Produktes, weil der Kunde die Bestellung abbricht. Um dies zu verhindern, werden Präventivmaßnahmen eingesetzt. Zur Verbesserung der Planung dieser sollen analytische Modelle entwickelt werden, mit den es möglich ist Zeitpunkte für die Maßnahmen besser vorherzusagen und sie kundenindividueller zu gestalten.<br>Im Laufe der Bachelorarbeit wurden zwei Modelle entwickelt. Eines, das in der Lage ist die Anzahl der Bestellabbrüche über einen Zeitraum vorherzusagen, und eines, das Bestellabbrüche kundenindividuell klassifizieren kann.  Für die Modellierung wurden Daten aus verschiedenen Datenquellen zusammengeführt und transformiert und Methoden der Regressionsanalyse eingesetzt, die im Zuge der Bachelorarbeit erläutert werden.<br>
30.03.17;04.08.17;2017;extern;Bachelor;DE;Möglichkeiten einer automatisierten Provisionierung Virtueller Server im zLinux-Umfeld;Schwerpunkt dieser Arbeit ist die Evaluierung von Möglichkeiten der Automatisierung von Prozessen<br>Virtueller Server im Großrechnerbereich. Durch Automatisierung von Prozessen werden manuelle Eingriffe reduziert, menschliche Fehlhandlungen begrenzt und teilweise komplett vermieden. Darüber hinaus werden Prozesse effizienter gestaltet, indem automatisierte Abläufe keine Verzögerungen mit sich bringen, personelle Ressourcen eingespart werden und automatisierte Prozesse qualitätsgesichert werden können. Die Effektivität kann gesteigert werden, indem Prozesse klar definiert und entsprechend automatisiert werden um das gewünschte Ergebnis der Verarbeitung zu erreichen.<br>Bereiche, in denen bereits Automatisierung etabliert ist, sollen weiter in Betracht gezogen werden um<br>Optimierung vorzunehmen und Effektivität, Effizienz sowie Prozess-Sicherheit weiter zu steigern und<br>zu optimieren.<br>Diese Bachelorarbeit wird bei SDV-IT in Nürnberg durchgeführt. SDV-IT ist seit 1983 IT-Dienstleister<br>der Sparda-Banken sowie der Netbank. Grundlegende Technik für Transaktionen im Bankgeschäft bildet<br>die Großrechner Architektur von IBM. Zu Beginn 2017 wurden zwei neue Großrechner angeschafft,<br>genannt LinuxONE. Die Besonderheit dieser Maschinen liegt in der überwiegenden Nutzung des Linux<br>Betriebssystems. Die Anschaffung der Maschinen wird als Anlass genommen erneut über die Automatisierung von Prozessen für Virtuelle Server nachzudenken und bereits vorhandene Automatisierung zu optimieren.
30.03.17;30.08.17;2017;intern;Bachelor;DE;Automatische Konfiguration der Zugriffskontrolle zur Datenbank einer Webanwendung;Die Insecure Direct Object References (OWASP Top 10, A4) ist eine der häufigsten Sicherheitslücken in Webanwendung. Dabei manipuliert der Angreifer die Parameter im URL-String, um so einen Zugriff auf Objekte zu bekommen, für die er nicht autorisiert ist. Ein Schutz bietet die Security-Appliance mit feingranularen Zugriffskontrollen durch parametrisierte Views. Diese parametrisierten Views werden über Zugriffsregeln definiert, welche die angeforderten Datenmengen für jeden Benutzer individuell eingrenzen. Diese Bachelorarbeit beschäftigt sich mit der Fragestellung wie die Erzeugung der Zugriffsregeln teil- bzw. voll automatisiert werden kann. Mit der Hilfe von zwei Proxys werden User-IDs im HTTP-Request dem auslösenden SQL-Statement zugeordnet. Die Zugriffsregeln für die parametrisierten Views lassen sich aus diesen Zuordnungen generieren. Die Automatisierung bedient sich der Methode vom unterstützenden Lernen durch Beobachten (statisches Lernen). Dabei protokolliert die Security-Appliance sowohl den HTTP-Verkehr, als auch den SQL-Verkehr, um daraus eine lückenlose Sammlung von Zugriffsregeln generieren zu können. Diese Sammlung dient als Konfiguration der Security-Appliance.
01.04.17;29.11.17;2017;extern;Master;DE;Prototype Implementation and Evaluation of Scenarios for an Adaptive Automotive Personal Assistant;Da immer mehr Sprachassistenten Einzug in den Automotive-Bereich halten, entwickelt die Firma Elektrobit Automotive GmbH einen eigenen Ansatz um einen intelligenten persönlichen Assistenten (IPA) im HMI-Umfeld produktreif zu etablieren. Innerhalb dieses Projekts sollen drei prototypische Szenarien implementiert und ausgewertet werden, um deren Praxistauglichkeit zu erforschen. Zu diesem Zweck wurden ein Learning Classifier System (LCS) und ein Clustering Algorithmus eingesetzt und dementsprechend angepasst. Die umgesetzten Szenarien werden anhand einer Umfrage evaluiert. Abschließend werden die Ergebnisse ausgewertet und aufgrund dessen eine Empfehlung für das weitere Vorgehen ausgesprochen.
01.04.17;21.08.17;2017;intern;Bachelor;DE;Rekonstruktion von relativen Kameraparametern aus Bildsequenzen und deren Verwendung zur Berechnung einer dreidimensionalen Punktwolke;Im Rahmen der vorliegenden Bachelorarbeit wird eine Verarbeitungskette zur Rekonstruktion dreidimensionaler Punktwolken aus einer Reihe von Bildern implementiert. Mittels Matching von SIFT-Merkmalen werden die Relationen der einzelnen Aufnahmen untereinander ermittelt und anschließend im Rahmen eines inkrementellen SfM-Verfahrens zur Berechnung der (relativen) Kamerapositionen und Orientierungen herangezogen. Die gewonnenen extrinsischen und intrinsischen Parameter werden anschließend zur Durchführung des PMVS-Verfahrens zur Gewinnung einer dichten Punktwolke verwendet. Abschließend wird die gewonnene Oberflächenrekonstruktion durch die Anwendung von Filteroperationen und dem Schließen von Löchern optimiert.
01.04.17;01.09.17;2017;intern;Bachelor;DE;Entwicklung eines interaktiven Spiels mit einem humanoiden Roboter als Spielpartner;"Diese Arbeit stellt einen neuen Ansatz zur Umsetzung des Spiels ""Tic- Tac- Toe"" zwischen einem Menschen und einem humanoiden Roboter vor. Durch wissenschaftliches Vergleichen diverser Bildverarbeitungsverfahren und dem Einsatz der so bestimmten effizientesten Verfahren wird eine stabile Spielumgebungserkennung durch den Roboter garantiert.<br>Die praktische Umsetzung des Spiels nutzt mit Außnahme des Roboters gebräuchliche, kostengünstige Mittel zur Realisierung. Entstehende Hindernisse werden hierbei weitgehend durch optionale Lösungswege umgangen. Bei unumgehbaren Behinderungen der Umsetzung wird eine hypothetische Lösung vorgestellt. <br>Durch eine Nutzerstudie mit freiwilligen Probanden wird das umgesetzte Spiel auf Benutzerfreundlichkeit und Qualität im Allgemeinen geprüft. Eine Auswertung der dadurch ehobenen Daten gibt sowohl Auskunft über die Repräsentation der Probandengruppe als auch über diverse Qualitätsaspekte des getesteten Spiels."
01.04.17;01.09.17;2017;extern;Bachelor;DE;Optimierung der Datenvisualisierung in der mediendesign AG mit Hilfe<br>der Software Tableau;In der mediendesign werden Daten zu Projekten und Mitarbeitern mit der Software Projektor erfasst. Zur Analyse der Daten, stehen derzeit der Projektor, und mit Eclipse BIRT erstellte Reports, zur Verfügung. Beide Varianten werden in Form einer statischen Tabelle ausgegeben und können schnell unübersichtlich werden. Deshalb wurde in einer vorherigen Bachelorarbeit nach alternativen Business Intelligence<br>Produkten eruiert. Tableau stellte sich dabei als passende Software für ein mittelständisches Unternehmen heraus.<br><br>Projekt- und Teamleiter sollen eine bessere Übersicht über Projekte und Mitarbeiter erhalten und auch die Detailanalyse soll erleichtert werden. Ziel der Bachelorarbeit ist es die Daten zu zentralisieren und die<br>Visualisierung so zu optimieren, dass neue Erkenntnisse zum Vorschein kommen oder bereits bekannte Informationen schneller erfasst werden können. Diese Informationen können somit als Grundlage für weitere Entscheidungen genutzt werden. Es kann beispielsweise entschieden werden, ob ein Projekt weiterhin rentabel oder ein Mitarbeiter angemessen ausgelastet ist oder ob ein Projekt- oder Teamleiter eingreifen muss.
01.04.17;30.08.17;2017;extern;Bachelor;DE;Evaluation des Einsatzes von Systemen zur Datenanalyse im Fertigungsprozess anhand von Bosch PPM;Das Sammeln und Auswerten großer Datenmengen nimmt vor allem im<br>industriellen Umfeld eine wachsende Rolle ein. Im Zuge des Konzeptes<br>Industrie 4.0 werden Unternehmen ermutigt, Prozess- und Produktdaten<br>in der Fertigung zu sammeln. Mit dem Production Performance Manager<br>(PPM) und dem Production Performance Management Protocol (PPMP)<br>will Bosch seinen Kunden eine Plattform und ein Übertragungsprotokoll<br>bieten, welche dies erleichtern sollen. In dieser Bachelorarbeit wird eine<br>Simulation für Fertigungsprozesse entwickelt, die Daten produziert und<br>sie mit Hilfe des PPMP in eine Installation des PPM übermittelt. Anschlie-<br>ßend werden mit den Werkzeugen des PPM Auswertungen und Berichte<br>über diese Daten generiert. Anhand dessen wird die Eignung der Platt-<br>form für das Sammeln von Daten und das Erzeugen von Berichten für<br>produzierende Unternehmen evaluiert.
01.04.17;29.08.17;2017;intern;Bachelor;DE;Einsatzmöglichkeiten von agilen Praktiken im Prozessmanagement;Diese Arbeit beschäftigt sich in erster Linie mit klassischen und agilen Vorgehensmodellen zur Entwicklung von Software. Hierbei stehen agile Geschäftsprozesse im Vordergrund. Dabei wird deutlich, dass die Einführung von agilen Geschäftsprozessen durch die Unternehmensstrategie gesteuert werden sollte. Eine Einführung von agilenGeschäftsprozessen bringt den großen Vorteil mit sich, dass schnell und flexibel auf neue Kundenwünsche bzw. auf den Markt reagiert werden kann. Mit der Microservice-Architektur soll eine Möglichkeit dargestellt werden, die die Einführung von agilen Geschäftsprozessen IT-technisch unterstützen kann. Die Vorteile die agile Geschäftsprozesse und Microservices mit sich bringen, können hierbei nur bewältigt werden, wenn ein agiles Mindset im Unternehmen vorhanden ist. Historisch gewachsene Organisationsstrukturen haben hierbei häufig Hierarchie-Strukturen, die mit der agilen <br>Softwareentwicklung und agilen Geschäftsprozessen nicht im Einklang stehen. Auch das Konzept der Microservices ist bei historisch gewachsenen IT-Landschaften häufig schwierig einzuführen. Zusammenfassend lässt sich daher sagen, dass die agilen Geschäftsprozesse im Zeitalter der Digitalisierung Marktvorteile mit sich bringen können, der Weg dorthin ist jedoch schwierig, da historisch gewachsene Strukturen aufgebrochen werden müssen.
01.04.17;01.09.17;2017;extern;Bachelor;DE;Evaluation möglicher Technologien eines Indoor Positioning Systems mit anschließender prototypischen Implementierung auf einem Smartphone.;IPS steht für Indoor Positioning Systems und wird dazu verwendet um den Standort<br>von Gegenstände und Personen in einem Gebäude zu identifizieren. Da die alleinige<br>Verwendung von GPS-Signalen in Gebäuden einen unzureichend genauen Stand<br>ort liefern, werden bei IPS verschiedene Technologien kombiniert, um ein möglichst<br>genaues Ergebnis zu erzielen, beispielsweise WLan, Bluethooth und GPS. Indoor<br>Positioning Systems haben ein weiträumiges Einsatzgebiet von Orientierungshilfen<br>in einem Krankenhaus  über die Lokalisierung von Wissensträgern in einem Unter<br>nehmen bis hin zum privaten Gebrauch.<br>Auf dem Markt gibt es bereits Unternehmen die mit proprietärer Software im Bereich<br>IPS vertreten sind. Allerdings gibt es für die Entwicklung von IPS bislang noch kein<br>standardisiertes Vorgehen.<br>Ziel dieser Bachelorarbeit ist es eine Übersicht über mögliche Technologien im Bereich IPS zu geben und diese zu evaluieren. Der Fokus hierbei soll auf Techniken<br>gelegt werden, welche von einem handelsüblichen Smartphone verwendet werden<br>können. Anschließend soll unter Verwendung der vorhergehenden Erkenntnisse eine<br>prototypische Implementierung für ein Smartphone mit dem Betriebssystem Android durchgeführt werden.
03.04.17;10.11.17;2017;extern;Master;DE;Befähigung einer Bank zur Bereitstellung einer Public API für PSD2;Banken sind europaweit davon betroffen, ihre Finanzdienstleistungen zu digitalisieren und im Internet zu veröffentlichen. Dies ist in den Zahlungsdienstrichtlinien PSD2 festgeschrieben, die den digitalen Zahlungsverkehr in Europa vereinheitlichen, erweitern und sicherer gestalten sollen. <br>Die Bereitstellung von Dienstleistungen erfolgt über festgelegte Schnittstellen (sog. Public API). Um den Zugriff darauf zu authentifizieren, autorisieren, analysieren und aktiv steuern zu können, werden Softwarekomponenten benötigt, welche auf die Erfüllung dieser Aufgaben spezialisiert sind. Übergreifend werden die Aufgaben und Herausforderungen in diesem Zusammenhang als API-Management bezeichnet. <br>Aufgrund der Nachfrage nach fertigen Softwarelösungen für erfolgreiches API-Management gibt es derzeit viele Anbieter, die sich dieser Thematik angenommen haben. Diese bieten dabei die notwendigen Softwarekomponenten und deren Vorkonfiguration als sogenannte API-Management-Lösung an.<br><br>Diese Arbeit verfolgt grundlegend drei Ziele. Zum einen werden neben den notwendigen Hintergründen, Herausforderungen und Chancen für Banken aufgezeigt, die durch eine öffentliche Bereitstellung ihrer Dienstleistungen entstehen. Zum anderen werden branchenunabhängige Aufgaben in Bezug auf ein erfolgreiches API-Management evaluiert. Das dritte Ziel sieht eine prototypische Umsetzung vor, die auf Basis einer eigenen API eine passende API-Management-Lösung aufgesetzt und die Dienstleistungen geregelt bereitstellt.
05.04.17;21.08.17;2017;intern;Bachelor;DE;Vergleich der Entwicklungsplattformen von Chatbot Systemen mit Bezug auf die Einkaufs- und Beschaffungsprozesse in Unternehmen;In dieser Arbeit geht es primär um die sich rasch verbreitenden Chatbot-Computersysteme. <br>Während im privaten Gebrauch ein deutliches Wachstum der Nutzerbasis nachweisbar ist, sieht es auf unternehmerischer Ebene anders aus. Trotz der vielen Anwendungsszenarien, in denen Chatbots großes Potenzial aufweisen, werden sie in der Praxis nicht oft angewandt.<br>Diese Abschlussarbeit legt den Fokus auf die Bereiche Einkauf und Beschaffung von Unternehmen. Anhand der Konstruktion und Beschreibung von Anwendungsfällen sowie des Vergleichs einiger Entwicklungsplattformen für Chatbots soll ein Fazit zur aktuellen Situation gezogen, und ein Ausblick auf die Zukunft geworfen werden.<br>Es wird festgestellt, dass die Entwicklungsplattformen viele Ähnlichkeiten aufweisen. Von daher muss je nach Anwendungsszenario eine individuelle Entscheidung getroffen werden, und es können keine universellen Empfehlungen diesbezüglich gegeben werden. Die Entwicklungsumgebungen werden laufend weiterentwickelt und diese Arbeit stellt lediglich eine Momentaufnahme dar.
05.04.17;04.12.17;2017;intern;Master;DE;Entwicklung eines Prototyps zur SolR-basierten Indizierung von mittels RDF repräsentierten relationalen Datenbanken;Das Semantic Web ist eine Vision, ähnlich dem World Wide Web und hat das Ziel <br>nicht nur den Austausch und die Vernetzung von Daten zu ermöglichen, sondern <br>auch ihre Struktur zu vereinheitlichen. Vorzugsweise sollen Daten im RDF-Format <br>gespeichert und durch einen SPARQL-Endpoint auf diese zugegriffen werden.<br>RDF (Resource Description Framework) und <br>SPARQL (SPARQL Protocol and RDF Query Language) <br>gehören zu den semantischen Technologien und wurden vom W3C <br>(World Wide Web Consortium) standardisiert.  <br>Die Menge der veröffentlichten RDF-Daten hat in der Vergangenheit stetig zugenommen. <br>Dies könnte dazu führen, dass immer mehr Institutionen die semantischen Technologien <br>nutzen. Falls RDF immer häufiger zum Speichern von Informationen genutzt wird, stellt <br>sich die Frage wie eine solche Informationssammlung mit einer Volltextsuche <br>durchsucht werden kann.<br><br>Die vorliegende Masterarbeit soll diese Fragestellung im Kontext der <br>Fakultätswebseite erörtern. <br>Daher soll ein Teilbereich der vorhandenen relationalen Datenbanken <br>beispielhaft mittels eines vorhandenen Mapping-Standards des W3C in eine <br>RDF-Datenbank überführt werden. Der hierbei als RDF-Graph entstehende <br>Ausschnitt der relationalen Datenbank bildet die Grundlage für die nachfolgende <br>prototypische Lösung einer Solr-basierten Indizierung für RDF-Graphen.
05.04.17;29.11.17;2017;intern;Master;DE;Entwicklung und Evaluierung von Geschäftsmodellen für einen Online-Marktplatz zum Verkauf von hausgemachten gastronomischen Angeboten;Trotz seiner Wichtigkeit für eine gesunde Ernährung investieren die Leute heutzutage für das Kochen wenig Zeit, obwohl sie die Fähigkeit dafür haben. Demgegenüber gibt es noch Leute, die sich der Essenszubereitung leidenschaftlich widmen. Daher wird ein Geschäftmodell für einen Online-Marktplatz, auf dem diese Personengruppen zusammengebracht werden, entwickelt. Mit Rücksicht auf die bestehenden Marktteilnehmer und die geltenden Rechtsvorschriften werden fünf unterschiedliche Geschäftsmodelle dafür entwickelt. Durch eine Reihe von Validierungen lässt sich erkennen, dass die potentiellen Kunden an dem Verkauf ihres selbstgemachten Essens ein geringes Interesse haben. Dies berücksichtigend wurde schließlich ein erfolgversprechendes Modell  ausgewählt und verbessert, welches die Kundenbedürfnisse erfüllen kann.
06.04.17;05.09.17;2017;extern;Bachelor;DE;"""Konzeption einer Testmethodik für den ""Feature Driven Development"" - Prozess am Beispiel einer Webentwicklung""";"Bekannte Techniken wie Continuous Delivery und Continuous Integration sorgen dafür, die Softwareentwicklung flexibel und schnell zu gestalten und somit den Auslieferungsprozess zu verbessern. Da aber sich die Qualität über die dadurch erreichbare hohe Liefergeschwindigkeit nicht verschlechtern darf, ist eine Testmethodik, welche sich nahtlos in die für kontinuierliche Integration und Lieferung notwendigen Verfahren einfügt, als ein wichtiger Schritt erforderlich. In dieser Abschlussarbeit wird nach Untersuchung und Analyse des ""Feature Driven Development"" ? Prozesses ein Konzept erstellt, welches sich damit befasst, inwieweit in den einzelnen Prozessschritten die Testaufgabe einfließen muss. Darüber hinaus soll eine Vorgehensweise vorgestellt werden, wie die Features und das Gesamtprodukt kontinuierlich getestet werden können, um die Qualität zu gewährleisten. Dabei soll mit Unterstützung von diversen Techniken durch die Optimierung des Softwareentwicklungsprozesses und die Sicherstellung der Softwarequalität eine qualitativ hochwertige Software erreicht werden. "
12.04.17;12.09.17;2017;extern;Bachelor;EN;EVS Channel-Aware Mode Performance Analysis and Optimization;"The 3GPP codec Enhanced Voice Services (EVS) is the speech codec for the next generation of mobile telephony, and, aside from a generally higher speech quality, provides improved behavior for transmission over disturbed IP networks. Therefore, the so-called ""Channel-Aware"" mode has been defined as part of the EVS codec. By adding compressed redundant information and also with the help of an adaptive jitter-buffer management, EVS is able to compensate packet loss better than a codec with only ordinary packet loss concealment.<br><br>The present work investigates the Channel-Aware mode on an algorithmic level and further examines the speech quality improvements. Furthermore, it tries to find potential for optimizations of the standardized methods. For this reason, measurements with POLQA and the Fraunhofer IIS Audio Communication Engine (ACE) were being performed to determine the Quality of Service parameter Mean Opinion Score (MOS) for a multitude of potential scenarios.<br><br>The Channel-Aware mode can be used with fixed parameters, but there is also an adaptive mode which continuously adjusts the parameters to the transmission conditions in a duplex communication session. It is based on a feedback loop which transmits the parameters to the sender through codec mode requests (CMRs). This functionality was implemented in the ACE within the scope of this thesis, and was subject to research, too. For these analyses, the reference delay/error profiles published by the 3GPP have been used."
15.04.17;15.09.17;2017;intern;Bachelor;EN;Evolution and Perspectives of the Middleware Concept;Middleware is a software layer on top of the operating system, but below the application layer. It links applications together, enhancing communication, management of data, and achieving location transparency, particularly in distributed systems. This thesis reviews the concept of middleware, evaluating its evolution from its foundations, up to today's cloud computing paradigms.<br>It addresses the significance of middleware research and development as it changed over the last decades outlining its characteristics. Typical platforms are presented in detail, together with specific use cases, particularly in view of the successes of service-oriented architectures and web-based services. The thesis sheds a light on related techniques, analyses the future potential and viability middleware concept.<br><br><br>Keywords: middleware, service-oriented architecture, web-based services,<br>
19.04.17;14.12.17;2017;extern;Master;DE;Konzeption und Entwicklung eines integrierten Qualitätsmanagements für eine Geschäftsdomäne in der DATEV eG;Diese Arbeit ist in drei Hauptteile untergliedert: Analyse, Konzeption und Implementierung.<br>In dem ersten Abschnitt der Arbeit wird zu Beginn der wissenschaftliche als auch der Stand der DATEV eG zu den Themen der QS und QM gesammelt. Darauf folgend wird eine Auswahl an QS-Software anhand definierter Parameter mit einer Nutzwertanalyse untersucht und abschließend eine Empfehlung ausgesprochen.<br>Der zweite Teil der Arbeit befasst sich mit der Konzeption eines QS-Ablaufplans. Ziel dieses ist es einen planbaren QS-Ablauf für Zeit und Kosten der Abteilung KUV zu ermöglichen. Im Anschluss wird die Quantität der Testfälle für die jeweiligen Teststufen untersucht, die Vor- und Nachteile der Gewichtung wird infolgedessen herausgestellt.<br>In dem letzten Teil der MA findet die Implementierung statt. Hierbei liegt der Fokus insbesondere auf den zwei Grundsätzen der EN DIN ISO 9001, dass alle beteiligten Personen einbezogen werden und einer faktengestützten Entscheidungsfindung. Demzufolge beschäftigt sich die Implementierung größtenteils mit der Kommunikation der Testfälle und deren Status.<br>Zum Abschluss der Arbeit wird zurückblickend eine Reflexion durchgeführt, sowie ein Ausblick für die möglichen Anwendungen gestellt.
19.04.17;19.09.17;2017;intern;Bachelor;DE;Vertrauen und Betrug im E-Commerce und E-Payment, Analyse des Nutzerverhaltens;In dieser Arbeit wurde untersucht, wie sich Vertrauen im E-Commerce und E-Payment bildet. Ebenfalls wurden Risiken, wie auch aktuelle Betrugsfälle in Betracht gezogen. Des Weiteren wurde ein Experiment, mit Hilfe von Eyetracking-Technologie und zehn Testpersonen durchgeführt. Hierzu wurden die Ergebnisse dokumentiert und die erfassten Fragebögen ausgewertet.
20.04.17;20.09.17;2017;extern;Bachelor;DE;Auswahl einer Software zur Kalkulation und Preisfindung von IT-Leistungen bei der N-ERGIE Aktiengesellschaft;In der vorliegenden Bachelorarbeit wurde der aktuelle theoretische Stand zum Thema der  Softwareauswahl in Unternehmen erarbeitet und mit den gewonnenen Erkenntnissen ein praktischer Auswahlprozess bei der N-ERGIE Aktiengesellschaft durchgeführt. Ziel war es, eine aktuell bereits existierende Lösung zur Kalkulation von IT-Leistungen, basierend auf Excel, abzulösen. <br>Für diesen Fall wurde der Softwareauswahlprozess von der Ist-Analyse bis zur Bewertung der Ausschreibungsrückläufer begleitet und entsprechend benötigte Dokumente wie eine Marktübersicht und ein Anforderungskatalog erstellt. Die Arbeit zieht Schlussfolgerungen zur Anwendbarkeit der allgemeinen Methodik und enthält unternehmensspezifische Handlungsempfehlungen zur Softwareauswahl.<br>Im Voraus werden die Grundlagen der innerbetrieblichen Leistungsverrechnung geklärt und ein mögliches IT-Servicemodell präsentiert, bevor der typische Softwareauswalprozess anhand ausgewerteter und aktueller Literatur beschrieben wird.<br>Diese Arbeit richtet sich in erster Linie an Interessenten und Unternehmen, welche die innerbetriebliche Leistungsverrechnung einführen bzw. verbessern wollen und vor der Problematik der Softwareauswahl stehen. 
20.04.17;29.09.17;2017;extern;Master;DE;Ergänzung des SAP Anfrageprozesses mit vordefinierten Warengruppentemplates;Thema dieser Masterthesis an der Technischen Hochschule Nürnberg Georg Simon Ohm ist die Ergänzung des Anfrageprozesses mit vordefinierten Warengruppentemplates. Die Arbeit entstand im Rahmen der Erlangung des akademischen Grades Master of Science in der Wirtschaftsinformatik.<br>Der Vergleich von Angeboten gestaltet sich durch deren vielfach unterschiedliche Struktur sehr langwierig und ineffizient. Der zugrundeliegende Anfrageprozess ist intransparent und durch häufige Absprünge nicht in seiner Gesamtheit erfasst. Das Ziel dieser Arbeit ist das Herausarbeiten einer Vorgehensweise, wie die Implementierung von Warengruppentemplates in den bestehenden Anfrageprozess ausgestaltet werden kann. Hierfür wurde dieser im Rahmen einer Geschäftsprozessanalyse untersucht und für die Implementierung drei Umsetzungskonzepte erstellt. Diese wurden mittels einer Nutzwertanalyse bewertet und das Ergebnis in Form einer Handlungsempfehlung konkretisiert. Die vordefinierten Templates sollten auf einem Server bereitgestellt werden und im Zuge der Anfrageerstellung im SAP-System automatisch mitversendet werden.
24.04.17;24.09.17;2017;extern;Bachelor;DE;Entwurf eines Portals zur Erfassung und Verdichtung qualitätskostenbezogener Daten<br>der Konzerndivision e-mobility bei der ZF Friedrichshafen AG<br>;Die ZF Friedrichshafen AG ist mit 29,2 Mrd. Euro Umsatz (Stand 2015) einer der größten Automobilzulieferer weltweit. Für das Konzernressort Qualität der Division e-mobility soll ein nachhaltiger, managementorientierter Ansatz zur Erfassung, Strukturierung und Kategorisierung qualitätsbezogener, fehlerkostenrelevanter Daten und deren Verdichtung in berichtbare Kennzahlen etabliert werden. Dazu sollen Daten aus den Bereichen Umsatz, Kunde, Produktion und Lieferant von Standorten weltweit gesammelt, zentral gespeichert und auswertbar gemacht werden. Es gilt die Anforderungen an das eingesetzte System formal zu spezifizieren, ein schlüssiges Datenmodell zu entwickeln, die Aussagekraft bereits definierter Kennzahlen zu prüfen und Auswertungsmöglichkeiten bereitzustellen.
27.04.17;27.09.17;2017;extern;Bachelor;DE;Konzeption eines Identity Access Management zur Automatisierung der Berechtigungsvergabe;Das Ziel der Bachelor Thesis war es, einen praktischen Leitfaden für die Implementierung eines Identity Access Management (IAM) zu entwickeln. Hierbei handelt es sich um die Verwaltung von Identitäten und deren Zugri?e in der gesamten IT Infrastruktur.<br><br>Dazu wird im ersten Schritt die aktuelle Situation hinsichtlich der Berechtigungsvergabe und der Systemlandschaft analysiert. Anhand der gewonnenen Ergebnissen aus der Schwachstellenanlyse wird ein geeignetes Berechtigungskonzept entworfen, welches sich durch Workflows automatisieren lässt. Außerdem wird für die technische Umsetzung eine Roadmap aufgestellt, welche alle wichtigen Punkte für die Einführung einer Benutzer- und Berechtigungsverwaltung behandelt. Diese enthält unter anderem neu definierte Prozesse und Richtlinien, sowie eine Betrachtung der Schnittstellen zu den Einzelsystemen, die angebunden werden sollen. Im Zuge der Roadmap für die Umsetzung des IAM wurde ein Stufenplan für die Realisierung ausgearbeitet.
27.04.17;20.12.17;2017;intern;Master;DE;Deep Learning als Ansatz für Empfehlungssysteme;"Empfehlungssysteme nehmen sowohl in der Forschung als auch in der Industrie eine kontinuierlich an Relevanz gewinnende Rolle ein. Mit Deep Learning rückte in den letzten Jahren ein Lernverfahren ins Rampenlicht der Forschung, welches aufgrund seiner bemerkenswerten Erfolge in den Bereichen der Computer Vision und Spracherkennung verstärkte Anwendung in weiteren Themenfeldern findet. Die vorliegende Arbeit beschäftigt sich zu diesem Zweck mit der Analyse und Anwendung von Deep Learning in einem Recommender-Kontext. Nach einem Überblick über grundlegende Konzepte und Verfahren innerhalb von Empfehlungssystemen wird eine Themeneinführung zu Deep Learning erörtert. Diese inkludiert sowohl eine fundierte Funktionsanalyse von neuronalen Netzstrukturen als auch eine Darlegung darauf aufbauender Deep-Learning-Architekturen. Eine anschließende Literaturrecherche bringt hervor, in welcher Form Deep Learning bereits in Empfehlungssystemen zur Anwendung kommt. In einer abschließenden Simulationsstudie wird unter Verwendung eines TensorFlow Frameworks die Anwendung eines eigenen Deep-Learning-Modells präsentiert. Hierzu erfolgt neben der Ergebnisinterpretation eine Ergebnisgegenüberstellung zu ""State-of-the-Art""-CF-Recommender-Algorithmen. Basierend auf den gewonnenen Erkenntnissen der Simulationsstudie werden im Ausblick mögliche Erweiterungen thematisiert.<br><br>"
28.04.17;28.09.17;2017;extern;Bachelor;DE;Evaluation unterschiedlicher Methoden zur intelligenten Verknüpfung heterogener Datenbanken zur Optimierung von Geschäftsprozessen in einem Fertigungsumfeld;Die Zusammenführung von Daten aus verschiedenen Quellen ist bereits seit den achtziger Jahren Gegenstand der Forschung und es wurden bereits mehrere Vorgehensweisen zur Überwindung von Heterogenität entwickelt.<br>Im Rahmen der vorliegenden Bachelorarbeit werden verschiedene Möglichkeiten für eine Datenverknüpfung vorgestellt und evaluiert.<br>Ziel dieser Arbeit ist es einen Ansatz für die Verknüpfung von Daten eines Fertigungsunternehmens zu erstellen und diesen auch praktisch zu erproben.<br>Zu diesem Zweck wird anhand des gewählten Ansatzes ein Prototyp erstellt.<br>Der Prototyp soll als Grundlage für spätere Implementierungen dienen und eine einfache Möglichkeit zur Datenverknüpfung bieten.
28.04.17;28.09.17;2017;intern;Bachelor;DE;Entwicklung eines Systems zur Erkennung eines Streckenverlaufs mit Hilfe einer 2D-Kamera;In Arbeit wird ein System entwickelt zur Erkennung eines Streckenverlaufs mit Hilfe einer 2D Kamera. Als Strecke kommt die Strecke des NXP Cups zum Einsatz und das System soll es ermöglichen Modellautos autonom durch diese Strecke zu navigieren. Hierfür wurde eine Erkennung für die zwei wichtigsten Streckenabschnitte, Gerade und Kurve, implementiert. Die Erkennung erfolgt durch eine Berechnung des Streckenwinkels und kann somit voraussagen wie der zukünftige Streckenverlauf aussieht. Dieser Winkel wird über eine USB Kommunikation nach außen kommuniziert. 
01.05.17;21.08.17;2017;intern;Bachelor;DE;"Interaktive und dynamische Visualisierung von Antwortdaten aus Online-Self-Assesments der TH-Nürnberg mit Hilfe der ""Data-Driven Documents"" JavaScript Bibliothek";Das Ziel der vorliegenden Bachelorarbeit besteht darin, eine interaktive Anwendung zu implementieren, die eine Visualisierung der Antwortdaten aus den Online-Self-Assessments (OSAs) der TH Nürnberg ermöglicht. Diese Daten sollen in grafischer Form aufbereitet und dargestellt werden. Durch die Bedienung dieses Tools  lassen sich Zusammenhänge zwischen verschiedenen Testkriterien und Ergebnissen erkennen und wertvolle Informationen über die einzelnen Tests und die Testteilnehmer sammeln können.<br><br>Das Ergebnis der Arbeit ist ein vollfunktionstüchtiges Auswertungstool, welches sich intuitiv bedienen lässt und die gewünschten Abhängigkeiten und Zusammenhänge offenlegen kann. Die Bachelorarbeit umfasst die Konzeption und Implementierung der Anwendung, beschreibt die notwendigen theoretischen Grundlagen und zeigt am Beispiel zweier Anwendungsfälle die Funktionsweise und die Vorteile dieser Art der Visualisierung. <br>
01.05.17;01.10.17;2017;intern;Bachelor;DE;Rasterbasierte SLAM-Verfahren für Laser-Entfernungssensoren;Forschungsgegenstand dieser Bachelorarbeit ist die Recherche rasterbasierter SLAM-Verfahren im Vergleich zur vektorbasierten Methodik. Im diesem Rahmen wird der rasterbasierte Hector SLAM als Untersuchungsobjekt verwendet. Dieser wurde in der Umgebung des an der Technischen Hochschule Nürnberg entwickelten Carbots implementiert. Dabei handelt es sich um einen Roboter der auf der Grundlage des vektorbasierten ICP SLAMs arbeitet. Um die Güte dieser beiden SLAM-Alternativen zu vergleichen, wurden virtuelle Test-Fahrten durch verschiedene Simulationsumgebungen durchgeführt. Zur Auswertung der Testreihe wurden sowohl die resultierenden Karten, als auch die hierbei erfassten Zeiten herangezogen. Bei der Auswertung der Daten erwies sich Hector SLAM als effektivere Lösung. Dies gründet einerseits in den realitätsnahen Kartierungen, andererseits in der schnelleren Durchführung des SLAMs. Daraus wird geschlossen, dass Hector SLAM sowohl effektiver ist, als auch weniger Rechenleistung erfordert. Die hierbei gewonnenen Erkenntnisse lassen sich jedoch nicht auf alle SLAM-Verfahren übertragen. Diese müssen vor dem Hintergrund der bestehenden Umstände analysiert werden. Zusammenfassend wird festgehalten, dass diese Arbeit einen tiefergehenden Einblick in SLAM-Systeme bietet. Sie ist für Leser von Interesse, die sich für rasterbasierte SLAM-Verfahren interessieren. Zudem für die Studenten und Professoren der Fakultät Informatik der Technischen Hochschule, die sich mit dem Carbot befassen.
01.05.17;02.10.17;2017;intern;Bachelor;DE;Zeichenbasierte Generierung von Texten mithilfe von Recurrent Neural Networks (RNN).;Die vorliegende Bachelorarbeit befasst sich mit dem Thema der zeichenbasierten Generierung von Texten mithilfe von Rekurrenten Neuronalen Netzwerken, kurz RNN. Sie gibt einen Überblick über die Funktionsweise von Künstlichen Neuronalen Netzen und untersucht den aktuellen Stand der Technik auf diesem Gebiet. Zudem werden die gewählten Methoden und die daraus gewonnenen Ergebnisse miteinander verglichen.<br>Mithilfe eines Open Source Codes von Andrej Karpathy, der ein Neuronales Netz auf Buchstabenebene trainiert und anschließend Text generiert, wurden Experimente mit verschiedenen Inputdaten durchgeführt.<br>Ziel dieser Arbeit ist, Text so zu generieren, dass er der Form des Inputs in größtmöglicher Weiße ähnelt, wobei der Semantik keine hohe Priorität beigemessen wird. Der Code wurde auf vier unterschiedliche Inputdaten angewandt, wobei verschiedene RNN Architekturen trainiert wurden.<br>Die Ergebnisse zeigen, dass die Generierung eines Textes nicht nur möglich ist, sondern sogar bemerkenswert gut funktioniert. Die gewonnenen Resultate ähneln den Vorgaben in Inhalt, Struktur und Form erheblich. Die Erstellung von Fließtext im Vergleich zu einem Code ist weitaus komplizierter, dies beruht auf der markanteren Form die Code mit sich bringt. Aufgrund der unterschiedlichen Codevarianten, die Herr Karpathy veröffentlichte, wurden unterschiedliche Betriebssysteme (Windows und Ubuntu) zur Generierung der Ergebnisse verwendet.
01.05.17;22.12.17;2017;extern;Master;DE;Evaluation verschiedener Softwarelösungen zur Analyse der syngo.via Installed-Base;Das Ziel der vorliegenden Arbeit war es, eine zukunftsfähige Softwarelösung zur Ana-lyse der syngo.via Installed-Base zu erarbeiten. Dazu wurden die wichtigsten Anforde-rungen spezifiziert und die Daten, die von einer solchen Softwarelösung ausgewertet werden sollen, im Detail analysiert. Auf dieser Basis wurden zunächst die zwei bereits existierenden Lösungen zur Analyse der syngo.via Installed-Base evaluiert. Diese zwei Softwarelösungen basieren beide auf einer klassischen Data-Warehouse-Architektur. <br>Im Anschluss wurde der Einsatz eines Big-Data-Systems zur Analyse der syngo.via In-stalled-Base untersucht. Dazu wurde ein auf Big-Data-Technologien basierender Proto-typ zur Analyse der syngo.via Installed-Base konzipiert und entwickelt. Um die richti-gen Entscheidungen bei der Technologie-Auswahl zu treffen, wurden auf Basis von den zuvor definierten Anforderungen die verschiedenen in Frage kommenden Big-Data-Technologien evaluiert und miteinander verglichen. Das Ziel dabei war, die Tauglichkeit eines Big-Data-Systems zur Analyse der syngo.via Installed-Base nachzuweisen und gleichzeitigt zu veranschaulichen, wie so ein System bestmöglich umzusetzen ist. Der so entstandene Prototyp zeigt auf, wie eine zukunftsfähige Softwarelösung zur Analyse der syngo.via Installed-Base umgesetzt werden kann und auf welche Punkte bei der Umsetzung geachtet werden muss.<br>
01.05.17;29.09.17;2017;extern;Bachelor;DE;Entwicklung eines Methodenbaukastens zum aktiven Einbezug von Mitarbeitern in der Gestaltung der agilen Transition innerhalb des Geschaftsfelds Personalwirtschaft der DATEV eG;"Die angestrebte Bachelorarbeit bewegt sich im Rahmen der agilen Transition innerhalb des Geschäftsfelds Personalwirtschaft der DATEV eG. Der Fokus der Arbeit liegt dabei auf den Einbezug der rund 308 Mitarbeiter in die Gestaltung des agilen Wandels und auf den definierten kulturellen Werten.<br>Das Ziel ist es, durch die aktive Begleitung der agilen Transition, Handlungsfelder (z.B. ""Selbstorganisation und Eigenverantwortung"") aufzudecken und diese zu definieren. Auf Basis der unterschiedlichen Handlungsfelder soll ein Methodenbaukasten entwickelt werden, der geeignete Methoden pro Handlungsfeld für den aktiven Einbezug von Mitarbeitern bereitstellt. Die ausgewählten Methoden sollen helfen alle Mitarbeiter in die agile Transition miteinzubinden sowie helfen die gewünschten Werte zu verinnerlichen und zu leben. Die Mitarbeiter sollen dadurch erfolgreich an das agile Vorgehen herangeführt und Unsicherheiten bei ihnen beseitigt werden.<br>Der erarbeitete Methodenbaukasten soll einen Überblick über mögliche Handlungsfelder in einer agilen Transition liefern und durch die entwickelten Methoden einen Orientierungsrahmen für Teams, Abteilungen und Unternehmen darstellen, die sich mit der agilen Softwareentwicklung beschäftigen.<br>"
01.05.17;29.09.17;2017;extern;Bachelor;DE;Identifikation von Dokumentenähnlichkeiten zur Qualitätssteigerung des Wissens-Projektmanagements in Attlassian Jira;In dieser Bachelorarbeit werden textuelle Ähnlichkeiten, mittels kontextuell gewichteter Wortvektoren und Ähnlichkeitsmaße, zur Optimierung des Projekt- und Wissensmanagements innerhalb Atlassian Jira eingesetzt.<br>Indem die in dieser Software enthaltenen Tickets, welche Arbeitsaufträge beschreiben und dadurch die Strukturierung von Projekten ermöglichen, anhand ihrer thematischen und semantischen Ähnlichkeiten verglichen werden, sollen Duplikate zur Bereinigung des Systems identifiziert werden. <br>Weiterhin werden die Bearbeiter der so berechneten ähnlichsten Tickets jeweils als geeigneter Ansprechpartner zur Hilfestellung vorgeschlagen.<br>Durch eine In-Memory Datenbank wird unter Einsatz eines Webhook die Echtzeitaktualisierung des   statistischen Modells ermöglicht. Über den Einsatz des Optical Cipher Recognition Tools Tesseract von Google, oder PDFMiner, werden auch Dateianhänge wie Screenshots und PDF-Dateien auf relevante Textuell vorliegende Daten untersucht. <br>Die in der Arbeit entstandene Wortgewichtung sowie ihre Kombination mit der Cosinus-Ähnlichkeit wird mit bestehenden verglichen.
01.05.17;12.12.17;2017;extern;Master;EN;Design and Evaluation of a Backbone Network for Wireless Sensor Networks;Large-scale installations of wireless sensor networks often consist of several distributed individual networks. A central access point for all sensor networks is required in order to optimally transfer the data from these networks to the application back end. This is provided by a gateway or backbone network which combines the distributed access points to the sensor networks. <br>The aim of this thesis is to design and implement a backbone network for wireless sensor networks based on the s-net communication stack developed at Fraunhofer IIS. To this end, protocols available in research and application for wireless sensor networks and their concepts for backbone networks will be investigated and evaluated. Based on this evaluation, a concept for a backbone network for s-net is developed. This concept introduces an address scheme whereby individual sensor nodes as well as specific networks and subnetworks can be addressed via the central access point of the backbone network. Furthermore, a special sensor node role is introduced, which enables distributed access points for the backbone network into the sensor networks. Based on this, the transmission characteristics of the sensor networks can be improved by extending the routing in the backbone network. <br>The prototypical implementation of the backbone network concept is designed to be as easy to install and use as possible, so that it can be used also by less experienced s-net users. Finally, the concept is tested and validated. 
04.05.17;04.01.18;2017;extern;Master;DE;Konzeption eines Cyber-Threat-Modells mit beispielhafter Umsetzung bei DATEV;Bei der DATEV eG werden aus Sicherheitgründen Informationen aus verschiedenen Quellen gesammelt und an einer zentraler Stelle, einem Security Information and Event Management (SIEM)-System, gespeichert. Das SIEM prüft die Informationen gegen bestehende Kompromittierungsindikatoren und alarmiert die Verantwortlichen, falls eine räumliche oder zeitliche Korrelation auf eine Bedrohung hinweist. Man spricht von einem Security Incident wenn dabei definierte Schwellwerte überschritten oder kritische Indikatoren erkannt werden.<br>In dieser Arbeit wurde ein Modell für Cyber Threats (digitale Bedrohungen) konzipiert. Das Modell stellt die Grundlage für die Umsetzung eines Verwaltungssystems für Informationen rund um Cyber Threats dar. Die resultierende Sammlung dieser Daten wird als Security Use Case bezeichnet.<br>Auf Basis der gestellten Anforderungen wurden bereits existierende Standards und Plattformen auf ihre Eignung zur Verwaltung von Security Use Cases geprüft und die Datenfelder definiert, die zur ihrer Abbildung benötigt werden. Schließlich wurden dem Konzept noch weitere Funktionalitäten hinzugefügt, z.B. eine Nutzerverwaltung oder die Anbindung an Datenbanken mit wertvollen Kontextinformationen.<br>Mit dem fertigen Konzept erfolgte zuletzt eine beispielhafte Umsetzung bei der DATEV eG. Dafür wurde eine Datenbank mit zugehöriger Weboberfläche entworfen. Mit der entwickelten Verwaltungsanwendung können nun Security Use Cases angelegt, eingesehen bearbeitet und koordiniert werden.
04.05.17;22.12.17;2017;extern;Master;DE;Konzipierung und Realisierung einer Quality-of-Service-Unterstützung in einem Computernetzwerk auf Basis von Software-defined Networking;"In der Abschlussarbeit wird ein Konzept sowie die prototypische Realisierung einer Quality-of-Service-Unterstützung auf Basis des digitalen Kommunikationsnetzwerks der LEONI AG vorgestellt. Dabei wird zunächst eine strategische Vorgehensmethodik beschrieben, um die Strukturierung der benötigten Arbeitspakete zu fördern und die existierende Themenkomplexität zu reduzieren. Außerdem beinhaltet die Projektdurchführung die Ist-Aufnahme des betroffenen Kommunikationsnetzwerks und die Konzipierung einer QoS-Unterstützung, die auf dem DiffServ-Modell basiert. Aufbauend auf dem Konzept erfolgt die prototypische Realisierung der QoS-Unterstützung, die ebenso im Rahmen einer Testumgebung zu verifizieren ist.<br><br>Zum Abschluss der Arbeit wird der aktuelle Trend ""Software-defined Networking"" (kurz: SDN) in Anlehnung an den Anwendungsfall ""Einführung und Wartung einer Quality-of-Service-Unterstützung"" bewertet. Zur Bildung einer Bewertungsgrundlage werden zunächst kritische Erfolgsfaktoren identifiziert, um im Anschluss eine SDN-Referenzimplementierung, die aus dem Produktportfolio des Netzwerkgeräteherstellers Cisco stammt, auf Einsetzbarkeit prüfen zu können."
05.05.17;05.10.17;2017;intern;Bachelor;DE;Untersuchung des Zusammenhangs zwischen Krebs und Ernährung mit dem Einsatz von Machine Learning;In den letzten Jahrzehnten sind die Krebsneuerkrankungen weltweit drastisch angestiegen. Vor allem aufstrebende Entwicklungsländer sind davon deutlich betroffen. Dabei ist besonders auffallend, dass einige Länder zunehmend westliche Lebensweisen annehmen und die damit oftmals verbundenen Ernährungsweisen. Ebenfalls ist der Zuckerkonsum in vielen Ländern weltweit erheblich angestiegen. Laut einigen wissenschaftlichen Studien besteht dabei ein ordentlicher Zusammenhang zwischen Ernährung und Krebs, insbesondere des Zuckerkonsums. <br>Aufgrund der modernen Methoden des Machine Learnings können diese Zusammenhänge anhand eines ausgewählten Verfahrens betrachtet sowie Prognosen für die zukünftige Entwicklung abgegeben werden. Für die gesamte Arbeit wurden dabei intensive Datensammlung zu Krebs und ausgewählten Ernährungsfaktoren betrieben und anschließend aufbereitet. Auf Basis dieser Datenbestände wurde ein zugrundeliegendes Modell konfiguriert, welches später für die Umsetzung im Vorfeld ausgesuchter Softwareprodukte diente. Vor der eigentlichen Umsetzung erfolgte die Durchführung einer linearen Regression, anhand welcher die spätere Bewertung der Ergebnisse stattfand. Auch wurden jeweils die Klassifizierungsergebnisse der Tools genauer betrachtet und bewertet. Abschließend fand eine Prognosedurchführung statt, um einen zukünftigen Vergleich im Jahr 2020 zu ermöglichen, um damit auf zusätzliche Weise eine Bewertungsgrundlage zu ermöglichen. <br>
08.05.17;08.10.17;2017;extern;Bachelor;DE;Konzeption einer Datensicherungsstrategie für Object-Storage-Systeme;Die Arbeit befasst sich mit der Erarbeitung eines Datensicherungskonzepts für Object-Storage-Systeme. Diese werden aufgrund des immer höher werdenden Datenaufkommens vor allem im Bereich der Onlinedienste verwendet und sind dementsprechend beliebig skalierbar. Dank der Architektur des Systems soll Ausfallsicherheit garantiert werden. <br>Sobald es sich um sensible Daten im Unternehmensumfeld handelt, ist allerdings mindestens eine Notfallsicherung des Datenbestandes unabdingbar. In dieser Arbeit werden verschiedene Vorgehensweisen zur Sicherung von Daten verglichen und ein konkretes Konzept für eine Sicherung von Object-Storage-Systemen erstellt. Daraufhin soll dieses Konzept auf das produktive Umfeld eines Nürnberger Softwarehauses angewandt werden.<br>
08.05.17;04.12.17;2017;intern;Master;DE;Prognose von volkswirtschaftlichen Faktoren unter Einsatz von Machine Learning ;"Wirtschaftliche Freiheit wurde in der Vergangenheit als wichtiger volkswirtschaftlicher Faktor angesehen, doch es stellt sich die Frage, in welcher Form sich diese auf eine Bevölkerung auswirkt. Wohlstand und Lebensqualität soll durch wirtschaftliche Freiheit steigen und letztlich gesellschaftliche Freiheit, auch in repressiven Staaten, etablieren. Die Komplexität eines globalen Wirtschaftssystems lässt sich nur beschränkt abbilden, eine punktuelle Abstraktion auf Basis von volkswirtschaftlichen Daten und modernen Machine-Learning-Algorithmen könnte jedoch möglich sein. Die wirtschaftliche Freiheit stellt einen zentralen Punkt dieser Arbeit dar. Auf ihrer Basis ist es das Ziel, deren mögliche Relevanz für Wohlstand und Lebensqualität einer Bevölkerung zu beurteilen. Untersucht werden hierfür volkswirtschaftliche Indizes: Ökonomische Freiheit repräsentiert durch den ""Economic Freedom of the World""-Index (EFW) sowie Wohlstand und Lebensqualität durch den Human Development Index (HDI) der Vereinten Nationen. Neben der grundlegenden Relevanz sind auch weitere mögliche Erkenntnisse über Zusammenhänge der untersuchten Daten von Interesse. Im Verlauf dieser Arbeit gilt es zusätzlich, ein taugliches Auswertungs-Werkzeug für den Anwendungszweck als auch passende Machine-Learning-Algorithmen für eine zielführende Analyse zu identifizieren und einzusetzen. Es zeigte sich, dass beide Indizes stark korrelieren und eine Prognose des HDI auf Basis des EFW zuverlässig möglich ist."
15.05.17;12.10.17;2017;extern;Bachelor;DE;Evaluation des Potentials von virtuellen Maschinen in einer Cloud-Computing-Plattform im Softwareentwicklungsumfeld bei der NÜRNBERGER Versicherung;Die IT nutzt seit Jahren das gleiche Modell zur Bereitstellung von Computern in Form von Rechnern, welche je nach gewünschter Leistung gekauft und physikalisch einem Platz zugewiesen werden. Mit dem voranschreiten der Technik etablieren sich immer neuere Modelle und Konzepte. In dieser Arbeit geht es primär um die sich rasch verbreitende Technologie der virtuellen Maschinen im Bereich des Cloud-Computings, welches auch unter dem Begriff der Desktop-Virtualisierung zu finden ist. Es wird im Rahmen dieser Abschlussarbeit ein Anwendungsszenario in Bezug zur Softwareentwicklungsabteilung der Nürnberger Versicherung erstellt, auf dessen Grundlage untersucht werden soll, in wie fern das neue Modell sinnvoll für den Einsatz ist. Mit Hilfe von Literaturrecherchen und dem Testen der Bedingungen im praktischen Umfeld werden verschiedene Chancen und Risiken aufgedeckt, sowie Maßnahmen erstellt, dieses Modell optimal zu nutzen. Es hat sich herausgestellt, dass der Einsatz dieses Modells nicht die erhofften Vorteile mit sich bringt, um die Risiken zu überwinden. Die Empfehlung ist daher kein breiter Einsatz dieses Modells, sondern eine individuelle Bereitstellung an Mitarbeiter, die einen Vorteil daraus erhalten würden.<br>
18.05.17;30.10.17;2017;extern;Bachelor;DE;Konzeption und prototypische Realisierung eines Dienstes zur Erfassung, Übertragung und Zuordnung von Anwendungstestergebnissen.;Im Rahmen der Bachelorarbeit wurde ein Dienst zur Erfassung, Übertragung und Zuordnung von Anwendungstestergebnissen konzipiert und prototypisch entwickelt.<br>Die Ausgangslage der Arbeit liegt der Tatsache zugrunde, dass in der DATEV eG momentan abteilungsübergreifend ein zentralisierter, standardisierter Prozess mit dem Ziel Continuous Delivery für alle Entwicklungsbereiche realisiert wird. <br>Gegenwärtig wird sowohl die Testdurchführung, als auch das Rückspielen der Testergebnisse auf den Testsystemen ausgeführt. Durch die Entkopplung von Testdurchführung und Verarbeitung von Testergebnissen, sollen sich die Testsysteme ausschließlich auf die Testdurchführung beschränken. <br>Das Ziel ist es, eine hohe Testüberdeckung zu erreichen, indem das Rückspielen von Testergebnissen zentralisiert von dem Dienst übernommen wird. <br>
30.05.17;30.10.17;2017;intern;Bachelor;DE;Entwicklung einer asynchronen, taskbasierten, threadsicheren Java-Bibliothek;
30.05.17;23.11.17;2017;extern;Master;DE;Einsatz des IBM Watson im Qualitätsmanagement bei Mercedes-Benz Vans;Der Fehlerabstellprozess wird in der Daimler AG auf Basis der CITAN-Fahrzeugdaten und geeigneter KI-Komponenten von IBM Watson innerhalb eines Pilotprojekts optimiert.<br>Werkstattfälle zu intransparenten Fehlerdokumentationen können mit dem WEX Content Analytics Miner vom 1st Level Support über angebundene Quellsensoren erleichtert, schneller und zuverlässiger bearbeitet werden. Zudem hat das 2nd Level mit dem WEX Application Builder die Möglichkeit, gesamtheitlich sowie global Fehleranalysen, deren Ursachen und Wirkungen an Fahrzeugen vorzunehmen. Das Zahnriemen-Fehlerbeispiel zeigt Anwendungsfälle in den dafür erstellten Benutzeroberflächen.<br>Durch das neue Fundament entwickeln sich Mehrwerte: integrierte Quellsensoren, konsolidierte Dateneinsicht und ein manuell zeitlich reduzierter Fehleranalyseaufwand.<br>Visionäre Optimierungen ergeben Weiterentwicklungen, wie simultan laufende Fehlerprognosen, Teileoptimierung in der Frühentwicklung sowie von Watson selbsterkannte Hinweise/Vorschläge. Die prädiktive Fahrzeuganalyse mit einbezogener Daten-Präskription auf Basis der explizit angepassten KI erweitert die bisherige deskriptive und diagnostische Analyse.<br>In den Werkstätten wird das gesamte Vorhaben mit einem zusätzlichen Knotenpunkt zu Watson effizient ausgeweitet. Kürzere Reparaturzeiten und ein höherer Fahrzeugdurchsatz sind Folgen, die auch Daimler-Kunden begrüßen. Das Zielszenario der verbesserten Fehlerfallbearbeitung erreicht eine nochmal leistungsstärkere Analysesituation.
01.06.17;30.10.17;2017;extern;Bachelor;DE;Optimierung von Bestellprognosen mit Hilfe von Deep Learning und TensorFlow;In dieser Arbeit wird der Einsatz von Deep Learning zur Verbesserung der Bestellvorhersagen analysiert. Die Vorhersagen des dabei erstellten Prototyps werden mit den Vorhersagen des Unternehmens und den Vorhersagen basierend auf Zeitreihenanalyse verglichen. Zur Erstellung des Prototyps müssen bereitgestellten Daten in eine numerische Form umgewandelt werden. Die Daten teilen sich dabei in Unternehmensdaten und in externe Daten auf. Unternehmensdaten teilen sich in Endprodukte und Zwischenprodukte auf. Wetterdaten, Feiertage und Saisondaten zählen zu den externen Daten. Ein Zusammenhang zwischen Wetter und Bestellung konnte nicht festgestellt werden, die Beeinflussung durch Feiertage wurde dagegen nachgewiesen. Eine Verbesserung der Vorhersagequalität aufgrund der Saisondaten konnte nicht eindeutig belegt werden. Zur automatisierten Parametrisierung des Prototyps wurden zwei Algorithmen implementiert genutzt. Der Vergleich ergab eine Verbesserung der Endprodukte Vorhersagegenauigkeit um 45,1 % gegenüber der Unternehmensprognose. Im Falle von Deep Learning in Gegenüberstellung zur Zeitreihenanalyse verbesserte sich die Vorhersagequalität der Zwischenprodukte um 2,1 % und die Vorhersagequalität der Endprodukte um 5 %.
01.06.17;01.11.17;2017;intern;Bachelor;DE;Erstellung interaktiver Szenen aus 360°-Aufnahmen;Das Thema der Arbeit liegt im Rahmen von bildbasiertem Rendering in Zusammenhang mit Interaktionskonzeption und Medienimmersion. Die Herausforderung in diesem Themenkomplex liegt insbesondere darin, Vorteile heutiger Visualisierungsmöglichkeiten, wie die verbreitete Rundumsicht in Panoramaaufnahmen, mit einem intuitiven Bedienungskonzept zu verbinden, um ein praktisches Werkzeug für individuelle Szenen-Editierung zu schaffen. Ziel ist es mit der Entwicklungsumgebung Unity einen Editor bereitzustellen, der es dem Anwender ermöglicht eigene 360°-Szenen zu erstellen und an beliebig gewählten Bildpunkten mit interaktiven Medieninhalten, wie Bildmaterial, Texten und Sounds zu füllen.<br><br>Ein praktisches Anwendungsbeispiel wird in einer prototypisch umzusetzenden virtuellen Umgebung vorgeführt, in welcher in begrenztem, aber repräsentativem Umfang selbst gewonnene 360°-Realaufnahmen abgebildet und miteinander verknüpft werden. Die erstellten Szenen werden durch abrufbare interaktive Inhalte mit textuellen Informationen sowie Audio- und Bildaufnahmen erweitert.
01.06.17;26.01.18;2017;extern;Master;DE;Virtual-Reality-optimierte Sensor Fusion für eine langzeitstabile Gestenerkennung der oberen Extremität;"Die Gruppe ""Sensorfusion und Ereignisverarbeitung"" am Fraunhofer-Institut für Integrierte Schaltungen (IIS) in Nürnberg, arbeitet an der Generierung und Verarbeitung von Sensor- und Positionsdatenströmen und deren statistischer Auswertung und Analyse auf verständlicher und abstrakter Ebene in Echtzeit. Dabei stellen die vorliegenden handelsüblichen Head-Mounted-Displays (HMD), zum Beispiel Samsung Gear VR und Oculus Rift, unter anderem relative Beschleunigungen, Drehraten und kurzzeitstabile Kopforientierung bereit, welche in Kombination mit dem bereits existierenden und erprobten Fraunhofer Holodeck VR System um absolute Positionen erweitert werden. Diese Positionen werden mit Hilfe geeigneter Bewegungsmodelle so in das Virtual Reality System (VR-System) eingepflegt, dass eine mögliche Simulatorkrankheit reduziert und vorgebeugt werden kann (sog. VR-optimierte Sensorfusion). Somit ermöglicht das Holodeck VR System immersive und frei begehbare virtuelle Welten.<br>Im Rahmen dieser Arbeit wird die Einsatztauglichkeit von Hand-Tracking-Systemen untersucht, beispielsweise von Leap Motion oder uSense, um die momentane Position und Stellung der Hand zu erfassen und möglichst latenzarm und präzise in der VR abzubilden. Neben Hand-Tracking-Systemen, die zentral am Kopf angebracht werden, werden auch Systeme untersucht, wie beispielsweise das Myo System oder die Eingabegeräte von Samsungs Gear VR und Googles Daydream Controller, das an den Händen oder Armen angebracht wird, um ..."
08.06.17;30.10.17;2017;intern;Bachelor;DE;CRM-Systeme: Chancen und Grenzen der Automatisierung ;Das Ziel der Bachelorarbeit war es, die Architektur und Funktion von CRM-Systemen zu systematisieren.<br>Aus den Risiken und Chancen der Automatisierung im CRM wurde herausgearbeitet, wie sich CRM mit den neuen IT-Technologien verbessern, automatisieren und beschleunigen lässt. Und es wurde aufgezeigt, welche Grenzen bei der Automatisierung vorkommen.
12.06.17;12.11.17;2017;extern;Bachelor;DE;Entwicklung einer Software zur Bestimmung der Qualität von merkmalsorientierter Bildverarbeitungsalgorithmik;Im Rahmen der Bachelorarbeit wird eine Software entwickelt, mit deren Hilfe eine Aussage<br>über die Qualität von Bildverarbeitungsalgorithmen zur Merkmalsdetektion an<br>dreidimensionalen Prüfstücken getroffen werden kann. Die Software soll sowohl während<br>der Entwicklung neuer Bildverarbeitungsalgorithmen, als auch zum Testen fertiger<br>Programme verwendet werden können.<br>Zur Einstufung der Qualität werden Ergebnisse der Bildverarbeitungsalgorithmen mit<br>händisch annotierten Bilddaten verglichen. In den Vergleich fließen Eigenschaften<br>gekennzeichneter Merkmalsbereiche, wie Merkmalstyp, Flächenabdeckung, Form und<br>relative Lage zueinander ein. Ebenso werden die Nichterkennung von Merkmalsbereichen<br>und das Auftreten fälschlich detektierter Merkmalsbereiche berücksichtigt.
20.06.17;07.09.17;2017;intern;Bachelor;DE;Konzeption und Realisierung eines TLS-Demonstrators für die Lehre mit Open SSL;Konzeption und Realisierung eines TLS-Demonstrators für die Lehre mit<br>Open SSL<br><br>Der Demonstrator soll Studierenden ermöglichen, im Laborversuch den Aufbau und Ablauf von mit TLS (Transport Layer Security) gesicherten Punkt-zu-Punkt-Verbindungen zu beobachten. Der Ablauf des TLS-Handshakes kann schrittweise verfolgt werden. Es werden wesentliche TLS-Varianten unterstützt (z.B. mit/ohne Client-Authentifizierung, RSA-basierte und Diffie-Hellman-basierte Ciphersuites). Als Anwendungsszenarien werden die Kommunikation zwischen einem Webbrowser und einem Webserver und die Kommunikation zwischen einer allgemeinen Client- und einer allgemeinen Server-Anwendung bereitgestellt. Kommuniziert wird zwischen zwei virtuellen Maschinen, die auf einem physischen Rechner installiert werden können.
01.07.17;01.03.18;2017;intern;Master;DE;Analyse und Vergleich aktueller JavaScript-Anwendungsframeworks;In den letzten Jahren sind zahlreiche JavaScript-Anwendungsframeworks entstanden, die die Entwicklung moderner Webseiten und sogenannter Single-Page- oder Rich Internet Applications vereinfachen sollen. Obgleich diese Frameworks eine bestimmte Softwarearchitektur erzwingen und damit zumindest dazu beitragen, komplexe JavaScript-Anwendungen besser zu strukturieren, führen sie meist auch eigene Paradigmen und domänenspezifische Sprachen oder Sprachbestandteile ein, die ihrerseits dem Entwicklungsprozess wieder zusätzliche Komplexität hinzufügen. Darüber hinaus entstehen häufig weitere Abhängigkeiten zu zahlreichen zusätzlichen Bibliotheken, die nicht nur die Lade- und Ausführungsgeschwindigkeit der damit erstellten Webseiten beeinflussen, sondern möglicherweise ein Sicherheitsrisiko darstellen.<br>Im Rahmen dieser Arbeit soll daher zunächst ein Überblick über die wichtigsten aktuellen JavaScript-Anwendungsframeworks geschaffen und deren Aufbau sowie die zugrundeliegende Softwarearchitektur untersucht und diese mit den Möglichkeiten aktueller Web-Technologien (ES6, Web-Components) verglichen werden. Darauf aufbauend wird anhand einer Beispielanwendung der Einfluss verschiedener Entwicklungsansätze auf die Performanz und Sicherheit einer Web-Anwendung untersucht. Schließlich soll unter Berücksichtigung der gewonnenen Erkenntnisse eine Aussage darüber getroffen werden, für welche Zwecke der Einsatz komplexer JavaScript-Frameworks sinnvoll bzw. nicht empfehlenswert ist. 
04.07.17;05.03.18;2017;intern;Master;DE;Prototypische Erstellung einer Plattform zur Visualisierung, Auswertung und Analyse von anonymisierten Personendaten;Im Rahmen dieser Masterarbeit wurde eine Plattform zur Erfassung und Auswertung von Studentendaten in Fach Programmieren I entwickelt. Dafür wurden zunächst verschiedenen Arten von Daten ermittelt die für diese Anwendung relevant sind und anschließend ein darauf basierendes Datenbankomdell erstellt.<br>Danach wurden ausgewählte Technologien auf Vor- und Nachteile geprüft, welche für die schlussendliche Nutzung relevant waren.<br>Anschließend wurde eine Systemarchitektur entworfen, die zum Schluss auch realisiert wurde.
14.07.17;14.12.17;2017;intern;Bachelor;DE;Entwurfsmuster - Design Patterns;Entwurfsmuster, im englischen Sprachraum auch Design Patterns genannt, sind gängige, geeignete Lösungswege für sich ständig wiederholende Entwurfsprobleme bzw. Gestaltungsaufgaben aus fast allen Bereichen des Lebens. Ein Muster dient als Vorlage zur Lösung eines Problems in einem bestimmten Anwendungszusammenhang. Dabei wird auf bewährtes Expertenwissen aus der Praxis zurückgegriffen und angewendet. Ziel dieser Bachelorarbeit ist es, nach der Mustertheorie von Christopher Alexander, herauszufinden, in welchen Bereichen, mit welchen Detail- oder Reifegrad, bereits Mustersprachen verwendet, wie solche Patterns entdeckt und dokumentiert wurden. Dabei wird auch auf die grundlegende Formalisierung und Beschreibung der Patterns näher eingegangen. Interessant sind hierbei die Methoden zu betrachten, die angewendet wurden, um derartige Muster zu entdecken sowie herauszufinden, welche weiteren Methoden noch existieren und welche mehr oder weniger vorteilhaft sind. Hierbei wird ebenfalls auf die Frage näher eingegangen, wie man in den einzelnen Bereichen vorgegangen ist, um diese Muster zu entdecken. Im weiteren Verlauf geht die Arbeit auch der Frage nach, welche Qualitätskriterien Patterns erfüllen müssen, damit sie beispielsweise auf Konferenzen vorgestellt werden dürfen.
18.07.17;30.04.18;2017;intern;Master;DE;Einsatz maschineller Lernverfahren zur Erkennung von Spielmechanismen in Spielanleitungen;Diese Arbeit zeigt, dass es durch den Einsatz maschineller Lernverfahren möglich ist, die in Brettspielen eingesetzten Mechanismen, in ihrer Repräsentation als Pattern, aus deren textuellen Spielanleitungen zu extrahieren. Durch die hierfür verwendeten überwachten Lernverfahren werden erfolgreich Modelle erzeugt, welche automatisiert trainierte Spiel-<br>mechanismen in Spielanleitungen erkennen. Verglichen werden hierfür Support-Vector Machines (SVM), mit k-Nearest Neighbor (kNN) und Naïve Bayes-Klassifizierern (NB), wobei SVMs Accuracy-Werte von über 80% erreichen.<br>Das Schwierigkeit der Textklassifikation von nicht nativ digitalen Daten, wird durch die Anwendung genauer Datenexploration und -bereinigung gelöst. Dabei wird eine neue Metrik vorgestellt, welche eine genaue Bewertung der durchgeführten Datenbereinigungsmaßnahmen erlaubt. Dieser Ansatz bewertet nicht, wie üblich, die Qualität eines bereinigten Textes anhand des Unterschieds zu einer Abbildung des Originaltextes, sondern verwendet zur Bewertung eine Bag-of-Words Repräsentation beider Texte.
19.07.17;19.12.17;2017;extern;Bachelor;DE;Untersuchung einer Blockchain Technik in Hinblick auf Anwendungen im Umfeld Internet der Dinge;Ziel dieser Bachelorarbeit war es, die Anforderungen einer Blockchain Technik an die benötigte Infrastruktur anhand eines praktischen Beispiels im Umfeld Internet der Dinge zu ermitteln.<br>Dabei wurde zunächst auf die Theoretischen Grundlagen und die Funktionsweise von Blockchain eingegangen um. Anschließend wurde ein Prototyp konzipiert und implementiert mithilfe dessen die Hyperledger Fabric Blockchain zum Speichern von Sensordaten verwendet wurde um somit Anforderungen, Vor- und Nachteile und Limitationen der Blockchain Technologie in diesem Anwendungsbereich ermitteln zu können. Und schlussendlich eine Aussage treffen zu können ob sich eine weitere Betrachtung des Themas Blockchain in diesem Bereich lohnt.
26.07.17;26.03.18;2017;extern;Master;DE;Vorgehensmodelle und Softwarearchitekturen zur Entwicklung interaktiver Chatbot-Systeme;Das Kommunizieren mit Computern via Bots ist eine bereits ältere Idee, doch jüngste Fortschritte im Bereich Machine Learning und Conversational User Interfaces, wie den Sprachassistenten Alexa, Siri und Cortana, haben Potentiale für alternative Kommunikationswege gezeigt. <br>Mit diesem Hintergrund soll in der Masterarbeit untersucht werden, welche Elemente ein Chatbot mit sich bringen muss, um als Mehrwert gegenüber herkömmlichen User Interfaces angesehen zu werden.  Um dieses Ziel zu erreichen soll ein empirischer Ansatz verfolgt werden. Dazu wird zunächst eine Analyse von Chatbots in Hinblick auf deren Alleinstellungsmerkmale und Funktionen im Vergleich zu klassischen Web- und Mobile-Kommunikationsschnittstellen erstellt. Zusätzlich sollen die weit verbreitetsten Chatbot-Plattformen und -Architekturen analysiert verglichen werden. Diese Schritte sollen<br>als Basis fu?r den weiteren Verlauf der Arbeit genutzt werden und eine Übersicht<br>der Thematik liefern. Mithilfe dieser Grundlagen soll ein erster Prototyp erstellt<br>werden, den Testnutzer im Rahmen eines Use-Case auf die implementierten Funktionen<br>überprüfen sollen. Grundlegend ist hierbei die Veranschaulichung von erweiterten und neuen Ansätzen die verwendet wurden um die Kernfunktionen des Chatbots zu bauen.
08.08.17;08.04.18;2017;extern;Master;DE;Verbesserung der Prozessautomatisierung - Robotic Process Automation - mit Methoden der künstlichen Intelligenz;Die vorliegende Arbeit befasst sich mit der Verbesserung der Technologie Robotic Process Automation (RPA) anhand von Methoden und Lösungen der künstlichen Intelligenz (KI). Prozesse, die einen unstrukturierten Dateninput, komplexe Entscheidungen oder einen veränderbaren Prozessablauf haben, lassen sich mit RPA nicht automatisieren. Diese Probleme könnten jedoch mit Methoden der KI gelöst werden, so dass punktuell RPA durch KI unterstützt werden könnte. Um mögliche Prozesse herauszufinden, die sich durch die Kombination der Techniken RPA und KI automatisieren lassen, wird in dieser Arbeit ein Bewertungsmodell erstellt. Die prototypische Realisierung des Prozesses Warenreklamation per E-Mail zeigt auf, dass sich nicht jede KI-Lösung für eine korrekte und vollständige Automatisierung von Prozessen eignet. Durch die Realisierung wird allerdings auch aufgezeigt, dass in der gemeinsamen Anwendung von RPA und KI großes Potential steckt, um in Zukunft eine größere Prozessbreite automatisieren zu können.
16.08.17;15.12.17;2017;extern;Bachelor;DE;Konzeptionierung und Implementierung eines Frameworks zur Darstellung von Phantomen innerhalb einer Simulationskomponente für Computertomographen;Im Rahmen dieser Bachelorarbeit wurde ein Framework zur Erzeugung und Darstellung<br>von Phantomen innerhalb einer Anwendung entwickelt, die einen Computertomographen<br>simuliert. Die Ausgangsanalyse ergab, dass die aktuell verwendete Implementierung nicht geeignet<br>war um kommende Anforderungen an Phantome gerecht zu werden. Neue Phantome konnten nur unter großem<br>Zeitaufwand entwickelt werden. <br>Die Entwicklung des Konzepts begann mit der Idee, die einzelnen Elemente eines Phantoms<br>als geometrische Objekte zu definieren. Dadurch wird es ermöglicht, ein Phantom als<br>ein Objekt aus einzelnen Bauteilen zu betrachten. Die einzelnen Elemente können für<br>neue Phantome wiederverwendet werden und bieten mathematische Operationen um<br>sich im Raum zu positionieren. Um diese Elemente zu gestalten, werden zunächst zwei<br>primäre Grundobjekte verwendet: Quader und Kreis. Aus diesen Objekten lassen sich<br>alle aktuell verwendeten Bauteile zusammensetzen. Die Objekte bieten eine umfangreiche<br>Parametrisierung für ihre Dimensionen und ihre Zusammensetzung. Sollten in der Zukunft<br>noch weitere Objekte benötigt werden, bietet das Framework ausreichend Schnittstellen<br>um Erweiterungen einzubauen. Das Framework wird in der Programmiersprache C# von Microsoft entwickelt. Die<br>beispielhafte Implementierung eines Phantoms sowie Schnittstellen und ausgewählte<br>Klassen werden vorgestellt und erläutert. <br>Schlussendlich werden die Bilder eines realen und simulierten Phantomes verglichen.
24.08.17;23.01.18;2017;intern;Bachelor;DE;Implementierung einer Microservice-Referenzarchitektur für die<br>Gamifizierung von Webseiten;Im Rahmen einer Masterarbeit wurde eine Microservice-Referenzarchitektur für die Gamification von Webseiten, die jedes Gamification-Element in einen eigenen Microservice kapselt, entworfen und prototypisch unter Verwendung von Java als serverseitige Programmiertechnologie verwendet. Im Rahmen dieser Bachelorarbeit wurde überpüft, in wie fern die Microservice-Referenzarchitektur unter Verwendung von PHP als serverseitiger Programmiertechnologie implementierbar ist. <br>Hierzu war eine Anwendung mit fünf Gamification-Elementen zu implementieren. Diese fünf Gamification-Elemente schließen die drei Gamification-Elemente aus der prototypischen Implementierung in der Masterarbeit ein. Vorgegeben waren also die Implementierung der Elemente Punkte, Level und Abzeichen. Als die zwei weiteren zu implementierenden Elemente wurden Fortschrittsanzeige und Leaderboard gewählt.<br>Die Microservice-Referenzarchitektur sieht zur Kommunikation zwischen der Webseite und einem Microservice REST und zur Kommunikation zwischen den Microservices Messaging vor.<br>Da in PHP die Webanwendung mit jedem Webaufruf neu gestartet wird, ist eine Implementierung einer Microservice-Architektur, die zur Kommunikation zwischen den Microservices Messaging vorsieht, nicht trivial.<br>Die im Rahmen dieser Arbeit implementiererte Anwendung zeigt jedoch, das dies sehr wohl möglich ist.
27.08.17;27.01.18;2017;extern;Bachelor;DE;Rechnungsprüfung und Verbuchung mit Dokumentenmanagement für Baubetriebe;In der Industrie ist die  Digitalisierung bereits in vollem Gange, dies bedeutet, was automatisiert werden kann, wird automatisiert. Tendenziell handwerklich geprägte, kleine und mittelständische, Unternehmen tun sich jedoch schwer die entsprechenden Schritte einzuleiten, da hierfür in den Betrieben weder Kompetenzen im Sinne spezialisierter Fachabteilungen existieren noch zeitliche oder finanzielle Ressourcen für den Veränderungsprozess wie in den Industriebetrieben bereitgestellt werden können. Durch veränderte Bedingungen im Umfeld, wie die zunehmende Anzahl der elektronischen Rechnungen sowie dem ständig zunehmenden Kosten- und somit Wettbewerbsdruck besteht jedoch auch hier die Erfordernis, die Verwaltungs- und dabei auch insbesondere die Belegprozesse zu optimieren. Diese Arbeit soll für einen abgegrenzten Anwendungsfall eine Lösungsmöglichkeit für handwerklich orientierte Bauunternehmen aufzeigen und durch die gleichzeitig aufgestellte Prozessmodellierung mit Verfahrensdokumentation gemäß GoBD den praktischen Anwendungsfall in den Vordergrund stellen.
01.09.17;12.01.18;2017;intern;Bachelor;DE;Simulation der Kinematik von Arthropoden;Im Rahmen dieser Arbeit wird untersucht, ob die Physik-Komponente der Simulationsumgebung des BugBot-Kinematics-Projekts durch die Java-Portierung jBullet der Physik-Engine Bullet Physics ersetzt werden kann. Daher wird beispielhaft eine Simulation eines Hexapoden basierend auf jBullet implementiert. Diese umfasst zum einen die Modellierung des Hexapoden als Mehrkörpersystem und zum anderen die Modellierung der Umgebung, die den Hexapoden beinhaltet. Zudem wird ein Ansatz demonstriert, um die alternierende tripode Gangart von Arthropoden zu realisieren. Anhand dieser Implementierung wird der erweiterte Funktionsumfang von jBullet gegenüber der bisherigen Physik-Komponente deutlich und zudem wird eine Schätzung des Änderungsaufwands für die Integration in den bestehenden Simulator getroffen. Die Visualisierung der Simulationsergebnisse erfolgt mit JavaFX.
01.09.17;01.02.18;2017;intern;Bachelor;DE;Konzeption und Entwicklung einer interaktiven Sicherheitsunterweisung unter Einbezug des realen Umgebungskontextes;Sicherheitsunterweisungen spielen in Unternehmen eine wichtige Rolle, damit Arbeitsunfälle vermieden werden können und Mitarbeiter möglichen Gefahrensituationen nicht hilflos ausgeliefert sind. In dieser Arbeit wird eine Lehrmethode vorgestellt, die Sicherheitsunterweisungen von einer neuen Seite betrachtet. Der reale Umgebungskontext des Lernenden wird bei der neuen Methode in dessen Lernprozess einbezogen. Diese Lehrmethode, die mittels einer mobilen Applikation umgesetzt wurde, soll einen höheren Lernerfolg ermöglichen. Um die Methode in der Praxis umsetzen zu können, sollen Objekte mit Hilfe von QR-Codes ausgestattet werden und bei Verknüpfung durch die mobile Applikation angezeigt werden. Im Rahmen einer kleinen Evaluation an Mitarbeitern und Studenten der Technischen Hochschule Nürnberg wurde die Methode untersucht. Das Ergebnis der Evaluation zeigt eine grobe Tendenz dazu, dass die neue Methode einen höheren Lernerfolg hervorruft.
01.09.17;31.01.18;2017;extern;Bachelor;DE;Full-HD Voice Conferencing im Browser mit Javascript;Für die Betriebssysteme iOS und Android entwickelte Fraunhofer bereits eine Anwendung zur Full-HD Voice Gruppenkommunikation. Damit diese aber auch Desktop-PCs zur Verfügung gestellt werden kann, wurde in dieser Abschlussarbeit untersucht, ob ein Browser-Support der Anwendung mit den zurzeit verfügbaren Mitteln möglich wäre. Hierbei hat sich herausgestellt, dass die verwendeten C++-Bibliotheken der Anwendung mit Hilfe von Emscripten nach JavaScript portiert werden können. Es wurde eine Lösung zum Streamen von Audio gefunden, bei der zum Testen einer Verbindung zwischen einem Client und einem Server, ein UDP-Server über den Browser mittels WebSockets angepingt wird. Hierfür wurde ein Proxy genutzt, der die Nachricht des Clients über UDP an den Server weiterleitet und dessen Antwort über ein WebSocket an den Client zurückschickt. Des Weiteren wurde ein Performance-Vergleich durchgeführt bei dem sich herausgestellt hat, dass asm.js noch viel langsamer ist als nativer Code. Im Gegensatz ist WebAssembly jedoch schon sehr nah an einer nativen Ausführung dran. Als Audio API wurde die Media Stream API von WebRTC ausgewählt, die unter anderem einfache Funktionen zum Ausführen eines Mikrofon Playbacks zur Verfügung stellt. Bei der Bearbeitung dieser Bachelorarbeit wurde festgestellt, dass es generell möglich wäre, die Gruppenkommunikationsanwendung im Browser ausführen zu lassen, sobald unter anderem benötigte Technologien, wie zum Beispiel WebAssembly, einen Thread-Support besitzen.
01.09.17;29.01.18;2017;extern;Bachelor;EN;Concept and realization of an identity service with Open ID Connect;Modern web applications often consist of a whole ecosystem of different clients, APIs and Microservices. Due to the distributed nature of these applications, the need for an identity service arises, which can perform authentication and provide identity information in a centralized and commonly understood manner. OpenID Connect is a light-weight identity layer which builds upon OAuth2.0 and is a standard which is becoming widely adopted. Using these technologies an identity service shall be designed, implemented and integrated into an existing application infrastructure. This service shall enable end users to perform single sign on and centrally administrate identity attributes. Finally the service will be evaluated based on the original requirements.
01.09.17;31.01.18;2017;extern;Bachelor;DE;Entwicklung einer mobilen Anwendung zur Erkennung und Suche von Produkten mittels künstlicher neuronaler Netze;In dieser Arbeit wurde eine mobile Anwendung zur Klassifizierung von Produkten der Dentalbranche implementiert. Hierzu kamen Convolution Neural Networks zum Einsatz, welche am Endgerät selbst ausgeführt wurden. Zur Umsetzung des Klassifikators wurden Lern-, Validierungs- und Teststichproben für 100 verschiedene Produkte erstellt. Bei der Wahl der Produkte wurden verschiedene optisch ähnliche Produkte berücksichtigt. Zudem wurden zwei Ansätze verglichen: Ein selbst erstelltes CNN mit 8 Schichten, sowie ein auf den ImageNet-Datensatz vortrainiertes Inception-V3-Netz. Die höchste Erkennungsrate von 96,51 % konnte mit 50 Stichproben pro Klasse für das Inception-V3-Netz erzielt werden. Des Weiteren wurde eine Auswirkung der Stichprobengröße auf die Erkennungsrate untersucht. Eine Einschränkung für den Klassifikator stellten Produkte dar, welche sich lediglich anhand leichter Farbvariationen voneinander unterschieden. In diesen Fällen empfiehlt sich eine manuelle Auswahl des Farbtons durch den Anwender. Je nach Endgerät war ein durchschnittlicher Zeitaufwand von 0,73 s bis 2,04 s für die Klassifikation nötig.
01.09.17;25.01.18;2017;extern;Bachelor;DE;Einführung von Software-defined networking bei der N-ERGIE;Die Einführung eines neuen Zonenkonzepts im Rechenzentrum der N-ERGIE bedingt den Einsatz einer softwarebasierten Steuerung der Netzwerkkommunikation.<br>Die vorliegende Bachelorarbeit gibt zunächst einen Überblick über die Funktionsweise und Möglichkeiten von Software-defined networking. Im weiteren Verlauf wird der Einsatz dieser Technologie bei der N-ERGIE AG in Form eines konkreten Produkts evaluiert. Dabei wird anfangs der momentane Arbeitsablauf analysiert, danach werden die Anforderungen im Hinblick auf den gewünschten Zielzustand festgehalten. Anhand des festgestellten Bedarfs werden marktübliche Vertreter von Software-defined networking<br>gegenübergestellt und der am besten geeignete ausgewählt. Durch eine prototypische Testinstallation und zuvor definierte Fallstudien werden die Vorteile der gewählten Lösung gegenüber dem alten Verfahren präsentiert. Das Ergebnis dieser Arbeit ist eine Handlungsempfehlung mit zugehöriger Bewertungsmatrix<br>zur Auswahl und Implementierung einer Software-defined networking Lösung bei der N-ERGIE.
01.09.17;01.02.18;2017;extern;Bachelor;DE;Head-tracked Spatial Conferencing;"Das Fraunhofer IIS entwickelte eine Applikation für Spatial Conferencing, welche es ermöglicht, die Teilnehmer einer Audiokonferenz akustisch in einem virtuellen Raum zu positionieren und unter Verwendung von Stereo-Headsets aus ihrer entsprechenden Richtung wahrzunehmen. Eine Problematik dabei ist, dass sich bei herkömmlichen Kopfhörern die Lautsprecher mit dem Kopf mitbewegen. Dadurch fühlen sich die Telefonkonferenzen unnatürlich an. Um dieses Problem zu beheben, wurde im Rahmen dieser Arbeit die Anwendung mit Hilfe von Head-Tracking erweitert, damit die Kopfbewegungen des Nutzers kompensiert und der Raumklang entsprechend angepasst wird.<br>Da die Audiosignale der Konferenzteilnehmer in der MCU gerendet werden, stellt sich die Frage, ob die zusätzliche Latenz, die durch das Streamen der Head-Tracking-Daten entsteht, das Hörerlebnis des Nutzers beeinflusst. Ein Tool wird entwickelt, um diese ""Motion-to-Sound""-Latenz messen zu können. Damit wird festgestellt, dass diese Latenz niedrig genug ist, um das Hörerlebnis des Hörers nicht beeinflussen zu können. Darauffolgend werden die Head-Tracking-Daten durch die OpenVR API implementiert und in der ACE integriert. Danach wird ein Hörtest vorbereitet und durchgeführt, um den Nutzen von ""Head-tracked Spatial Conferencing"" beurteilen zu können. Die Ergebnisse des Hörtests zeigen, dass Konferenzen mit Head-Tracking sich natürlicher anfühlen und der Hörer das Gefühl bekommt, sich mit den Konferenzteilnehmern in einem Raum zu befinden."
01.09.17;01.02.18;2017;extern;Bachelor;DE;Konzeption und Entwicklung einer sprachgesteuerten Anwendung zur Steuerung von Robotic Process Automation Software;Die Zielsetzung der Bachelorarbeit ist die Konzeption und Entwicklung einer sprachgesteuerten Anwendung, die es ermöglicht, mithilfe von Robotic Process Automation Software automatisierte Prozesse zu starten, stoppen und überwachen. In der Arbeit wird zunächst auf Robotic Process Automation (RPA) sowie UiPath, einen Anbieter von Robotic Process Automation Software eingegangen. Im Anschluss werden die Spracherkennungsdienste Bing-Spracheingabe-API, Google Speech und IBM Watson analysiert und verglichen. Die Bing-Spracheingabe-API stellte sich als geeignetste Spracherkennung heraus. Anschließend werden verschiedene Ansätze zur Interpretation von Sprachbefehlen diskutiert. Hier zeigte sich, dass Natural Language Understanding den besten Ansatz darstellt, der den Benutzer zudem die Befehlsstruktur frei wählen lässt. Es folgt eine Analyse möglicher kontextbasierter Kriterien, anhand derer dem Benutzer Prozesse zur Ausführung vorgeschlagen werden können. Zudem wird eine Benutzeroberfläche entworfen. Basierend auf diesen Ergebnissen wird die sprachgesteuerte Anwendung mit C# und WPF umgesetzt. Zur Interpretation der Spracheingaben wird LUIS, ein von Microsoft angebotener Natural Language Understanding Service eingesetzt. Abschließend wird eine Benutzerevaluation durchgeführt.
01.09.17;01.02.18;2017;extern;Bachelor;DE;Flexible Parametrisierung der Fehlernachrichten eines REST-basierten Backends;Diese Arbeit beschäftigt sich mit den verschiedenen Definitionssprachen für REST-Schnittstellen. Im Detail wurde näher auf die Spezifikation der Fehlernachrichten eingegangen, um ein Konzept zu entwickeln, diese flexibel zu parametrisieren. Dafür ist zunächst ein Referenzbackend und dessen Ausnahmebehandlung näher betrachtet worden. Anschließend wurden die Sprachen RAML, API Blueprint und OpenApi näher behandelt und deren Umsetzungsmöglichkeiten für das Konstrukt der Polymorphie. Diese Ergebnisse wurden zum Schluss in das Referenzbackend eingebaut, um eine Nutzwertanalyse durchzuführen.
01.09.17;01.02.18;2017;intern;Bachelor;DE;Evaluation der Programmiersprache Kotlin bezüglich Sprachfeatures und Effizienz der Softwareentwicklung gegenüber Java anhand einer Android App;Kotlin ist eine von JetBrains entwickelte, objektorientierte, statisch typisierte Programmiersprache mit funktionalen Elementen. Sie wird zu Java Bytecode kompiliert und ist somit auf der Java Virtual Machine lauffähig. Dies ist die Grundlage für ein potentiell breites Feld von Anwendungen. Darüber hinaus hat Google am 19.05.2017 auf der Developer Conference Google I/O bekannt gegeben, dass Kotlin neben Java und C++ eine offiziell unterstützte Sprache für Android wird.<br><br>Im Zuge dieser Arbeit werden die Sprachfeatures hinsichtlich ihrer prägnanten Syntax und zeitsparenden Eigenschaften genauer untersucht. Soweit vorhanden, werden sie mit ihren gleichwertigen Gegenstücken in Java verglichen. Der Schwerpunkt dieser Arbeit liegt in diesem Vergleich und der Analyse dieser neuen Sprachkonzepte.<br><br>Zum besseren praktischen Verständnis wird zudem eine Android Tacho-App entwickelt, mit der einige Kotlin spezifische Neuerungen in einfacher Weise dargestellt werden. Die App wird für Fahrrad- und Autofahrer angepasst. Neben der Anzeige von Geschwindigkeit, Tageskilometer und Durchschnittsgeschwindigkeit sind auch eine Reset-Funktion, eine animierte Oberfläche, ein Nachtmodus sowie ein Graph für eine statistische Visualisierung implementiert.
04.09.17;24.01.18;2017;extern;Bachelor;DE;Analyse von Grafikbibliotheken für die interaktive Visualisierung von 2D-/3D-CAD-Daten;"In Zusammenarbeit mit endobit software solutions soll für die Robert Bosch GmbH ein neues CAD-Tool entwickelt werden, welches ein momentan verwendetes Tool namens ""NCCAD"" ersetzen soll. Als Entscheidungsgrundlage werden im Rahmen der Bachelorarbeit mehrere Grafikbibliotheken auf folgende kritische Aspekte untersucht und anschließend verglichen: Einfachheit der Benutzung der Bibliothek, 3D Renderung un einem Viewer und Hardwarebeschleunigtes Rendering. Es sollen zudem Prototypen mit ausgewählten Grafikbibliotheken implementiert werden. Somit wird praktische Erfahrung gesammelt, womit die Bibliotheken besser eingeschätzt werden können. Das Ziel ist eine geeignete Grafikbibliothek für ein CAD-Tool zu finden. Jedoch werden auch andere Anwendungsfälle von Grafikbibliotheken bedacht, für welche Empfehlungen ausgesprochen werden."
05.09.17;05.02.18;2017;intern;Bachelor;DE;WebGL-basiertes Volume-Raycasting<br>;Das Ziel der vorliegenden Bachelorarbeit war es, einen WebGL-basierten Volume-Raycaster in JavaScript zu implementieren. Dabei sollte überprüft werden, ob diese Technologie für das direkte Volume-Rendering-Verfahren eignet ist. Des Weiteren sollten verschiedene WebGL-Implementierungen auf ihre Leistung evaluiert werden. Zusammenfassend kann gesagt werden, dass die Technologie für das direkte Volume-Rendering-Verfahren geeignet ist, solange die 3D-Datensätze nicht all zu groß sind. 
05.09.17;05.02.18;2017;extern;Bachelor;DE;Ermittlung und Umsetzung einer Methode zur automatisierten Bereitstellung kundenspezifischer Linuxserver im Rahmen eines Entwicklungsprojektes;Im Rahmen eines größeren Softwareentwicklungsprojekts stellt die Voigtmann GmbH eine Rahmeninfrastruktur für ein Softwaremodul eines Kunden bereit. Diese beinhaltet die Programmierung einer App als Benutzerschnittstelle für mobile Endgeräte, eines webbasierten Backend als Benutzerschnittstelle zur Administration und den Betrieb der hierfür pro Mandant (Kunde des Kunden) benötigten Server.<br>Die Vorliegende Arbeit beschäftigt sich im Kern mit der Automatisierung der Bereitstellung der benötigten Infrastruktur zum Betrieb des Backend für verschiedene Kunden in Form von Speziell angepassten Linuxservern.  Es wurden hierzu Kriterien erarbeitet, anhand derer verschiedene Methoden des automatisierten Deployment bewertet werden konnten. Die präferierte Methode wurde im Anschluss umgesetzt. <br>
07.09.17;30.01.18;2017;extern;Bachelor;DE;Konzeption und Umsetzung einer Testmethode für PPTX-Dateien;Die SCHEMA Holding GmbH in Nürnberg entwickelt das XML-basierte Redaktionssystem SCHEMA ST4 DocuManager. Es dient zur Erstellung und Verwaltung modularer Inhalte. Zum Funktionsumfang der Software gehört auch, dass Anwender ihre MS PowerPoint Präsentationen im PPTX-Format als einzelne Folien in ST4 importieren können. Hier können diese nach eigenen Vorstellungen wieder zu Präsentationen zusammengeführt und produziert werden. Eine geeignete, automatisierte Methode zum Testen der exportierten Dateien ist aktuell nicht vorhanden. Im Rahmen dieser Bachelorarbeit soll eine geeignete Testmethode für PPTX-Dateien evaluiert und entwickelt werden.
14.09.17;14.02.18;2017;intern;Bachelor;DE;Einsatz von Machine Learning im Bereich Human Resources;Zielsetzung: Personalauswahl und Potenzialbeurteilung gehören zu den wichtigsten Aspekten<br>des Personalmanagements in Unternehmen wie z.B. bei Einstellungen. Besonders größere<br>Unternehmen, die sehr viele Bewerbungen erhalten, setzen auf computerbasierte<br>Bewerberauswahl, um den Bewerbungsprozess effizienter zu gestalten.<br>Im Rahmen dieser Bachelorarbeit wird gezeigt, wie anhand des Machine Learning Verfahrens<br>die Bewerbungsunterlagen elektronisch analysiert werden und eine Vorauswahl getroffen<br>wird. Dabei wird das Stellenanforderungsprofil mit dem Profil, das aus den<br>Bewerbungsunterlagen, insbesondere dem Lebenslauf, hervorgeht mit Hilfe von MatchingAlgorithmen<br>abgeglichen. Schließlich wird die Machine Learning Verfahren den klassischen<br>Methoden gegenübergestellt, um die möglichen Vorteile bzw. Nachteile festzustellen.
14.09.17;15.06.18;2017;extern;Bachelor;DE;Vergleich skalierbarer Speicherlösungen für Binärdaten variabler Größe mit Fokus auf schnelle Zugriffszeiten;"	Das Ziel dieser Arbeit ist der Vergleich von Speicherlösungen, bei dem die Skalierbarkeit eine entscheidende Rolle spielt. Als Hilfselement hierfür wird ein Testframework zum Load-Testing entwickelt. Das Framework dient zur Messung von Zugriffszeiten auf Binärdaten variabler Größe, unter der Verwendung verschiedener Technologien und Parameter. Die Erweiterbarkeit und das damit verbundene Hinzufügen weiterer Technologien soll für die Zukunft gesichert sein.<br>	<br>	Ein selbstgeschriebener BLOB-Generator dient dazu Testdaten zu generieren. Zusätzlich wird ein File Manager zur Verwaltung von BLOBs integriert. Sowohl BLOB Generator, als auch File Manager sind lediglich Hilfstools und haben keinen Bezug zu den Testergebnissen. Für das Testframework kommt als Programmiersprache Java zum Einsatz.<br>	<br>	Das Hauptaugenmerk der zu testenden Umgebungen liegt auf relationalen- und NoSQL-Datenbanken, sowie auf verteilten Dateisystemen. Als Vertreter dienen hierfür PostgreSQL, Cassandra und GlusterFS. Das Ergebnis soll Messwerte für die Zugriffszeiten unter der Bedingung verschiedener Variablen, wie zum Beispiel Dateigröße oder Dateimenge beinhalten. Es wird von der Verwendung von Bilddateien ausgegangen, welche eine maximale Größe von bis zu zwei Megabyte haben können. Dies beschränkt sich lediglich auf die Messungen, die diese Arbeit beinhaltet. Größere Dateien sind für das Framework ebenfalls denkbar."
18.09.17;18.02.18;2017;intern;Bachelor;DE;WebAssembly;WebAssembly ist ein neues Binärformat für portable und effiziente Web-Anwendungen, für das seit kurzem erste Implementierungen in aktuellen Browsern verfügbar sind. Im Rahmen dieser Bachelorarbeit sollen die Architektur und die Implementierung der Wasm-Plattform untersucht werden. Insbesondere soll auf die aktuellen Möglichkeiten sowie Limitierungen der Technologie eingegangen werden. Anhand verschiedener Beispiele soll die erreichbare Performance im Vergleich zu herkömmlichen JavaScript sowie nativen Implementierungen in C++ untersucht werden.
28.09.17;28.02.18;2017;extern;Bachelor;DE;Konzeption und Entwicklung eines generischen Messaging Service mit<br>webbasierter Visualisierung für die Continental Engineering Service GmbH;Es werden Themen in den Gebieten des Messaging und Usability untersucht, welche die Konzipierung und Entwicklung unterstützen werden. Die Anforderungsanalysen werden mit Hilfe der UML Modelliersprache dokumentiert und in der Implementierungsphase umgesetzt. Mit der Konzeption einiger Prototypen werden die Anforderungen an die Weboberfläche genauer spezifiziert. Anhand der Beobachtung von aktuell angewandeten Technologien wird die Umsetzung ausgearbeitet und später durch einfache Funktionale Test geprüft.  
01.10.17;01.06.18;2018;intern;Master;DE;Assoziationsanalyse der eingesetzten Spielemechaniken in prämierten Gesellschaftsspielen;"Gamification bezeichnet das Einbringen von Spielmechaniken in spielfremde Prozesse mit der Absicht, zusammen mit den Mechaniken auch deren motivationale Wirkung zu transferieren. Im Rahmen des EMPAMOS-Forschungsprojektes werden Mechaniken und ihr Kontext abstrakt als Gamification-Muster beschrieben, um ein Expertensystem zur Entwicklung von Gamification-Konzepten zu schaffen.<br>	Ziel dieser Arbeit war es, Methoden der Assoziationsanalyse auf ihre Eignung für die Analyse des Beziehungsnetzwerkes der Muster zu testen. Dazu sollte versucht werden, datengetrieben Hypothesen zur Struktur der Beziehungen der Gamification-Muster aufzustellen. Als Datengrundlage wurden 210 mit dem Preis ""Spiel des Jahres"" prämierte Gesellschaftsspiele auf in ihnen enthaltene Muster untersucht und eine Datenbank mit den Zuordnungen von Mustern zu Spielen erstellt.<br>	Die Algorithmen FP-Growth und MagnumOpus wurden angewandt, um Frequent Itemsets sowie Assoziationsregeln zu finden. Der Vergleich der Ergebnisse ergab, dass MagnumOpus interessantere Ergebnisse liefert. Es wurde gezeigt, wie prototypische Visualisierungen des Netzwerkes erstellt werden können. <br>	Aufgrund des geringen Datenbestands sowie durch Einschränkungen der Datenqualität bedürfen die inhaltlichen Ergebnisse dieser Arbeit einer Nachuntersuchung. Die Eignung der angewandten Methoden zur Gewinnung von nützlichen Assoziationsregeln und Untersuchung der Musterbeziehungen konnte aber bestätigt werden. "
01.10.17;22.01.18;2018;intern;Bachelor;DE;Konzeptionierung und Umsetzung eines Webauftritts für einen Fakultätsjahresbericht mittels WordPress;Die Fakultät Informatik der technischen Hochschule Nürnberg veröffentlicht jedes Jahr im November einen Jahresbericht in Form einer gebundenen Broschüre. Dieser informiert auf rund 60 Seiten über die Projekte und Unternehmungen des vergangenen Jahres und bietet außerdem eine Übersicht der Zahlen und Fakten, wie die Anzahl der eingeschriebenen Studierenden und Dozenten. <br>Eine solche analoge Form der Informationsvermittlung verliert allerdings immer mehr an Nutzen und bringt unangenehme Probleme mit sich. Diese umfassen sowohl hohe Kosten, als auch einen erhöhten Aufwand. <br>Ziel dieser Arbeit ist es ein System zu konzipieren, sowie zu implementieren, welches die Probleme eines veralteten Jahresberichts löst und eine neue Plattform bietet, welche sowohl der vorhandenen Papierversion gerecht wird, als auch neue Möglichkeiten bietet, enthaltene Informationen zu präsentieren. <br><br>Dies geschieht in Form eines Webauftritts, der als Basis das WordPress Blogsystem nutzt, welches für die gewünschten Funktionalitäten entsprechend angepasst wurde. <br>Diese Arbeit wird dabei auf die zu behandelnden Problemstellungen und deren Lösungsversuche eingehen, sowie die bei Konzeption und Implementierung entstandenen Herausforderungen erörtern. Des Weiteren werden Alternativen und Erweiterungen zu den genannten Lösungen aufgezeigt. <br>Das Projekt wurde in enger Zusammenarbeit mit Herrn Wienkop, dem Erstbetreuer, sowie Frau Sörgel, Frau Theelke und Herrn Ulrich durchgeführt.
01.10.17;26.02.18;2018;intern;Bachelor;DE;IT-basiertes Innovationsmanagement zur Steigerung der Prozesseffizienz: Bewertung unterschiedlicher Innovationsverfahren;Das klassische Innovationsmanagement hat eine klare Grenze: Die unternehmensinterne Grenze in den Markt. Damit das Innovationsmanagement ein Unternehmen grundsätzlich bei der Prozesseffizienz unterstützen kann, müssen Unternehmen ihre Innovationsprozesse nach außen hin öffnen. Durch den steigenden globalen Wettbewerb sowie kürzere Produktlebenszyklen und zugleich sinkenden F&E-Budget müssen Unternehmen ihre Prozesse beschleunigen. <br>Im Rahmen dieser Bachelorarbeit war es zu prüfen, inwieweit eine erhöhte Effizienz erreicht werden kann, wenn Unternehmen Innovationsverfahren anwenden. Hierbei wurden die Ansätze Open Innovation, Design Thinking und Crowdsourcing bewertet. Auch der Aspekt der Einbindung von externen Dienstleistern in den Innovationsprozess wurde in die Bewertung integriert. Hierbei hat sich heraus kristallisiert, dass die Einbeziehung externer Dienstleister von Vorteil ist. Crowdsourcing lässt sich optimal als Erweiterung für das Projekt einsetzen. Ein Vorteil von Design Thinking ist die Verknüpfung zwischen den Kundenwünschen und der Machbarkeit, sowie die Wirtschaftlichkeit des Produktes. Bei dem Verfahren Open Innovation stellen der größte Nachteil und gleichzeitig der größte Vorteil die Zusammenarbeit mit externen Partnern dar. <br>Schlussendlich lässt sich sagen, dass Unternehmen die Balance zwischen internen und externen Innovationsimpulsen finden müssen. Bei optimaler Anwendung können die Verfahren ein fester Bestandteil des Innovationsmanagements werden.
01.10.17;28.02.18;2018;extern;Bachelor;DE;Entwurf einer effizienten Kategorisierung von Transaktionsdaten zur Schaffung eines Mehrwerts für Bankkunden;Durch die Einfu?hrung der Payment Services Directive 2 bricht das Monopol der Banken beim Zugriff auf die Kontodaten ihrer Kunden. Gerade Drittanbieter profitieren davon und bieten Bankkunden Anwendung zur zentralen Verwaltung unterschiedlicher Konten an. Auch die Kategorisierung der Transaktionen ist dabei ein wichtiger Bestandteil, um Ausgaben u?bersichtlicher darzustellen.<br>In dieser Arbeit wird untersucht, wie mit Hilfe etablierter Verfahren aus den Gebieten Information Retrieval und Textanalyse eine effiziente Kategorisierung von Banktransaktionen umgesetzt werden kann. Dazu werden sowohl Mittel der Computerlinguistik, als auch des Maschinellen Lernens (Machine Learning) betrachtet. Ziel ist es, eine Kategorisierung von Banktransaktionen zu entwerfen und in einem Prototypen umzusetzen.<br>Nach Erla?uterung der Funktionsweise unterschiedlicher Textklassifikationsverfahren folgt eine Evaluation der Leistungsfa?higkeit. Gleichzeitig wird eine Vorverarbeitung der Daten und Optimierung auf Banktransaktionen durchgefu?hrt. Dabei wird gezeigt, welche Parametrisierung fu?r eine Kategorisierung von Banktransaktionen optimale Ergebnisse liefert. Auf Basis dieser Erkenntnisse wird ein Modell fu?r die spa?tere Implementierung gebildet.<br>Die anschließende Umsetzung geschieht in Form eines Prototypen, welcher das optimierte Modell nutzt. Dieser bildet ein eigensta?ndiges Kategorisierungssystem und es wird gezeigt, wie dieser in spa?teren Anwendung zur Finanzplanung eingebunden werden kann.
01.10.17;01.03.18;2018;extern;Bachelor;DE;Automatische Klassifikation digitalisierter Dokumente durch Verwendung eines neuronalen Netzes ;Das Ziel der vorliegenden Bachelorarbeit ist es, für die Firma mediendesign AG<br>eine prototypische Anwendung zu entwickeln, um automatisiert digitale Dokumente<br>zu sortieren. Wurden in der Vergangenheit oftmals Methoden der Textanalyse bei<br>der Klassifikation von Dokumenten eingesetzt, soll in dieser Arbeit dagegen die<br>Machbarkeit auf Basis eines künstlichen neuronalen Netzes untersucht werden. Um ein<br>bestmögliches Ergebnis zu erzielen, werden zwei unterschiedliche Lösungsstrategien<br>verfolgt. Für den ersten Ansatz wird auf Transferlearning zurückgegriffen, für den<br>zweiten werden eigene Modelle erstellt.<br>Nachdem an das Problem herangeführt wurde, werden die wesentlichen Aspekte<br>künstliche neuronale Netze und speziell Convolutional Neural Networks im Detail<br>erläutert.<br>Die Vorgehensweise bei der Implementierung der Anwendung in der Programmierspra-<br>che Python, und dabei insbesondere die Erstellung der Klassifikatoren mit Tensorflow<br>und Keras sowie deren Evaluation, bilden den Schwerpunkt dieser Arbeit. Dabei wird<br>gezeigt, dass durch iterative Optimierung der Klassifikatoren ein vergleichbar gutes<br>Ergebnis mit beiden Lösungsansätzen erzielt wird. Im Anschluss an die Evaluation<br>wird eine Einschätzung zu den sehr guten Ergebnissen beider Lösungsstrategien sowie<br>eine Empfehlung für den produktiven Einsatz gegeben.
01.10.17;01.02.18;2018;extern;Bachelor;DE;Entwurf eines Berichtstools mit korrigierbarer Datengrundlage auf Basis von SAP BOE und SAP PI.<br>;Das neu eingeführte Business Intelligence Tool SAP Business Objects Enterprise der Firma Grenzebach Maschinenbau GmbH bietet keine Möglichkeit, Berichte so zu erstellen, dass Korrekturen oder Aktualisierungen der zugrundeliegenden Datenbasis durchgeführt werden können. <br>Im Rahmen dieser Arbeit sollen mögliche Konzepte erstellt und anhand eines prototypischen Berichtstools erstellt und evaluiert werden.<br>Dieses soll soweit möglich mit dem in BOE integrierten Berichtstools Web Intelligence vergleichbare Performance und Bedienkomfort erreichen. 
01.10.17;01.03.18;2018;extern;Bachelor;DE;Werkzeuggestützte, automatisierte Auswertung von Usability-Tests;Usability-Tests stellen eine zeit- und kostenintensive Methode dar, um Nutzungsprobleme,<br>welche bei der Bedienung eines interaktiven Systems auftreten, aufzudecken. Ziel der vorliegenden <br>Arbeit war es deshalb zu untersuchen, ob eine Reduzierung des manuellen Aufwands, welcher im <br>Rahmen der Auswertung betrieben werden muss, durch Automatisierung möglich ist. Im Zuge dessen<br>wurde basierend auf den vorangegangenen Recherchen ein Evaluations-Tool konzipiert und prototypisch umgesetzt.<br>Da für die systematische Auswertung von Daten bereits die Erfassung dieser Daten strukturiert und gezielt <br>erfolgen sollte, soll das Tool ein Beobachtungsprotokoll im Rahmen der Test-Durchführung anbieten, <br>welches eine problemorientierte Dateneingabe ermöglichen soll. Um die Auswertungszeit zu <br>verkürzen, bietet das Tool die Möglichkeit die erhobenen Daten in eine tabellarische Struktur <br>zu überführen, sodass diese für die anschließende Analyse bereits übersichtlich aufbereitet <br>vorliegen und im günstigsten Fall nur noch gesichtet und interpretiert werden müssen. <br>Ob der manuelle Aufwand unter Nutzung des Tools im Vergleich zur Auswertung ohne <br>Tool-Unterstützung geringer ist, muss im Rahmen eines Tests noch geprüft werden.
01.10.17;01.03.18;2018;extern;Bachelor;DE;Konzeption und Implementierung eines Frameworks zur Entwicklung von mobilen Anwendungen für IOS und Android auf Basis von Xamarin.Forms.;Im Rahmen dieser Bachelorarbeit soll ein Framework für die Entwicklung von iOS- und<br>Android-Apps konzipiert und implementiert werden, um eine Basis für zukünftige AppProjekte<br>der Firma infoteam Software AG zu bilden. Dieses Framework baut selbst auf<br>Xamarin.Forms auf und wird bestehende Funktionen erweitern oder überschreiben. Ein<br>Schwerpunkt liegt dabei auf einer benutzerfreundlichen Konfiguration der Navigation<br>zwischen Oberflächen, aber auch auf der Unterstützung der eigentlichen Entwicklung von<br>Oberflächen. Zusätzlich soll das Framework den Anwender zum Umsetzen des MVVM-Patterns<br>motivieren, um bei der zu erstellenden App eine saubere Trennung zwischen<br>Oberflächen- und Geschäftslogik zu gewährleisten.
01.10.17;01.03.18;2018;extern;Bachelor;DE;"Fotorealistische Visualisierung von räumlich variierenden Materialien durch eine Annäherung der BRDF-Parameter auf Basis des NVIDIA-Tools ""Photo To Material: 2shot""";Diese Arbeit befasst sich mit der fotorealistischen Visualisierung von Materialien. Hierfür werden Herangehensweisen zur Ermittlung einer allgemeingültigen Vorschrift für das Reflexionsverhalten verschiedener Oberflächen vorgestellt. Der Schwerpunkt liegt in der Validierung eines automatisierten Materialmodellierungsprozesses, der auf Basis zwei unterschiedlich belichteter Bilder die BRDF-Parameter generiert. Hierfür wurden verschiedene Aufnahmesettings mittels eines iPhone- und einer Spiegelreflexkamera getestet, um den Vorgang zusätzlich zu optimieren. Die Qualität und entsprechende Anwendbarkeit der Resultate wird an zahlreichen Beispielen illustriert.
01.10.17;01.03.18;2018;extern;Bachelor;DE;Eine Webanwendung zur Erstellung neuer Colorways (Farbvarianten) von Schuhen mit dem Framework Three.js und dem WebGL-Interface;Diese Bachelorarbeit adressiert die Optimierung des Prozesses der Erstellung neuer Colorways (Farbgebungen) von Schuhen in der Firma adidas. Es wird eine Webanwendung programmiert, die über einen Deferred-Shading-Ansatz den beleuchteten Schuh anzeigt. Die Schattierung erfolgt mit einem Physically Based Rendering. Die dabei verwendeten Technologien sind das JavaScript-Framework Three.js und die Schnittstelle WebGL.
01.10.17;01.03.18;2018;intern;Bachelor;DE;Analyse der Ansätze von Reflection in C++ und Entwicklung einer eigenen Implementierung;C++ standardisiert keine Reflection, sondern nur eine einfache Runtime Type Information (RTTI). Für Reflection gibt es jedoch einige Anwendungsgebiete, unter anderem Serialisierung von Datenstrukturen, Herstellen von Interoperabilität zwischen Programmiersprachen und Unterstützung von GUI-Programmierung.<br><br>Im Rahmen der Bachelorarbeit soll daher untersucht werden, welche Mächtigkeit eine standardkonforme Implementierung der RTTI besitzt. Weiter sollen bestehende, umfassendere Implementierungen von Reflection analysiert und verglichen werden. Zudem soll eine eigene Implementierung im Hinblick auf die Serialisierung von Datenstrukturen entwickelt werden.
02.10.17;31.01.18;2018;extern;Bachelor;EN;Automatic Extraction of modernization features in German real estate exposés ;Relation Extraction is an important subtask of Information Extraction which describes a relation between entities in a given document. There are two main groups of Information Extraction which is a field of Natural Language Processing (NLP). The traditional knowledge engineering approach seeks to exploit structured patterns. These systems mostly require various resources,  experiences in the domain of the texts and time of humans who are constructing them. The other approach utilizes statistical methods to extract features by the trainable systems. Currently the field of Information Extraction, especially methods for Relation and Named Entity Extraction are widely researched with varied Neural Networks. Neural Networks belong to the area of Deep Learning which is a subfield of Artificial Intelligence (AI). The neural networks is a programming paradigm inspired by the biological brain and tries to simulate the brain in learning. Neural Networks are applied in many areas of image recognition, speech recognition and natural language processing. This work deals with German real estate exposé texts with the task of extracting modernization features by comparing two approaches. The traditional Knowledge Engineering is represented through the class Rule Based. And the Deep Learning method is shown through the class Convolutional Neural Network. The responsive scores of each system will be compared each other.
02.10.17;02.03.18;2018;extern;Bachelor;DE;Erstellung einer Netzwerkschnittstelle zu einem Model Checker für Cyberphysikalische Systeme;Die Siemens AG evaluiert aktuell den Aufbau eines Model Checkers fu?r Cyberphysikalische Systeme auf Basis von symbolischen SMT-Lo?sern. Die Bachelorarbeit behandelt die Frage, wie ein solcher Model-Checker in einer heterogenen IT-Umgebung sinnvoll mit einer Netzwerkschnittstelle ausgestattet werden kann. Hierbei wurden die Anforderungen zur Ausgestaltung einer Netzwerkschnittstelle mithilfe eines modellbasierten Werkzeugs (Capella) und einer architekturzentrierten Vorgehensweise (Arcadia) erhoben. Die aus Arcadia generierten Diagramme und Modelle dienten als Diskussionsgrundlagen und Entscheidungshilfe für eine konkrete API-Technologien. Zur Diskussion standen hierbei SOAP, REST und RPC-mäßige Schnittstellen wie z.B. XML- oder JSON-RPC. <br>Anschließend wurde die Implementierung umgesetzt in Form einer zweistufigen Kommunikation: Zum einen kommuniziert der Client mit einem in nodeJS implementieren Webserver und zum anderen kommuniziert der Webserver mit dem in OCaml implementierten Model Checker. Also Protokolle kamen hier HTTP und TCP zum Einsatz, wobei jede Kommunikationsstufe der JSON-RPC 2.0 Spezifikation folgt. 
02.10.17;26.02.18;2018;intern;Bachelor;DE;Digitale Dokumentenverwaltung im Bürobereich durch den Einsatz von IT-Systemen;Digitale Dokumentenverwaltung im Bürobereich durch den Einsatz von IT-Systemen<br><br>Im Rahmen meiner Bachelorarbeit, wird die Realisierung eines papierlosen Büros betrachtet.  Diese richtet sich an alle Personen, die Verwaltungsprozesse gestalten. <br>Im Rahmen des papierlosen Büros werden die Dokumente digital verwaltet und auf Ausdrucke wird verzichtet. Vorteile sind, dass Kosten gesenkt werden, die Prozesse beschleunigt werden, keine Archivräume benötigt werden, die manuellen Arbeitsschritte reduziert werden und die Wettbewerbsfähigkeit gesteigert wird.<br>Zunächst wurde ein Marktüberblick über derzeit am Markt vorhandene DMS und CRM Systeme aufgezeigt. Anschließend wurden drei DMS Systeme ELOoffice, TagSpaces und CompuDMS testinstalliert und bewertet. CompuDMS erzielte die höchste Punktzahl im Scoring Modell. Des Weiteren wurden drei CRM Systeme Julitec, 1CRM und SuccessControl CRM testinstalliert und bewertet, hierbei erzielte SuccessControl CRM die höchste Punktzahl. <br>Es wurde ebenfalls auf den Einsatz eines digitalen Notizbuches eingegangen. Hierzu wurden OneNote und Evernote getestet. Hierbei kann auf Notizzettel verzichtet werden und die Notizen werden elektronisch verwaltet. <br>Insgesamt lässt sich feststellen, dass durch die digitale Dokumentenverwaltung Kosten für Ausdrucke, Kopien und Aufbewahrung vermieden werden. Allerdings fallen Kosten für die Systeme und dessen Betrieb an.  <br>Derzeit am Markt vorhandene DMS- und CRM Systeme ermöglichen eine digitale Dokumentenverwaltung
04.10.17;04.03.18;2018;extern;Bachelor;DE;Mehrmaschinentests und deren Implementierung in openQA am Beispiel der Implementierung einer systemd-networkd Testsuite;Bei openQA handelt es sich um ein System zum Testen von Betriebssysteminstallationen.<br>Das zu testende Betriebssystem wird in einer virtuellen Maschine unter<br>Simulation von Benutzereingaben installiert.<br>In der vorliegenden Arbeit wurden verschiedene Ansätze untersucht,<br>um in openQA Mehrmaschinentests zu realisieren.<br>So können auch Programme und Betriebssystemfunktionen getestet werden,<br>die ein Cluster aus mehreren Maschinen erfordern.<br><br>Untersucht wurden folgende Ansätze:<br>- openQA Lock API: interaktion der Testmaschinen mehrerer parallel laufender openQA Tests<br>- Verschachtelte Virtualisierung: starten mehrerer VMs innerhalb der Testmaschine<br>- Docker-Container: start mehrerer Container in der Testmaschine<br>- Nspawn-Container: start mehrerer Container in der Testmaschine<br><br>Die Ansätze wurden nach Wiederverwendbarkeit, Konfigurationsaufwand,<br>Ressourcenverbrauch und Performance, Nachvollziehbarkeit, Portierbarkeit vorhandener<br>Testsuites und Automatisierbarkeit verglichen.<br>Die verschachtelte Virtualisierung schnitt zusammen mit Nspawn-Containern am besten ab. <br>Zudem wurde festgestellt, dass auch Mischformen aus Containern und VMs möglich sind.<br><br>Unter Einsatz von Nspawn-Containern wurde anschließend eine Testsuite für den <br>Systemd-Networkd-Netzwerkstack implementiert.
05.10.17;12.03.18;2018;intern;Bachelor;DE;Entwicklung eines Serious Game zur Sensibilisierung von Erstsemesterstudenten für die Risiken eines Studienabbruchs in einem technischen Studiengang.;Zielsetzung der Bachelorarbeit ist es, ein Serious Game in Form eines browserbasierten Text Adventures zu entwickeln. Mit diesem sollen Studenten angesprochen werden, die sich im ersten Semester ihres Studiums an der Fakultät Informatik der Technischen Hochschule Nürnberg befinden. Indem sie interaktiv ein virtuelles Studium durchspielen, sollen die Studenten für die typischen Ursachen und Risiken eines Studienabbruches sensibilisiert werden. Die Gründe für einen Studienabbruch sind vielfältig und sollen in dieser Bachelorarbeit näher erläutert und gewichtet werden. Viele der Ursachen sind jedoch abwendbar, wenn sich die Studierenden zu Beginn ihres Studiums intensiv mit den klassischen Gründen und Risiken eines Studienabbruchs beschäftigt hätten. Deshalb soll in Zukunft ein interaktives Spiel namens OHMSim eingesetzt werden, um Studierende über die Risiken und Hürden in einem technischen Studiengang aufzuklären<br>Um die Wirkung eines solchen Serious Game auf Studenten zu ermitteln sowie den Erfolg zu messen, sollen mehrere Probanden im Anschluss an das interaktive Spiel einen UEQ ? Fragebogen zur ihrer User-Experience ausfüllen.<br>Die Bachelorarbeit ist sowohl für Studierende im Bereich Wirtschaftsinformatik als auch für Angehörige im Bereich Medienpädagogik interessant.<br>
05.10.17;05.03.18;2018;extern;Bachelor;DE;Evaluierung der Möglichkeiten und Herausforderungen des Einsatzes von E-Procurement in der Baubranche;Das Ziel der Arbeit war es, Möglichkeiten und Herausforderungen beim Einsatz von E-Procurement in der Baubranche aufzuzeigen. Dafür wurde im ersten Schritt E-Procurement auf Basis einer Literaturanalyse theoretisch betrachtet, um ein grundlegendes Verständnis dieses Themenfelds aufzubauen. Hierbei wurde festgestellt, dass die Einführung von E-Procurement zunächst eine Analyse der elektronisch zu unterstützenden Beschaffungsprozesse voraussetzt. Daher wurde das bisher wenig erforschte Gebiet der Baubeschaffung untersucht und literaturbasierte Annahmen zum Beschaffungsprozess in der Baubranche mit einem Experteninterview überprüft, um so spezifische Merkmale der Baubeschaffung herauszuarbeiten. Dies war die Grundlage für eine anschließende SWOT-Analyse, in der die Perspektive einer fiktiven Baufirma eingenommen wurde und die Rahmenbedingungen für E-Procurement überprüft wurden. Unternehmensbezogene Stärken und Schwächen, wie zum Beispiel das Vorhalten lokaler Artikelstammdaten, aber auch marktseitige Chancen und Risiken, wie die Verwendung von branchenüblichen Datenaustauschstandards, sind dabei aufgezeigt worden. Die Resultate daraus wurden von einem Einkäufer aus der Baubranche evaluiert und im Wesentlichen als praxisrelevant bestätigt. Es konnte aufgezeigt werden, dass Teilbereiche des Einkaufs in Bauunternehmen elektronisch unterstützt werden können. Ein umfassender Einsatz von E-Procurement wird jedoch auch aufgrund der derzeitigen Marktsituation erschwert.
05.10.17;01.06.18;2018;extern;Master;DE;Entwicklung eines Konzepts zur digitalen Transformation bei der IHK Nürnberg für Mittelfranken;Ziel der vorliegenden Arbeit ist es, ein Konzept zur digitalen Transformation der IHK Nürnberg (für Mittelfranken) zu entwickeln. Dieses Konzept soll es ermöglichen, die IHK Nürnberg ganzheitlich und zielgerichtet in eine digital transformierte Organisation zu wandeln. Um dieses Ziel zu erreichen, wird zunächst der theoretische Rahmen erarbeitet. Anschließend wird dieser aufgegriffen und zur Analyse der ermittelten Transformationsdimensionen angewandt. Zunächst erfolgt die Analyse der produktabhängigen Dimensionen der Kundenprozesse und internen Prozesse anhand eines Customer-Journey-Mappingverfahrens. Anschließend wird die produktunabhängige Dimension Organisation mit einer SWOT-Analyse untersucht. Im Anschluss werden die Erkenntnisse aus der Analysephase zusammengefasst und als Maßnahmen zu einer digitalen Landkarte zusammengeführt. Diese Landkarte dient als Konzept zur digitalen Transformation der IHK Nürnberg. Insgesamt kann festgehalten werden, dass das Konzept erfolgreich zur digitalen Transformation eingesetzt werden kann, hierbei jedoch stets die Entwicklungen der VUCA-Umwelt zu berücksichtigen sind.<br>
09.10.17;28.02.18;2018;extern;Bachelor;DE;Analyse, Konzeption und prototypische Realisierung eines Build-Verfahrens mit Docker;In der SDV IT werden bisher Realease-Builds auf einem zentralen Release-<br>Server des Teams INPU gebaut. Aufgrund der verschiedenen Anforderungen<br>der Anwendungen müssen an diesem direkt Änderungen vorgenommen<br>werden. Diese Änderungen sollen durch die Integration von Docker in den<br>Release-Prozess vermieden werden. Die benötigten Umgebungen für die Anwendungen<br>sollen mittels Docker-Images abgebildet werden.<br>Die Arbeit hat drei Ziele. Zum einen soll die nötige Struktur für den Einsatz<br>von Docker zu erarbeiten werden. Docker in den Release-Prozess einer Anwendung<br>prototypisch zu integrieren werden, und die Vor- und Nachteile der<br>Lösung mit Docker zu dem bisherigen Verfahren sind herauszuarbeiten.
09.10.17;09.03.18;2018;extern;Bachelor;DE;Analyse, Konzeption und prototypische Umsetzung des DATEV eG Intranets (Publishing) für mobile Endgeräte;"Das Intranet der DATEV eG ist hauptsächlich über den Desktop-Arbeitsplatz erreichbar. Der Zugriff auf das Intranet über mobile Endgeräte ist nur eingeschränkt möglich. Hierbei treten Probleme der Benutzbarkeit auf.<br>Das Ziel der Arbeit ist es, eine passende Benutzeroberfläche für mobile Endgeräte, mittels Prototyp, bereitzustellen. Im Hinblick auf den Prototypen muss herausgefunden werden, wel-che funktionalen und nicht-funktionalen Anforderungen die Anwender für ein mobiles Intranet fordern. Die Anforderungen der Anwender werden mit Erhebungstechniken, wie z.B. mittels Fragebogen, ermittelt. <br>Die Konzeption der Benutzeroberfläche wird mit der Webdesign-Strategie ""Responsive De-sign"" umgesetzt. Im Designkonzept werden die von der DATEV eG zur Verfügung gestellten DATEV-Farben verwendet.<br>"
09.10.17;09.03.18;2018;extern;Bachelor;DE;Vergleich der Empfehlungsqualität von Neuronalen Netzen mit dem bestehenden Recommender-Algorithmus eines großen deutschen Immobilienportals;Ziel der Arbeit ist der Vergleich der Empfehlungsqualität eines bestehenden Recommender-Algorithmus und eines Ansatzes der auf Neuronalen Netzen beruht. <br>Im Rahmen einer Simulationsstudie sollen die Metriken AUC und Recall für einen bereitgestellten Trainings-/Testdatensatz bestimmt werden. Dabei soll auf eine in R implementierte Simulationsstudie, ein <br>geeignetes Framework für Neuronale Netze und den in R implementierten Algorithmus für das bisherige bestehende Recommender-System zurückgegriffen werden. Um valide Testmetriken zu erzeugen, ist insbesondere auf die Vergleichbarkeit der Simulationsstudie auf Basis der Neuronalen Netze und der Simulationsstudie auf Basis des bestehenden Algorithmus zu achten.<br>Ergebnis der Arbeit ist die Bewertung und Interpretation der Metriken der Simulationsstudie. Im Rahmen eines Ausblickes werden Handlungsempfehlungen für die Sicherstellung der Echtzeitfähigkeit einer Lösung, die auf Neuronalen Netzen beruht, gegeben.
09.10.17;18.01.18;2018;extern;Bachelor;DE;Untersuchung und Evaluierung der Einsatzgebiete von räumlichen Daten auf einem Immobilienportal;Im Rahmen dieser Bachelorarbeit werden die Einsatzmöglichkeiten von räumlichen Daten und Karten auf einem Immobilienportal aufgezeigt. Hierzu werden im Rahmen der Wettbewerbsanalyse die Produkte von europäischen und außereuropäischen Mitbewerbern ausgewertet. <br>Ein firmeninternes Brainstorming nach der kreativen Methode 635 wird genutzt, um zusätzliche neue Einsatzgebiete zu identifizieren und neue Produktideen für die Verwendung von Geodaten zu generieren. Mit der Anwendung verschiedener Methoden der Ideenbewertung und Einbeziehung verfügbarer Informationen über Zielgruppen und deren Verhalten, werden diejenigen Produktideen identifiziert, deren Geschäftswert und Kundennutzen am höchsten ist. Dabei werden die Produktalternativen zuerst mit der Checkliste-Methode ausgewertet. Die verbleibenden Ideen werden mit der Portfolio- und Nutzwertanalyse bewertet. Als Ergebnis wird die erfolgsversprechende Produktidee ausgewählt.<br>Anschließend wird diese Produktidee genauer beschrieben und dazu ein Mock-up erstellt.
09.10.17;23.03.18;2018;extern;Bachelor;DE;Identifikation von Verbesserungspotenzialen in der Planung und Steuerung eines skalierten Scrum-Ansatzes im IT-Systemhaus der Bundesagentur für Arbeit;"Die Abteilung SEP51 des IT-Systemhauses der Bundesagentur für Arbeit hat sich vor rund fünf Jahren dafür entschieden, auf Scrum als Rahmenwerk für die Softwareentwicklung umzusteigen. Aufgrund der Größe und der Komplexität der Anwendung, die durch die Abteilung entwickelt wird, sind viele Scrum-Teams nötig, weshalb eine Skalierung von Scrum zum Einsatz kommt. Über die Jahre hat die Abteilung SEP51 unter dem Namen ""Scrum@VAM"" ihren eigenen skalierten Scrum-Ansatz entwickelt. Im Rahmen der Bachelorarbeit wurden die Probleme in der Planung und Steuerung dieses Ansatzes anhand von Interviews mit den verschiedenen Rollen analysiert. Zur Lösungsfindung wurden die skalierten Scrum-Frameworks Nexus, Large-Scale Scrum und Scaled Agile Framework untersucht. Die Hauptprobleme, welche sich herauskristallisiert haben, sind die fehlende objektive Priorisierung der Anforderungen, der starre Release Container, welcher die zu schaffenden Features fest definiert, sowie der fehlende Feedbackzyklus. Die verschiedenen skalierten Scrum-Frameworks boten unter anderem mit einem priorisierten Product Backlog, kurzen Releasezyklen, einem Sprint-Review und einer übergreifenden Planung durch die Teams viele Möglichkeiten der Verbesserung, jedoch können nur wenige innerhalb der Abteilung, ohne die Mitwirkung von außen, umgesetzt werden. Das Problem hierbei liegt in dem nicht agilen Denken des Fachbereichs und der Bundesagentur für Arbeit allgemein."
09.10.17;26.01.18;2018;extern;Bachelor;DE;Entwicklung einer App zur Anzeige von Verlegerstatistiken;Im Rahmen dieser Bachelorarbeit wird die Entwicklung einer App zur Anzeige von Verlegerstatistiken,<br>über die Phasen Analyse, Konzeption bzw. Entwurf und Implementierung<br>hinweg, durchgeführt. Die App soll den Verlegern eine unkomplizierte Einsicht in ihre Statistiken<br>bieten. Darunter werden im Kontext dieser Arbeit beispielsweise Klicks, Views,<br>Leads oder Sales verstanden. Derzeit ist die Anzeige lediglich über eine stark veraltete,<br>fehlerhafte und nicht performante Webanwendung möglich. Die Verleger wünschen<br>sich eine Möglichkeit, ihre Statistiken auf ihrem Smartphone einsehen zu können. Das<br>Ziel dieser Arbeit ist die Konzeption und Entwicklung einer App, die den Verleger beim<br>Einsehen seiner Daten unterstützt. Dafür sollen intuitive und einheitliche Darstellungsmöglichkeiten<br>verwendet werden. Nach einer Einführung in die technischen Grundlagen<br>zum Verständnis der Arbeit folgt die Erstellung eines Anforderungskataloges sowie die<br>Ermittlung eines geeigneten Entwicklungsansatzes, gefolgt von der Wahl eines nützlichen<br>Frameworks. Anschließend erfolgt die Konzeption der App. Diese ist in die Phasen<br>Grobentwurf und Feinentwurf unterteilt. Nach abgeschlossener Entwurfsphase wird die<br>Implementierung der App erläutert. Letztlich erfolgt ein Benutzer-Akzeptanztest und<br>damit einhergehend eine Evaluation als Mixed-Methods-Ansatz, deren Motiv es ist, die<br>Stärken und Schwächen des App-Prototypen aufzuzeigen. Abgerundet wird die Arbeit<br>durch einen Anforderungsabgleich.
10.10.17;11.06.18;2018;intern;Master;DE;Haptic Exploration of Virtual Objects;In den letzten Jahren wurde die Darstellung einer virtuellen Realität, speziell für den Videospielemarkt, stets weiterentwickelt und ist so auf großes Interesse gestoßen. Neben dem hohen Spaßfaktor hat diese Technologie das Potenzial einen barrierefreien Zugang zu Informationen für im blind und taube Menschen zu ermöglichen. Diese Arbeit zeigt auf, welche Ansätze und Möglichkeiten es bereits gibt, virtuelle Objekte haptisch zu erkunden und wie diese eingesetzt werden. Darüber hinaus wird eine Anwendung entwickelt, die durch Verwendung von vibrotaktilen Aktuatoren sowie Audiosignalen, das Ertasten von virtuellen Objekten ermöglicht. Die Anwendbarkeit der Technologie dieser Arbeit wird im Rahmen einer Benutzerstudie evaluiert.
11.10.17;09.02.18;2018;extern;Bachelor;DE;Konzeption und prototypische Realisierung eines Systems zur automatisierten Durchführung und Auswertung von Lasttests ;Das Unternehmen führt Lasttests für angebotene Anwendungen durch, um zum Beispiel einen erhöhten Ressourcenverbrauch festzustellen. Um Änderungen an bestehenden Anwendungen vor dem Übergang in die Produktion zu testen, sollten Lasttests regelmäßig durchgeführt werden. Auch soll die Auswertung der Ergebnisse automatisch erfolgen und ein Report mit definierten Kennzahlen nach Abschluss der<br>Lasttests bereitgestellt werden.<br>Die Arbeit soll passende Werkzeuge auf deren Eignung einer Automatisierung prüfen. Hierbei gilt es ein Konzept zu erarbeiten, welches prototypisch an einer Anwendung umgesetzt wird. Das Vorgehen beinhaltet die Abstimmung relevanter Kennzahlen, sowie die Installation und Administration des Werkzeuges. <br>Nach Abschluss der Arbeit sollen Lasttests regelmäßig und automatisiert ablaufen und anschließend Reports mit definierten Kennzahlen veröffentlicht werden.
11.10.17;11.03.18;2018;extern;Bachelor;DE;Konzeption sowie prototypische Realisierung der Einbindung eines Schedulingsystems in eine PaaS-Umgebung;Die vorliegende Bachelorarbeit betrachtet verschiedene Arten der Anbindung und Integration eines Job-Schedulers in eine Plattform as a Service Umgebung in der DATEV eG.<br><br>Ziel war es, verschiedene Umsetzungsalternativen für den Betrieb eines Schedulers für die Batchverarbeitung als Soll-Konzept zu erarbeiten, daraus die vorteilhafteste Lösung abzuleiten und prototypisch umzusetzen. Hierzu wurden zunächst drei Umsetzungsalternativen erarbeitet und anschließend aufgezeigt. Dabei werden die Vor- und Nachteile beschrieben und Allein-stellungsmerkmale der jeweiligen Alternative hervorgehoben. Augenmerkliche Unterschiede fanden sich zwischen den Alternativen bei der Auswahl der Laufzeitplattform für den Betrieb der Software.<br><br>Die verschiedenen Umsetzungsalternativen wurden hinsichtlich ausgewählter Kriterien quali-tativ mittels einer Nutzwertanalyse, welche mit Experten aus dem Entwicklerteam des Schedulers durchgeführt wurde, verglichen. Die Nutzwertanalyse ergab, dass die dritte Um-setzungsalternative umzusetzen ist. Bei dieser Alternative wurde die Auswahl der Laufzeit-plattform abhängig von der Stage ausgewählt, da auf Teststages andere Kriterien im Vorder-grund stehen als auf produktiven Stages. <br><br>Mit der Wahl der Plattform steht die Art des Betriebs des Schedulers eng zusammen. So wird auf produktiven Stages eine zentrale Instanz des Schedulers auf dem IBM Mainframe bereit-gestellt und von einem Team verwaltet. Auf Teststages hingegen ist es möglich, sich in der Plattform as a
12.10.17;06.02.18;2018;extern;Bachelor;DE;Analyse und Einführung eines Versionskontrollsystems zur Verwaltung von SSIS-Paketen für das Data Warehouse Team der Immowelt AG ;"Ziel dieser Arbeit ist es, den Änderungsprozess der SSIS-Pakete zu optimieren. Aus diesem Grund wurden zunächst ausgewählte Versionsverwaltungssysteme miteinander anhand einer Nutzerwertanalyse verglichen und dadurch das passende System für den beschriebenen Anwendungszweck evaluiert. Um dabei ein repräsentatives Ergebnis zu erhalten, ist die Durchführung einer ausführlichen Literaturrecherche und eines internen Meetings von Bedeutung gewesen. Die daraus gewonnenen Erkenntnisse führten zu einem Kriterienkatalog, anhand dessen jedes Kriterium für jedes der ausgewählten Systeme mit einer entsprechenden Punktzahl zu bewerten war. Das Ergebnis hat gezeigt, dass die Systeme in der Regel nahe beieinanderliegen. Letztendlich fiel die Auswahl für die Implementierung auf die Versionskontrolle ""Team Foundation Server"". Bei der Implementierung waren zuerst einmal die Grundlagen für ein erfolgreiches lauffähiges System zu schaffen und in Zusammenarbeit mit dem Projektteam einige Entscheidungen, wie die Versionskontrolle zukünftig zu nutzen sein soll, zu treffen. Nachdem schließlich alle Erwägungen in Betracht gezogen waren, erfolgte das Hinzufügen der SSIS-Pakete und der Strukturierung des Teamprojektes. Um das ganze Thema abzurunden, wurden abschließend praxisnahe Testszenarien erläutert und anschließend durchgeführt. Da alle Prüfungen des Systems erfolgreich verlaufen sind, steht einer zukünftigen Teamarbeit mit der Versionskontrolle ""Team Foundation Server"" nichts mehr im Wege."
12.10.17;12.03.18;2018;extern;Bachelor;DE;Bildklassifikation auf Basis von Firmenlogos zur Einordnung von Dokumenten mit DATEV.;Diese Bachelorarbeit adressiert die Einordnung von Dokumenten mit Methoden des Machine Learnings auf Basis von Firmenlogos. Es soll untersucht werden, ob eine Klassifikation von Dokumenten anhand ihrer Logos möglich ist. Ziel dieser Arbeit ist daher die Konzeption, Realisierung und Evaluierung eines überwachten Klassifikationssystems. Es werden aktuelle Verfahren zur Detektion und Klassifikation von Objekten in Bilddaten untersucht. Die verwendeten Technologien sind die Tensorflow Object Detection API und ein Faster R-CNN. Weiterhin wird die Erstellung und Verwendung von synthetischen Trainingsdaten untersucht. <br><br>Die Ergebnisse zeigen, dass die Klassifikation von Dokumenten durch ihre Firmenlogos möglich ist. Allerdings fallen die Evaluierungs-Ergebnisse hinter den Anforderungen zurück. Dies kann darauf zurückgeführt werden, dass sich die verwendeten synthetischen Trainingsdaten zu stark von der Gesamtheit der Daten unterscheiden.
12.10.17;09.03.18;2018;extern;Bachelor;DE;Integration der Honorarordnung für Architekten und Ingenieure in das ERP-System Microsoft Dynamics NAV;Das ERP-System Microsoft Dynamics NAV stellt eine Basis für die Abbildung aller relevanten Geschäftsprozesse eines Unternehmens dar. Jedoch gibt es auch einige Branchen mit speziellen Anforderungen, die darin nicht abgebildet sind.<br><br>Dazu zählen Architekten und Ingenieure, für welche in Deutschland eine gesetzliche Verordnung existiert, die sogenannte Honorarordnung für Architekten und Ingenieure.<br>Diese definiert zu erbringende Leistungen sowie die Höhe der dafür anfallenden Honorare und die Form, in der diese Honorare abzurechnen sind.<br><br>Da die Inhalte der Honorarordnung damit von erheblicher Bedeutung für Architekten und Ingenieure sind, wird für Microsoft Dynamics NAV eine Erweiterung benötigt, um diese Vorgaben abzudecken. Das Ziel dieser Arbeit besteht darin, eine solche Erweiterung zu entwickeln. Dafür wird das angewandte Vorgehen beschrieben, sowie die so erzielten Ergebnisse. <br><br>Nach einer Schilderung der Ausgangssituation bildet hierbei eine Beschreibung der durchgeführten Anforderungsanalyse den Anfang, wobei auf das Vorgehen, die herangezogenen Quellen und die so ermittelten Anforderungen eingegangen wird. Aus den Anforderungen wird anschließend das Soll-Konzept der Erweiterung erarbeitet. Abschließend wird die Kodierung des ermittelten Konzepts näher beleuchtet, wobei insbesondere auf aufgetretene Schwierigkeiten und besondere Herausforderungen eingegangen wird.<br>
12.10.17;12.03.18;2018;intern;Bachelor;DE;Analyse und Bewertung von Apps für das Wissensmanagement;Das Thema dieser Arbeit beschäftigt sich mit der Analyse und der Bewertung der aktuellen Apps, die es auf dem Markt für das Wissensmanagement gibt. Mittels der Analyse wurde indirekt die Frage untersucht, welche Apps in den Phasen des Bausteinmodells von Probst ihre Anwendung finden. Anschließend werden für die Bewertung funktionale und nicht-funktionale Kriterien einer App für das Wissensmanagement aufgedeckt. Daraufhin wird eine Alternative unter den Apps für das Knowledge-Management ermittelt, die für den Einsatz in ein Unternehmen in Frage kommen könnte. 
12.10.17;12.03.18;2018;intern;Bachelor;DE;"""Evaluation von Werkzeugen zur Testautomatisierung von mobilen Android-Applikationen""";"Die Arbeit mit dem Titel ""Evaluation von Werkzeugen zur Testautomatisierung von mobilen Android-Applikationen"" wird sich letztendlich mit der Untersuchung und Bewertung von Tools zur Testautomatisierung von mobilen Anwendungen befassen. <br>In Anbetracht dessen, dass der Markt für mobile Anwendungen sich in einem rasanten Wachstum befindet und zufriedene Nutzer unabdingbar für wirtschaftlich erfolgreiche Apps sind, sollte die Qualitätssicherung keineswegs vernachlässigt werden. Testautomatisierungs-Tools sollen dabei die Aufgabe erleichtern und beschleunigen. <br>Im ersten Schritt der Arbeit sollen geeignete Tools ermittelt werden und diese dann anhand eines Anwendungsbeispiels getestet und bewertet werden.<br>Hierfür wurden zunächst geeignete Tools ermittelt und miteinander verglichen. Daraufhin wurden, mithilfe einer Beispiel-App, Testfälle entworfen und implementiert. Schließlich wurde die Eignung der einzelnen Tools bewertet. <br>Die Evaluation hat gezeigt, dass sich das offizielle Werkzeug Espresso für single-platform-Apps am besten eignet. Für cross-platform-Apps ist eine Kombination aus Espresso und Appium denkbar."
12.10.17;12.03.18;2018;extern;Bachelor;DE;Konzeption und prototypische Implementierung von digitalen Türbeschilderungen der DATEV eG mithilfe eines zentralen Digital Signage Systems;Die Arbeit befasst sich mit der Erarbeitung eines Medienkonzeptes für die effiziente Raumbuchung mithilfe von digitalen Türschildern aus dem Digital Signage Produktportfolio sowie deren prototypische Umsetzung. Durch die wachsende Nachfrage nach Besprechungs- und Konferenzräumen konnte der Bedarf der Mitarbeiter nicht optimal gedeckt werden. Durch den Einsatz digitaler Türschilder im Unternehmen wird eine Entlastung der IST-Situation erstrebt. Auf Basis von Recherchen, einer Marktanalyse und einem Produkttest wurde für das Unternehmen ein Türschild identifiziert. Anschließend wurde die Technik der Türschilder kritisch begutachtet. Unter Beachtung aller Faktoren wurde ein Konzept erarbeitet, das als Leitfaden für die Umsetzung auf das produktive Umfeld eines Nürnberger Softwarehauses angewandt werden kann.
13.10.17;13.03.18;2018;intern;Bachelor;DE;Erstellung eines IT-Grundschutz-Profils als Referenzmodell für kleine bis mittelständische Steuerberatungskanzleien <br>;Ziel meiner Bachelorarbeit ist es, ein IT-Grundschutz-Profil in Zusammenarbeit mit der DATEV eG zu erstellen. Dieses Profil richtet sich an Steuerberaterkanzleien, mit den hierfür typischen Geschäftsabläufen im Hinblick auf das Rechnungswesen, Jahresabschlüsse, Lohnverarbeitung, Steuerdeklaration und Wirtschaftsberatung sowie kanzleieigene Prozesse. Der Fokus liegt auf kleine und mittelständische Steuerkanzleien mit bis zu 15 Mitarbeitern, bei denen in der Regel davon auszugehen ist, dass Sie über keine professionelle IT-Kompetenz verfügen. Außerdem berücksichtigt es die besonderen Anforderungen dieses Berufsstands an die Verschwiegenheitspflicht und die damit einhergehende Vertrauensposition des Beraters gegenüber seiner Mandanten. Das Profil soll es den Steuerkanzleien ermöglichen einen Mindestschutz im Sinne des BSI Standards für seine Kanzlei zu erhalten. Dazu werden verschiedene Empfehlungen im Profil bereitgestellt. <br>Das mit der Bachelorarbeit erarbeitete Profil soll später als Referenzmodell für ein BSI IT-Grundschutz-Profil für den Steuerberatenden Beruf dienen. Auf dessen Basis etwaige spätere Zertifizierungen wie beispielsweise nach ISO-27001 durchzuführen sind. <br>Um die hierfür notwendige Wissensgrundlage zu erlangen, werden zahlreiche Interviews geführt sowie eine intensive Auseinandersetzung mit internen und externen Steuerberatern betrieben. Basis hierfür sind die vom BSI neu veröffentlichten Bausteine zur Erstellung eines Grundschutzprofils nach BSI Standard. 
17.10.17;13.03.18;2018;extern;Bachelor;DE;Vergleich der Empfehlungsqualität von Fakturisierungsmaschinen mit dem bestehenden Recommender-Algorithmus eines großen deutschen Immobilienportals;Ziel dieser Bachelorarbeit ist der Vergleich der Empfehlungsqualität eines bestehenden Recommender-Algorithmus der Immowelt AG, mit einem auf Faktorisierungsmaschinen beruhenden Ansatz. Zu Beginn werden die theoretischen Grundlagen von Recommendersystemen im Allgemeinen, sowie die Funktion von Faktorisierungsmaschinen erläutert. Zudem sind Rahmenbedingungen, in Form einer in R implementierten Simulationsstudie, sowie eines Immobiliendatensatzes vorgegeben. Die Studie stellt die wissenschaftliche Vergleichbarkeit der Ansätze sicher und musste an die Faktorisierungsmaschine angepasst werden. Der von der Immowelt AG zur Verfügung gestellte Datensatz, beinhaltet verschiedene Arten von Immobilien und stellt die Grundlage für die Auswertungen dar. Die Änderungen, um mit diesen Daten Vorhersagen generieren zu können, werden im weiteren Verlauf beschrieben. Bei der Implementierung des neuen Ansatzes wurde sich für eine Faktorisierungsmaschine höherer Ordnung entschieden, da diese in der Lage ist, Ähnlichkeiten zwischen mehreren Variablen zu ermitteln. Parallel zu dieser Bachelorarbeit wird ein auf neuronalen Netzen beruhender Ansatz mit denselben Daten getestet. Der Vergleich erfolgt daher neben dem Recommendersystem der Immowelt AG auch mit diesem Ansatz. Die Empfehlungsqualität der Ansätze wurde mit den vorgegebenen Metriken Receiver Operating Characteristics Curve und Recall bestimmt. 
18.10.17;30.01.18;2018;extern;Bachelor;DE;Konzepterstellung für eine Verbesserung des EB tresos-Konfigurationswerkzeuges basierend auf einem Vergleich mit anderen AUTOSAR-Werkzeugen;Die vorliegende Bachelorarbeit beschreibt die Optimierung der Gebrauchstauglichkeit der Software EB tresos Studio aus dem automobilen Bereich. Die Vorgehensweise der Arbeit basiert auf bestehenden theoretischen Grundlagen zur Gebrauchstauglichkeit von Produkten. <br><br>Im praktischen Teil der Arbeit wird untersucht, ob sich Benutzerbefragungen und der Vergleich konkurrierender Produkte für die Optimierung der Gebrauchstauglichkeit eignen. Dies wird in einem Usability-Test mithilfe von abgeleiteten Anforderungen anhand eines Prototyps geprüft.<br><br>Das Ziel dieser Bachelorarbeit ist es, einen effektiven Standardprozess zur systematischen Verbesserung der Gebrauchstauglichkeit von Software zu finden. Diese Arbeit ist interessant für alle, die sich mit der Optimierung der Gebrauchstauglichkeit von Produkten befassen. Außerdem richtet sie sich an Personen, die sich mit Methodiken zur Analyse von Software und mit benutzerorientierter Entwicklung von Software beschäftigen.<br><br>Die Ergebnisse dieser Bachelorarbeit sind die Verknüpfung von zwei Methodiken zur Optimierung der Gebrauchstauglichkeit von Software sowie die Entwicklung eines Prototyps und die Testergebnisse aus dem Usability-Test.
18.10.17;07.06.18;2018;extern;Master;DE;Prognose von Absatzzahlen mithilfe eines neuronalen Netzes bei MediaMarktSaturn;Ziel dieser Arbeit war eine Machbarkeitsstudie über die Verwendung von neuronalen Netzen zur Prognose von Absatzzahlen zu erstellen. Dabei lag der Fokus auf Feed-Forward und Long Short-Term Memory Netzen. Diese wurden mit Absatzinformationen aus den vergangenen vier Jahren trainiert. Als Vergleichsmodell wurden Support Vector Machines trainiert.<br><br>Der Test der trainierten Modelle zeigte, dass die Modelle zwar besser als eine naive Prognose funktionieren, aber die aktuell vorhandenen Trainingsdaten nicht ausreichend für das Training zuverlässiger Modelle sind. Ein Vergleich der Modelle zeigte, dass neuronale Netze in diesem Fall bessere Performance liefern als Support Vector Machines. Zwischen den neuronalen Netzen war kein eindeutig besseres Modell erkennbar.<br><br>Um zukünftig präzisiere Modelle trainieren zu können, ist eine Erweiterung der Trainingsdaten nötig. Das betrifft zum einen den Zeitraum, der größer sein muss, um saisonale Effekte besser trainieren zu können. Zum anderen müssen die Input-Features erweitert werden, um bisher fehlende Einflussfaktoren abzubilden.
19.10.17;20.02.18;2018;extern;Bachelor;DE;Strategische und operative Aspekte der Performanceoptimierung bei Kundensystemen der DATEV eG;Ziel dieser Bachelorarbeit ist es, die Performance von Software als Faktor für Kundenzufriedenheit, aber auch für Servicebelastung im Softwarehaus einzuordnen. Vor diesem Hintergrund werden die strategischen und operativen Aspekte der Performanceoptimierung bei Kundensystemen betrachtet. Der operative Teil der Bachelorarbeit befasst sich mit der Optimierung eines konkreten Serviceprozesses zur Performanceanalyse von Kundensystemen der DATEV eG. Die strategischen Aspekte beleuchten, wie mittelfristig Performanceprobleme, aber auch Serviceanfragen zum Thema Performance präventiv vermieden werden können. Langfristig wird die Bedeutung von Performanceoptimierung im Hinblick auf die zunehmende Digitalisierung in sämtlichen Branchen und dem Trendwandel von On-Premises- zu Cloud-Lösungen betrachtet: Welchen Einfluss haben diese Entwicklungen auf den Serviceprozess der Performanceanalyse und wie muss der Prozess unter Berücksichtigung dieser Faktoren weiterentwickelt werden. Neben der Fallstudie im Unternehmen DATEV eG wird der Blick darauf ausgeweitet, welche Aspekte der Performanceoptimierung auf andere Unternehmen übertragen werden können und welche Voraussetzungen für die Übertragbarkeit der Erkenntnisse notwendig sind.
20.10.17;21.02.18;2018;extern;Bachelor;DE;Konzeption und Integration eines Sicherheitskonzeptes in einem Data Warehouse;Das Ziel dieser Bachelorarbeit besteht darin, gesetzliche Richtlinien des Datenschutzes in Bezug auf eine Business Intelligence Architektur zu betrachten. Insbesondere die europäische Datenschutzgrundverordnung gibt neue Anreize für alle datenverarbeitenden Unternehmen, die neuen Richtlinien bis zum Inkrafttreten  der Verordnung umzusetzen. Vor diesem Hintergrund wird sich anfangs mit den neuen rechtlichen Bestimmungen und den daraus resultierenden Konsequenzen beschäftigt. <br>In der Konzeptionsphase werden verschiedene Möglichkeiten betrachtet, die es erlauben den Zugriff auf Daten über unterschiedliche Benutzergruppen zu differenzieren. Insbesondere Daten mit Personenbezug gilt es nach dem Grundsatz der Datenvermeidung nur Anwendern zur Verfügung zu stellen, welche ein berechtigtes Interesse besitzen. Dabei werden die Vor- und Nachteile der Lösungsansätze betrachtet und Methoden zur Entscheidungsunterstützung angewendet. <br>Schließlich wird die evaluierte Alternative im Rahmen einer prototypischen Umsetzung realisiert. Dabei werden die Voraussetzungen, welche in der BNP Paribas S.A. Niederlassung Deutschland für die Marke Consorsbank bestehen, berücksichtigt und die Einsatzfähigkeit der Lösung im Unternehmensumfeld kritisch betrachtet. <br>
20.10.17;20.03.18;2018;extern;Bachelor;DE;Vergleich von SAP User Experience Techniken mit Hilfe der Implementierung von Beispieldialogen bei der Dematic GmbH;Die Firma Dematic ist einer der weltweit führenden Generalunternehmen im Bereich<br>der Intralogistik, der Steuerung des Materialflusses und der Lagerautomatisierung. In<br>einem Lagerkomplex werden viele verschiedene Techniken zur effizienten Bearbeitung<br>von Aufträgen benutzt.<br>Ein Großteil dieser Techniken wird durch einen oder mehreren Mitarbeitern durchgeführt.<br>Dafür benötigt man eine Schnittstelle vom System zum Mitarbeiter, die in der<br>Regel durch Dialoge realisiert wird.<br>Dematic nutzt hierfür ein eigenes Framework, das die klassische Dynpro-Programmierung<br>durch HTML und JavaScript Elemente erweitert, um somit den Kundenanforderungen<br>besser gerecht zu werden. SAP hat jedoch mehrere Techniken entwickelt, um diese Dialoge<br>einfach und benutzerfreundlich zu implementieren, die unter dem Begriff der SAP<br>User Experience (UX) zusammengefasst sind.<br>Im Rahmen dieser Arbeit werden mit Hilfe der von SAP publizierten Techniken Dialog-<br>Prototypen entwickelt, um diese anhand mehrerer Kriterien vergleichen zu können.<br>Dadurch kann abgewogen werden, ob die Kundenanforderungen mit diesen Techniken<br>besser und effizienter erfüllt werden können und ob dadurch das Dematic-eigene<br>Framework abgelöst werden kann.
20.10.17;14.03.18;2018;extern;Bachelor;DE;Erarbeiten einer Qualitätsmanagement Strategie im agilen Softwareentwicklungsumfeld bei DATEV eG;"Zur Steigerung der Produktqualität der Abteilung EM3 des Entwicklungsbereichs der DATEV eG mit dem Produkt Kanzleimanagement muss der agile Entwicklungsprozess optimiert werden.  <br><br>Ziel dieser Bachelorarbeit ist das Erarbeiten einer Qualitätsmanagementstrategie im Rahmen des agilen Softwareentwicklungsprozesses für das Produkt Kanzleimanagement. Diese beschreibt ein ideales Endresultat, auf das hingearbeitet werden soll und repräsentiert damit zugleich die Antwort auf die Frage ""Wo wollen wir hin?"".<br><br>Für die QM-Strategie wurden Ziele erarbeitet. Für diese Ziele wurden zur Konkretisierung Eckpfeiler erarbeitet, die das Erreichen des Ziels unterstützen sollen.<br>Zudem wurde eine erste Maßnahme umgesetzt um dem Zielbild der Qualitätsmana-gementstrategie schrittweise näher zu kommen.<br>"
23.10.17;14.03.18;2018;extern;Bachelor;DE;Überführung von Windows-Presentation-Foundation-Anwendungen auf das Web-Framework Angular;
23.10.17;23.03.18;2018;extern;Bachelor;DE;Konzeption und Implementierung eines radiologischen Informationssystemsimulators als Teil einer Testumgebung für medizinische Bildsysteme;Radiologische Informationssysteme (RIS) dienen in klinischen Einrichtungen der zentralen Verwaltung und Dokumentation von Patienten- und Untersuchungsdaten. Das RIS liefert auf Anfrage eine sogenannte Modality Worklist. Also die für die nächste Zeit anstehenden Untersuchungen für verschiedene medizinische Geräte (auch Modalität, z.B. ein MRT oder CT). Des Weiteren findet vor einer radiologischen Untersuchung noch weitere Kommunikation mit anderen medizinischen Systemen, wie einem Bildarchiv, statt.<br><br>Ziel dieser Bachelorarbeit, die in Kooperation mit der Siemens Healthcare GmbH angefertigt wurde, war es, einen Simulator für ein solches radiologisches Informationssystem zu entwickeln. Dieses sollte in ein internes Tool integriert werden, welches medizinische Testdaten verwaltet. Der RIS-Simulator soll einem zu testenden System eine Modality Worklist bereitstellen, und auf Wunsch des Nutzers eine komplette radiologische Untersuchung simulieren. Hierzu wurden bereits implementierte Features des Tools mit der neuen Implementierung des RIS-Simulators kombiniert, um den kompletten Arbeitsablauf einer radiologischen Untersuchung zu simulieren.
25.10.17;25.03.18;2018;intern;Bachelor;DE;Spielerische Anreizmechaniken in digitalen Anwendungen zur Förderung gesunder Ernährung und Bewegung;Diese Arbeit beschäftigt sich mit der Motivation von gesundem Ernährungs- und Sportverhalten unter der Zuhilfenahme von digitalen Anwendungen. Es wird der Frage nachgegangen wie der aktuelle Stand von spielerischen Anreizmechaniken in Ernährungs- und Sportanwendungen ist und wie diese gleichzeitig ethisch bewertet werden können.<br>Diese Frage wird auf Grundlage der Auswertung aktueller Fachliteratur über Gamification und Verhaltensänderungstheorien diskutiert. Zur Beschreibung des aktuellen Stands wird repräsentativ für die digitalen Anwendungen der App-Markt von Google?s Playstore auf Anreizmechaniken untersucht und mit aktuellen Auswertungen ergänzt.<br>Das Ergebnis der Untersuchungen zeigt eine schwache Präsenz spielerischer Anreizmechaniken in Ernährungs- und Sport-Apps. Die Apps enthalten zwar Motivationselemente, diese sind jedoch kaum spielerisch. Die Tendenz liegt in der vermehrten Nutzung sozialer Elemente und simpler Elemente, wie Punkte und Badges. Eine langfristige Verhaltensänderung wird nur bedingt gefördert.<br>Aus ethischer Sicht sind mehrere Aspekte klargeworden. Einer Spielsucht sollte vorgebeugt werden. Die Anreizmechaniken dürfen nicht zum Kaschieren anderer Schwachstellen der Anwendung genutzt werden und die Effektivität der Anwendung sollte immer im Vordergrund stehen. Wichtige Funktionalität sollte nicht vorenthalten werden, um dann später mit teurem Premium-Content Geld zu erwirtschaften und alle Arten von Zwängen, wie sozialer Druck oder Geldstrafen, sollten 
26.10.17;11.06.18;2018;extern;Master;DE;Analyse, Konzeption und Umsetzung einer prototypischen IoT-Architekturlösung unter Verwendung von Microsoft Azure im Anwendungsbereich der Industrie 4.0.<br>;Ziel dieser Masterarbeit war die Analyse, Konzeption und Umsetzung einer prototypischen IoT-Architekturlösung unter Verwendung von Microsoft-Azure im Anwendungsbereich der Industrie 4.0. Hierzu wurden im ersten Teil der Ausarbeitung die theoretischen Grundlagen in den Bereichen analytische Informationssysteme, Internet of Things und Industrie 4.0 dargelegt. Zur Synthese dieser Themengebiete wurde ein Modell von Industrie 4.0 eingeführt. Anschließend wurde ein Einsatzszenario für den zu entwickelten Prototyp beschrieben. Dazu wurde eine Ist-Analyse anhand einer beispielhaften Pharma Supply Chain durchgeführt und Geschäftsprozesse wurden bewertet. Auf Basis dieser Ergebnisse wurden konkrete Anwendungsfälle entwickelt und funktionale und nicht funktionale Anforderungen erhoben. Anschließend wurde ein für den Prototyp geeignetes Referenzmodell identifiziert und ein Architekturentwurf erstellt. Für die Umsetzung des Prototyps wurden die Komponenten Datenstreaming, Datenprozessierung, Daten-speicherung und Datenanalyse in der Cloud-Computing-Plattform Microsoft Azure realisiert. Anschließend wurde dargelegt, wie die gesammelten Informationen durch das Präsentationstool Power-BI Geschäftsprozessen verfügbar gemacht werden könnten. Im abschließenden Fazit wurden die Ergebnisse kritisch bewertet. 
01.11.17;01.07.18;2018;intern;Master;DE;Gesichtsdetektion in Bildern mittels Region-based Convolutional Neural Networks;Das Ziel dieser Masterarbeit ist es, die Detektion von Gesichtern in Bilddateien mittels Region-based Convolutional Neural Networks (R-CNNs) zu untersuchen. Zunächst werden die theoretischen Grundlagen von R-CNNs vorgestellt und diese Methoden sowohl gegenübergestellt als auch verglichen. Anschließend werden aktuelle Methoden zur Detektion von Gesichtern in Bildern mit Gesichtsdetektoren auf Basis von neuronalen Netzen verglichen.<br>  <br>Im praktischen Teil der Arbeit wird ein Region-based CNN für die Detektion und Lokalisierung von Gesichtern in Bildern erstellt und trainiert. Anhand einer oder mehrerer geeigneter Teststichproben wird die Erkennungsrate und der benötigte Rechenaufwand der Verfahren ermittelt und verglichen. Zusätzlich wird ein Vergleich mit einem klassischen Gesichtsdetektor wie dem Viola-Jones-Algorithmus durchgeführt. 
02.11.17;03.04.18;2018;extern;Bachelor;DE;Proof of Possession - Zwei-Faktor-Authentifizierung zur Gewährleistung gesicherter Client-Server-Kommunikation;In der Bachelorarbeit geht es darum, das Proof-of-Possession-Verfahren auf einem Android-Client umzusetzen. Mit dem Proof-of-Possession-Verfahren können wir sicherstellen, dass die Person, zu der das Konto gehört, sich mit ihrem physischen Gerät anmeldet und nicht ein Hacker von einem anderen Gerät aus. Somit können die Daten von Personen vor Angriffen geschützt werden. Mit Hilfe von Kryptographie soll die Authentifizierung einer Person beim Anmelden in eine Banking-App, Versicherungs-App, Email-App, etc., noch sicherer gemacht werden. 
03.11.17;03.04.18;2018;intern;Bachelor;DE;Konzeption und Realisierung einer optimierten Bahnplanung für Roboter;
06.11.17;06.04.18;2018;intern;Bachelor;DE;Wiedereinspielungsangriffe auf funkbasierte Autoschlösser mithilfe eines softwarebasierten Sendeempfängers;Das Ziel der vorliegenden Bachelorarbeit war es, mithilfe eines softwarebasierten Sendeempfängers, dem HackRF-One, Signale funkbasierter Autoschlüssel neuerer Fahrzeugmodelle abzufangen und wieder abzuspielen. Der Angriff erfolgt hierbei durch Wiedereinspielung abgefangener Signale. Funksignale neuere Fahrzeugmodelle verwenden zur Abwehr von Hack-Angriffen Rolling-Codes. Mithilfe des GNU-Radio-Companion und des YARD-Stick-Ones wurde jedoch gezeigt, dass diese dennoch angreifbar gemacht werden können. Hierzu wurde ein YARD-Stick-One mithilfe der RfCat-Framework als Störsender umfunktioniert und ein HackRF-One mithilfe des GNU-Radio-Companions als Empfänger und Sender der Autofunkschlüsselsignale verwendet. Die aufgezeichenten Signale wurden mittels eines Bandpass-Filters vom Störsignal des YARD-Stick-ones gefiltert, sodass diese beim Abspielen vom Auto ohne Probleme erkannt werden konnten. So konnte bewiesen werden, dass Autos mit Rolling-Code-Systemen angreifbar und damit unsicher sind.  
06.11.17;05.04.18;2018;extern;Bachelor;DE;Konzeption und Implementierung eines integrierten Dienstleistungserfassungssystems;"Ziel dieser Bachelorarbeit war die Konzeption eines Dienstleistungserfassungssystems und dessen  Implementierung in das Enterprise-Content-Management-System DOCUframe der Firma GSD-Software unter Verwendung der Programmiersprache DOCUcontrol.	 <br>Dazu wurden die zugrunde liegenden Arbeitsschritte, vom Eingang eines Arbeitsauftrages bis hin zu dessen Abschluss, analysiert und anschließend in einer Anforderungsanalyse festgehalten.<br>Grundlegende Bestandteile des geplanten Systems waren ein effizienter Erfassungsvorgang, eine Verwaltungsoberfläche für bestehende Tickets, eine Arbeitszeiterfassung für die Benutzer, sowie eine automatisierte Zeiterfassung Ticketeinträge.	<br>Am Ende der Arbeit steht ein funktionsfähiges System mit allen grundlegenden Funktionen der Anforderungsanalyse sowie der Vorgaben des Unternehmens .<br>"
08.11.17;04.04.18;2018;extern;Bachelor;DE;Konzeption einer mobilen Projektzeiterfassung für das ERP-System Odoo;Um den Gesetzen zur Arbeitszeit gerecht zu werden und die betrieblichen Abläufe zu beschleunigen, stellen Firmen auf eine elektronische Zeiterfassung um.<br>Zeitgleich werden auch ERP-Systeme (Enterprise-Resource-Planning) eingeführt.<br>Eine Verknüpfung beider Bereiche mittels Smartphone-Apps führt zu einer weiter gesteigerten Effizienz.<br><br>Deshalb wird im Rahmen dieser Arbeit zusammen mit der Firma LSK Engineering Services GmbH ein Prototyp für eine Projektzeiterfassungs-App entwickelt, der sich den Bedürfnissen des Betriebes nach die Mitarbeiter führenden und trotzdem flexiblen Zeiterfassung anpasst.<br>Dieser Prototyp besteht aus einem Plugin für das ERP-System Odoo-10-Community-Edition und aus einer App für die Plattformen Android, iOS und Windows 10.<br><br>Dazu wird der IST-Zustand der Zeiterfassung bei LSK untersucht und anschließend die Anforderungen an eine Projektzeiterfassung ermittelt.<br>Diese werden mit anderen Zeiterfassungs-Apps verglichen.<br>Anschließend wird eine eigene Zeiterfassungs-App erarbeitet.<br>Diese App unterstützt sowohl die Erfassung nach dem Mindestlohngesetz, als auch die Erfassung der Projektzeiten.<br>Bei Benutzung der App werden die Mitarbeiter auf die gültigen Gesetze zur Arbeitszeit hingewiesen.
09.11.17;20.03.18;2018;extern;Bachelor;DE;Analyse und Optimierung von Usability und Design einer plattformübergreifenden App für IT-Asset Management;Im Zuge der Migration von Cordova zu Xamarin.Forms einer mobilen App für IT-Asset Management der Firma Fair Computer Systems GmbH sind aufgrund von plattformübergreifendem Code einige Designschwierigkeiten aufgetreten.<br><br>Um eine benutzerfreundliche App bereitzustellen, wurden Schwachstellen aufgedeckt und reduziert. Anhand von nativen Design-Vorlagen der Betriebssysteme Android, iOS und UWP konnten Trends identifiziert und umgesetzt werden. Um das Layout neu zu gestalten und die Akzeptanz der Benutzer zu steigern, wurden Konzepte mit Hilfe von Methoden aus dem User Centered Design erarbeitet. Des Weiteren konnte das Gesamterlebnis durch die Analyse von Usability-Zielen gesteigert und das neue User Interface auf Grundlage der Konzepte realisiert werden.
09.11.17;14.03.18;2018;extern;Bachelor;DE;Wirtschaftlichkeitsanalyse von Single-Source-Publishing-Lösungen am Beispiel eines mittelständischen Unternehmens;Single Source Publishing ist ein Verfahren bei dem Informationsprodukte an einer zentralen Stelle erstellt und verwaltet werden. Informationsprodukte werden von Technischen Redakteuren benötigt um z. B. Bedienungsanleitungen für technische Geräte oder Angebotsbeschreibungen für Onlineshops zu erstellen.<br><br>Im Jahr 2014 wird die doctima GmbH von einem mittelständischen Unternehmen beauftragt, eine geeignete Single-Source-Publishing-Lösung für ihren neuen Webauftritt zu konzipieren. Neben der Evaluation geeigneter Software ist auch Eigenentwicklung von Komponenten nötig.<br><br>Das Ziel dieser Arbeit ist die Analyse der Wirtschaftlichkeit einer Single-Source-Publishing-Lösung. Kennzahlen wie Zeitaufwand, Kosten, Qualität des Contents, Benutzerfreundlichkeit und Zugriffszahlen sollen mit geeigneten Methoden gewonnen und ausgewertet werden. Außerdem soll untersucht werden wie sich die Einführung einer Single-Source-Publishing-Lösung auf Bereiche außerhalb der Technischen Redaktion auswirkt. Zusätzlich soll ein Überblick über die eingesetzten Methoden und Technologien, zur Umsetzung der Projektziele, gegeben werden.<br><br>Die Ergebnisse bestätigen, dass sich die Einführung einer Single-Source-Publishing-Lösung positiv auf die oben genannten Kennzahlen auswirkt. Bei der Gegenüberstellung von Kosten und Nutzen ist erkennbar dass eine Amortisierung der Kosten in wenigen Jahren möglich ist.<br>
10.11.17;10.04.18;2018;extern;Bachelor;DE;Konzeption der Verwaltung von kundenspezifischen Anpassungen für standardisierte ERP-Systeme im Mittelstand;Im Rahmen dieser Bachelorarbeit wird anhand der Firma Vepos GmbH & Co. KG und deren ERP-Software v.Soft untersucht, wie kundenspezifische Anpassungen verwaltet werden können. Motivation ist der hohe Aufwand für die Verwaltung zahlreicher unterschiedlicher Versionen bei steigender Kundenanzahl. Nach der Systematisierung kundenspezifischer Adaptionen und der Problem- und Ursachenanalyse werden Lösungsansätze identifiziert, untersucht und bewertet, die es ermöglichen, kundenspezifische Anpassungen aufwandsarm zu verwalten. Das Ziel ist die Erarbeitung einer Lösungsstrategie, die mit den gewonnenen Erkenntnissen sinnvoll umgesetzt werden kann und die derzeitige Verwaltung ersetzt.
13.11.17;22.02.18;2018;extern;Bachelor;DE;Konzeption und Entwicklung eines lernenden Chatbots für die Unterstützung der digitalen Rechtsberatung;Ziel der Bachelorarbeit war es, ein Framework zur Erstellung von Chatbots<br>für den Rechtsschutzmarkt zu entwickeln. Ein Chatbot, der mit dem prototypischen<br>Framework erstellt wurde, soll durch Angaben des Kunden erkennen,<br>welches Anliegen dieser hat. Die Herausforderung dabei besteht<br>in der Fähigkeit des Bots, anhand von gesammelten Daten seinen Ablauf<br>zu optimieren. Dazu zählt eine Situations-Analyse und das Erstellen eines<br>Konzeptes aus den Resultaten der Analyse. Abschließend wurde ein Testfeld<br>gesucht und durchgeführt. Damit wurde bewiesen, dass Chatbots zur<br>Kundensteuerung am Rechtsschutzmarkt beitragen können.
13.11.17;13.03.18;2018;intern;Bachelor;DE;Lernende Organisationen im Spannungsfeld verschiedener organisationaler Gruppen und das dies-bezügliche spezifische Risikomanagement.;Durch die sich ändernden außerorganisationalen Gegebenheiten müssen Organisationen ggf. strukturelle Änderungen vornehmen und Vorgehensweisen anpassen. Dies führt zu unterschiedlichen Reaktionen der organisationalen Gruppen. Daher sollen Notwendigkeit und Perspektiven von spezifischem Risikomanagement bezüglich der organisationalen Gruppen herausgearbeitet werden. Für das Herausarbeiten wurde Literaturrecherche zu Definitionen der zentralen Begrifflichkeiten betrieben. Parallel dazu erfolgte eine empirische Untersuchung in Form eines Fragebogens und eine anschließende Auswertung der Ist-Situation. Ergebnis der Arbeit ist eine Dokumentation von Defiziten und Best Practices im Umgang mit organisationalen Gruppen.
17.11.17;16.07.18;2018;intern;Master;DE;Entwicklung eines Systems zur Erstellung und Benutzung von interaktiven taktilen Graphiken auf Basis eines Lasergravur-Verfahrens;Taktile Karten unterstützen blinde und sehbeeinträchtigte Menschen bei deren Orientierung<br>und Mobilität. Durch die Verwendung von Touch Displays und Audio<br>Feedback, konnte herkömmliches Schwellpapier bereits mit interaktiven Informationen<br>angereichert werden. Des Weiteren wurde durch den 3D-Druck, eine weitere Herstellungsvariante<br>von taktilen Karten ermöglicht. Nichtsdestotrotz birgt vor allem<br>der 3D-Druck auch diverse Einschränkungen. Insbesondere die Erstellung von größeren<br>3D-gedruckten Karten, führt zu einem überproportional großen Zeitaufwand. Aus<br>diesem Grunde wird in dieser schriftlichen Ausarbeitung, eine weitere Herstellungsalternative<br>unter Zuhilfenahme eines Lasergravur-Verfahrens vorgeschlagen. Darüber<br>hinaus wird ein geschlossenes und kostengünstiges System, bestehend aus Raspberry<br>Pi, Touch Display und Laser, für den Unterricht an Blindenschulen vorgestellt.<br>Mit dessen Hilfe kann das Lehrpersonal eigenes Unterrichtsmaterial erstellen und dieses<br>mit digitalen Informationen anreichern. Im späteren Verlauf ermöglicht das System<br>den Schülern, diese interaktiven taktilen Karten, für den Lernprozess zu verwenden.<br>Diese Arbeit behandelt insbesondere die Anforderungen an das umgesetzte Lehrer-<br>/Schülersystem, sowie die Erstellung und Analyse der neuen Herstellungsalternative.<br>Eine durchgeführte Benutzerstudie mit Lehrern, unterschiedlichen Alters und technischer<br>Erfahrung, bestätigte im Anschluss die grundsätzliche Funktionalität des<br>umgesetzten Systems.
21.11.17;14.03.18;2018;intern;Bachelor;EN;Gender and Cultural Diversity in Software Engineering - Exploring Challenges within Global Teams using Sentiment Analysis;Global software engineering teams are faced with a number of novel challenges compared to co-located teams. While cultural and gender diversity can enrich the software engineering process it is important to acknowledge the challenges that arise from it. In this thesis cultural and gender differences in informal work conversation among software engineers are explored using Sentiment Analysis on Twitter data. Gender differences could be found regarding the sentiment expressed towards conversation topics, confirming previous findings that suggest a preference for sports-related topics in male but not female software engineers. Users from collectivist cultures were found to express less overall sentiment in Twitter posts than users from individualist cultures, confirming previous findings based on e-mail and instant messaging conversations. The thesis shows that cultural and gender differences in the software engineering community also emerge in social media communication and that Sentiment Analysis can be a suitable tool to identify them. Some prospects for future research are provided towards developing approaches for a more inclusive communication culture in global software engineering teams.
22.11.17;06.02.18;2018;intern;Bachelor;DE;Edition der mathematischen Textaufgaben aus dem Anhang von Anton Neudörffers Anweisung in die Arithmetic (1627);"Die Vermittlung mathematischen Wissens in Stadtschulen oblag vom 16. bis ins 18. Jh. sogenannten Rechenmeistern, die sich überdies als Autoren von Rechenbüchern auszeichnen konnten. Der Nürnberger Schreib- und Rechenmeister Anton Neudörffer (1571 ? 1628) ist durch seine mehrfach aufgelegte ""Anweisung in der Arithmetic"" bekannt. Durch die Wirren des 30jährigen Krieges wurde seine mit Vorabdrucken angekündigte ""Grosse Arithmetic"" weder gedruckt, noch ist ein Manuskript überliefert. Die Bayerische Staatsbibliothek München besitzt jedoch eine von Georg Wendler (1619 ? 1988) verfasste Handschrift, in der er unter anderem 390 Prosa- und Reim- Textaufgaben daraus behandelt. In dem Projekt soll auf der Basis dieser Handschrift eine Edition erstellt werden, die sowohl Aufgabentexte als auch Lösungen in heute verständlicher Form enthält. (vgl. https://www.th-nuernberg.de/forschung-innovation/die-zehn-leitthemen-der-technischen-hochschule-nuernberg/medien-und-kommunikation/forschungsprojekte/)"
22.11.17;14.03.18;2018;intern;Bachelor;DE;Schwarmintelligenz;Die folgende Bachelorarbeit untersucht verschiedene ACO-Algorithmen im Bereich der Schwarmintelligenz im Bezug auf Optimierungsprobleme. Ziel ist es die effizientesten ACO-Algorithmen für dasselbe Optimierungsproblem zu finden um einen aktuellen Überblick zu erhalten. Es werden die effizientesten Parameter für bewährte ACO-Algorithmen anhand des Travelling-Salesman-Problems gesucht und miteinander verglichen.
24.11.17;24.04.18;2018;extern;Bachelor;EN;Deep Learning based Chatbot Technologies for the Corporate First Level Support;This thesis describes the principles of machine learning in combination with one of the newest chatbot platforms. The main goal was to create a concept to build a platform where chatbots can easily be built by the various departments of a corporate - in this case Siemens. To reach this aim, a chatbot prototype was built. The example platform and the chatbots are based on the open source framework Rasa Stack, which combines two layers of natural language understanding with Rasa NLU and the chatbot basis Rasa Core. The testing of the prototype is successful.
24.11.17;24.04.18;2018;extern;Bachelor;DE;Feingranulare Datenbankzugriffe mit dokumentbasierten Datenbanken;Oftmals ist die Datenbank einer Webapplikation gegen unbefugte Zugriffe von autorisierte Benutzer nicht geschützt und Daten können von diesen extrahiert werden.<br>Entweder werden tatsächliche Werte von Datenbankobjekten statt benutzerabhängiger Referenzwerte in der Applikation verwendet, oder die Applikation überprüft bei der Abfrage die Berechtigung des Benutzers für den Ressourcenzugriff nicht.<br>Modifiziert ein Angreifer gezielt Parameter einer Anfrage und erhält Daten, welche sich auf den modifizierten Parameter beziehen, als Antwort, obwohl ihm dazu die Zugriffsberechtigung fehlt, spricht man von insecure direct object reference.<br>Deshalb wird in dieser Arbeit ein Konzept vorgestellt, welches verhindert, dass aufgrund von Parametermanipulation einer Abfrage oder fehlender Zugriffsüberprüfung, ein unberechtigter Zugriff auf Ressourcen einer dokumentenbasierten Datenbank stattfinden kann.<br><br>Als Grundlage der Konzeptentwicklung dient eine Fallstudie eines webbasierten Notenverwaltungssystems, welches die Daten in einer relationalen Datenbank sichert.<br>Die Prozesse werden daraufhin analysiert, welche Faktoren bei der Entscheidung der Zugriffsberechtigung zu beachten sind.<br><br>Um die Umsetzbarkeit des Konzepts zu verdeutlichen wurde dieses prototypisch implementiert.<br>In diesem wurden das Anlegen, Lesen und Löschen von Ressourcen implementiert.<br>Die Operation des Modifizierens wurde nicht implementiert, da erforderliche Prüfungen schon implementiert wurden.
27.11.17;23.04.18;2018;intern;Bachelor;DE;Integration dynamischer Objekte in die Carbot-Simulationsumgebung;Die Carbot-Simulationsumgebung erlaubt die Definition statischer Umgebungen, die aus einfachen Hindernissen (z.B. Wände, Säulen) bestehen. In diesen Umgebungen kann sich der simulierte Roboter bewegen und erhält entsprechende simulierte Sensoreingaben (beispielsweise ein Kamerabild, einen Laser-Entfernungs-Scan). Verfahren zur Kartographierung dieser statischen Umgebung stehen zur Verfügung. Rein statische Umgebungen liegen in der Realität aber sehr selten vor. Sehr häufig bewegen sich dynamische Hindernis, z.B. Menschen in Sensorreichweite. Diese sind von der Natur aus anders, dürfen beispielsweise nicht dauerhaft in eine Hinderniskarte eingetragen werden. Damit Algorithmen zur Handhabung dynamischer Hindernisse entwickelt und getestet werden können, wurde die Simulationsumgebung mit dieser Arbeit um dynamische Hindernisse erweitert. Es wurde ein Verfahren entwickelt, mit welchem die bewegten Hindernisse anhand einer Umgebungsdatei in die Simulationsumgebung eingelesen werden können und die gewünschte Bewegungsart (linear oder zufällig) von der CarbotSim umgesetzt und korrekt dargestellt wird. Die dynamischen Objekte besitzen zudem eine eigene Kollisionserkennung, damit sie sich nicht durch einander durch bewegen können. Es wurden zwei verschiedene Hindernistypen - Menschen und Carbots - integriert. Zur Umsetzung wurde an die bestehenden Technologien angeschlossen, die Grundstruktur der Anwendung bleibt unverändert.
27.11.17;29.06.18;2018;extern;Master;DE;Systematische Modernisierung von Legacy-Systemen;Bei der Modernisierung von Legacy-Systemen kommt es immer wieder zu Schwierigkeiten. Oft kommen diese aus den Systemen selbst. Im Rahmen der Masterarbeit wurden die Gründe für diese Schwierigkeiten untersucht. Das geschah zum einen durch Recherche von Literatur und zum anderen anhand von Experteninterviews. Diese wurden mit Personen geführt, die an Modernisierungsprojekten mit positiven Ausgang beteiligt waren. So sollte ermittelt werden, auf was besonders zu achten ist und wie ihr Erfolgsrezept lautet. Die Interviews wurden daraufhin ausgewertet, die Ergebnisse diskutiert und die Empfehlungen daraus vorgestellt. Am Ende ergeben sich daraus interessante Erkenntnisse, mit denen man teilweise so vielleicht nicht gerechnet hatte. Denkbar war, dass vor allem Abhängigkeiten, Komplexität und Vernetztheit der Systeme entscheidend sind. Sie führen zu individuellen Problemen, die sich nicht mit einer Musterlösung beseitigen lassen. Ein möglicherweise unerwarteter Punkt ist die Bedeutung des Stakeholder Managements. Das ist ein wichtiges Instrument. Außerdem scheint es als seien die Unterschiede zu Green Field Projekten nicht so groß. 
30.11.17;14.03.18;2018;extern;Bachelor;DE;Konzeption und Realisierung eines universellen Dashboards für den Vertrieb im Autoteilegroßhandel auf Basis von Microsoft Dynamics NAV und Qlik Sense;Ziel der Bachelorarbeit ist es, ein Qlik Sense-Template für die Branche Automotive für den Bereich Vertrieb zu konzeptionieren sowie zu realisieren.<br><br>Die Aufgaben belaufen sich dabei auf der Analyse der bestehenden Prozessabläufe zu Automotive im Bereich Vertrieb sowie die Erweiterung des bestehenden Datenmodells. Anforderungen müssen erhoben, dokumentiert und kategorisiert werden. Dadurch wird ein Mockup konzeptioniert, um das grobe Design darzustellen. Anschließend wird das Dashboards erstellt. Dabei müssen die richtigen Visualisierungsarten verwendet werden. Standards und Best Practices werden angewendet, um sinnvolle Oberflächen zu erstellen. Letztendlich entsteht eine Applikation, welche die Analyse verschiedener Perspektiven für eine Kennzahl ermöglicht. <br>
01.12.17;02.05.18;2018;extern;Bachelor;DE;Design und prototypenhafte Umsetzung eines zentralen Archivierungssystems, <br>zur Unterstützung der Aufnahmeplanung in der industriellen CT<br>;Die Durchführung einer Computertomographie unterliegt einer großen Fülle an Parametern. Je nach Bauteil und Prüfaufgabe ist eine entsprechende Parameterkombination sinnvoll. Daher ergibt sich eine sehr große Menge an Parameterkombinationen. Bisher ist die Wahl dieser Parameter an das Spezialwissen und die Erfahrung des Benutzers gebunden. Dauerhaft ist daher das Ziel, dieses Wissen, weg vom jeweiligen Benutzer hin zu einem intelligenten System zu führen. Grundlage dieses intelligenten Systems ist die Sammlung und Verwaltung der jeweiligen Parameterkombination mit der Verknüpfung zum Bauteil bzw. der Prüfaufgabe. Bestandteil dieser Arbeit ist daher die Konzeption und Erstellung eines digitalen Verwaltungssystems des oben beschriebenen Wissens. Die Einträge in das System sollen hierbei intelligent eingeordnet werden, damit hieraus Rückschlüsse auf den Zusammenhang der Parameter zu dem Bauteil und der Prüfaufgabe hergestellt werden können.
04.12.17;03.05.18;2018;extern;Bachelor;DE;Realisierung eines Werkzeugs zur Verwaltung von Konfigurationen für entwicklungsbegleitende Tests;Bei einer Vielzahl von Software-Produkten in einem Unternehmen, die in unterschiedlichen Beziehungen stehen, müssen die Kombinationen dieser Produkte erfasst und getestet werden. Wenn darüber hinaus noch Beziehungen zu fremder Software bestehen, ist es umso wichtiger, die gemeinsame Funktionalität der Produkte auf einem Rechnersystem sicherzustellen. Ein Ansatz dazu ist das Bereitstellen von Testumgebungen, welche die Kombinationen abbilden. Um dieses zu können, bedarf es an Informationen, welche die Testumgebungen beschreiben und zentral verwaltet werden.<br>Im Rahmen dieser Bachelorarbeit wird ein Konzept für ein Werkzeug ausgearbeitet, das die Verwaltung von Testkonfigurationen in der DATEV eG zentralisiert und erleichtert. Zudem wird ein Prototyp im engeren Sinne entwickelt, welcher die Funktionen der Oberflächen beinhaltet. <br>Anhand der Erkenntnisse, die durch die Umsetzung des Prototyps ausgehend vom Konzept gewonnen werden, wird eine Entscheidung zur Fertigstellung des Tools getroffen.<br>
07.12.17;07.08.18;2018;extern;Master;DE;Evaluation und Implementierung geeigneter Verfahren zur Nutzbarmachung von nicht identischen Duplikaten und Synonymen im Umfeld archivierter Kassendaten;Eine hohe Datenqualität ist ein wichtiger Erfolgsfaktor für alle IT-Unternehmen. Daher müssen Datenfehler, welche die Qualität von Daten beeinträchtigen, gefunden und beseitigt werden. Zwei der am häufigsten auftretenden Datenfehler sind Duplikate und Synonyme. <br>Die vorliegende Arbeit zeigte gängige Verfahren zur Duplikaterkennung auf und verglich diese hinsichtlich ihrer Effektivität und Effizienz. Außerdem wurde eine in vielen Unternehmen eingesetzte Methode zur Synonymerkennung vorgestellt. Die Verprobung und Implementierung der vorgestellten Verfahren wurde anschließend anhand der Datenbasis einer kleinen Lebensmittelkette vorgenommen. <br>Das Ergebnis der Evaluation, welche mithilfe von Maßen  des Information Retrieval durchgeführt wurde, zeigte auf, dass eine vorgelagerte Synonymerkennung die Qualität der anschließenden Duplikaterkennung erhöht und aufgrund der unterschiedlichen Ursachen der vorliegenden Duplikate (Rechtschreibfehler, Wortvertauschungen) eine Kombination aus mehreren Duplikaterkennungsverfahren das beste Mittel zur Erhöhung der Datenqualität ist. Außerdem wurde deutlich, dass sich deutliche Effizienzunterschiede nur durch den Einsatz unterschiedlicher Partitionierungsverfahren ergeben. Allerdings erkennen die implementierten Verfahren weitaus noch nicht alle vorhandenen Duplikate. Daher ist es notwendig, diese schrittweise zu verbessern, beispielsweise durch eine vorgelagerte Rechtschreibprüfung oder den Einsatz von Ontologien und künstlicher Intelligenz. 
07.12.17;07.05.18;2018;extern;Bachelor;DE;Konzeption und Realisierung eines Software-defined networks und einer<br>Mikro-Segmentierung im Netzwerk-Access-Bereich;Um das Management eines Firmennetzwerks zu vereinfachen und besser auf Ver-<br>änderungen der Netzwerkstruktur reagieren zu können, ist es nötig, die Steuerung<br>des Netzwerkverkehrs von der reinen Weiterleitung, die von der Hardware übernom-<br>men wird, zu trennen. Dies wird durch Software-defined networking ermöglicht.<br>Die Beschränkung des Zugriffs der Nutzer auf die jeweils benötigten Ressourcen<br>(Clients, Drucker, Abteilungs-, Test- und Entwicklungsserver) ist eine der wichtigsten<br>Anforderungen an ein Netzwerk. Diese Beschränkung soll erreicht werden, indem<br>die Ressourcen, zu denen der Nutzer Zugang hat, in einem gesonderten Netzwerk-<br>segment gekapselt werden.<br>Ziel der Arbeit ist es, ein Konzept für ein Software-defined network und darauf<br>aufbauend eine Mikro-Segmentierung im Firmennetzwerk der N-Ergie zu erstellen.<br>Hierbei liegt der Fokus auf den benutzernahen Bereichen. Dafür wird eine Anfor-<br>derungsanalyse durchgeführt und anhand des Ergebnisses eine passende Software<br>ausgewählt. Dies macht es möglich, einen Laboraufbau zu entwickeln, mit dem das<br>Konzept umgesetzt werden kann.
07.12.17;07.05.18;2018;extern;Bachelor;DE;Auswahl und Implementierung eines IT-Management-Tools für das interne Kontrollsystem eines IT-Dienstleisters im Bankensektor;"Die Sparda-Datenverarbeitung eG (SDV-IT) ist ein mittelständischer IT-Dienstleister der Sparda-Banken. Das bestehende interne Kontrollsystem (IKS) begleitet die kontinuierliche Verbesserung der Prozesse und unterstützt ordnungsgemäße, nachvollziehbare und wirtschaftlich durchgeführte Unternehmensaktivitäten. Die Verantwortung für das IKS liegt im ""Vorstandsstab"" beim IKS-Beauftragten. Um einer effizienten Unternehmensorganisation gerecht zu werden und als Unterstützung zur Einhaltung gesetzlicher Anforderungen, ist die Einführung einer Software, mit der Zielsetzung eines integrierten Managementsystems geplant. Anhand des Tools sollen die im Vorstandsstab angesiedelten Disziplinen IKS, Prozess-, Datenschutz-, IT-Sicherheits- und Risikomanagement in der Verwaltung der jeweiligen Maßnahmen, Feststellungen und Anforderungen unterstützt werden und Schnittstellen effizient bedient werden. Infolge dessen bildet die prototypische Implementierung einer Risiko-Kontroll-Matrix anhand der Anwendung einen Bestandteil der Arbeit. Die Dokumentation der Second Level Controls (Beschreibung, Kontrolldurchführung, Maßnahmen) mit Hilfe der Software ist ein weiterer Baustein der Bachelorarbeit. Die Auswahl dieses Tools soll auf Basis eines zu definierenden Kriterienkatalogs erfolgen. "
14.12.17;14.08.18;2018;intern;Master;DE;Bahnplanung für einen autonom fahrenden Roboter mit endlicher Lenkgeschwindigkeit, basierend auf Klothoiden;Im Rahmen des Carbot-Projekts wird analysiert, inwieweit Klothoiden sich eignen, um das Bahnplanungssystem des autonomen Roboters zu ergänzen und zu verbessern. Als wichtige Maßgabe gilt hier, dass Klothoidenbahnen sich berechnen lassen ohne dabei durch eingeschränkte Wertbereiche der Parameter für Fahrzeugposition, -ausrichtung und eingeschlagenem Lenkwinkel beeinträchtigt zu werden. <br>Dafür werden verschiedene Ansätze zur Berechnung von Klothoidenbahnen analysiert und auf ihre Tauglichkeit geprüft. Die Ergebnisse zeigen dabei, dass sich die gängigen Rechenansätze nicht eindeutig analytisch durchdringen lassen und somit nur eingeschränkt für das System eignen. Es wurde allerdings ein vielversprechender Lösungsansatz gefunden, welcher noch weiter untersucht werden müsste.
14.12.17;14.03.18;2018;extern;Bachelor;DE;Realisierung eines sicheren Webportals zur formularbasierten Kundenkommunikation für individuelle Geschäftsprozesse;Ein wichtiger Bestandteil des Tagesgeschäfts der Voigtmann GmbH ist die Erfassung von Kundendaten für individuelle Geschäftsprozesse. Der dafür verwendete Prozess zeigt einige Problemstellen auf und soll optimiert werden. Hierfür wird ein Webportal implementiert, über welches zukünftig die Erstellung und Verteilung der Formulare sowie die Erfassung der Kundendaten geregelt werden soll. Insbesondere soll hierbei die Sicherheit der Anwendung gewährleistet sein, weshalb die Anwendung unter Beachtung der OWASP Top 10 Sicherheitsrisiken für Webanwendungen analysiert wird.
20.12.17;17.07.18;2018;intern;Master;DE;Konzeption und prototypische Realisierung eines Assistenzsystems bei der Stellensuche;Die Hochschul-Jobbörse der Technischen Hochschule Nürnberg bietet Studierenden die Möglichkeit deutschlandweit nach einer Vielzahl an Anstellungen zu suchen. Aktuell werden den Suchenden jedoch nur Stellenangebote angezeigt, die genau auf ihre Suchanfrage passen. Damit werden für Studierende potentiell attraktive Stellen nicht angezeigt, da sie nicht genau den eingegebenen Suchbegriffen entsprechen. Die Masterarbeit umfasst die Konzeption und prototypische Implementierung eines Assistenzsystems für die Stellensuche. Dabei soll eine Instanz geschaffen werden, die verschiedenen Szenarien betrachtet und anschließend den Suchenden bei der Einschränkung oder Erweiterung seiner Suchanfrage unterstützt. Der Assistent soll dabei ohne Zutun des Nutzers das Verhalten des Studierenden beobachten und autonom entscheiden, welche Option ein optimiertes Suchergebnis liefert.
20.12.17;20.08.18;2018;extern;Master;DE;Konzeption der Content Pool Benutzerschnittstelle eines webbasierten Unternehmens Interfaces ;Diese Arbeit steht eng in Zusammenhang mit dem neuartigen Unternehmens Interface der Axinom GmbH, das die derzeitige Website ersetzt. Durch ein Conversational Interface (CI) ? in Form eines persönlichen Chats ? als alleinige Schnittstelle nach außen, wird die direkte Kommunikation mit allen Interessenten erwirkt. Der Content Pool dient der multimedialen Bereitstellung aller Informationen bezüglich des Unternehmens (große Anzahl heterogener Inhalte) und präsentiert nach der ersten Kontaktaufnahme im Chats, den Benutzern das Unternehmen. In dieser Arbeit wurde zuerst eine Benutzergruppenanalyse durchgeführt, daraus entstanden sieben Personas. Aufgrund der hohen Anzahl an Personas, erlangte die Personalisierung der Benutzerschnittstelle besondere Bedeutung. Hierfür wurde ein Vektormodell-basiertes Konzept zur Ähnlichkeitsberechnung zwischen dem aktuellen Benutzer und den enthaltenen Inhalten erarbeitet. Die berechneten Ähnlichkeiten werden im UI visualisiert, dafür findet eine Kategorisierung der Inhalte statt. Die graphische Benutzerschnittstelle visualisiert die Inhalte als Graph. Alle Inhalte werden als Knoten und ihre Struktur durch Kanten dargestellt, der Kontext der Inhalte wird so visuell sichtbar. Aufgrund der hohen Anzahl an Inhalten können nicht alle gleichzeitig sichtbar sein, deshalb wurde ein schlankes Interaktionskonzept entwickelt. Die abschließenden Evaluationen der Personalisierung und der graphischen Benutzerschnittstelle zeigten vielversprechende Ergebnisse.
20.12.17;20.08.18;2018;extern;Bachelor;DE;Die Entwicklung moderner .NET Controls für HMI-Systeme;Die Bachelorarbeit handelte davon, für die Siemens AG herauszufinden, ob und wie es möglich ist .NET Controls in das HMI-System zu integrieren und wie viel Aufwand dies mit sich bringt. <br><br>Die Integration der .NET Controls ist über den Global Assembly Cache von .NET möglich. Dort werden Anwendungen gespeichert, die unter .NET entwickelt und als DLL (Assemblies) gespeichert wurden. <br><br>Es wurden zwei Diagramme zur Darstellung statischer Daten entwickelt, nämlich das Boxplot und das Histogramm. Die beiden Controls wurden im Visual Studio in C# unter .NET entwickelt und bei der Entwicklung der Benutzeroberfläche wurde auf den Werkzeugsatz von WinForms zurückgegriffen. <br><br>Im Versuchsaufbau wurde eine Steuerung verwendet, an welcher ein Temperatursensor angeschlossen war. Die Steuerung war mit einem Algorithmus zur Aufnahme, Verarbeitung und Weitergabe dieser Sensordaten an das Visualisierungssystem ausgestattet. Die beiden Controls wurden in die Benutzerschnittstelle des Visualisierungssystems integriert. Der Datenaustausch zwischen dem Visualisierungssystem und der Steuerung geschieht über Polling. Die Daten werden über die HMI-Tags des Visualisierungssystems, welche mit den Variablen der Controls verknüpft wurden, an die Diagramme übergeben und angezeigt. <br><br>Fazit: Die Entwicklung eines Anwendungsbeispiels, wie man .NET Controls entwickeln und in das HMI-System integrieren kann, bringt der Siemens AG einen größeren Mehrwert, als selbst .NET Controls zu entwickeln.
09.01.18;25.05.18;2018;extern;Master;DE;Evaluation von Einsatzszenarien der Blockchaintechnologie in der Logistik anhand eines Proof-of-Concepts;Effiziente Prozesse und hohe Transparenz in Supply Chains sind für Unternehmen entscheidende Faktoren, um erfolgreich zu sein und die steigenden Qualitätsansprüche erfüllen zu können. Mangelndes Vertrauen zwischen den Akteuren und Betrug durch Produktfälschungen stellen die Unternehmen vor zusätzliche Herausforderungen. <br>Die Blockchain-Technologie bietet durch die unveränderbare Speicherung von Informationen und das Ausführen von Business-Logik mittels Smart Contracts trotz mangelndem Vertrauen eine mögliche Grundlage zur Zusammenarbeit aller Beteiligten. <br>Im Siemens-Werk Erfurt werden Stanzteile aus Blech für Generatoren hergestellt und an Kunden weltweit versandt. In Kooperation mit der Siemens AG wurde im Rahmen dieser Arbeit ein Proof-of-Concept entwickelt, um den Prozess von der Stahlherstellung bis zur Übergabe an den Kunden durch die Blockchain zu unterstützen. Die Umsetzung hat gezeigt, dass sich Medienbrüche vermeiden und Prozessabläufe beschleunigen lassen, was zu Bestandsreduktionen und Kosteneinsparungen führen kann. <br>Die Sicherstellung der Daten- und Prozessintegrität, der Verzicht von intermediären oder wechselnden Kooperationspartnern - die Blockchain-Technologie bietet ein breites Spektrum an Einsatzszenarien in der der Logistik. Der niedrige Reifegrad, mangelnde Standards und fehlende gesetzliche Rahmenbedingungen sind auf der anderen Seite aktuell die größten Hürden für eine schnelle Umsetzung von Projekten mit der Blockchain-Technologie. <br> 
15.01.18;14.09.18;2018;extern;Master;DE;I/O-Fuzzing im Linux-Kernel;Diese Arbeit entwickelt ein Konzept, wie das I/O-Subsystem des Linux-Kernels<br>mittels Fuzzing getestet werden kann. Fuzzing ist eine Technik im Bereich des<br>Software Testings, bei der ein zu testendes System mit semi-zufälligen<br>Eingabedaten penetriert wird. Die Beobachtung des Systems und die Registrierung<br>von unerwünschtem Verhalten hilft Entwicklern dabei, Softwarefehler zu<br>identifizieren und zu beseitigen.  Als Teil des I/O-Subsystems spielen<br>Dateisysteme im Linux-Kernel eine wichtige Rolle. Es soll gezeigt werden, wie<br>spezielle Bereiche von Dateisystemen innerhalb des Linux-Kernels penetriert<br>werden können. Der Schwerpunkt liegt dabei auf der Identifizierung der<br>entsprechenden Datenbereiche unterhalb der Dateisystemebene sowie deren<br>Modifikation. Für die technische<br>Umsetzung soll das Fuzzing-Framework syzkaller verwendet werden, das<br>ursprünglich für das Testen von Systemaufrufen entwickelt wurde. Mithilfe eines<br>Machbarkeitsnachweises soll gezeigt werden, welche Überlegungen und technischen<br>Ansätze nötig sind um dies umzusetzen.  Im Zuge dieser Arbeit ist ein<br>Kernel-Modul entstanden, das eine Injektion von Daten in den Block-I/O-Layer<br>des Linux-Kernels erlaubt. Durch eine Erweiterung des Fuzzing-Frameworks ist es<br>gelungen, durch syzkaller generierte ext2-Inode- sowie<br>Btrfs-Superblock-Strukturen in den Linux-Kernel zu injizieren. Während der<br>Testdurchführung wurde ein Use-After-Free-Fehlverhalten in der<br>Btrfs-Implementierung des Linux-Kernels entdeckt.
22.01.18;19.09.18;2018;extern;Master;DE;Anomaly Detection in der Buchführung in Kooperation mit der DATEV eG;Die Masterarbeit evaluiert den Einsatz der Anomalieerkennung als Methode für die Überprüfung der Buchführung von Unternehmen. Dazu wurden die Grundlagen der Wirtschaftsprüfung im Bezug auf die Buchführung dargestellt und Anforderungen an neue Methoden festgelegt. Die zwei wichtigsten sind die Verständlichkeit und die Darstellbarkeit der Ergebnisse der Algorithmen. Außerdem wurden die Grundlagen der Anomalieerkennung und die Techniken der unüberwachten Anomalieerkennung aufgearbeitet.  Die Algorithmen HBOS, KNN und LOF wurden von einer Erweiterung des Data Mining Tools RapidMiner nach Python bzw. C++ portiert und deren Einsatz wurde in drei Buchführungen evaluiert. Bei der praktischen Evaluation hat sich herausgestellt, dass es Sinn macht, die Algorithmen auf ein Merkmal gleichzeitig anzuwenden und die sich daraus ergebenden Anomalie-Scores aufzusummieren. Dies ermöglicht die Visualisierung der Ergebnisse aus einem Merkmal und macht sie verständlich. Identisch dazu ermöglicht der Einsatz eines Merkmales in verschiedenen Kontexten, Objekte aus verschiedenen Blickwinkeln zu betrachten und darin Anomalien zu erkennen. Der HBOS ist für diese Methode nicht geeignet, da die Höhe seiner Anomalie-Scores sich nicht zwischen zwei Datensätzen vergleichen lassen. Der LOF und KNN sind geeignet. Wobei der Anomalie-Scores des KNN am verständlichsten ist. Er erfüllt die Anforderungen an die Methoden in den evaluierten Anwendungsfällen.
29.01.18;26.09.18;2018;intern;Master;DE;Generierung und Visualisierung interaktiver bildbasierter 3D-Szenen mittels merkmalsbasierten Morphings;Im Rahmen dieser Arbeit wird untersucht, inwieweit die Realisierung von frei navigierbaren bildbasierten Welten mit Hilfe des Image-Morphing-Verfahrens möglich ist. Hierbei wird eine Verarbeitungskette konzeptioniert und prototypisch realisiert, welche aus einer unsortierten Bildermenge eine interaktive bildbasierte 3D-Szene generiert. Während des Vorverarbeitungsprozesses wird ein Bildgraph erstellt. Hierzu werden mittels Matching von Merkmalen die Relationen der Bilder untereinander ermittelt. Anschließend werden mittels eines Structure-from-motion Verfahrens die relativen Kameraparameter berechnet. Im Visualisierungsprozess der Verarbeitungskette kann dann mit Hilfe des Graphen jede mögliche virtuelle Ansicht rekonstruiert werden. Dabei werden anhand der Pose der virtuellen Kamera die geeignetsten Nachbarknoten ausgewählt und eine entsprechende Gewichtung pro Knoten berechnet. Anschließend wird das Morphing-Verfahren dreiecksbasiert umgesetzt. Daher werden für die in den ausgewählten Knoten enthaltenen Bilder Dreiecksnetze anhand identischer Merkmale erzeugt. Hierzu wird die Delaunay-Triangulation eingesetzt. Durch das Morphing der entsprechenden texturierten Dreiecksflächen unter Berücksichtigung der zuvor berechneten Gewichtungen können dann neue Ansichten in Echtzeit erstellt werden. Mittels der prototypisch realisierten Verarbeitungskette werden im Rahmen dieser Arbeit erste Praxisbeispiele evaluiert. Des Weiteren wird ein Ansatz für zukünftige Projekte geschaffen.
30.01.18;30.06.18;2018;intern;Bachelor;DE;Echtzeit-Darstellung von Fahrzeugparametern mittels Arduino, OBD2 und CAN;In dieser Arbeit wird die Entwicklung und Umsetzung eines CAN-BUS-Kommunikationsgeräts dokumentiert. Als Basis dient ein Arduino UNO R3 und ein dazu passendes CAN-BUS-Shield. Dieses Shield verfügt über die nötigen Mikrokontroller um mit dem CAN zu kommunizieren. Die Auswahl der Komponenten wurde dokumentiert und eine Einführung in nötigen Themen wurde verfasst. Es wurden die Werte Motordrehzahl, Kühlwasser- und Ansaugtemperatur mithilfe des CAN ermittelt. Hierfür mussten Anpassungen an Bibliotheken gemacht werden und die Pinbelegung der OBD2-Schnitstelle ermittelt werden. Zusätzlich wurde, mithilfe einer Spannungsteilerschaltung und eines NTC-Ressistor, ein Öltemperaturfühler verbaut. Dieser ermittelt die aktuelle Öltemperatur des Motorrads. Mithilfe eines OLED-Displays werden die ermittelten Werte dem Fahrer zur Verfügung gestellt. Abschließend wird über die erfüllten Ziele diskutiert und mögliche Erweiterungen oder Themenfortführungen aufgezeigt.
01.02.18;01.10.18;2018;extern;Master;DE;Robustes Inside-Out Tracking für großflächige Mehrnutzer VR Systeme <br> ;Die Verbreitung der virtuellen Realität (VR) in unserem Alltag nimmt immer noch zu.<br>Früher waren VR-Systeme teuer und aufwändig zu installieren. Die Entwicklung moderner<br>Head-Mountet-Displays (HMD) ermöglicht es jedoch kundenfreundliche Systeme<br>zu entwickeln. Trotzdem sind diese VR-Systeme nur auf kleinen Flächen (ca. 20m2)<br>einsatzbereit. und für wenige Nutzer geeignet oder erfordern teure Kamerasysteme,<br>die aufwändig aufgebaut und eingemessen werden müssen. Die aktuelle Entwicklung<br>von Inside-Out-Tracking (IO-Tracking) soll in Zukunft zwar allgegenwärtige VR ermöglichen,<br>leidet jedoch noch an schlechter Zuverlässigkeit und niedriger Genauigkeit.<br>In dieser Arbeit wird ein Verfahren vorgestellt, das durch die Fusion von Funk- und<br>IO-Tracking ein System realisiert, das mehrere Nutzer auf einer Fläche von über ca.<br>30x30m zuverlässig und genau in der VR abbilden kann und die Wahrnehmung und<br>das Wohlbefinden der Nutzer nicht negativ beeinflusst.
01.02.18;01.10.18;2018;extern;Master;DE;Robuste Posenschätzung durch Identifikation von Kalibriermomenten mittels Maschine Learning;Die Verbreitung der virtuellen Realität (VR) in unserem Alltag nimmt immer mehr zu. In diesem Kontext ist ein Tracking System entstanden, das die Kopforientierung und die Position von Benutzern zuverlässig erfasst. Um die Präsenz der Nutzer in der VR weiter zu steigern muss die Interaktionsfähigkeit der Nutzer ermöglicht werden und somit das zuverlässige und dauerhaft stabile Erfassen der Hand-Pose. <br>Erste naive Versuche mit Inertial Measurement Units (IMUs) können aufgrund von relativen Positionsdaten und Orientierungsdrift keine langzeit-stabile Hand-Pose ermitteln. Magnetsensoren und Sensorfusionen können etwaige Fehler in Innenraumszenarien nicht auflösen. <br>Im Rahmen dieser Arbeit wurde mit Ansätzen des Machine Learning (ML) versucht die Hand zu Körper Pose in der Bewegung wiederzufinden und mit Hilfe von vorhandenem Weltwissen die Fehler zu korrigieren. Eine Support Vector Machine löst mit einer Genauigkeit von über 30\% die Hand zu Körper Pose korrekt auf. Somit kann der vorgeschlagene Ansatz in 3 von 10 Fällen die absolute Orientierung korrekt bestimmen und etwaige Fehler auflösen. In den restlichen 7 Fällen passiert nichts, dass heisst es findet auch keine Verschlechterung der statt. 
08.02.18;30.09.18;2018;extern;Master;DE;Tool zur Registrierung und Flächenrekonstruktion von Surfboards;In Kooperation mit der HNO-Klinik des Uni-Klinikums Erlangen (Prof. Michael Döllinger) wird ein Programm in MATLAB entwickelt, das die CT-Daten eingescannter Surfboards automatisiert in ein 3D-Modell umwandelt, mit welchem dann numerische Strömungsanalysen durchgeführt werden können.<br>Die verschiedenen Datensätze eines mittels Computertomographie (CT) gescannten Surfboards werden rekonstruiert, indem sie einzeln segmentiert werden. Durch Translation und Rotation werden die Surfboard-Teile zueinander registriert und danach zu einem Objekt zusammengesetzt.  Die zum Surfboard gehörenden Finnen und einteilige Surfboards werden in einem eigenen Programmablauf segmentiert. Diese Vorgänge sollen automatisiert ablaufen.<br>Das Programm enthält mehrere grafische Benutzeroberflächen, in welchen die Funktionen zum Laden der CT-Daten für Surfboard und Finnen und das Speichern des fertigen 3D-Objekts eingebunden werden. Auch die Voreinstellungen für die Segmentierung und das Festlegen der manuellen Merkmalspunkte werden vom Anwender anhand der grafischen Benutzeroberflächen vorgenommen.<br>Die Implementierung des Programms wird in MATLAB vorgenommen.
08.02.18;08.07.18;2018;extern;Bachelor;DE;Ein Konzept zur Einführung eines Customer Order Decoupling Points bei Schwan-Stabilo Cosmetics;Schwan-STABILO Cosmetics (SSC) ist einer der größten Produzenten von Kosmetikstiften. Durch den Wandel, welchen die Digitalisierung und soziale Plattformen mit sich gebracht haben, steigen die Anforderungen der Kunden. Das macht sich vor allem hinsichtlich der Lieferzeit bemerkbar. Um den Anspruch der Kunden gerecht zu werden, gilt es also die Durchlaufzeit zu reduzieren. In dieser Arbeit wurde also der Auftragsabwicklungsprozess analysiert, um Stellen zu identifizieren, die der Grund für die hohe Durchlaufzeit sind. Die Analyse ergab, dass vor allem die hohe Vorlaufzeit für die Beschaffung der Komponenten ins Gewicht fällt. Dazu muss man wissen, dass bei SSC auftragsbezogen gefertigt wird und die Komponenten des Kosmetikstiftes auftragsbezogen bestellt werden. Dadurch entstehen mehrere Wochen an Vorlaufzeit, die für die Auftragsabwicklung sehr kostbar sind. Als Lösungsansatz ergibt sich somit eine Entkopplung des Beschaffungsprozesses, indem man die Komponenten auftragsanonym beschafft. Kundenindividuelle Massenfertigung (Mass customization) und Variantenproduktion erschweren die Lagerhaltung, weil es wirtschaftlich nicht von Vorteil ist, alle möglichen Varianten von Komponenten zu lagern. Folglich macht nur eine Lagerhaltung von nicht kundenspezifischen Komponenten Sinn, weil diese variabel für mehrere Kunden verwendbar sind. Durch eine Lagerhaltung von Standardkomponenten kann somit die Durchlaufzeit reduziert werden. Der Beschaffungsprozess wird somit entkoppelt.
15.02.18;16.07.18;2018;extern;Bachelor;EN;Analysis, conception and implementation of a Client-Server communication layer for a social gaming app;The purpose of this thesis is to conceive and implement a Client-Server communication layer for a social media gaming app in cooperation with the company K&K Kommunikationssystem GmbH. The application is a social- network game that can run on multiple mobile devices, in which players can challenge themselves and other players. Player who completes a challenge with best result will be the winner. There are different types of challenges which involve different data formats (image, text, video etc.)  and different winning conditions (shortest time, highest rating etc.). The result of this thesis ensures a stable, reliable communication between Clients and Servers.
15.02.18;15.10.18;2018;extern;Master;DE;Konzeption und Entwicklung eines Machine Learning-Ansatzes zum dynamischen Frequency Capping von Online-Werbeanzeigen;Die vorliegende Master-Thesis erforscht die Fragestellung, auf welche Weise Machine Learning-Technologie im Online-Marketing der ING-DiBa AG eingesetzt werden kann, um eine personalisiertere Aussteuerung von Werbemitteln zu ermöglichen. Anhand ausgewählter Produktivdaten wird ein Datenmodell abgeleitet und ein fachliches Konzept entwickelt, das sowohl Anforderungen, als auch Verarbeitungsschritte eines technischen Lösungsansatzes definiert. Aufbauend darauf wird ein Machine Learning-Ansatz konzipiert und entwickelt, der die Möglichkeiten zur personalisierten Limitierung von Werbeausspielungen durch Frequency Capping erforscht. Zur Identifikation eines geeigneten ML-Ansatzes wird das Random Forest, XGBoost- und KNearestNeighbor-Verfahren in einem Multi-Label-Setting untersucht und anhand verschiedener Metriken vergleichend evaluiert.<br>Die Untersuchungen zeigen, dass Machine Learning das Potential besitzt, die personalisierte Ausspielung von Anzeigen zu verbessern und den wirtschaftlichen Mehrwert von Werbung zu erhöhen. Entscheidungsbaumbasierte Ensemble Learning-Verfahren erweisen sich in den Untersuchungen als performante Methoden, da sie aufgrund ihrer Genauigkeit, Skalierbarkeit und Robustheit für die effiziente Verarbeitung strukturierter Daten geeignet sind. Die personalisierte Begrenzung von Werbung durch Frequency Capping erweist sich als ungeeigneter Ansatz, da eine individuelle Wirksamkeit von Anzeigen von einer Vielzahl individueller Faktoren abhängig ist.
19.02.18;19.07.18;2018;intern;Bachelor;DE;Analyse externer Manipulation von künstlichen neuronalen Netzen;Künstliche Neuronale Netze finden sich überall wieder. In modernen Haushalten zum Beispiel finden sie Einzug mit Apple Siri oder Amazon Alexa. Jedoch werden sie in verschiedenen anderen Bereichen verwendet, unter Anderem auch in sicherheitskritischen Bereichen. Aus diesem Grund ist es wichtige diese Technologie auf ihre Sicherheit gegen Manipulation und auf die Zuverlässigkeit im Ergebnis zu prüfen. Das Ziel der vorliegenden Bachelorarbeit war es, ein künstliches Neuronales Netz zu entwickeln sowie eine Manipulation, welche eine Fehlklassifizierung hervorruft. Hierbei sollte vor allem die besagte Sicherheit und Zuverlässigkeit künstlicher Neuronaler Netze erforscht werden.<br>Zur Entwicklung des Neuronalen Netzes wurde TensorFlow verwendet, was eine Erweiterungsbibliothek für Python ist, dies ist eine der meist verwendeten Hilfsbibliotheken in diesem Bereich. Die Arbeit befasst sich mit der Erstellung des Netzes, sowie mit einer Manipulation dessen. Des Weiteren werden bekannte Manipulationen und verschiedene Schutzmechanismen angesprochen. Das künstliche Neuronale Netz, welches in dieser Arbeit entwickelt wurde, soll eine sechsstellige hexadezimale Zahl, welche einen Rot-Grün-Blau-Wert darstellt, als Farbe klassifizieren. Es wurde außerdem eine Manipulation konzipiert, die mit dem vorher entwickelten Netz verifiziert wurde. Im Vorfeld wurden verschiedene Manipulationen recherchiert, diese werden in dieser Arbeit vorgestellt.
21.02.18;21.07.18;2018;intern;Bachelor;DE;Analyse und Bewertung des Einsatzes von Apache Spark als zentrale Infrastruktur für die Vorverarbeitung und Analyse von Textdaten am Beispiel von Brettspielanleitungen;In der aktuellen Vorverarbeitung tauchen immer wieder Probleme im Ablauf auf. Diese treten aufgrund von heterogenen Daten auf und gehen mit anderen Problemen wie dasVerwenden von zwei Betriebssystemen einher, was eine automatischen Ablauf verhindert. Es wurde die Vermutung aufgestellt, dass die Probleme mit der Verwendung von Apche Spark als zentrale Infrastruktur für die Vorverarbeitung zu lösen sind, was im Laufe der Arbeit diskutiert wird.<br>Anfangs werden die Probleme der aktuellen Vorverarbeitung diskutiert um einen Einblick zu geben weshalb die Arbeit nötig wurde. Weiter werden grundlegende Kenntnisse im Zusammenhang mit Apache Spark und anschließend das Prinzip der RDDs erklärt. Weiter wird ein Einblick über die Komponenten der Open-<br>Source-Software und deren Funktionen dargestellt. Abschließend zum theoretischen Teil wird die Architektur einer Anwendung von Spark und dessen Komponenten erklärt. Zudem werden die möglichen Datenbanken erwähnt und auf Apache Cassandra, welche aktuell verwendet wird, mit dem HDFS in Kontrast gesetzt.<br>Danach werden die Skripte für die Vorverarbeitung nach Python übersetzt, Optimierungen vorgenommen und zur Verwendung in Spark angepasst. Abschließend wird über die sich ergebenden Vor- und Nachteile durch die Verwendung von Spark diskutiert und eine Wertung über Spark als zentrale Infrastruktur abgegeben. Weiter werden die noch offenen Möglichkeiten, die Spark für das Projekt bietet angesprochen und Zum Schluss ein persönliches Resümee gezogen
21.02.18;21.07.18;2018;intern;Bachelor;DE;Feingranulare Zugriffskontrolle in Webanwendungen mit Oracle Virtual Private Databases;-
22.02.18;22.07.18;2018;extern;Bachelor;DE;Orchestrierung von IoT-Geräten am Beispiel von Siemens Edge Systemen;
01.03.18;01.08.18;2018;extern;Bachelor;DE;Analyse und Evaluierung aktueller MR Tracking Systeme am Beispiel ARKit;In dieser Arbeit werden MR-Trackingsysteme zur sogenannten Selbstlokalisierung mithilfe der auf dem freien Markt erhältlichen Plattformen Apple ARKit und Google ARCore realisiert.<br>Mithilfe der Analyse von Schwachstellen dieser Systeme konnten Indikatoren für robuste und genaue Selbstlokalisierung gefunden werden. <br>Die Indikatoren stehen in direktem Zusammenhang mit der Umgebungsbeschaffenheit (Anzahl der identifizierbaren Merkmale) und Bewegung (im Umfeld oder vom Anwender).<br>Konkret konnten aus den Schwachstellen und Indikatoren eine Bewertungsvorlage zusammengestellt werden, welche Parameter für stabiles Tracking und den direkten Vergleich zwischen Systemen bereitstellt.<br>Daraus wurden Messfälle konzipiert, die einerseits Laborbedingungen für Informationsgesamtheit, aber auch alltagsähnliche Szenarien beschreiben.<br>Die Evaluation zeigte, dass die Umgebungsdynamik in merkmal-basierte Trackingsystemen starke Probleme auslöst, bei länger andauernder Verdeckung der Umfeld nicht zu korrigieren ist. <br>Das System verliert in diesen Fällen jegliche, zur Verortung verwendete Merkmale. Ohne Merkmale fehlt die Korrelation aus optischem Fluss und der eigenen Bewegung und es kann keine Pose bestimmt werden.<br>Aus den Messungen konnten Grenzwerte unterschiedlicher Szenarien für die Beschaffenheit der Umgebung und Bewegungszustände ermittelt werden, damit MR-Anwendungen ohne signifikanten Drift oder Systemausfälle verwendet werden können.<br>
01.03.18;24.08.18;2018;extern;Master;DE;Entwicklung eines Verfahrens zur Qualitätssicherung mittels neuronaler Netze in der Elektronik-Fertigung;Die Prüfung von Leiterplatten auf eine korrekte Bestückung stellt eine komplexe Aufgabe für die industrielle Bildverarbeitung dar. Um diese Herausforderung zu bewältigen, werden aufwändige Bildverarbeitungssysteme und tiefgreifendes Expertenwissen benötigt. Die rasante Entwicklung im Bereich des maschinellen Lernens ermöglicht einerseits solche Systeme günstiger zu gestalten und andererseits deren Bedienung zu vereinfachen. Die vorliegende Abschlussarbeit demonstriert die Realisierung eines neu entwickelten Prüfverfahrens, dass dieses Potential ausschöpft. Da die Datenmenge ein zentraler Faktor für lernende Verfahren darstellt, wurde ein optisches Prüfsystem an der Bestückungslinie in der Fertigung der Firma IDS aufgebaut, um Prüfobjekte abzubilden. Diese Bilder wurden für das nicht überwachte Training diverser Autoencoder-Architekturen und deren anschließenden Evaluierung verwendet. Anhand einer Ähnlichkeitsanalyse der originalen und der vom Autoencoder generierten Bilder konnten fehlerbehaftete Platinen detektiert werden. Durch die Gegenüberstellung eines bisherigen Prüfverfahrens mit dem neu entwickelten, mit Fokus auf Autonomie und Bedienbarkeit, konnten konkrete Optimierungsmaßnahmen formuliert werden. Das neu entwickelte Verfahren kann durch Nutzung entsprechender Trainingsdaten auf ein breites Aufgabenspektrum aus dem Bereich der Qualitätssicherung erweitert werden.
06.03.18;01.08.18;2018;extern;Bachelor;DE;Visualisierung der weltweiten IT-Migrationen bei einer Prüfungs- und Beratungsgesellschaft mit Microsoft Power BI;Ein essenzieller Teil eines jeden Projektes ist das Reporting an das Management und<br>weitere Stakeholder. In der Regel werden, mit hohem Aufwand, individuelle Inhalte, der<br>aktuelle Projektstatus sowie KPIs (Key Performance Indicators) mit den bekannten Microsoft<br>Office Produkten visualisiert und für die jeweilige Interessengruppe angepasst. Für<br>die Umsetzung wird meist sehr viel Zeit aufgewendet, wodurch andere Aufgaben untergeordnet<br>werden müssen und der Projektfortschritt stagniert.<br>Ziel dieser Bachelorarbeit ist eine Verbesserung der täglichen Projektarbeit durch Automatisierung<br>des Reportings und dem Einbau interaktiver graphischer Darstellungen.<br>Zunächst sollen die gewünschten Erwartungen an das allgemeine Reporting innerhalb<br>des Projektes Global Office bei Rödl & Partner durch eine Anforderungsanalyse erhoben<br>werden. Anschließend werden mehrere Reporting-Möglichkeiten evaluiert und verglichen.<br>Schlussendlich soll mit der Software Microsoft Power BI ein aktuelles und verständliches<br>Berichtswesen mithilfe von Automatisierungen und interaktiven Elementen entwickelt werden,<br>auf dessen Basis auch nachfolgende Projekte aufbauen können.
06.03.18;06.08.18;2018;intern;Bachelor;DE;Identifikation und Evaluation von Spielertypenmodellen hinsichtlich ihrer Eignung den Übertrag von Spiel-Design-Elementen in einen spielfremden Kontext zu unterstützen.;Der Evalautionsgegenstand dieser Arbeit sind vier Spielertypenmodelle, die unterschiedlichen Kontexten entstammen. Anhand von verschiedenen Evalationsszenarien und unter zur Zuhilfenahme von Patterns aus Gesellschaftsspielen wird geprüft, welches dieser Modelle sich am besten für den Einsatz in der Gamification eignet.
13.03.18;13.08.18;2018;extern;Bachelor;DE;Analyse und Umsetzung eines Deploymentprozesses von Anwendungen in Container;In der modernen Softwareentwicklung wird der Deploymentprozess von Anwendungen<br>auf Server vermehrt optimiert. Mehrere Anwendungen sollen möglichst unabhängig<br>voneinander auf einem Server lauffähig sein. Dies kann durch den Einsatz von virtuellen<br>Containern realisiert werden.<br>In dieser Bachelorarbeit wird in Kooperation mit der Firma endobit software solutions ein<br>solcher Deploymentprozess entwickelt, der Anwendungen in Container auf einer Cloud-<br>Plattform lauffähig macht. Für die Container-Technologien Docker und Turbo.net sowie<br>den Cloud-Plattformen Microsoft Azure, Amazon Web Services (AWS) und Google Cloud<br>Platform wird eine Analyse und anschließend eine Bewertung durchgeführt. Schließ-<br>lich wird jeweils eine Technologie gewählt, um ein prototypisches Deployment einer<br>Webanwendung durchzuführen.<br>Es wird gezeigt, dass der Aufwand zur Durchführung dieses Deployment-Prozesses gering<br>ist, aber dennoch Einschränkungen bei neueren Funktionen der verfügbaren Techno-<br>logien vorhanden sind. Im Vergleich zu vorherigen Deployments auf einen einzelnen<br>Anwendungsserver hat sich dieses Vorgehen als geeignete Alternative erwiesen.
15.03.18;13.08.18;2018;intern;Bachelor;DE;Konzeption und prototypische Realisierung einer Webapplikation für die individualisierte Online-Schlafberatung;Der Beratungsbedarf und das Beratungsangebot nehmen in allen Gesellschaftsbereichen durch das in den letzten zwei Jahrzehnten gestiegene Lebenstempo rasant zu. Der daraus entstehende Orientierungsverlust des Einzelnen führt zu einer extremen Nachfrage an Beratungsangeboten. Die Bachlorarbeit beschäftigte sich daher, am Beispiel der Online-Schlafberatung, mit der Entwicklung einer universal nutzbaren Beratungsplattform. Ausgangspunkt war dabei der erste Entwurf einer existieren Beratungsplattform. Diese wurde kritisch beleuchtet und durch den Einsatz moderner Webtechnologien, wie Angular 6, sukzessiv um weitere Funktionen erweitert. Die gestellten Anforderungen konnten vollständig umgesetzt und damit ein Mehrwert für die Beratung geschaffen werden. Schlussendlich wurde der bestehende Server betrachtet und eine Handlungsempfehlung auf Basis aktueller Frameworks, wie Loopback.js, erarbeitet. Der erste Entwurf eines neuen Servers, der die bestehenden Probleme behebt, wurde ebenfalls erfolgreich umgesetzt. Die Arbeit ordnet sich in die Schlafforschung des Instituts für E-Beratung der TH-Nürnberg ein und entstand in Zusammenarbeit mit diesem Institut. 
15.03.18;31.08.18;2018;extern;Master;DE;Anwendungsfelder künstlicher Intelligenz zur Schaffung eines exzellenten Kundenservice;Ziel der vorliegenden Arbeit ist es, Anwendungsfelder künstlicher Intelligenz (kurz KI) für den Bereich des Privatkundenservice zu identifizieren, zu konzeptionieren und zu evaluieren. Anhand derer soll anschließend aufgezeigt werden, wie mithilfe von KI die dem Kundenservice zur Verfügung stehenden Ressourcen möglichst qualitätssteigernd und gewinnbringend eingesetzt werden können. Adressaten der Arbeit sind dabei strategische Mitarbeiter sowie Projektverantwortliche der IT und des Kundenservice.<br><br>Zur Zielerreichung wird zunächst der theoretische Rahmen erarbeitet. Darauf aufbauend werden branchen- und unternehmensübergreifende Analyseerkenntnisse in einem Gesamtbild zusammengefasst, spezifische Kundenreisen der N-ERGIE evaluiert und kundenservicespezifische Anwendungsmöglichkeiten von KI definiert. Auf Basis dessen erfolgt anschließend die Formulierung einer Vision für den Kundenservice der Zukunft sowie die Ableitung von Transformationsprojekten zur Umsetzung dieser. Abschließend wird zur Verifizierung der ermittelten Erkenntnisse der Anwendungsfall der Auswertung von Kundenmails exemplarisch hinsichtlich Sprache, Kundenstimmung und Inhaltskategorie erprobt.<br><br>Im Ergebnis wird deutlich, dass zur Etablierung eines zukunftsfähigen Kundenservice eine Entlastung von nicht wertschöpfenden Tätigkeiten durch KI unabdingbar ist.
15.03.18;15.08.18;2018;intern;Bachelor;DE;Vergleich von medizinischen Aktometern mit Smartwatches;"Die Bachelorarbeit ""Vergleich von medizinischen Aktometern mit Smartwatches"" bei Herr Professor Gallwitz soll erarbeiten, ob ein Vergleich von medizinischen Geräten mit Fitnessarmbändern oder Smartwatches möglich ist. Dies soll im Rahmen einer Onlineschlafberatung des Instituts für E-Beratung geschehen. Bisher wird die Schlafqualität vom Probanden angegeben. Diese subjektiven Angaben können aber von der tatsächlichen Situation abweichen, wodurch eine optimale Beratung erschwert wird. Das Ziel ist es, die Schlafqualität objektiv zu ermitteln. Zusätzlich soll die Beratung der breiten Masse verfügbar gemacht werden, weshalb nach Möglichkeit auf die teuren medizinischen Geräte verzichtet werden soll. Dazu muss erarbeitet werden, welche Messwerte eines Aktometers für die Ermittlung der Schlafqualität herangezogen werden. Diese müssen aus geeigneten Smartwatches oder Fitnessarmbändern ausgelesen und mit denen, eines professionellen Geräts verglichen werden."
15.03.18;15.08.18;2018;extern;Bachelor;DE;Marktanalyse industriefähiger Single-Board Mikrocontroller und Programmierung dieser für den Einsatz im Globalen Datenraum der Firma ABC IT GmbH;Das Ziel dieser Arbeit ist es, zu zeigen, dass heutige Mikrocontroller in der Lage sind, größere Aufgaben zu erledigen und zwar auf industrieller Ebene. Hierbei werden drei Single-Board Mikrocontroller ausgesucht, die für die Industrie gedacht sind und bestimmte Kriterien erfüllen. Anschließend werden in alle drei Boards eine industrielle Kommunikationstechnik implementiert, in diesem Fall das GDX-Protokoll der Firma ABC IT GmbH. Abschließend werden Stabilitätstests und Datenverlustmessungen durchgeführt, die zeigen, dass Mikrocontroller die Leistung und Stabilität für den industriellen Einsatz bringen können.   
19.03.18;19.08.18;2018;extern;Bachelor;DE;Konzeption von Workflows im Gefahren-Management-System ;"Die DATEV eG ist ein Software- und IT-Dienstleister für Steuerberater, Wirtschaftsprüfer, Rechtsanwälte, mittelständische Unternehmen, Kommunen, Vereine und Institutionen. Das Unternehmen zählt zu den größten IT-Dienstleistern und Softwarehäusern in Deutschland. Aufgrund des besonderen Risikos der Datenkompromittierung, unterliegt das Unternehmen hohen Sicherheitsansprüchen. Die IT-Sicherheit hat die Aufgabe, auf technische Ereignisse, wie Angriffe durch Hacker, Viren, Troja-ner und Spyware zu achten.<br>Die zweite Komponente des Sicherheitsanspruches wird durch die ""Physische Sicherheit"" wahrgenommen. Physische Sicherheit ist der Schutz von Mitarbeitern, Infrastruktur, Gebäuden, Anlagen, Hardware und Daten vor äußeren Gefahren und Ereignissen, die Schadensauswirkungen auf das Unternehmen haben könnten. Darin enthalten sind der Schutz vor elementaren Schäden, Einbruch, Diebstahl, Vandalismus, Terrorismus und Wirtschaftsspionage. Die ""Physische Sicherheit"" basiert auf den technischen, organisatorischen und personellen Komponenten ""Sicherheitstechnik"" und ""Betriebsschutz"". Anhand der Konzipierung von Workflows für das Gefahren-Management-System soll der Sicherheitsanspruch an die Physische Sicherheit effektiv und effizient gedeckt werden. Diese Konzeption bildet einen wesentlichen Bestandteil der nachfolgenden Arbeit. "
19.03.18;16.09.18;2018;intern;Bachelor;DE;Exemplarische Realisierung einer Automotive Ethernet Anwendung zu Lehr- und Forschungszwecken;Ziel dieser Bachelorarbeit war die Entwicklung einer auf der Elektrobit Werkzeugkette basierenden AUTOSAR-Beispielanwendung zum Thema Automotive Ethernet für das Automotive Software Labor der Fakultät Informatik an der TH Nürnberg. Dazu wurden, neben der Vermittlung der notwendigen<br>Grundlagen, eine geeignete Beispielanwendung ausgewählt, der Ablauf von <br>der Planung bis zur Auswertung eines einfachen Automotive Software Engineering Projekts aufgezeigt, und die verwendeten Werkzeuge vorgestellt.<br>Das gesetzte Ziel einer lauffähigen Software wurde allerdings verfehlt.
19.03.18;19.08.18;2018;intern;Bachelor;DE;Evaluierung von GitLab CI in Kombination mit docker für den Einsatz an einer Hochschule;"Aktuell wird an der Technischen Hochschule Nürnberg eine GitLab Installation angeboten. Dort können Software-Projekte mit Quellcode, Aufgaben und Meilensteinen verwaltet werden. In der modernen Softwareentwicklung wird ein als Continuous Integration bezeichnete Verfahren genutzt, das von GitLab mit dem Produkt ""GitLab CI"" unterstützt wird.<br><br>Im Rahmen dieser Bachelor-Arbeit wird evaluiert, ob ""GitLab CI"" für den Einsatz an der Technischen Hochschule Nürnberg geeignet ist. Hierbei ist auf Datenschutz, Sicherheit, die Vielfalt der Anwender und deren Anwendungsfälle zu achten. Um den Anforderungen gerecht zu werden ist zunächst angedacht die Integrationsmöglichkeit von ""GitLab CI"" und der Virtualisierungstechnologie docker zu nutzen um Flexibilität und Sicherheit zu gewährleisten."
20.03.18;20.08.18;2018;extern;Bachelor;DE;Out-of-the-Box IoT Connectivity Lösung;Im Rahmen dieser Bachelorarbeit wurde eine Software-Lösung entwickelt, die es ermöglicht, einen Bluetooth Low Energy Mikrocontroller als Co-Prozessor eines eingebetteten Systems zu verwenden. Dies ermöglicht eine Einbindung der drahtlosen Kommunikationstechnologie in bereits bestehende technische Anwendungen, welche standardmäßig keine Unterstützung hierfür mit sich bringen oder auf denen eine lokale Implementierung nicht in Frage kommt. <br>Dabei wurde eine Firmware für einen ESP32 Mikrocontroller entwickelt, welcher als Bluetooth System on a Chip eingesetzt werden kann und grundlegende Bluetooth Low Energy Funktionalitäten über Datenbusse frei konfigurierbar zur Verfügung stellt. Ergänzend hierzu wurde eine passende Software Bibliothek entworfen, welche für eine einfache Integration der von der Bluetooth Hardware bereitgestellten Funktionalitäten auf einem Anwendungs-Controller eingesetzt werden kann. <br>Die Bachelorarbeit gibt zu Beginn eine Einführung in den Bluetooth Standard sowie in die hierbei eingesetzten Technologien und gibt eine Analyse über bereits vorhandene Lösungsansätze. Anschließend wird auf die zur Umsetzung verwendeten Konzepte eingegangen, die unter Einbeziehung der zuvor durchgeführten Analyse daraus übernommen oder abgeändert wurden. <br>Zuletzt wird beschrieben, wie das hierbei entstandene Produkt in ein konkretes Anwendungsszenario eingesetzt werden kann.?
23.03.18;23.08.18;2018;extern;Bachelor;DE;Intelligente Verknüpfung von Routenzügen und fahrerlosen Transportsystemen unter Nutzung von Digitalisierungsansätzen für die interne Materialversorgung des Gerätewerks Erlangen der Siemens AG;Diese Bachelorarbeit wurde in Zusammenarbeit mit der Siemens AG in Erlangen im Bereich der Inbound-Logistik erstellt. Ziel war es Optimierungspotentiale für die internen Transportsysteme zu ermitteln. Hierfür wurden zunächst, mit Hilfe der im Prozess erhobenen Daten, verschiedene Ursachen für die berechnete geringe Produktivität erarbeitet. Anhand einer Vision konnten diese dann in Kategorien und Maßnahmen übersetzt werden. Mit einer Expertenschätzung konnten einzelnen Maßnahmen Potentiale zugewiesen werden, die ihre Effektivität, hinsichtlich der Optimierungsmöglichkeiten, darstellen. Abschließend wurden ein Stufenkonzept entwickelt, mit dem die Maßnahmen einer sinnvollen Reihenfolge zugeordnet werden konnten. 
26.03.18;26.08.18;2018;extern;Bachelor;DE;Konzeptionierung und Implementierung einer Benutzerschnittstelle für einen 3D-Bio-Drucker nach der Norm DIN EN 62366;Im Rahmen eines Forschungsprojektes arbeiten mehrere Partnerfirmen an der Erforschung und Evaluation des innovativen 3D-Druckers für die biologischen Zwecke, der entsprechenden Prozesse sowie an der Datenaufbereitung für das 3D-Bio-Printing und der Konzeption sowie Realisierung einer offenen, normkonformen und anpassbaren Software-Plattform zur Ansteuerung und Bedienung des Bio-Printers. Eine der wichtigen Ziele ist die Bereitstellung einer Software-Plattform, welche die Bedienung, Nutzung und Konfiguration eines 3D-Bio-Printer-Geräts ermöglicht und dabei eine vom Druckermodell unabhängige Kommunikationsschnittstelle evaluiert.<br><br>Für den Benutzer soll es möglich sein, Materialien, Füllmuster und Druckmodelle hinzuzufügen, zu verändern und auszuwählen, Parameter für einen Fertigungsprozess einzustellen und, falls der Drucker angeschlossen ist, einen vorgespeicherten Druckauftrag ausführen lassen. Der Benutzer mit einer entsprechenden Berechtigung kann noch zusätzlich druckerspezifische Parameter einstellen.<br><br>Diese Arbeit befasst sich mit der Konzeption und Entwicklung einer intuitiv und komfortabel bedienbaren Benutzerschnittstelle für die Ansteuerung des 3D-Bio-Printers. Dabei wird nach der Norm DIN EN 62366 vorgegangen um die Effektivität, Effizienz, Lernförderlichkeit und Zufriedenstellung des Benutzers zu erhöhen und die möglichen Risiken zu vermeiden.
27.03.18;20.08.18;2018;intern;Bachelor;DE;Effizienzsteigerung des Budgetierungsprozesses durch den Einsatz agiler Methoden am Beispiel von Beyond-Budgeting;-
27.03.18;27.08.18;2018;intern;Bachelor;DE;E-Learning im Studium - ein Vergleich zu  Präsenzunterricht am Beispiel eines integrativen Vermittlungskonzepts zum Thema Knowledge Modeling und Description Language - quantitative Analyse und Erarbeitung von Handlungsempfehlungen;
01.04.18;28.11.18;2018;intern;Master;DE;Evaluierung eines virtuellen, sprachgesteuerten Assistenten zur Erweiterung eines Fuzzy-Optimierungssystems auf Basis von Open-Source-Technologien;Die vorliegende Masterarbeit zeigt durch die Evaluierung eines virtuellen, sprachgesteuerten Assistenten wesentliche Vorzüge und Schwachstellen einer rein sprachlichen Ein- und Ausgabe bei der Bedienung einer Software. Das betrachtete Fuzzy-Optimierungssystem steht dabei stellvertretend für komplexe Anwendungsbereiche, welche über einfache Tätigkeiten wie dem Setzten eines Weckers hinausgehen. Nach der Entwicklung eines Prototyps für den Open-Source-Sprachassistenten Mycroft AI erfolgt die Bewertung des Basismodells durch eine Nutzwertanalyse. Eine qualitative Bewertung der Erweiterung mit Einbezug externer Probanden im Zuge eines Usability-Tests trägt zu einer objektiven Einschätzung bei. Es wird gezeigt, dass Sprachassistenten im Bereich der Programmsteuerung einer konventionellen, oberflächengestützten Software überlegen sind, jedoch durch die rein sprachliche Wiedergabe komplexer Inhalte schnell an die Grenzen der menschlichen, auditiven Auffassungsgabe stoßen. Der Autor empfiehlt daher den Einsatz beider Technologien mit unterschiedlichen Schwerpunkten. Während die Programmsteuerung im Regelfall rein sprachlich erfolgen sollte, trägt eine visuelle Darstellung neben der sprachliche Ausgabe zu einem höheren Gesamtnutzen bei.
01.04.18;31.08.18;2018;extern;Bachelor;DE;Design und prototypische Implementierung eines Performance Profilers für SPS-Anwenderprogramme auf Basis von TIA Portal Openness;"Automatisierungstechniker müssen Performance Tests für SPS-Anwenderprogramme heute händisch implementieren. Hierzu sind SPS-Code und entsprechende Protokollierungs- und Auswertungsmöglichkeiten zu implementieren. Die Tests werden dann meist manuell ausgeführt. Die Folge ist ein hoher manueller Aufwand, welcher zwangsläufig auch zu fehleranfällige Implementierung führen kann.<br>Ziel der Bachelorarbeit ist es, ein Prototyp für automatisierte Performance Analysen von SPS-Anwenderprogrammen auf verschiedenen Zielsystemen (S7-1500, S7-1200, etc.) zu implementieren. Mit diesem soll es dem Anwender ermöglicht werden, ohne tiefe Kenntnisse von Hochsprachenprogrammierung automatisierte Performance Analysen auf dem Zielsystemen durchzuführen. Im Baukastenprinzip soll sich der Anwender seine gewünschten Analysen (Speicherbedarf, Laufzeit, etc.) auswählen können, daraufhin wird ihm automatisch der benötigte Code generiert und auf dem Zielsystem ausgeführt. Dies erfolgt über eine automatische Codegenerierung, welche mittels TIA Portal Openness angebunden ist. Die beispielhafte Umsetzung, die Teil dieser Bachelorarbeit sein wird, dient der Siemens AG als ""Proof of Concept""."
02.04.18;02.09.18;2018;intern;Bachelor;EN;Cross-plattform development using the Electron Framework, Angular<br>and ASP.NET Core;The purpose of this work is to explain how the Electron, Angular, and ASP.NET Core frameworks can be used to create a cross-platform application with a single code base. A brief introduction is given on the proof-of-concept application and its architecture. Each framework is described in general, followed by a section about the challenges presented by development and possible solutions. These are illustrated by detailed examples of the code written for the proof-of-concept application. The implementation of notifications, creation of a system tray icon, and websocket communication are addressed in detail. The adaptability and ease of use of these three frameworks is analyzed and compared to the advantages and disadvantages presented by a pure desktop or a pure web application.
04.04.18;03.09.18;2018;extern;Bachelor;DE;"Analyse von ""Mobile Connect"" als 2-Faktor-Authentisierung für Online-Services und Portal-Lösungen in Verbindung mit Open ID Connect";"DATEV eG stellt als eingetragene Genossenschaft Software für seine Mitglieder aus den Berufsständen Steuerberater, Wirtschaftsprüfer und Rechtsanwälten bereit. Bei der Anbindung von neuen Zielgruppen und Märkten sollen marktkonforme, sichere Lösungen im Bereich der 2-Faktor-Authentisierung betrachtet und analysiert werden.<br>Von den Netzbetreibern in Deutschland ist für das vierte Quartal 2018 der bereits in einigen Ländern verfügbare Dienst ""Mobile Connect"" angekündigt worden, durch den sich Kunden über ihr Smartphone mittels eines Kontos bei ihren Mobilfunkanbietern bei Online-Services anmelden können. Dadurch entfällt die Notwendigkeit, sich auf jeder Seite registrieren zu müssen, sofern die Seite Mobile Connect unterstützt.<br><br>In der Abschlussarbeit wird Mobile Connect analysiert. Dabei werden zuerst die Eigenschaften des Dienstes und seine Funktionsweise dargestellt. Daraus werden fachliche, technische und rechtliche Vor- und Nachteile, die für eine Verwendung sprechen, behandelt, um anschließend mögliche Einsatzszenarien aufzuzeigen.<br>Zusätzlich wird die Implementierung eines beispielhaften Prototypen ausgeführt. Anhand dieses Prototypen wird dargestellt, welche Schritte notwendig sind, um Mobile Connect in eine bestehende Webapplikation einzuführen.<br>Anhand dieser Informationen wird ein Fazit gezogen und ein Ausblick auf die Einführung des Dienstes in Deutschland gemacht."
05.04.18;01.02.19;2018;intern;Master;DE;Analyse probabilistischer Bahnplanungsverfahren und Entwicklung eines Verfahrens für einen autonomen, mobilen Roboter;Die Arbeit befasst sich mit der Analyse probabilistischer Bahnplanungsverfahren der mobilen Robotik und der Entwicklung eines Prototyps für einen autonomen, mobilen Roboter, den Carbot.<br>Der Carbot ist ein autonomer, nicht-holonomischer und radgetriebener Roboter, der von Prof. Dr. Jörg Roth an der Technischen Hochschule Nürnberg entwickelt wird. Dieser verfügt über deterministische Algorithmen zur Navigation (Pfad- bzw. Routenplanung) sowie anschließenden Bahnplanung (Fahrbahnbestimmung) im Zweidimensionalen und soll um ein zufallsbasiertes Bewegungs- bzw. Bahnplanungskonzept erweitert werden.<br>In dieser Arbeit werden Verfahren zur probabilistischen Bewegungs- bzw. Bahnplanung untersucht und verglichen. Anschließend erfolgt die formale Konzeption und prototypische Implementierung einer zufallsbasierten Bewegungs- bzw. Bahnplanung für die Carbot-Umgebung. Abschließend wird ein Vergleich des Prototyps mit den bereits verfügbaren deterministischen Algorithmen zur Navigation und Bahnplanung durchgeführt.
06.04.18;05.09.18;2018;extern;Bachelor;DE;Evaluation of an existing color trend prediction model and investigation of potential effects on the result quality by means of sales data in a global sporting goods manufacturer;Das Ziel dieser Bachlorarbeit war es, eine Handlungsempfehlung zur Verwendung von Verkaufsdaten in zukünftigen Farbtrendprognosen in der Modebranche zu geben. Dazu wurde eine Literaturanalyse durchgeführt und bereits bestehende Farbtrendprognosen anhand von Verkaufszahlen ausgewertet. Variablen die nach Erkenntnissen dieser Arbeit großen Einfluss auf das Kaufverhalten und somit Verkaufsdaten haben, wurden dabei besonders berücksichtigt. Ergebnis dabei war es, dass die Verwendung von Verkaufsdaten, nur bedingt zur erstellung von Prognosen dieser Art geeignet ist. 
09.04.18;10.09.18;2018;intern;Bachelor;DE;IT- Outsourcing: Aktuelle Trends, Chancen und Risiken durch die Digitalisierung in Unternehmen;Die Arbeit soll einen aktuellen Überblick über das Thema des IT-Outsourcings geben.<br>Folgende Fragen stehen somit im Zentrum der Arbeit:<br>1) Welche Formen des IT-Outsourcings existieren aktuell, um dieses zügig und flexibel<br>zu gestalten und entwickeln?<br>2) Welchen aktuellen Trends und Herausforderungen stehen Outsourcer und Provider<br>gegenüber?<br>3) Handelt es sich bei einem IT-Outsourcing-Projekt um ein risikoreiches Vorhaben?<br>4) Gibt es gewisse Rahmenbedingungen, die beachtet werden sollen?<br>5) Was müssen Unternehmen beachten, die IT-Aktivitäten zu einem externen Partner<br>auslagern wollen?
12.04.18;12.12.18;2018;intern;Bachelor;DE;Einsatz von Web 2.0 in Schwangerschaft, Geburt und Wochenbett- Entwicklung eines Konzepts für Online-Hebamme;Das Ziel dieser Arbeit ist eine Online-Plattform zu konzipieren, die den Eltern einen orts- und zeitunabhängigen Zugang zu Hebammenleistungen ermöglicht. Dazu wird die Forschungsfrage gestellt: Wie kann Web 2.0 als Instrument für die Digitalisierung des Hebammenangebots in Deutschland verwendet werden?<br>Um diese Forschungsfrage zu beantworten, sind eine Analyse des Hebammenangebots in Deutschland und Interviews durchgeführt worden. Die Befragten wurden in zwei Gruppen unterteilt: Eltern eines oder mehrerer Kinder einerseits und Hebammen, die in Deutschland freiberuflich oder als Angestellte praktizieren andererseits. Die Analyse der Interviews zeigt, dass sich die meisten Eltern Online-Beratung oder Beratung per Chat wünschen und das Angebot einer Online-Hebamme in Anspruch nehmen würden. Die befragten Hebammen sehen solche Angebote als eine ergänzende Möglichkeit zu der herkömmlichen Beratung. Eine weitere Analyse zeigt wie das Angebot der Online-Hebamme dank der Web 2.0 Tools erweitert werden könnte, um einen breiteren Kundenkreis zu erreichen und eine Kundenbindung auf Dauer zu schaffen. <br>Nach der Erstellung eines Online- Hebamme Konzepts für Online-Hebamme wurde eine abschließende Evaluation durch Eltern und Experten durchgeführt. Nach Auswertung aller Ergebnisse erfolgen Handlungsvorschläge seitens der befragten Eltern, Experten und der Autorin.<br>Schlüsselwörter: Hebamme, Digitalisierung, Online-Beratung, Web 2.0, Soziale Netzwerke, Webblogs, YouTube, Experteninterview
17.04.18;17.09.18;2018;intern;Bachelor;DE;Untersuchung der Anforderungen und Entwicklung eines Konzeptes für die Einführung eines Dokumentenmanagementsystems an einer Hochschule;An der Technischen Hochschule Nürnberg soll ein neues Dokumentenmanagementsystem eingeführt werden, da das alte System den Ansprüchen nicht mehr genügt. Hierzu wurden zunächst die Stakeholder- und technischen Anforderungen an das System erhoben und analysiert. Daraus ergab sich eine Darstellung des bisherigen Systems und seiner Umgebung, inklusive anderer koexistierender Dateiablagen. Nachdem die anderen Ablagen und die Anforderungen bekannt waren, konnte ein Konzept für ein Dokumentenmanagementsystem erstellt werden. Bei der Erstellung des Konzeptes wurden die weiteren Ablagesysteme genau betrachtet und in die Überlegungen miteinbezogen. Damit genügt das Konzept den Anforderungen und ergänzt die restlichen Ablagen sinnvoll. Für diese Ergänzungen wurden ebenfalls zusätzliche Optimierungsmöglichkeiten aufgeführt, da auch nach Miteinbeziehung der gestellten Anforderungen weiteres Verbesserungspotenzial zu erkennen war. Nachdem sowohl der Ist- als auch der Soll-Zustand bekannt waren, wurde ein geeigneter Migrationsprozess gewählt, um die Ablösung des alten Systems zu bewerkstelligen. Die Arbeit ist damit besonders für die Mitarbeiter des Rechenzentrums von Interesse.
25.04.18;21.11.18;2018;extern;Master;DE;Entwicklung und prototypische Umsetzung eines Transformationskonzeptes einer Legacy-Infrastruktur zu  Containern anhand eines konkreten Proof of Concepts im Applikationsserverumfeld;Die vorliegende Arbeit befasst sich mit der Ausarbeitung eines Konzepts zur Etablierung einer Container-Plattform in die bestehende Unternehmensinfrastruktur. Zur Themeneingrenzung wurde im Speziellen auf infrastrukturelle Fragestellungen eingegangen. Im Rahmen der Analyse wurde zunächst der Ist-Zustand dokumentiert und dargestellt. Zur Ausarbeitung des Konzeptes wurden neben Ist-Analyse auch Erkenntnisse der IT-Abteilung eines Bekleidungsherstellers sowie Referenzimplementierungen anderer Unternehmen herangezogen. Basierend darauf wurde ein Konzept zur Etablierung einer Container-Plattform ausgearbeitet. Abschließend wurde in einer prototypischen Implementierung einer Legacy-Anwendung gezeigt, dass das erstellte Konzept in der Praxis umsetzbar ist.<br>Das Ergebnis der Arbeit besteht in einem Konzept zur Etablierung einer Container-Plattform innerhalb des Unternehmens. Es hat sich herauskristallisiert, dass eine Migration von Legacy-Anwendungen nicht immer sinnvoll ist, vielmehr muss geprüft werden, inwieweit Anwendungen in Containern betrieben werden können. Trotz alledem konnte gezeigt werden, dass eine Container-Plattform und implizit dadurch auch der Betrieb von Anwendungen in Containern einige Vorteile und Chancen mit sich bringt, wenngleich es technische, organisatorische und kulturelle Veränderungen im Unternehmen erfordert. Es wurde abschließend ein Prozess aufgezeigt, welcher zur schrittweisen Einführung der Technologie herangezogen werden kann.<br>
28.04.18;28.09.18;2018;intern;Bachelor;EN;Real-Time Audio Communication in Web Browsers;The major initiative towards equipping web browsers with real-time communication capabilities is WebRTC, which is currently in the process of being standardized on different fronts by the W3C and the IETF. For certain use cases, however, use of WebRTC may be either undesired or impossible.<br>This paper aims to evaluate whether and how a real-time communications engine can be built using contemporary web browser technologies ? avoiding WebRTC whenever possible. The resulting application has then been compared to WebRTC using various metrics, such as sound quality, delay or CPU usage.<br>While the custom application performed worse than WebRTC on every single performance metric considered, it is still capable of providing real-time communication capabilities at a practically acceptable level. With a more sophisticated implementation, performance can most probably be improved further. However, there also remain certain issues that are hard to circumvent, and implementing a custom solution for real-time communication instead of using WebRTC is seen as being generally unnecessary outside of very specialized scenarios.
01.05.18;20.12.18;2018;intern;Master;DE;Segmentierung von Gebäudefassaden mit Hilfe Neuronaler Netze;In der vorliegenden Arbeit wurde die Aufgabe der Segmentierung mit Hilfe neuronaler Netzwerke am Beispiel von Gebäudefassaden untersucht. Hierfür wurden die eingesetzten Techniken erläutert und verschiedene Verfahren zur Segmentierung mit Hilfe neuronaler Netzwerke untersucht und verglichen. Dabei wurden sowohl allgemeine, als auch speziell zur Segmentierung von Gebäudefassaden entworfene Verfahren untersucht. Im Anschluss wurde Deeplabv3+ eingesetzt, um damit drei unterschiedliche Datensets mit Fassadendaten zu segmentieren. In den Experimenten wurde die Auswirkung verschiedener Parameter auf die Ergebnisse untersucht. Ebenfalls wurde die Leistungsfähigkeit des trainierten Netzwerkes auf eigenen Aufnahmen des Autors getestet, um die Anwendbarkeit im Rahmen des Projektes Interaktive Gebäudevisualisierung des Energiecampus Nürnberg zu untersuchen. Die Ergebnisse zeigen bereits vielversprechende Segmentierungen, welche in Zukunft weiter untersucht werden können, um darauf aufbauend 3D-Modelle von Gebäuden zu erstellen.
01.05.18;01.10.18;2018;intern;Bachelor;DE;Monokulare Tiefenschätzung mit neuronalen Netzen;In dieser Arbeit gilt es eine Transferleistung von neuronalen Netze zu prüfen. Dafür soll einDatensatz aus monokular aufgenommenen RGB-Bildern und Tiefendaten angelegt werden. Der Trainingsgegenstand ist ein Modellgebäude aus Lego. Das neuronale Netz soll mit dem Datensatz trainiert werden. Anschließend soll getestet werden, ob das neuronale Netz eine akzeptable Tiefenschätzung mit monokular aufgenommenen Bildern von realen Gebäuden vornehmen kann. Zudem soll ermittelt werden, welche Leistung aktuelle neuronale Netze in Bezug auf monokulare Tiefenschätzungen erbringen können. Um die Daten aufzunehmen wurde eine Kinect for Windows v1 Kamera von Microsoft verwendet. Die Tiefendaten des Modells wurden um den Faktor vierzig erhöht, damit das neuronale Netz die Maße eines realen Gebäudes lernt. Als neuronales Netz wurde ein Residual Neural Net von Laina et al. gewählt. Aus einer Stichprobe an neuronalen Netzen konnte ermittelt werden, dass Residual Neural Nets die besten Ergebnisse bei monokularer Tiefenschätzung liefern. Das Experiment mit den hochskalierten Tiefendaten liefert Genauigkeitswerte mit denen die fragliche Transferleistung des neuronalen Netzes mit dem in dieser Arbeit generierten Datensatz nicht zweifelsfrei nachweisbar ist. Außerdem ist in der Arbeit ersichtlich geworden, dass die Kinect for Windows v1 nicht für den Außeneinsatz geeignet ist, da bei der Aufnahme der Tiefendatenim Außenbereich der Sensor durch die Sonneneinstrahlung gestört wird. Für weitere
01.05.18;01.10.18;2018;intern;Bachelor;DE;Konzeption und prototypische Umsetzung eines digitalen Magazins für die Fakultät Informatik;Diese Arbeit befasst sich mit der Konzeption eines digitalen Magazins für die Fakultät Infor-matik der Technischen Hochschule Nürnberg. Dieses wird mit dem Content Management System WordPress prototypisch umgesetzt. Im Rahmen der Konzeption werden aktuelle Websites analysiert, um ein modernes und für die Fakultät passendes Erscheinungsbild zu kreieren. Weiterhin thematisiert die Arbeit die Informationsarchitektur. Die Informationsar-chitektur beschreibt die Strukturierung einer Website und umfasst die Bereiche Organisati-onssystem, Navigationsstruktur und Suchsystem. Es werden jeweils mehrere Lösungsansätze vorgestellt und bewertet. Weiterhin erfolgt die Dokumentation der Umsetzung einiger aus-gewählter Strategien. Daraus ergibt sich der Prototyp eines digitalen Magazins, das den Jah-resbericht der Fakultät ablöst und um einige weitere Inhaltsbereiche erweitert.
01.05.18;30.09.18;2018;extern;Master;DE;Neukonzeption der digitalen Kundenansprache eines IT-Dienstleisters mit modernen Online Marketing Methoden;Die Arbeit zeigt, dass es fu?r Firmen nicht zwingend darum geht, grundlegend neue Wege zu gehen. Content Marketing ist beispielsweise schon 127 Jahre alt. Vielmehr geht es um die Flexibilita?t, die Methoden an neue Herausforderungen wie die Schnelllebigkeit der heutigen Zeit, die Bedu?rfnisse und Wu?nsche der Zielgruppe aber auch an die sich sta?ndig a?ndernden Algorithmen der Suchmaschine anzupassen.<br>Webseiteninhalte sollten immer fu?r den Nutzer und fu?r die Suchmaschinen optimiert werden. Die ho?chste Pra?misse der Suchmaschine ist die Auslieferung von relevanten Suchergebnissen fu?r den Nutzer. Daher sollte der Nutzer mit seinen Bedu?rfnissen auch bei der Erstellung und Optimierung von Inhalten immer an erster Stelle stehen.<br>Die angewandten Methoden eignen sich fu?r den sehr spezifischen Anwendungsfall eines B2B IT Beratungs- und Entwicklungsdienstleisters im neuen und wenig umka?mpften Bereich der digitalen Mobilita?t. Die Methoden sollten keinesfalls als fertige Lo?sungen fu?r andere Anwendungsbereiche betrachtet werden. Es ist erforderlich, jede Situation von Grund auf neu zu bewerten und zu analysieren.<br>Zusa?tzlich beweist die Ausarbeitung in diesem Fall, dass wissenschaftliche Arbeit und die Schaffung von wirtschaftlichem Mehrwert gut zusammenpassen ko?nnen.
02.05.18;02.10.18;2018;intern;Bachelor;DE;Entwicklung eins gamifizierten Citizen-Science-Konzepts zur Mitwirkung unbeteiligter Dritter an datenbasierten Forschungsprojekten.;Zielsetzung der Bachelorarbeit ist es, ein gamifiziertes Citizen-Science-Konzept zu entwerfen, das es unbeteiligten Dritten ermöglicht, sich spielerischen an einem datenbasierten Forschungsprojekt zu beteiligen. Dies soll erreicht werden, indem auch an Forschung interessierte Laien mithilfe von Game-Design-Elementen dazu motiviert werden, an der Datenvorverarbeitung und -analyse mitzuwirken. Das Konzept fußt auf der Recherche und Analyse schon bestehender Ansätze zum Thema Motivation durch Gamification. Neben dem Konzept, das beschreibt, wie man Personen zur Mitwirkung an einem datenbasierten Forschungsprojekt motivieren kann, soll auch ein Mockup erstellt und getestet werden, um sich erste Eindrücke über eine mögliche Umsetzung in eine mobile Applikation zu verschaffen.
02.05.18;02.10.18;2018;intern;Bachelor;DE;Entwicklung eines DoS-Angriffs auf ein prototypisches CAN-Bus Netzwerk;Ziel der Arbeit ist es, einen Angriff auf ein prototypisches CAN-Bus Netzwerke zu implementieren,<br>welcher die Funktionalität einzelner Netzwerkteilnehmer temporär, für die Dauer des Angriffs,<br>komplett verhindert.<br>Das anzugreifende Netzwerk soll aus mindestens zwei Arduinos, welche mit CAN-Shields bestückt<br>sind, bestehen und leicht erweiterbar sein.<br>Der Angriff wird durch die selbst zusammengestellte Angreifer-Hardware ausgeführt.<br><br>Bei der Datenübertragung über den CAN Bus ist das 0-Bit dominant und das 1-Bit rezessiv. Daraus<br>folgt, dass wenn zwei Teilnehmer gleichzeitig senden würden, die rezessiven 1-Bits von den<br>dominanten 0-Bits überschrieben würden.<br>In dem zu implementierenden Angriff wird das erste gesendete 1 Bit nach der Identifizierung des<br>anzugreifenden Netzwerkteilnehmers durch den Angreifer mit einer dominanten 0 überschrieben.<br>Da der aktuell sendende Teilnehmer seine gesendeten Daten mit dem logischen Wert auf dem Bus<br>live vergleicht und feststellt, dass seine Nachricht verändert wurde, bricht dieser das senden ab,<br>schickt eine Fehler-Nachricht auf dem Bus und erhöht seinen internen Zähler für Sende-Fehler.<br>Falls dieser Zähler einen bestimmten Wert überschreitet wird die Sendefähigkeit dieses Teilnehmers<br>für einen bestimmten Zeitraum oder bis zu einem Reset eingestellt.<br><br>Des weiteren kann noch die Anbindung einer Bluetooth-Schnittstelle in das CAN-Bus Netzwerk<br>sowie eine Möglichkeit den Angriff zu verhindern implementiert werden.
07.05.18;07.10.18;2018;intern;Bachelor;DE;Evaluierung, Auswahl und prototypische Umsetzung eines Datenschutzmanagementtools für eine Hochschule zur Umsetzung der Datenschutzgrundverordnung (EU-DSGVO);Die EU erließ die Datenschutzgrundverordnung, die am 25. Mai 2018 in Kraft getreten ist. Aufgrund des Inkrafttretens der DSGVO fasste die Hochschule den Entschluss, für den Bereich des Datenschutzes ein IT-Tool einzusetzen, um die mit der DSGVO verbundenen erhöhten Dokumentations- und Nachweispflichten besser managen zu können. Da zudem auch in den Bereichen des Informationssicherheitsmanagements sowie des IT-Architekturmanagements aktuell noch keine Managementtools eingesetzt werden, soll mithilfe dieser Bachelorarbeit evaluiert werden, ob Tools existieren, die bedeutende Anforderungen aller Bereiche abdecken können. Damit könnte von Synergieeffekten zwischen den Bereichen profitiert werden, weshalb auch untersucht werden soll, ob Zusammenhänge zwischen den Bereichen existieren. Anforderungen an das einzuführende Tool wurden im Voraus mit Verantwortlichen der Hochschule im Rahmen von Interviews ausgearbeitet. Basierend darauf wurde ein Kriterienkatalog mit den Kategorien Datenschutz, ISMS, IT-Architekturmanagement, Usability erarbeitet. Die Evaluation der Tools wurde anhand einer prototypischen Umsetzung durchgeführt und die Tools mithilfe einer Nutzwertanalyse bewertet. Die Evaluation hat gezeigt, dass IT-Tools existieren, die Anforderungen aus allen drei Teilbereichen erfüllen können. Ein Tool konnte über alle vier Kategorien hinweg punkten und ist damit als das geeignetste aus der Evaluation herausgegangen und wird somit für einen Einsatz an der Hochschule empfohlen.
15.05.18;10.10.18;2018;extern;Bachelor;DE;Konzeption und Implementierung eines Event Stores mit Event-Versionierung;Für Softwareentwickler, die eine microservicebasierte Architektur als Ausgangspunkt haben, liefert diese Bachelorarbeit einen grundlegenden Überblick über die Funktionsweise und Konzepte im Zusammenhang mit Event Sourcing. Des weiteren wird eine alternatives Konzept zur konventionellen Speicherung nach dem Create-Read-Update-Delete (CRUD) Prinzip in Form von Command-Query-Responsibility-Segregation (CQRS) aufgezeigt. Die Pattern wurden ausführlich analysiert und der Umgang mit der Versionierung von Events untersucht.<br>Auf Basis der umfangreichen Analyse wurde ein Event Store Microservice konzipiert, der alle Events eines Messaging Systems langfristig speichert und diese für Analysezwecke zur Verfügung stellt. Dabei galt es einige Anforderungen von Softwarearchitekten der Firma Schaeffler einzuhalten und die bestehende Architektur sinnvoll zu ergänzen. Die prototypische Umsetzung erfolgte mit Open-Source Technologien der Firma Elastic.<br>Durch die Verwendung von Event Sourcing wurde eine Möglichkeit geschaffen, zusätzliche Daten für Analysezwecke bereitzustellen und eine unveränderbare Datenhistorie anzubieten, die als Basis für weitere Anwendungsfälle dient.<br><br>
15.05.18;15.10.18;2018;intern;Bachelor;DE;Entwicklung eines Eclipse-Plugin zur Berechnung nicht explizit modellierter, linearer Qualitätsmerkmale, von zusammengesetzten EAST-ADL Systemkomponenten;Ziel der Arbeit ist es, eine Applikation für die Berechnung einer impliziten Qualität einer Systemkomponente aus den Qualitäten der in der Komponente enthaltenen Unterkomponente zu erstellen. Dazu ist zum einen erforderlich, alle zulässigen Konfigurationen der Unterkomponenten zu finden. Zum anderen muss herausgefunden werden, welche Unterkomponenten zu welchen Komponenten gehören. Aus den Konfigurationen soll die Qualitätseigenschaft der Komponente ermittelt werden. Zuletzt ist das Ergebnis dann in eine Zielfunktion zu überführen. 
15.05.18;10.01.19;2018;extern;Master;DE;Konzeption einer Vorgehensweise zur Entwicklung digitaler Geschäftsmodelle für produzierende Unternehmen;Durch die Digitalisierung sind viele Veränderungen notwendig. In dieser spielen Begriffe wie Industrie 4.0, Internet der Dinge und die Transformation von Geschäftsmodellen eine wichtige Rolle. Die Transformation ist notwendig, damit sich Unternehmen auch in der Zukunft gegen Wettbewerber aufstellen können. Das Problem ist jedoch, dass Unternehmen die Relevanz dieses Themas nicht sehen und die Transformation nicht oder nur teilweise durchführen. Dies könnte auf fehlende Informationen, dem Wissen über dieses Thema oder auch Problemen innerhalb der Unternehmensarchitektur zurückzuführen sein. Das Ziel dieser Arbeit ist eine Konzeption für die Erstellung von digitalen Geschäftsmodellen. Es gilt zu klären, welches Wissen bzw. Fähigkeiten und Methoden für die Erstellung der Geschäftsmodelle benötigt werden sowie welcher Prozess durchlaufen werden muss. Es wurde daher zunächst Grundlagenwissen, wie Definitionen von Geschäftsmodellen, Digitalisierung und Strategie näher betrachtet. Auch bereits bestehende Ansätze für die Entwicklung von Geschäftsmodellen sind ein wichtiger Teil. Zusätzlich wurden verschiedene Methoden zur Findung und Erstellung von Geschäftsmodellen erläutert, welche mit einem erstellten Bewertungsraster validiert wurden. Neben diesem erfolgte die Konzeption einer Checkliste zur Validierung der Ist-Situation und dem Bereitschaftsgrad zur Digitalisierung. Als Abschluss wurde ein Prozess mit den Inhalten der Ansätze und des Bewertungsrasters erstellt. 
15.05.18;12.10.18;2018;intern;Bachelor;DE;"Prototypische Konzeption und Umsetzung eines Roboterhaustiers basierend auf dem Robotersystem ""Cozmo""";Thema der Arbeit ist die software-technische Konzeption und Umsetzung eines Roboterhaustiers auf Basis des von der US-amerikanischen Firma Anki entwickelten Robotersystems Cozmo. Das von Anki für die Programmierung in Python bereitgestellte Open Source Cozmo SDK wird im Rahmen dieser Arbeit in eine C++-Umgebung eingebettet. Die Herausforderung besteht darin, unter Beachtung der vorhandenen Software-Architektur, ein neues C++-API für das Robotersystem zu konzipieren und zu implementieren.<br>Die C++-Einbettung bildet damit die Grundlage für das eigentliche Umsetzungsziel: die Entwicklung eines prototypischen Roboterhaustiers. Diese Realisierung setzt sich aus folgenden Funktionalitäten zusammen. Eine selbstständige Standortermittlung der Ladestation bei niedrigem<br>Batterie-Ladezustand inklusive Navigation und Parken. Die natürliche Mensch-Roboter-Interaktion in Form von Begrüßung und Verabschiedung bei der Erkennung eines menschlichen Gesichtes. Außerdem soll das Roboterhaustier in der Lage sein, einen neuen Gegenstand zu erkennen und darauf in Form einer Animation zu reagieren. Zudem werden die Kantendetektion, die Entfernungsmessung der gefahrenen Strecke mittels Odometrie und die Fortbewegung entlang eines Musters auch auf Basis des C++-API umgesetzt.<br>Das Ergebnis ist eine Ansammlung von Funktionalitäten in Form von acht Anwendungsbeispielen, welche die Grundlage für die Implementierung eines Roboterhaustiers bildet.
16.05.18;14.01.19;2018;intern;Master;DE;Entwicklung und Analyse von Gamificationkonzepten als Beitrag zur Stadtentwicklung;"Um die Ehre des Titels Kulturhauptstadt Europas 2025 bemüht sich zurzeit die Stadt Nürnberg. Da im Jahr 2025 eine deutsche Stadt den Titel erhält, nutzt Nürnberg die Chance und fokussiert in der Bewerbung verschiedene Themenbereiche. Ein Bereich umfasst die Themen ""Arbeit, Lernen und Spiel"". In diesem Zusammenhang ist Gamification ein passender Begriff. Dieses Wort tritt in der heutigen Zeit vermehrt auf und wird im Rahmen unterschiedlichster Kontexte verwendet, da die Einbindung spielerischer Elemente in spielfremden Prozessen vielseitig anwendbar ist. Somit stellt sich im Zusammenhang der Kulturhauptstadtbewerbung mit dem beinhalteten Themenbereich die Frage, inwieweit Gamification im Rahmen der Stadtentwicklung eingesetzt werden kann. Die Komplexität der Frage wurde in einzelnen Teilen beantwortet. Einleitend ist eine allgemeine Verständnisvermittlung des bestehenden Kontextes ""Gamification innerhalb der Stadtentwicklung"" gegeben. Auf Basis eines einheitlichen Verständnisses wurden aus einer Vielfalt von Gamificationkonzepten unterschiedliche Konzepte analysiert. Da innerhalb der analysierten Gamificationkonzepte das Potential für eine Übertragung auf die Stadt Nürnberg erkennbar war, wurden die Bedürfnisse verschiedener Ämter bzw. Einrichtungen Nürnbergs ermittelt. Diese Erkenntnisgewinnung diente der Erstellung individueller Konzepte für Einrichtungen und Ämter der Stadt Nürnberg, welche die Stadtentwicklung und zudem die Kulturhauptstadtbewerbung unterstützen können."
16.05.18;16.01.19;2018;intern;Master;DE;Autonome Navigation und Raumidentifikation in unbekannten Umgebungen am Beispiel des <br>Robotersystems Pepper;Die Arbeit umfasst die Konzeption und Implementierung einer erweiterbaren C++ SLAM-Datenverarbeitungskette für den von SoftBank Robotics entwickelten Roboter Pepper. Der Fokus liegt hierbei auf dem Abspeichern von Informationen mit räumlichen Kontext.<br><br>Bestandteil der Datenverarbeitungskette ist das Erkunden und Erstellen einer 2D-Karte der Umgebung mit Hilfe der drei Lasersensoren am Boden des Roboters. Hierbei werden die Odometrie-Informationen des Roboters und das Real-Time Correlative Scan Matching Verfahren verwendet. Dies dient dazu das inkrementell aufaddierende Rauschen der Odometrie- und Sensordaten zu bereinigen.<br><br>Zusätzlich wird der in Computerspielen weit verbreitete A*-Algorithmus als Navigationskomponente in die Datenverarbeitungskette integriert. <br><br>Des Weiteren wird in der Arbeit untersucht, ob mit Hilfe von Bildverarbeitungsverfahren wie zum Beispiel morphologischen Operationen und Region Growing aus der erstellten 2D-Karte Räume identifiziert werden können. Die identifizierten Räume sollen als selbst erlernte Navigationspunkte sowie als Kontext Information für weitere Aufgaben dienen. Ein Beispiel hierfür ist das Suchen eines Objektes in einem spezifischen Raum.
21.05.18;18.01.19;2018;extern;Master;DE;Neukonzeption der Datenhaltung im Bereich Netzwerk Services der DATEV eG;"Die Speicherung und Verarbeitung von Daten ist ein grundlegender Bestandteil vieler IT-Systeme. <br>Trotz dieser zentralen Rolle wird die Datenhaltung bei Veränderungen, wie wechselnden Anforderungen oder wachsenden Datenmengen nur selten angepasst. Daher wird in dieser Arbeit am Beispiel des Bereiches ""Netzwerk Services"" der DATEV eG ein Konzept zur Anpassung einer bestehenden Datenhaltung an neue sich verändernde Anforderungen in IT-Systemen erstellt. <br>Hierbei wird besonders auf Systeme bestehend aus mehreren Anwendungen und gemeinsamer Datenhaltung eingegangen. Dabei werden einerseits die theoretischen Hintergründe dieser Probleme erläutert. Des Weiteren wird ein Vorgehensmodell erstellt, mit dem ein vorhandenes IT-System und dessen Datenhaltung analysiert und überarbeitet werden kann. Dieses Modell wird am Anwendungsfall ""Netzwerk Services"" der DATEV eG beispielhaft durchgeführt."
24.05.18;24.10.18;2018;intern;Bachelor;DE;Konzeption und Entwicklung eines eingebetteten Systems mit<br>webbasierter Konfigurationsmöglichkeit zur Fernsteuerung von<br>veranstaltungstechnischer Hard-und Software;Gegenstand der Bachelorarbeit ist eine Bedienoberfläche (Controller), bestehend aus den gängigsten Kontrollarten (Schiebe- und Drehregler, Taster, Display). Im Vordergrund steht dabei die Softwareentwicklung und Betrachtung einiger Kommunikationsprotokolle wie MIDI, OSC, OCA, TCP- und UDP Streams sowie REST Schnittstellen.<br>Hintergrund des Themas ist die Digitalisierung in vielen Bereichen der Veranstaltungsindustrie. Dadurch werden immer mehr früherer Hardwaregeräte durch Software ersetzt, da dies mittlerweile zumindest gleichwertige Qualität, zudem aber mehr Möglichkeiten der Reproduzierbarkeit, Transportierbarkeit und Parametrierbarkeit bietet. <br>Lediglich die Kontrollierbarkeit leidet hierunter, da Hersteller sich oft auf Funktionalität konzentrieren und die Bedienung bei Maus- und Tastatureingabe beschränkt bleibt.<br>Ziel der Bachelorarbeit ist es, einen Prototyp zu entwickeln, der verschiedene Systeme fernsteuern kann. Dies soll über eine Weboberfläche konfiguriert werden können. Des Weiteren findet eine Analyse und Bewertung gängiger Kommunikationsprotokolle statt.
25.05.18;28.09.18;2018;extern;Bachelor;DE;Konzeption und Realisierung der Personalverwaltung für ein Webportal des pharmazeutischen Einzelhandels;Das Ziel dieser Arbeit ist die Konzeption und Realisierung einer Personalverwaltung<br>in einem Webportal. Die Webanwendung der Firma Endobit Software Solutions stellt<br>eine Plattform für den pharmazeutischen Einzelhandel zur Verfügung, die individuelle<br>Konfigurationsmöglichkeiten für klein- und mittelständische Unternehmen bietet. Die<br>Implementierung umfasst die Organisation und Erstellung eines Dienstplans auf Basis<br>mitarbeiterspezifischer Dienstplanvorlagen. Für den Praxiseinsatz ist vorgesehen, dass<br>Arbeits-, Urlaubs- und Fehlzeiten bearbeitet werden können und das deren Auswirkungen<br>auf den Schichtplan berücksichtigt werden. Die Umsetzung erfolgt mithilfe von Microser-<br>vices, um eine modulare Integration in das als Single-Page-Webanwendung existierende<br>Webportal zu verwirklichen.
28.05.18;05.10.18;2018;extern;Bachelor;DE;Weiterentwicklung eines bestehenden Visualisierungstools im Bereich autonomes Fahren;Die Elektrobit Automotive GmbH ist in dem Projekt EB robinos mit der Entwicklung von Software für autonomes Fahren beschäftigt. Ein Teil dieses Projekts ist die Road Fusion. Die Road Fusion Komponente ist dabei zuständig für die Berechnung von Hypothesen, wo genau die Straßen- und Fahrstreifenenbegrenzungen liegen. Dazu bekommt sie verschiedene Eingangsdaten, zum Beispiel Fahrstreifen und Straßenmarkierungen von verschiedenen Quellen. Aus diesen berechnet sie dann die Hypothesen. Die Visualisierung hilft den Entwicklern genau zu sehen, was wo relativ zur eigenen Position berechnet wurde.<br>Zu den Datenstrukturen der Road Fusion gibt es jeweils einen Layer, der diese graphisch darstellt, und ein Widget, in dem man alle Objekte der einzelnen Datenstrukturen ganz ausblenden kann oder sie einzeln auswählen kann und dort zusätzliche Informationen angezeigt bekommt. Gespeicherte Eingangsdaten können per JSON Stream an die Road Fusion übergeben werden. Aus deren Berechnungen kann die Visualisierung die Berechnungen eines ganzen Zeitfensters zur Laufzeit graphisch darstellen. Bei Testfahrten werden die Berechnungen ebenfalls in Echtzeit dargestellt.<br>Die erste Aufgabe dieser Arbeit ist es den Ist-Zustand zu analysieren. Da die Aufgabe darin besteht die Visualisierung weiterzuentwickeln, soll dann zunächst mit Hilfe geeigneter Methoden die Anforderungen an die neue Visualisierung ermittelt werden. Diein einem Lastenheft zusammengetragenen Anforderungen sollen implementiert werden.
29.05.18;29.10.18;2018;extern;Bachelor;DE;Erfassung von Anlagenzuständen über XDK-Mikrocontroller;"Es soll eine dezentrale, standardisierte Lösung geschaffen werden, um Fertigungssysteme zu überwachen. Hierbei ist das Ziel einen Mikrocontroller so einzurichten, dass dieser den Status einer angebrachten Ampel ausliest und per WLAN an ein Backend meldet. Hierfür wird das ""XDK ? Cross Domain Development Kit"" der Robert Bosch GmbH eingesetzt."
01.06.18;30.09.18;2018;extern;Bachelor;DE;Konzeption und Realisierung einer Crossplattform-Applikation für Neukundenbefragungen in Friseur- oder Kosmetikstudios;In dieser Arbeit wurde eine Crossplattform-Applikation für Neukundenbefragungen in Friseur- oder Kosmetikstudios für die Head-on Solutions GmbH konzipiert und erstellt. Zunächst erfolgt eine Analyse des Ausgangszustandes der Anwendung und der zu lösenden Problemstellung. Daraus abgeleitet erfolgt die Definition des Zielzustandes der Applikation. Zur Findung eines für die Applikation geeigneten Frameworks erfolgte eine Analyse von verschiedenen Frameworks hinsichtlich deren Anwendbarkeit, Funktionsumfang und Umsetzbarkeit der an die Applikation gestellten Anforderungen. Zur Findung des für die mobile Applikation zu verwendenden Frameworks wurde mit drei verbleibenden Frameworks eine Testapplikation umgesetzt. <br>In einer eingehenden Anforderungsanalyse werden das Konzept für die Benutzeroberfläche und die Softwarearchitektur behandelt. Anschließend wird die Umsetzung der mobilen Anwendung behandelt und die hierbei angewandten Methoden und Technologien im Detail besprochen. Abschließend wird ein Fazit gezogen, bestehend aus Zielerreichung und Ausblick.
12.06.18;12.11.18;2018;intern;Bachelor;DE;Migration bestehender ABS-Software auf neues Steuergerät auf Grundlage von AUTOSAR;Diese Bachelorarbeit behandelt das Thema der Migration bestehender ABS-Software auf ein neues Steuergerät auf Grundlage von AUTOSAR. Ausgehend von der Systembeschreibung und der implementierten Applikationssoftware werden detailliert die notwendigen Arbeitsschritte erläutert, um die ABS-Software auf ein anderes Steuergerät zu übertragen. Beim neuen Steuergerät handelt es sich um KIT_AURIX_TC297_TFT von infineon. Zunächst wird mit dSpace SystemDesk 4.7 die Systembeschreibung aktualisiert. Anschließend wird mit EB Tresos Studio 22.0.1 TC29XT Multicore die Basissoftware konfiguriert. Zum Übertragen der kompilierten Konfiguration und Applikation auf das Steuergerät wird Lauterbach TRACE32 Software und Lauterbach Debugger Hardware verwendet. 
14.06.18;14.11.18;2018;intern;Bachelor;DE;Konzeptionelle und anwendungsspezifische Unterschiede der Datenmodellierung für relationale und nicht-relationale Datenbanken, speziell für dokumentenorientierte und Key-Value-Datenbanken;Als nicht-relational bezeichnet man Datenbanken, die einen alternativen Ansatz zu den weit verbreiteten relationalen Datenbanken verfolgen. Nicht-relationale Datenbanken erfreuen sich immer größerer Beliebtheit. Doch die genauen Unterschiede zum relationalen Datenmodell sind oft nicht im Detail klar. Ziel dieser Arbeit ist es, diese Unklarheiten auszuräumen. Anhand einer Fallstudie werden verschiedene nicht-relationale Modellierungskonzepte erläutert. Dabei werden die Unterschiede zur Datenmodellierung relationaler Datenbanken aufgezeigt. Die in der Arbeit gewonnenen Erkenntnisse werden abschließend in verallgemeinerter Form zusammengefasst.
15.06.18;13.02.19;2018;intern;Master;DE;Interaktive und dynamische Visualisierung von Studentendaten in Bezug zum Studienerfolg und Identifikation möglicher Ursachen für den Studienmisserfolg an der TH Nürnberg;Auf unterschiedliche Weise kann ein Studium zu einem Misserfolg führen. Dabei wird das Studium beendet ohne den angestrebten akademischen Grad zu erhalten. Für alle Beteiligten wäre es von Vorteil bereits im Vorfeld Wissen über Faktoren zu haben welche den Erfolg des Studiums beeinflussen. So könnten zielgerichtet Maßnahmen durchgeführt werden welche dem Misserfolg im Studium entgegenwirken. <br><br>Um diesem Ziel näher zu kommen wurde eine Anwendung geschaffen mit der vielfältige Analysen möglich sind. Die Daten wurden erstmals in dieser Form und Menge miteinander verknüpft. Auf anschauliche Weise werden die sie repräsentiert. Dafür wurde eine Visualisierungskonzept entworfen. Die Daten können durch viele Filter beeinflusst werden wobei sich diese Anpassungen auf die Darstellung auswirken. <br><br>Das entwickelte Programm wird für erste Analysen, hauptsächlich hinsichtlich des Studienmisserfolgs, genutzt. Es werden selbst gewählte und von zwei Testpersonen entworfene Fragestellungen behandelt. Die Vorgehensweise und Ergebnisse werden protokolliert. Gefundene Zusammenhänge lassen sich über eine Exportfunktion aus der Anwendung heraus extrahieren. Die Exportfunktion wurde ebenfalls im Rahmen dieser Arbeit entwickelt. <br><br>Durch die Analyse wurde unter anderem ermittelt, dass eine hohe Anzahl an Fachsemestern das Risiko auf einen Misserfolg nicht stark erhöht. Weiterhin hat sich gezeigt: eine Fünf in dem Fach welches im Studiengang am häufigsten nicht bestanden wird kann das Risiko erhöhen. 
18.06.18;18.11.18;2018;intern;Bachelor;DE;Analyse und Vergleich von plattformunabhängigen Ansätzen für Webanwendungen am Beispiel der Nahrungs- und Genussmittelindustrie;Im Rahmen dieser Bachelorarbeit werden die plattformunabhängigen Konzepte des Graceful Degradation, Progressiv Enhancement und Mobile First analysiert und <br>miteinander verglichen. Innerhalb der Analyse möchte ich auf die einzelnen <br>entwicklungsspezifischen Aspekte der Vorgehensweisen eingehen. Mithilfe der drei Konzepte soll eine beispielhafte Webanwendung für die Nahrungs- und <br>Genussmittelindustrie entwickelt werden.<br>Am Ende soll der Leser ein Verständnis für die drei unterschiedlichen Konzepte <br>besitzen und die jeweiligen Vor- und Nachteile kennen.<br>
18.06.18;18.11.18;2018;extern;Bachelor;DE;Evaluierung der Front-End-Webframeworks Angular, Vue und React <br>für den Einsatz in einem Feedback-Management-System;Die vorliegende Bachelorarbeit stellt die Front-End-Webframeworks Angular, React und Vue gegenüber. Dabei wurde eine Evaluierung anhand der Kriterien TypeScript, Lernkurve,Performance,Boilerplate-Code,InternationalisierungundUnit-Testingdurchgeführt.DieErgebnissederArbeitbringendieStärkenundSchwächen,sowiedieUnterschiedederFrameworkshervor.EbensowerdendieVorgehensweisenundLeitgedanken derFrameworksverglichen.DadurchkönnenAnwendungsfällede?niertwerden,fürwelche die einzelnen Frameworks eingesetzt werden können. Die Evaluierung wurde dabei an einer bereits bestehenden Webanwendung - einem Feedback-Management-System der MATHEMA Software GmbH - durchgeführt. Aus dem System wurde exemplarisch eine Webseite ausgewählt. Für diese sollte ein Entwurf konzipiert werden, welcher in allen drei Frameworks implementierbar ist. Im Rahmen der Arbeit wurde außerdem eine Umfrage, die sich besonders auf die Einschätzung und Erfahrung der FrameworkNutzer fokussiert, durchgeführt und analysiert. Insgesamt nahmen 127 Entwickler an der Umfrage teil. Die Zielgruppe der Bachelorarbeit sind Projektteams und Entwickler,diesichbereitsgrundlegendeKenntnisseimBereichderFront-End-Webentwicklung angeeignet haben.
22.06.18;22.02.19;2018;extern;Master;DE;Automatisierte Erstellung von User-Dokumentationen für ALM-Prozesstemplates in der Softwareentwicklung mittels Continuous Delivery im DevOps-Kontext;"Die evosoft GmbH stellt für Siemens das Application Lifecycle Management (ALM) Tool ""Team Foundation Server"" (TFS) bereit, auf das täglich mehr als 10.000 Software-Entwickler zugreifen. Neue Features werden monatlich zur Verfügung gestellt und eine dazu passende User-Dokumentation parallel dazu erstellt.<br>Zukünftig sollen Features viel häufiger, schneller und fehlerärmer bereitgestellt werden, indem auch die Generierung der User-Dokumentation mit in den bestehenden Build- und Release-Prozess integriert wird.<br>Zu Beginn werden im Rahmen einer Analyse der bestehenden Vorgehensweise sinnvolle Ansätze für eine mögliche Prozessveränderung ermittelt. Zusätzlich werden mithilfe einer Stakeholderanalyse die Anwendungsszenarien, Nutzen und Risiken eines neuen Ansatzes aufgezeigt. Darauf basierend entsteht ein Konzept, welches vor der Überführung in den produktiven Einsatz einer kritischen Bewertung hinsichtlich realisierbarer Einspar- und Verbesserungspotenziale unterzogen wird.<br>"
25.06.18;23.04.19;2018;intern;Bachelor;DE;Konzeption und prototypische Umsetzung eines Interventionstools zur Verbesserung der Studierfähigkeit in der Studieneingangsphase;
11.07.18;10.12.18;2018;extern;Bachelor;DE;Vergleich der Distributed Ledger Technologien IOTA und Ethereum bei Anwendung in der Energiewirtschaft;Distributed Ledger werden als die disruptivste Technologie der letzten Jahre eingestuft. Sie sollen Prozesse vereinfachen und die Transparenz und Auditierbarkeit erhöhen. Von ihnen werden sich viele Effizienzgewinne, die mit Herkömmlichen Technologien nicht realisierbar sind, versprochen. Mit IOTA und Ethereum gibt es zwei Vertreter, die das Konzept der Distributed Ledger erweitern.  <br><br>Ethereum ermöglicht die Erstellung von Smart Contracts, mit deren Hilfe dezentrale Applikationen realisiert werden könne. IOTA auf der anderen Seite verspricht durch den Einsatz des Tangles die Probleme der Blockchain Technologie, wie begrenzte Skalierbarkeit und hohe Transaktionskosten, zu beheben. <br><br>Das Ziel dieser Arbeit ist es, diese beiden Distributed Ledger Technologien miteinander zu vergleichen. Dies geschieht einerseits im Kontext eines Anwendungsbeispiels und andererseits auf Basis etablierter Messkriterien für Distributed Ledger.  <br><br>Als Anwendungsbeispiel wurde die Implementierung eines digitalen Marktplatzes zum Stromhandel, auf Basis eines Distributed Ledgers, gewählt. Die vielfältige Einbindung von Intermediären und die starke Zentralisierung des Energiesektors, sowie die Fähigkeit von Distributed Ledgern eben dieser Zentralisierung entgegenzuwirken, qualifizieren dieses Anwendungsbeispiel als Kontext für den Vergleich von IOTA und Ethereum.
12.07.18;15.02.19;2018;extern;Master;DE;Edge Computing - Potenziale, Grenzen und Auswirkungen dezentraler Datenstromverarbeitung<br>;Die vorliegende Arbeit beschäftigt sich mit einer technologischen Untersuchung im Kontext des Edge Computings. Neben einer allgemeinen technologischen Untersuchung in Bezug auf zur Verfügung stehende Soft- und Hardwarekomponenten findet eine Evaluierung drei aktueller Edge Computing Tools statt. Die für die Evaluierung notwendigen Bewertungskriterien werden anhand der Charakteristiken des Softwarequalitätsmodells nach ISO 25010 und auf Basis von typischen Edge Computing Anwendungsfällen identifiziert. Durch die Entwicklung und Implementierung eines prototypischen Edge Computing Szenarios werden die Tools in Form von Apache Edgent, Azure IoT Edge sowie AWS IoT Greengrass anschließend hinsichtlich der vorab identifizierten Anforderungen evaluiert. Im Zuge dessen wird ersichtlich, dass keines der drei Tools alle Anforderungen gleichermaßen erfüllt. Es ist vielmehr eine detaillierte Betrachtung des jeweiligen Einsatzzwecks sowie dessen konkreten Anforderungen notwendig, um eine valide Aussage über das zu präferierende Tool treffen zu können.
14.07.18;14.03.19;2018;intern;Master;DE;Entwicklung einer domänenspezifischen Sprache zur Realisierung von Sensornetzanwendungen;In dieser Masterarbeit wird eine domänenspezifische Sprache entwickelt, mit deren Hilfe sich Sensornetzanwendungen realisieren lassen. Zu diesem Zweck wird zunächst die Bereitstellung der Entwicklerwerkzeuge vereinheitlicht. Zusätzlich wird ein vermaschtes Netz mit Routingalgorithmus in TinyOS implementiert. Für die Entwicklung der Sprache wird dargelegt, dass YAML als Beschreibungssprache dafür geeignet ist. Weiterhin wird eine Beispielimplementierung der Sprache in C++ mit anschließendem Funktionstest durchgeführt.
16.07.18;11.03.19;2018;extern;Master;DE;Entwicklung von Strategien für die Paketierung und Lizenzierung von Software für große Unternehmenskunden;Das Ziel der vorliegenden Masterarbeit ist es, durch eine Analyse der eingesetzten Preismodelle in ausgewählten Industrien die Optimierungspotenziale im derzeitigen Preismodell für MRI-Software von Siemens Healthineers aufzuzeigen und basierend darauf ein neues Modell zu entwickeln.<br>Die Grundlage der Arbeit bildet eine Literaturrecherche, mithilfe derer ein Überblick über die relevanten Gestaltungsparameter und Erfolgsfaktoren eines Software-Preismodells gegeben wird. Danach werden vom Autor die Produkte und das derzeitige Lizenzierungsmodell vorgestellt und ein Dashboard für die Visualisierung von Kennzahlen und Strukturen in den vergangenen Verkäufen der MRI-Software erstellt. Mithilfe der Analyse der Einkaufsdaten werden im Anschluss die Stärken und Schwächen des derzeitigen Preismodells ermittelt und aufgezeigt, welche Verbesserungspotenziale es für das Preismodell der Software-Optionen gibt. Die Analyse der Einkaufsdaten führte zu dem Ergebnis, dass die Etablierung eines neuen flexibleren Preismodells hohes wirtschaftliches Potenzial für das Unternehmen birgt. Die Literaturrecherche zeigte außerdem, dass in Bezug auf die Zahlungsform der Trend hin zu Preismodellen mit wiederkehrenden Gebühren geht. Zur Komplexitätsreduktion bei einer hohen Produktvielfalt werden Bündelungsstrategien empfohlen. Für das neue Preismodell werden daher eine Bündelung der Produkte und die Einführung einer auf dem Subscription-Modell basierenden, nutzungsunabhängigen Lizenzierung vorgeschlagen.
18.07.18;17.12.18;2018;intern;Bachelor;DE;Konzeption und Umsetzung einer Webanwendung für die Erstellung von Echtzeit-kollaborativen Mindmaps;Bestehende Lösungen um gemeinsam an Mindmaps arbeiten zu können sind oft kostenpflichtig,<br>nur nach einer Registrierung nutzbar oder speichern die Daten auf ausländischen<br>Servern. Die Kosten- sowie Registrierungspflicht sind insbesondere dann problematisch, wenn die<br>Lösung zu Unterrichtszwecken eingesetzt werden soll. Um auch sensible Daten mit der Anwendung verarbeiten zu können, müsste in jedem Fall gewährleistet sein, dass die Daten in einem zweifelsfrei sicheren und vertrauenswürdigen Umfeld gespeichert werden.<br><br>Das Ziel dieser Arbeit ist die Entwicklung einer Webanwendung, die es ermöglicht in Echtzeit, kollaborativ an Mindmaps zu arbeiten. Die hierbei entwickelte Lösung soll zu Lehrzwecken eingesetzt werden können und dabei<br>ohne Registrierung, sowie unabhängig vom Endgerät nutzbar sein. Auch die Sicherheit der Daten, die mit der Anwendung erzeugt werden, muss gewährleistet sein, indem die Anwendung auch auf eigenen Servern betrieben werden kann. <br><br>Zu Beginn der Arbeit wird analysiert, welche Technologien für die Umsetzung in Frage kommen. Daraufhin werden die einzelnen Komponenten der Anwendung entworfen. Dazu bedarf es einer funktionalen und<br>gestalterischen Planung der Benutzeroberfläche, sowie einer strukturellen Planung des Datenbankmodells und des Backends. Nach Abschluss der Arbeit wird der entwickelte Quellcode als Open-Source veröffentlicht, um eine<br>stetige Weiterentwicklung der Anwendung zu ermöglichen.
09.08.18;09.01.19;2018;extern;Bachelor;EN;Capturing, Storing and Visualization of Automotive Testing Data;Prototypical development of a software system, used for capturing, storing and visualization of primarily subjective automotive testing data. This thesis contains the concepts as well as the implementation of required components. To capture the data, an embedded system was developed, accessing the car's internal data via CAN. Subjective events during the test ride shall be logged via voice commands. Therefore diverse voice recognition software were compared and evaluated. The created data is digitally stored, and visualized in an application. Processes regarding subjective data (subjective forms) shall be automated.
27.08.18;27.01.19;2018;extern;Bachelor;DE;Einsatzmöglichkeiten von Augmented Reality in modularen Fertigungsanlagen zur Unterstützung von Anlagenbedienern aus unterschiedlichen Fachbereichen;Das Ziel dieser Arbeit besteht in der Konzeptionierung und Entwicklung von Augmented<br>Reality Anwendungen zur Lösung von Problemstellungen im Umfeld von modularen<br>Fertigungsanlagen. Konkret werden zwei Problemstellungen untersucht.<br>Zum einen werden zukünftig in modernen Fertigungsanlagen Roboter-Umhausungen durch<br>ausgeklügelte dynamische Sicherheitskonzepte ersetzt. Die dabei zum Einsatz kommenden<br>Sicherheitseinrichtungen wie beispielsweise Lichtgitter oder Laserscanner sind für das<br>menschliche Auge nicht sichtbar. Zudem lässt sich die komplexe Dynamik solcher Systeme<br>mit herkömmlichen Medien einem Nichtfachmann nur schwer erklären. Die Arbeit beschäftigt sich in diesem<br>Zusammenhang mit der Fragestellung, wie durch die Visualisierung mit Augmented<br>Reality die dynamischen Sicherheitskonzepte besser demonstriert und überprüft werden<br>können.<br>Zum anderen gibt es bei modularen Fertigungsanlagen eine hohe Anzahl an möglichen<br>Anlagenrüstungsvarianten. Um die Anlagenrüstung für den bevorstehenden Produktionsauftrag<br>optimieren zu können, wird ein Experte benötigt. Trotz umfassender Erfahrung<br>kann dabei meist keine perfekte Lösung gefunden werden. Ein weiteres Ziel der Arbeit besteht<br>deshalb darin, auch einem Anlagenbediener mit weniger Erfahrung die Optimierung<br>einer modularen Fertigungsanlage zu ermöglichen. Die Bestimmung eines Optimums erfolgt dabei anhand von computergestützten Simulationen. Der Bediener wird beim Umkonfigurieren durch virtuelle Arbeitsanweisungen unterstützt.
29.08.18;01.03.19;2018;intern;Bachelor;EN;Betreiben eines neuronalen Netzes auf einem Microcontroller am Beispiel der autonomen Steuerung eines Modellfahrzeuges;Subject of this thesis is a self-driving model car and its ability to identify the lanes of a standardized test parkour. The car is equipped with a linescan camera and a decision logic is used to detect and qualify the lanes. The intention of this thesis is, to show, how the existing interpretation algorithm can be replaced by a neuronal network. Various topologies are discussed and means are given how to replace the existing processor hardware by a more powerful one. It is shown, that a deep neuronal network with two hidden layers is capable to master this task.iii<br>
01.09.18;01.02.19;2018;extern;Bachelor;DE;Auswirkung der EU-Verordnung 2017/746 auf die Weiterentwicklung einer Softwareplattform für In-vitro-Diagnostika;Die neue EU-Verordnung 2017/746 über In-Vitro-Diagnostika (IVD), die am 26. Mai 2017 in Kraft getreten ist, setzt Hersteller von IVDs unter Druck. Neue Produkte können nur noch unter Einhaltung der neuen Vorgaben in Verkehr gebracht werden. Bisher genehmigte Produkte müssen innerhalb von fünf Jahren erneut zertifiziert werden. Produkte, die bis zum 26. Mai 2022 nicht den neuen Anforderungen entsprechen, dürfen nicht mehr weiterentwickelt oder verändert werden. Die neue Verordnung verlangt grundlegende Veränderungen bei der Softwareentwicklung im Bereich IVD. Ein Beispiel dafür ist die überholte Sicherheitsklassifizierung, die Software in andere Sicherheitsklassen einteilt als bisher. Mit der neuen Sicherheitsklassifizierung gehen andere Verpflichtungen einher, die bei der Entwicklung einzuhalten sind.<br>Die Arbeit zieht einen Vergleich zwischen der alten Richtlinie 98/79/EG und der neuen Verordnung 2017/746 der EU. Dabei wird die Auswirkung der Verordnung 2017/746 anhand der bei der infoteam Software AG entwickelten Softwareplattform untersucht. Dazu soll die Softwareplattform um eine neue Komponente erweitert werden, die konform zu den neuen und geänderten Anforderungen der Verordnung 2017/746 ist.<br>
01.09.18;01.02.19;2018;extern;Bachelor;DE;Konzeption, Entwurf und Implementierung eines Transformators von EAST-ADL- zu AUTOSAR-Modellen;Diese Arbeit befasst sich mit der Transformation, oder auch Umwandlung, von Systemarchitekturmodellen, erstellt mit der Architekturbeschreibungssprache EAST-ADL, in Softwarearchitekturmodelle, erstellt mit AUTOSAR. Die Arbeit richtet sich somit an Softwareentwickler in der Automobildomäne mit Bezug zur System- und Softwarearchitektur von Fahrzeugsystemen.<br>Die Umwandlung der Modelle geschieht manuell durch den Softwareentwickler und beansprucht dadurch dessen Zeit, birgt hohes Fehlerpotential und verursacht Kosten. Diese Missstände sollen durch eine automatisierte Transformation abgeschafft werden.<br>Um dieses Ziel zu erreichen wird nach dem V-Modell und mittels Scrum eine Java Eclipse Applikation entwickelt, welche die Transformation automatisiert durchführen soll.<br>Dazu werden die Anforderungen anhand von Anwendungsszenarien ausgearbeitet und in Form der IEEE-830 1998 dokumentiert. Zudem wird ein Zuordnungsschema zwischen EAST-ADL- und AUTOSAR-Elementen aufgestellt. Dabei wurde das Zuordnungsschema aus der Masterarbeit von Ahsan Shamim geprüft, aktualisiert und angepasst. Das resultierende Zuordnungsschema ist die Basis der Transformation der Modelle.<br>Des Weiteren wird die Softwarearchitektur der Applikation aufgestellt und ein Entwurf der Software ausgearbeitet. Die Implementierung der Applikation erfolgt prototypisch. Es wird die grundlegende Konfiguration der Entwicklungsumgebung beschrieben und auf die Verwendung der Entwurfsmuster Strategy und Singleton eingegangen.
01.09.18;01.02.19;2018;extern;Bachelor;DE;Konzeption und prototypische Implementierung eines Moduls zur automatischen Erkennung und Verarbeitung von Nachrichten im internationalen Flugverkehr;Diese Bachelorarbeit wurde als Projekt der Firma ISO Software Systeme GmbH in Nürnberg im Zeitraum von 01.09.2018 bis 01.02.2019 erstellt. <br>Ziel dieser Arbeit war die Konzeption und prototypische Implementierung eines Moduls, das in die SKYport Suite der ISO Software Systeme GmbH integriert werden kann.<br>Dieses Modul soll automatisiert Nachrichten, die im internationalen Flugverkehr versendet werden, erkennen und verarbeiten.<br>Dazu wurden mehrere Frameworks verglichen, die zum Parsen der Nachrichten geeignet sein könnten.<br>Danach wurde auf die Anforderungen an das Modul und auf mögliche Designentwürfe und -entscheidungen, die diesen Anforderungen gerecht werden, eingegangen.<br>Anschließend wurde der Prozess dargestellt, den die Nachricht im Modul durchläuft.<br>Zuletzt wurden Performanz und Robustheit des Moduls geprüft.<br>Daraus resultierte ein Prototyp, der Nachrichten, die nach dem AHM Standard definiert sind, erkennt und verarbeitet. Dieser Prototyp wurde in die SKYport Suite integriert.
01.09.18;01.02.19;2018;extern;Bachelor;DE;Entwicklung und ausgewählte prototypische Umsetzung einer Business-Intelligence-Strategie für den Zentraleinkauf der DATEV eG;Im Zuge der Digitalisierung werden auch Einkaufsabteilungen mit Big Data konfrontiert. Um diesbezüglich Wettbewerbsvorteile gegenüber der Konkurrenz zu realisieren, ist es entscheidend, die großen Datenmengen nicht einfach nur anzuhäufen, sondern sie auch zielgerichtet einzusetzen. Eine Möglichkeit hierfür bietet der Einsatz von Business Intelligence. Im Fokus dieser Arbeit steht die Entwicklung einer Business-Intelligence-Strategie für den Zentraleinkauf der DATEV eG. Hierfür werden nach Erläuterung der theoretischen und praxisbezogenen Grundlagen die Phasen Analyse, Bewertung, Konzeption und Maßnahmen des Strategieentwicklungsprozesses durchlaufen. In diesen Prozessphasen kommen verschiedene Methoden zum Einsatz, die jeweils konkrete Ergebnisse liefern. <br>Sowohl die durchgeführte Bedarfserhebung als auch die SWOT-Aufstellung und Reifegradmodell-Einteilung zeigen Handlungspotential im Berichtswesen auf. Die Befragung ergab, dass insgesamt 60 Kennzahlen für den Zentraleinkauf der DATEV eG relevant sind. Jedoch werden diese aufgrund technischer oder organisatorischer Schwachstellen derzeit nicht vollständig ermittelt. Um diese Probleme zu beheben, wird der Einsatz einer Business-Intelligence-Lösung geplant. Im Rahmen der Konzeption werden beispielsweise Kennzahlen bewertet, Business-Intelligence-Produkte verglichen sowie das Einkaufsvolumen als Kennzahl prototypisch umgesetzt. Mithilfe der formulierten Business-Intelligence-Roadmap kann eine planvolle Realisierung erfolgen.
01.09.18;01.02.19;2018;intern;Bachelor;DE;Bildung und Bewertung von Standortindikatoren für Kundensegmentierung aus frei zugänglichen Datenquellen  zur Verwendung in Machine Learning-Anwendungen;Das Ziel dieser Bachelorarbeit war es, Standortindikatoren für Kundensegmentierung mittels Relation zwischen den unternehmensexternen Marktdaten zu bilden und zu bewerten. Hierzu wurden drei Hypothesen erstellt:<br>1) Es gibt einen Zusammenhang zwischen soziodemographischen, ökonomischen und psychographischen Merkmalen<br>2) Das Zufriedenheitsniveau der Einwohner hängt von der Anzahl der verschiedenen Angebote in ihrem Wohnort, wie zum Beispiel Gastronomie, Sport- und Freizeitmöglichkeiten oder Naturobjekte ab<br>3) Auf Basis der Anzahl von verschiedenen Einrichtungen in einem Wohnort, kann man die Kaufkraft der Bewohner prognostizieren.<br>Um diese Hypothesen zu prüfen, wurde eine riesige Datenbank in PostgreSQL mit statistischen, soziodemographischen, ökonomischen, psychografischen und OpenStreetMap-Daten erstellt und bearbeitet.<br>Nach der durchgeführten statistischen Analysen wurde festgestellt, dass die Hypothese über den Zusammenhang zwischen soziodemographischen, ökonomischen und psychographischen Merkmalen bestätigt wurde. Zwei weitere Hypothesen zur Prognose der Kaufkraft und der Zufriedenheit auf Basis der Anzahl von verschiedenen OSM-Objekten wurden wegen unzureichendem Zusammenhang verneint.<br>Die Ergebnisse der vorliegenden Arbeit können als ein Instrument angesehen werden, um eine Grundlage für eine weitere Standortanalyse, Geomarketing oder unternehmerische Entscheidungen zu schaffen.
01.09.18;29.01.19;2018;extern;Bachelor;DE;Machbarkeitsstudie und prototypische Entwicklung eines Time-Travel-Debuggers im Kontext eines konkreten Embedded Systems;"In der Softwareentwicklung kostet die Analyse von Fehlern durch Softwareentwickler viel Zeit. Herkömmliche Debugger geben dabei keine Auskunft über den Fehlerhergang, sondern nur über den Programmzustand zum Fehlerzeitpunkt. Diese Lücke schließen Time-Travel Debugger, die durch Aufzeichnen des Programms den genauen zeitlichen Verlauf des Fehlers rekonstruieren können.<br><br>Das Ziel dieser Arbeit ist es, in Kooperation mit der Firma e.solutions GmbH, eine Machbarkeitsstudie zum Einsatz eines Time-Travel Debuggers für das reaktive Embedded System ""Virtual Cockpit"" durchzuführen. Dabei war insbesondere relevant, wie hoch der Performance-Overhead bei der Aufnahme des Programms zur Ausführungszeit ausfällt und ob es möglich ist, das aufgenommene Programm in der PC-Simulation wiederzugeben.<br><br>Dazu wurde, aufbauend auf bekannten Architekturen, ein Konzept erarbeitet und anhand eines prototypischen Time-Travel Debuggers umgesetzt. Dieser wurde erfolgreich auf seine Tauglichkeit im Embedded-Umfeld getestet.<br><br>Um die Aufnahme zu einem beliebigen Zeitpunkt starten zu können, anstatt nur bei Programmstart, müsste der Prototyp um eine Snapshot-Funktionalität erweitert werden. Diese kann allerdings erst realisiert werden, wenn die Grundlagen vom Gesamtsystem geschaffen worden sind."
03.09.18;21.01.19;2018;extern;Bachelor;DE;Regelsätze und Werkzeugerweiterung für eine automatische Software-Analyse von C#-Projekten mit exemplarischer Visualisierung einer Auswertung;"Das Ziel der vorliegenden Bachelorarbeit war es eine automatische Software-Analyse für C# Anwendungen zu entwickeln.<br>Um Verletzungen einer Softwarearchitektur zu entdecken, wurden Regelsätze definiert und entwickelt.<br>Mithilfe des C# Scanners Architecture Analyzer werden Code Abhängigkeiten in Assemblies entdeckt und in Knoten und Kanten in eine Neo4j Graphdatenbank hochgeladen.<br>Der Architecture Analyzer wurde für das Entwickeln der Regelsätze erweitert.<br>Die entdeckten Verletzungen für Abhängigkeiten zwischen Assemblies, ungenutzte MEF Exports und öffentliche Klassen, welche nur in der eigenen Assembly verwendet werden, wurden in einem tabellarischen Report bzw. in einem Graphen visualisiert.<br>Ein Jupyter Notebook diente als Ausführungskette und führte die folgenden Aktionen durch:<br>?	Identifikation der C# Assemblies<br>?	Ausführen des Architecture Analyzers<br>?	Ausführen der Regelsatz Abfragen<br>?	Aufbereitung und Überprüfung der Treffer<br>?	Visualisierung der Ergebnisse in einem Report und in einem Graphen<br>"
10.09.18;25.01.19;2018;extern;Bachelor;EN;Development of a restbus based simulation- and test environment ;Since the 80s the number of Electronic Control Units (ECUs) keeps increasing and in the same way the complexity of test setups does. In order to test developed software for ECUs, it was necessary that the needed hardware components were physically available. Alternatively, it is possible to use restbus simulations which simulate missing hardware components and decrease the dependency for real hardware. This thesis was realized in cooperation with Elektrobit Automotive GmbH (EB). Goal of this thesis was, to develop a restbus based simulation prototype which shall be used to test hardware components of EBs product EB cadian Sync. It was possible to create a working prototype which fulfilled all defined requirements of this thesis. Additionally, it is possible to use the developed prototype as a basis for future projects and extend its functionality.
10.09.18;08.02.19;2018;intern;Bachelor;DE;Rust und Go im Vergleich;Sowohl Rust als auch Go sind relativ junge und populäre Programmiersprachen, die als Alternativen für C und C++ entwickelt wurden und ihren Fokus auf systemnahe Entwicklung legen. Go zielt auf Einfachheit und hohe Effektivität ab, dagegen fokussiert sich Rust auf Schnelligkeit, Sicherheit und Nebenläufigkeit. <br>In dieser Arbeit werden die Go und Rust miteinander verglichen. Hierfür werden die vergleichbaren Features der Programmiersprachen gegenübergestellt, um inhaltliche und konzeptionelle Unterschiede herauszuarbeiten. Anschließend werden einige Testfälle in beiden Programmiersprachen ausgewählt und weitestgehend äquivalent implementiert, um eine Performanceanalyse, die aus Laufzeitanalyse und Speichernutzungsanalyse bestehen, durchzuführen. Die hierdurch empirisch ermittelnden Daten werden dargestellt und Unterschiede zwischen den Sprachen erläutert. Die Ergebnisse zeigen, dass Rust mit der Compiler-Optimierung die effizienteste Sprache für die vorliegende Herausforderung ist.
12.09.18;12.02.19;2018;intern;Bachelor;DE;Graphische Netzwerkvisualisierung einer Game Design Pattern Language und quantitativer Vergleich mit der Pattern Language des EMPAMOS-Projektes;Ziel der Arbeit ist der vorwiegend quantitative Vergleich der bislang fremden Game Design Pattern Language (PL) von Staffan Björk mit der PL aus dem Forschungsprojekt EMPAMOS der TH Nürnberg. Auf diese Weise soll herausgearbeitet werden, wo strukturelle Gemeinsamkeiten oder Unterschiede bestehen und an welchen Stellen ein inhaltlicher Vergleich der Mustersprachen sinnvoll wäre. Dafür müssen die Daten von Björks PL extrahiert werden und eine Netzwerkvisualisierung soll deren Inhalte übersichtlicher darstellen. Der theoretische Teil der Arbeit befasst sich mit den Themengebieten der Game Design PL sowie der Netzwerkanalysen. Im praktischen Teil der Arbeit wurde mit Python und Scrapy ein Webcrawler entwickelt, der die Inhalte von Björks PL extrahiert. Anschließend wurde die Netzwerkvisualisierung mittels Cytoscape.js durchgeführt und die Daten aus beiden Pattern Languages wurden mit Gephi und Python-NetworkX analysiert und verglichen. Zentrale Erkenntnisse aus den Analyseergebnissen sind unter anderem, dass die PL aus dem EMPAMOS-Projekt trotz geringerer Größe auf eine höhere Evidenzbasis zurückgreifen kann und ihr Netzwerk sehr viel stärker vernetzt ist. Das Netzwerk der um einiges älteren PL von Björk ist stark zentralisiert, besitzt also wenige zentrale Patterns und viele Außenseiter. Eine Clusteranalyse von Björks PL zeigt abschließend, trotz unterschiedlicher Evidenzbasis, einige Patterns auf, die sich für einen inhaltlichen Vergleich mit den Patterns der EMPAMOS PL eignen.
13.09.18;13.02.19;2018;intern;Bachelor;DE;"Implementierung einer plattformunabhängigen Pipeline zwischen den Robotern ""Pepper"" sowie ""NAO"" und Software zur Objekterkennung.";"Im Rahmen dieser Bachelorarbeit wird dem Roboter Pepper die Fähigkeit gegeben, durch rein mündliche Bedienung Objekte und deren Position zu erkennen und zu erlernen.<br>Durch manuellen Einsatz von zusätzlicher Software ist es Pepper bereits möglich konkrete Objekte zu erlernen und anschließend wiederzuerkennen. Allerdings kann dabei immer nur das konkrete Objekt wiedererkannt werden.<br>Das Hauptziel dieser Arbeit ist es, den Lernprozess vollständig zu automatisieren, sodass Pepper durch mündliche Interaktion Objekte erlernen und erkennen kann. Dabei können Objekte derselben Art zusammengefasst werden.<br>Hierzu wird ein, auf dem Deep Learning-Ansatz [2]  basierendes Objekterkennungs-system eingesetzt; Faster RCNN [3], ein tiefes neuronales Netzwerk, welches eine robuste Objekterkennung ermöglicht. Da Pepper nicht leistungsstark genug ist, um dieses System in hoher Geschwindigkeit auszuführen, wird dieses als eigenständiges Programm implementiert, welches durch eine REST-Schnittstelle angesprochen werden kann.<br>Als Ergebnis soll eine plattformunabhängige Softwarelösung entstehen.<br>Dadurch wird Pepper ermöglicht hunderte verschiedene Objekte zu erlernen und zu erkennen."
13.09.18;25.01.19;2018;extern;Bachelor;DE;Implementierung eines Management-Dashboards bei einer Direktbank zur Visualisierung von Unternehmenskennzahlen in Echtzeit;Um dem Top-Management der Consorsbank einen aktuellen Einblick in die operativen Systeme und die wichtigsten Bereiche des Geschäfts zu ermöglichen, ist die Anforderung des Chief Data Officer, ein Kennzahlendashboard für die neue Management Area bereitzustellen. Mittels der Software TIBCO Spotfire sollen verschiedene Metriken der Produkteröffnungsprozesse, der Besucheranzahl auf den Plattformen, der Auslastung des Kundendialogs sowie des Tradings in diversen Diagrammen dargestellt und mit historischen Werten verglichen werden. Hierfür ist es notwendig, Daten aus verschiedenen Quellen wie dem Data Warehouse und den operativen Systemen mithilfe des ETL-Prozesses anzubinden. Die einzelnen Phasen dieses Prozesses gestalten sich je nach Integrationsweise unterschiedlich und erfordern verschiedene Softwarelösungen. Zusätzlich wird das Projekt einer kaufmännischen Betrachtung unterzogen. Es wird im Nachgang eine Total-Cost-of-Ownership-Analyse durchgeführt, um die angefallenen und noch anfallenden Kosten des Vorhabens zu beziffern.
14.09.18;14.02.19;2018;intern;Bachelor;DE;Automatisierte Bestimmung einer Zuordnung von Benutzerkennungen zu SQL-Queries in Webanwendungen;"Ein weit verbreiteter Typ von Sicherheitslücken in Webanwendungen sind Broken Access Controls (OWASP Top10: A5-20017): Zugriffsbeschränkungen für authentisierte Benutzer werden nicht richtig durchgesetzt. Eine externe Security-Appliance nach [PrGrTr2013], die einen Reverse-HTTP-Proxy zwischen Browser und Webanwendung sowie einen SQL-Proxy zwischen Webanwendung und Datenbank einsetzt, könnte eine bestehende, fehlerhafte Webanwendung gegen solche Angriffe absichern, ohne dass Änderungen am Quelltext vorgenommen werden müssen. Ziel dieser Arbeit ist dazu die Entwicklung einer sogenannten ""Mapping Engine"" zur automatisierten Zuordnung der Benutzerkennung desjenigen Benutzers, der ursprünglich einen HTTP-Request an die Webanwendung gestellt hatte, zu der in Folge durch die Webanwendung ausgelösten SQL-Query. Es soll keine manuelle Konfiguration der Mapping-Engine erforderlich sein."
20.09.18;13.12.18;2018;extern;Bachelor;DE;Evaluierung der Möglichkeiten und Herausforderungen von automatisierten Performancetests auf Kundensystemen der DATEV eG;Performance-Kennzahlen, die die Programmdurchlaufzeiten darstellen, sind für einen Softwarehersteller wie der DATEV eG entwicklungsseitig relevant, da sie ein Gradmesser für die potentielle Kundenzufriedenheit sind. Das zentrale Performancemesstool ?GKPer-fTool?, das im Sinne einer Testautomatisierung einen Use-Case simuliert, wird derzeit bei der DATEV eG intern für entwicklungsbegleitende Qualitätssicherungsmaßnahmen ge-nutzt. <br>Im Rahmen dieser Arbeit werden die Möglichkeiten einer automatisierten Performance-messung auf Kundensystemen der DATEV eG genauer untersucht. Außerdem werden Herausforderungen, die bei einer Umsetzung entstehen, geprüft und Lösungsmöglichkeiten evaluiert. Abschließend wird, aufgrund der Gegenüberstellung von Herausforderungen und Möglichkeiten, eine Handlungsempfehlung aufgezeigt. Für die Untersuchung gelten die Rahmenbedingungen des bestehenden Performancemesstools ?GKPerfTool?. <br>
01.10.18;01.03.19;2019;extern;Bachelor;DE;Testautomatisierung für Workflows am Beispiel des Workflow-Management-Systems JobRouter;Diese Arbeit befasst sich mit der Testautomatisierung von Workflows und richtet sich an Workflow-Designer und Workflow-Tester, die mit webbasierten Work-flow-Management-Systemen arbeiten. <br>Anhand der Perspektiven eines Workflows werden die Anforderungen an das automatisierte Testen von Workflows herausgearbeitet und in einem praktischen Beispiel angewendet. Es wird ein Weg gezeigt, wie ein automatisierter Workflow-Test für ein webbasiertes Workflow-Management-System programmiert werden kann. <br>Für den Test wird ein Workflow gewählt, der ein Rollenkonzept, Parallelisierun-gen, Benutzer-, wie auch Systemaktivitäten enthält. Das genutzte Workflow-Management-System für dieses Beispiel ist JobRouter. Für die Testimplementie-rung werden neben Selenium WebDriver in der Programmiersprache C# die Frameworks NUnit für das Testmanagement und Extent Reporting für die graphi-sche Aufbereitung der Testergebnisse genutzt. <br>Das entstandene prototypische Testkonzept mit Open Source Mitteln kann auf andere webbasierte Workflow-Management-Systeme übertragen werden, solange diese einen clientseitigen Zugriff auf Workflow-Variablen und -Informationen erlauben. Das entwickelte Testkonzept ermöglicht ein vollständiges Testen des Kontrollflusses und Rollenkonzepts des Workflows. Die Integration des Daten-flusses, die Beurteilung kostenpflichtiger Testwerkzeuge und deren Vergleich mit Selenium WebDriver können Themen für weitere Arbeiten darstellen.<br>
01.10.18;01.03.19;2019;extern;Bachelor;DE;Konzeption und Ausarbeitung eines Prototyps zum Austausch betrieblicher Regelungen in der N-ERGIE AG.;Diese Arbeit behandelt eine Problemstellung im Auftrag der N-ERGIE AG Personalabteilung.<br>Betrachtet wird der Informationstransfer betrieblicher Regelungen, welcher durch die Personalabteilung verantwortet wird. Ziel ist ein schneller, einfacher und auf den Mitarbeiter<br>positiv wirkender Informationstransfer. Erzielt wird dies, indem die betrieblichen Regelungen nach Zielgruppen unterteilt und in eine klare Struktur aufgearbeitet sind. Dabei<br>wird die Ansammlung von Betriebsvereinbarungen und der hohe personelle Aufwand zur<br>Kommunikation gelöst. Der Personalabteilung ist es wichtig, dass die Mitarbeiter Kenntnis<br>über die Regelungen haben, diese schnell verstehen und anwenden können.<br>Im Rahmen leitfadengestützter Interviews, wird Aufschluss darüber gegeben, welche Potenziale in der Kommunikation erreicht werden können. Zudem wird die Ist Situation<br>festgehalten. Befragt werden zwei konträre Zielgruppen, wobei die Unterschiede in den<br>jeweils zu vermittelnden betrieblichen Regelungen liegen. Aus den Ergebnissen der Interviews, erschließt sich, dass die Ausgangssituation nicht zielführend ist.<br>Zur Problemlösung wird ein Konzept ausgearbeitet. Dieses wird zur visuellen Darstellung<br>in Form eines interaktiven Prototyps realisiert. Aus einer qualitativen Inhaltsanalyse gehen<br>die Anforderungen hervor. Sie werden in User Stories abgeleitet und dienen als Input für<br>die Erstellung des Konzepts.
01.10.18;01.03.19;2019;extern;Bachelor;DE;Geolocation im Transformator-Werk der Siemens AG: Kosten-Nutzen-Analyse zur Verbesserung des Materialflusses;Bei der Produktion der Großtransformatoren besteht das Problem darin, dass durch unzureichende Kennzeichnung von einzelnen Teilen das Material häufig nicht aufgefunden werden kann oder gar verloren geht.<br>Der Materialfluss im Werk erfolgt, je nach Materialgruppe (Fremd, Eigen, Isolierteile, Stahlteile, etc.) und verantwortlicher Organisation, in unterschiedlicher Form und dementsprechend variierender Ausprägung der Systemunterstützung. Eine durchgängige Steuerung und Lokalisierung von Einzelteilen über alle Materialgruppen hinweg entlang der Prozesskette ist nicht gegeben. <br>Es entstehen lange und nicht-wertschöpfende Suchzeiten der Materialien. Dies kann wiederum zur Verzögerungen in der Produktion, Kapazitätsverschwendung, Non-Conformance-Costs und Kundenunzufriedenheit bei möglicher verspäteter Lieferung führen. <br>Die Identifizierung und Reduzierung von diesen Verlusten ist somit eine Priorität für die Produktion, um Beeinträchtigungen zum Nachteil des Unternehmenserfolgs zu vermeiden. <br>Das Kernergebnis dieser Arbeit ist es eine Basis für eine Geolocation-Technologie zu schaffen, damit alle Materialien und wesentlichen Fertigungshilfsmittel aufwandsarm identifizierbar und jederzeit auffindbar sind. Dadurch sollen die Suchaufwände verringert und ein reibungslosen Produktionsablauf sichergestellt werden. <br>
01.10.18;26.02.19;2019;extern;Bachelor;DE;Prototypische Anbindung von Power BI an die DATEVconnect-Schnittstelle von Kanzlei-Rechnungswesen;Im Rahmen vorliegender Arbeit wird untersucht, inwieweit sich gesetzliche Auswertungen wie Bilanzen sowie Gewinn- und Verlustrechnungen in einem Business-Intelligence-Werkzeug (BI-Werkzeug) betriebswirtschaftlich korrekt gemäß der Gliederungsstruktur abbilden lassen. Dazu werden zunächst die wesentlichen Anforderungen an die korrekte Darstellung und Aufberei-tung gesetzlicher Auswertungen spezifiziert. Anschließend wird unter Berücksichtigung der zuvor beschriebenen Herausforderung ein ETL-Prozess (Extract, Transfer, Load) implementiert. Dieser basiert auf einem Python-Skript, welches die durch eine DATEV-interne Anwendung (DATEV Referenzsystem) bereits vorverarbeiteten Daten aus DATEV Kanzlei-Rechnungswesen, von einer normierten REST-Schnittstelle (DATEVconnect) abfragt und in eine Form überführt, die sich mit einem BI-Werkzeug verarbeiten lässt. Am Ende wird auf Ba-sis der durch den ETL-Prozess aufbereiteten Daten ein prototypischer Bericht mit dem BI-Werkzeug Microsoft Power BI erstellt, welcher der gesetzlichen Gliederungsstruktur von Bilanz sowie Gewinn- und Verlustrechnung entspricht und so die Grundlage für standardisierte Be-richte, interaktive Apps, Dashboards usw. bildet.
01.10.18;01.03.19;2019;intern;Bachelor;DE;Fusion und interaktive Visualisierung von Terraindaten am Beispiel Bayern;In dieser Arbeit werden Terraindaten des Bayerischen Landesamts für Digitalisierung, Breitband und Vermessung, des Advanced Spaceborne Thermal Emission and Reflection Radiometer sowie der Shuttle Radar Topography Mission im Gebiet von Bayern untersucht und auf Qualität, Verschiebungen und Höhendifferenzen relativ zueinander geprüft und bewertet. Mit den dadurch gewonnenen Erkenntnissen werden die Daten zu einem kombinierten Höhenmodell mit einer Auflösung von 1 m fusioniert, wobei fehlende Höhenwerte durch Interpolation berechnet werden. Anhand dieses Höhenmodells wird beschrieben, wie ein interaktiver Terrain Viewer erstellt werden kann. Darin wird das Terrain des Höhenmodells als dreidimensionale Karte visualisiert und kann frei und stufenlos vom Benutzer durch Überfliegen erkundet werden.
01.10.18;26.02.19;2019;extern;Bachelor;DE;Konzeption und Umsetzung einer multimodalen Mensch-Maschine-Schnittstelle für den Service von Produktionsmaschinen;Für den Service von Produktionsmaschinen stellt die Benutzerschnittstelle einen wesentlichen Bestandteil dar. Diese ist jedoch hauptsächlich auf den Produktionsbetrieb ausgerichtet und unterstützt den Menschen, bei der Instandhaltung, nur eingeschränkt. Abhilfe kann der Einsatz von natürlichen Interaktionskanälen schaffen und führt somit zu dem Einsatz einer multimodalen Mensch-Maschine-Schnittstelle.<br><br>Das Ziel der Bachelorarbeit war die Untersuchung einer multimodalen Mensch-Maschine-Schnittstelle für den Service von Produktionsmaschinen. Hierzu sollte ein Konzept aufgestellt und anschließend ein Softwaredemonstrator umgesetzt werden. Anhand des Softwaredemonstrators sollte der Mehrwert sowie die Begeisterungs- und Akzeptanzkriterien evaluiert werden.<br><br>Für die Untersuchung wurde die Ist-Situation eines charakteristischen Wartungsszenarios analysiert. Anschließend wurden auf Basis von identifizierten Optimierungspotenzialen die Anforderungen abgeleitet. Bezüglich der ermittelten Anforderungen wurde ein multimodales Konzept aufgestellt, das eine taktile, visuelle und auditive Modalität unterstützt. Dieser Entwurf diente als Grundlage für die Realisierung des Softwaredemonstrators.<br><br>Der Softwaredemonstrator wurde im Rahmen einer Nutzerstudie mit 11 Probanden aus dem industriellen Umfeld evaluiert. Dabei konnte gezeigt werden, dass durch den Einsatz natürlicher Interaktionskanäle, ein Mehrwert geschaffen werden kann und dies eine hohe Akzeptanz bei den Probanden aufweist.
01.10.18;01.03.19;2019;intern;Bachelor;DE;Grafische Bedienoberfläche und funktionelle Erweiterung eines Programms zur Berechnung spieltheoretischer Funktionen;Die Arbeit beschäftigt sich mit der Weiterentwicklung eines Terminalprogramms zur Berechnung spieltheoretischer Funktionen. Hauptaufgabe dabei war es eine grafische Bedienoberfläche und somit eine neue Menüführung zu entwickeln. Dabei wurde besonders darauf geachtet, dass die zuvor implementierten Funktionen weiterhin funktionieren, sich die Benutzerfreundlichkeit erhöht und es für die Zukunft gute Änderungsmöglichkeiten gibt. Zudem wurde das Programm um die Berechnung des Holler-Packel-Index erweitert. Des Weiteren wurde eine Laufzeitabschätzung mit in die Anwendung implementiert, diese war zwar schon vorhanden, aber nur in Form eines eigenständigen Programms.
01.10.18;29.03.19;2019;extern;Bachelor;DE;Analyse von Produkten zur Qualitätssicherung - Klassifizierung und Lokalisierung von Produktteilen mittels bildverarbeitender Neuronaler Netzwerke im industriellen Umfeld<br>;In den letzten Jahren gewann das Forschungsgebiet der künstlichen neuronalen Netzwerke und der Bedarf an dynamischen und modularen Fertigungsanlagen im industriellen Umfeld eine immer größer werdende Bedeutung. Im Speziellen wurde in dieser Arbeit ein Prozess entwickelt, der den Einsatz von bildverarbeitenden neuronalen Netzwerken im Kontext einer modernen Forschungsanlage ermöglicht. Hierzu liefert diese Arbeit eine fundamentale Wissensbasis zum Umgang mit künstlichen neuronalen Netzwerken, deren Training und dem Transferieren von Wissen. Im speziellen wurde hierbei auf die CNN eingegangen und deren Möglichkeiten zur Objekterkennung. Um ein solches Netzwerk im industriellen Umfeld, speziell zur Qualitätskontrolle, einsetzen zu können wurden u. a. beschreibende Kriterien der bildverarbeitendes Qualitätssicherungssysten erläutert. Es erfolgte die Auswahl von Mask R-CNN unter mehreren state-of-the-art Netzwerken. Der entwickelte Prozess ermöglicht den Einsatz von CNNs in modernen Fertigungsanlagen. Mit den Kernpunkten AR zur Umgebungserfassung und des on-the-?y Datensatzgenerierung wurde die Daten Generierung gestaltet. Die Ergebnisse des eingesetzten Mask R-CNN waren äußerst zufriedenstellend.
01.10.18;28.02.19;2019;extern;Bachelor;DE;Agile Softwareoptionen im Outsourcing-Kontext beim IT-Systemhaus der Bundesagentur für Arbeit;Die vorliegende Bachelorarbeit, die in Kooperation mit dem IT-Systemhaus der Bundesagentur für Arbeit geschrieben wurde, beschreibt Konzepte für die Softwareentwicklung, den Betrieb sowie für die Zusammenarbeit der beiden Teams. Die Konzepte vereinen die Themen Agilität, externe Dienstleister wie auch verteilte Teams und versuchen, Lösungsansätze für all die Herausforderungen aufzuzeigen, die durch die unterschiedlichen und teils gegensätzlichen Themengebiete entstehen. Zu beachten ist, dass die Konzepte speziell für den Servicebereich BAS2 des IT-Systemhauses entworfen und die verwendeten agilen Methoden, konkret Scrum und Kanban, individuell auf die vorhandenen Gegebenheiten angepasst wurden. Die Übertragbarkeit dieser Konzepte auf andere Unternehmen ist somit ohne eine Anpassung wohl kaum möglich, jedoch können die Konzepte als Beispiel für die Verwendung von agilen Methoden unter den Geschichtspunkten des Einsatzes von externen Dienstleistern im Unternehmen und verteilten Teams im Sinne von verteilten Teammitgliedern dienen.
01.10.18;01.03.19;2019;intern;Bachelor;DE;Deep Learning im Browser;Der Fokus dieser Arbeit liegt auf der Evaluation von JavaScript Bibliotheken, deren Mechanismen auf Deep Learning, einer untergeordneten Art des Machine Learning, basieren und im Browser verwendet werden.<br>Zu Beginn der Bachelorarbeit werden die Grundlagen zu Deep Learning, WebGL und den Bibliotheken TensorFlow.js, ConvNetJS und Brain.js vermittelt. Der Primärteil befasst sich mit der Umsetzung und Auswertung der genannten Bibliotheken in einer Anwendung, die durch die Verarbeitung von gezeichneten Ziffern die konkrete Ziffer ermitteln kann. In der anschließenden Evaluation werden die Trainingsgeschwindigkeit und -qualität der Modelle, die Auswirkungen der Verarbeitung auf die User Experience im Browser sowie die Ressourcenauslastung mit und ohne WebGL ausführlich gemessen und die Ergebnisse entsprechend erläutert.<br>Durch die Evaluationsergebnisse ist das Trainieren der Modelle im Browser aufgrund einer hohen Auslastung und der daraus resultierenden Auswirkungen auf die User Experience nicht zu empfehlen. Trainierte Modelle sollten für die Nutzung im Browser über bereitgestellte Importfunktionen geladen werden. Grundsätzlich bietet TensorFlow.js - zusammen mit aktiver WebGL-Unterstützung - die besten Performanceergebnisse. <br>Unabhängig von den Performanceauswirkungen entkoppelt Deep Learning im Browser jegliche Verarbeitung auf einem Server und kann, durch den Zugriff auf Web APIs, schnell und einfach vorhandene Eingabemedien auf jedem Endgerät mit einem Browser nutzen.
01.10.18;27.02.19;2019;extern;Bachelor;DE;Konzeption und Ausarbeitung der Prototyping-Phase im Innovationsprozess;"Innerhalb der N-ERGIE IT GmbH erfolgt aktuell eine Umstrukturierung vom internen Dienstleister, welcher sich hauptsächlich um den Systembetrieb kümmert, hin zum Innovationstreiber, welcher die Geschäftsbereiche mit neuen digitalen Lösungen unterstützt. Ziel dieser Arbeit ist es, die allgemeinen Vorgaben zum Innovationsprozess in der N-ERGIE AG darzustellen und einen angepassten Innovationsprozess für die N-ERGIE IT GmbH zu entwickeln. Weiterhin soll eine Prototyping-Software, welche innerhalb der N-ERGIE IT GmbH für die Erstellung digitaler Prototypen als Standardsoftware verwendet wird, ausgewählt und in einer Beispielanwendung getestet werden.<br><br>Die vorliegende Arbeit gibt zunächst einen Überblick über die theoretischen Grundlagen des Innovationsprozesses und spezifiziert nachfolgend die Konzernvorgabe bezüglich des Prozesses der N-ERGIE AG. Basierend auf dieser Rahmenvorgabe wird ein Innovationsprozess entwickelt, welcher speziell an die Anforderungen der N-ERGIE IT GmbH angepasst ist. Anschließend wird die Prototyping-Software für die N-ERGIE IT GmbH ausgewählt. Hierfür werden zuerst die Anforderungen an die Anwendung definiert. Mit dieser Software ist im Anschluss ein konkreter Prototyp umzusetzen.<br><br>Das Ergebnis dieser Arbeit ist die Lean Spiral Methode als angepasster Innovationsprozess für die N-ERGIE IT GmbH. Im Auswahlprozess der Prototyping-Software wird mit Hilfe einer Nutzwertanalyse das Produkt ""Axure RP"" als Empfehlung festgelegt. Mit dieser Anwendung wird im Ans"
01.10.18;28.01.19;2019;extern;Bachelor;DE;Analyse und graphische Aufbereitung von Logdaten und Server-Metriken mittels des Elastic Stacks zur Unterstützung von Managemententscheidungen;Durch die steigende Komplexität und Größe von Softwareapplikationen steigt gleichfalls die Menge an erzeugten Logdaten. Um einen Überblick über diese zu behalten, ist es häufig notwendig eine detaillierte Loganalyse durchzuführen. Daher wurden in dieser Arbeit Logdaten und Server-Metriken aus dem AnalyzeIT-Umfeld analysiert und graphisch aufbereitet, um die Entscheidungen des Managements zu unterstützen. Dazu wurden die Logdaten und Server-Metriken mit Hilfe des Elastic Stack gesammelt, aufbereitet und entsprechend visualisiert. Das bestehende Setup wurde durch Installation neuer Komponenten wie einem Metricbeat erweitert bzw. durch Modifikation der Konfigurationsdateien von Logstash angepasst. Nach der Aufbereitung wurden die gewonnenen Informationen in Elasticsearch gespeichert und konnten mit dem Visualisierungswerkzeug Kibana graphisch aufbereitet werden. Ergebnis dieses Prozesses ist ein Dashboard, bestehend aus speziell für die Bedürfnisse der Stakeholder angefertigten Visualisierungen. Dabei wurde auf die Auswahl geeigneter Visualisierungsformen geachtet. Das Dashboard ermöglicht dem Management einen schnellen Einblick in die Vorgänge und den Zustand der Applikation AnalyzeIT. Es ist fester Bestandteil des Entscheidungsprozesses. Zudem ist eine Erweiterung der Nutzung durch andere Applikationen geplant.
01.10.18;01.03.19;2019;extern;Bachelor;DE;Analyse, Konzeption und Implementierung einer Wissensmanagement-Lösung <br>zur Sicherung und Weitergabe des Wissens<br>;"Die Bachelorarbeit beschäftigt sich mit dem Thema Wissensmanagement bei WITRON Informatik & Logistik GmbH. Im genauen handelt es sich um die Analyse, Konzeption und Implementierung einer Wissensmanagement-Lösung zur Wissenssicherung und Wissensweitergabe. Der Handlungsbedarf ist dadurch gegeben, dass Projekterfahrungen mangelhaft erfasst und nicht zielgerichtet ausgetauscht werden. Diesbezüglich ist das Ziel die Auswahl, Gestaltung und Einführung einer Wissensmanagement-Lösung, mit deren Hilfe Projekterfahrungen effizienter erfasst, organisiert und zugänglich gemacht werden.<br>Um das Ziel zu erreichen wurde zunächst eine Ist-Analyse durchgeführt. Hierbei haben sich bestimmte Optimierungspotentiale und deren Ursachen herausgestellt. Nach der anschließenden Ermittlung der <br>Anforderungen an die Soll-Situation, konnten Optimierungsansätze zur Behebung der Schwachstellen ausgearbeitet werden. Für die Lösungsansätze, bestehend aus ""Mikroschulungen"", ""Wissensbewahrung durch Dokumentation"" und ""Wissensbewahrung durch Unterstützung IuK-Technologie"" erfolgte, soweit möglich, die Ausarbeitung eines Konzepts und die Einführung dieses im Unternehmen. "
01.10.18;14.03.19;2019;extern;Master;DE;Entwicklung eines Vorhersagemodells für den Maintenance-Prozess mit Hilfe eines künstlichen neuronalen Netzes.;Künstliche Intelligenz hat in den letzten Jahren große Fortschritte gemacht. Mit Hilfe von Deep Learning können heute beispielsweise komplexe Muster in Daten erkannt werden. Dies kann unter anderem dazu verwendet werden Vorhersagen zu machen. Die Maintenance-Abteilung der \suse ist für die Instandhaltung der Produkte zuständig. Durch das Veröffentlichen von Updates für Softwarepakete werden Sicherheit und Stabilität der Produkte gewährleistet. Wie lange ein Update zur Veröffentlichung benötigt hängt dabei von vielen Faktoren ab wie beispielsweise dem Testaufwand. Durch die Vorhersage der Update-Dauer sollen wichtige sicherheitskritische Updates künftig schneller veröffentlicht werden können. Zu diesem Zweck wurden zwei künstliche neuronale Netze implementiert. Mit einem neuronalen Netz wird die Zeit in Tagen vorhergesagt. Ein zweites Netzwerk sagt die Zeit mittels Klassifikation vorher. Beide neuronalen Netzwerke erzielten keine exakten Vorhersagen und bieten somit keine Rechtfertigung für den Einsatz in der Maintenance-Abteilung. Die Ursache der Ungenauigkeiten der Vorhersage ist in den Daten zu finden. Dennoch konnte während der Trainingsphase ein Lernfortschritt erzielt werden. Diese Erkenntnis legt nahe, dass durch die Verwendung besserer Daten auch die Vorhersage verbessert werden kann.
01.10.18;11.03.19;2019;intern;Bachelor;DE;Effektivität der Wissensvermittlung durch Chatbot und FAQ im Vergleich;
01.10.18;27.05.19;2019;extern;Master;DE;Digitale Assistenten und Sprachdialogsysteme im Unternehmen - eine Analyse am Beispiel Amazon Echo mit Schwerpunkt Nutzung in der Qualitätssicherung;Im Rahmen der Arbeit wurde ein Prototyp für einen Alexa-Skill konzipiert und implementiert. Schwerpunkt bei der Entwicklung war es, möglichst kurze und einfache Dialoge mit Alexa zu bieten, um Informationen aus einer Datenbank zu Schadensfällen zu finden. Die Ergebnisse können dem Nutzer sowohl vorgelsesen werden, als auch in Textform auf ein kompatibles Gerät gesendet werden. Im Zuge dessen ist Alexa mit Konkurrenzprodukten verglichen worden, auf seine Tauglichkeit in verschiedenen Umgebungen getestet worden und es wurden verschiedene Möglichkeiten zu einer Implementierung betrachtet. Aus den gebotenen Alternativen wurden die am passendsten wirkenden gewählt und ein Skill entwickelt, der auf den Diensten von AWS aufbaut und in NodeJS geschrieben ist. Potentielle Schwierigkeiten bei der Erstellung eines Interaktionsschemas und beim Datenschutz wurden identifiziert und Lösungsmöglichkeiten vorgestellt. Für die Konzeption und Implementierung wurde ein empirisches Vorgehen gewählt, um eine möglichst zufriedenstellende Lösung zu erreichen. Die Qualität des Prototyps konnte nicht in einer Nutzerstudie getestet werden. Gründe dafür waren technische Probleme, die außerhalb des Einflusses des Projektteams lagen, sowie zeitliche Gründe um alternative Lösungen für eine Studie zu finden. Insgesamt konnten die meisten der Anforderungen zufriedenstellend erfüllt werden, besonders für Datenschutz und Zugriffskontrolle müsste Alexa for Business verwendet werden (in D noch nicht verfügbar).
02.10.18;02.03.19;2019;intern;Bachelor;DE;Interaktive Visualisierung des Netzwerkgraphen einer Pattern Language für Spiel-Design-Elemente;Das Forschungsprojekt EMPAMOS setzt sich mit motivierenden Spielelementen in Gesellschaftsspielen auseinander, die immer wieder in bestimmten Zusammenhängen und Kombinationen zum Einsatz kommen. Meine Arbeit beschäftigt sich mit der graphischen Aufbereitung dieser Spielelemente. Dabei wird die Frage verfolgt, welche Art der Darstellung und Interaktion dem Nutzer den effektivsten Einblick in die Spielelemente gibt. So stand im Mittelpunkt, den Zusammenhang zwischen den wissenschaftlichen Forschungsergebnissen und dem theoretischen Bereich der Gesellschaftsspiele zu verdeutlichen. Dazu wurde zunächst eine Stakeholder- und Zielgruppenanalyse durchgeführt und unter anderem das Spielearchiv befragt. Im Rahmen der Anforderungsermittlung konnten dann aus Personas und daraus resultierenden User-Stories Erwartungen an die Anwendung generiert werden. In der Phase der Anwendungskonzeption wurden dann die Anforderungen aller Stakeholder zusammengetragen und daraus eine graphische Benutzeroberfläche konzipiert. Die Forschungsergebnisse des EMPAMOS-Projektes wurden anschließend mit Hilfe von verschiedenen Frameworks in Form einer Netzwerkstruktur visualisiert und in die Anwendung integriert. Daraufhin konnte ein Prototype entwickelt werden, der per REST-Schnittstelle auf die Daten des Forschungsprojektes zugreift. Abschließend wurde die Anwendung per Usability-Test validiert, um Optimierungen für die nächste Iteration festzuhalten und im letzten Schritt auf einem Tablet installiert.
04.10.18;01.03.19;2019;extern;Bachelor;DE;Untersuchung und Bewertung von Anwendungsfällen im Bereich Augmented Reality zur Unterstützung der Fahrzeugdiagnose und beispielhafte prototypische Implementierung<br>;Bei der Fahrzeugdiagnose werden mithilfe von Softwarewerkzeugen u.a. Prüfabläufe erstellt, validiert und schließlich ausgeführt. Diese unterstützen den Werker bei der Ausführung verschiedener Arbeitsschritte z. B. durch An-zeige von relevanten Informationen. Geeignete Augmented Reality Brillen könnten den Arbeitsprozess des Werkers unterstützen, indem sie die Mensch-Maschinen-Interaktion erleichtern. Durch die integrierten Kameras und inno-vativen Projektionsmöglichkeiten ist ein Zugriff auf benötigte Informationen möglich, ohne den aktuellen Arbeitsfluss zu unterbrechen. <br><br>Als Beispiel für ein Fahrzeugdiagnose-Werkzeug wird das SIEMENS Produkt SIDIS Pro verwendet. Im Kontext von SIDIS Pro werden sinnvolle Unterstüt-zungsmöglichkeiten für die Werker ermittelt, ausführlich betrachtet und bewer-tet. Für eine industrietaugliche Augmented Reality Brille wird das relevanteste Anwendungsszenario prototypisch umgesetzt.<br>
09.10.18;28.02.19;2019;extern;Bachelor;DE;Konzeption und Realisierung eines Dashboards für Reiseveranstalter;"Das Ziel der vorliegenden Bachelorarbeit ist es, ein Dashboard auf Basis des Reservierungssystems eines Reiseveranstalters zu konzipieren und realisieren. Die Problemstellung besteht darin, dass die Vorgangsdatensätze für das Controlling über eine Schnittstelle exportiert und die Daten dabei komprimiert werden, sodass das Controlling auf der Ebene einer Reise mit allen Reisedetails nicht mehr möglich ist. Das Ziel des Dashboards ist es, eine kaufmännische Auswertung der operativen Daten unter Einbezug aller Details möglich zu machen.<br>Dabei standen die drei zentralen Fragen im Vordergrund:<br>?	Welche kaufmännischen Kennzahlen gibt es bei Reiseveranstaltern und welche sind relevant?<br>?	Wie können diese Kennzahlen technisch in ein Dashboard eingebunden werden?<br>?	Wie erstellt man konzeptionell und visuell ein praktikables Dashboard?<br>Die Kennzahlen wurden in der Konzeptionsphase gefunden und betrachtet. Es wurde die Frage bezüglich der Umsetzung in der Realisationsphase beantwortet. Die Grundstruktur des Dashboards wurde im Konzeptionskapitel dargelegt und die visuelle Gestaltung im Realisationskapitel abgehandelt. Es wurde ein praktikables Dashboard erstellt, das ein Vertriebsprototyp ist und kein fertiges Produkt repräsentiert.<br>"
10.10.18;25.01.19;2019;extern;Bachelor;DE;Konzeption und Implementierung eines Prozessablaufes für die Einführung und Migration einer ERP-Software bei kleinen und mittelständischen Unternehmen;Die Vepos GmbH \& Co. KG ist ein ERP-Anbieter für den Handel, das Projektmanagement und den Service. Bei der Einführung eines ERP-Systems in kleinen und mittleren Unternehmen wird im Vorfeld ein Analyse-Workshop durchgeführt, in dem die Soll-Prozesse des Kunden und eventuell nötige Anpassungen an der Software aufgenommen werden. Ziel dieser Arbeit ist es, Software-Referenzmodelle zu entwickeln, anhand derer Abweichungen vom Standard dokumentiert werden können. Eine Prozessaufnahme soll durch die Veranschaulichung mittels BPMN-Modellen und eine Darstellung in Excel erleichtert werden. Abweichungen vom Standard werden festgehalten und dem Kunden zur Verfügung gestellt. Diese Dokumentation dient im weiteren Verlauf als Grundlage für kundenspezifische Tests bei Updates und dazu passende Schulungen. Hierzu wurden die Standardprozesse der Software ermittelt und als Referenzmodelle mit begleitender Excel-Tabelle erfasst. Im Rahmen eines prototypischen Workshops bei einem Bestandskunden wurde das neue Konzept getestet und anschließend die Ergebnisse evaluiert.
10.10.18;10.03.19;2019;intern;Bachelor;DE;Durchführung von und Schutz vor Angriffen auf das YOLO Objekterkennungssystem mit einem Trojan Trigger;Diese Bachelorarbeit befasst sich mit dem Thema der Durchführung eines Angriffs auf ein Objekterkennungssystem und des Erstellens eines Schutzes gegen derartige Angriffe. Nach der Schilderung der Problemstellung, der Vorstellung der Motivation und der Zielsetzung sowie der Präsentation der Vorgehensweise und der Ergebnisse wird ein kurzer Überblick über die Grundlagen der neuronalen Netze vorgestellt. Anschließend werden das YOLO Objekterkennungssystem sowie der Trojan Trigger vorgestellt und ausführlich beschrieben. Nach der Präsentation Anforderungen wird eine Einführung in die Entwicklung eines Entwurfs des Angriffs sowie in die Analyse der möglichen Schutzvorkehrungen gegeben. Zudem wird auf die Analyse der Entwicklungsrisiken, die Inbetriebnahme des  YOLO Objekterkennungssystem, die Beschreibung der Anforderungen und der Bestandteile des Angriffs sowie die Erarbeitung der Abwehrmethoden näher eingegangen. Danach werden die Phasen der Angriffsdurchführung und die Implementierung des Schutzprogramms ausführlich erklärt. Anschließend werden die Implementierung eines entsprechenden Schutzes und die Anwendung der Abwehrmethode beschrieben. Hiernach wird die Durchführung der Tests geschildert und analysiert. Abschließend wird aus der Analyse der Ergebnisse ein Fazit gezogen, wobei eine persönliche Bewertung abgegeben und ein Ausblick präsentiert werden.
10.10.18;10.03.19;2019;extern;Bachelor;DE;Analyse und Weiterentwicklung von Metriken der Softwarequalität bei der Schema Gruppe;In dieser Arbeit werden nach der Identifikation und Analyse vorhandener Metriken der Schema Gruppe zur Softwarequalität, weitere Metriken hinsichtlich der bekannten Problemfelder ermittelt. Da zum Zeitpunkt der Bearbeitung eine Auswertung der Codemetriken nicht möglich war und an erster Stelle Produktmetriken ermittelt werden sollen, wurde der Fokus auf Fehler- sowie Testmetriken gesetzt. Die Ermittlung der Metriken erfolgt anhand der Top-down und Bottom-Up Ansätze. Beim Top-Down Ansatz wird die Literatur als Hilfestellung hergenommen. Anfangs werden hierzu Ziele in Bezug zur Softwarequalität formuliert. Da nicht alle Ziele analysiert werden können, und die vorhandenen Metriken sich weitestgehend auf die Zuverlässigkeit beziehen wurde der Fokus auf das Ziel der Verbesserung der Zuverlässigkeit gesetzt. Ausgesehen von diesem Ziel werden Fragestellungen abgeleitet und mit Metriken in Verbindung gesetzt. Da für die ermittelten Metriken kein Datenbestand vorliegt, wird das weitere Vorgehen mit dem Bottom-Up Ansatz ergänzt. Dazu werden anhand des vorliegenden Datenbestandes Annahmen getroffen und eine Datenauswertung durchgeführt. Die Auswertung des Datenbestandes ermöglicht es neue Metriken zu ermitteln, die zuvor durch die Top-Down Methode nicht in Betracht gezogen bzw. abgeleitet wurden. Insgesamt konnten durch beide Ansätze neue Erkenntnisse und Metriken generiert werden. 
10.10.18;07.03.19;2019;intern;Bachelor;DE;Entwicklung und Bewertung von automatisierten Unit-Tests im SAP-Umfeld der Dematic GmbH;Das Ziel dieser Arbeit ist es zu ermitteln, ob sich eine Einführung von Testautomatisierung im Bereich der Unit-Tests in der SAP-Abteilung der Dematic GmbH effizienter und zugleich effektiver auf den Testprozess auswirken könnte. Dabei stellen sich Fragen wie, welchen Anforderungen müssen die zu testenden Objekte entsprechen um mithilfe der Unit-Tests prüfbar zu sein, was für Kosten treten durch den aufkommenden Aufwand in der Testerstellung und -durchführung auf sowie ob ein Mehrwert durch eine Testautomatisierung erreichbar ist.  <br>Um auf all diese Fragen eine entsprechende Antwort zu bekommen, wurde eine Kosten-Nutzen-Analyse durchgeführt, die durch das Gegenüberstellen des IST-Zustands zum gewünschten SOLL-Zustand eine repräsentative Rückmeldung wiedergibt. Dabei konnte das Ergebnis ermittelt werden, dass eine Testautomatisierung von Unit-Tests einige Vorteile mit sich bringt. Außerdem ist aufgrund der Bewertung erkennbar, dass ab einer geringen Anzahl von Testdurchführungen die Kosten bei den Unit-Tests geringer ausfallen, als bei der manuellen Testdurchführung. Beachtet werden muss nur, dass dies nicht für alle zu testenden Objekte gilt und bestimmte Gegebenheiten herrschen müssen, um Unit-Tests realisieren und automatisieren zu können. <br>Zusammenfassend ergab sich das Ergebnis, dass eine Testdurchführung mittels der Test-Tools und den Frameworks empfehlenswert ist. Dies lässt sich durch die gewonnenen Erkenntnisse, Vorteile sowie der möglichen Kosteneinsparung begründen.
11.10.18;11.03.19;2019;extern;Bachelor;DE;Zukunft des Berechtigungsmanagements der DATEV eG mit Fokus auf der Ermöglichung von agilem Arbeiten;Zukünftig plant die DATEV eG verstärkt auf agile Methoden zu setzen. Für die Zentrale Rechteverwaltung im Unternehmen stellt diese sukzessive Umstellung vor allem für die Elemente des Berechtigungsmanagement, Rechteprüfung und Rechteverwaltung eine Herausforderung dar. Die Anwendung von agilen Methoden, hat Auswirkungen auf bestehende Organisationsstrukturen und somit auf die damit verbundenen Verantwortlichkeiten. Nach aktuell praktizierten Verfahrensweisen müssen die Mitarbeiter ihre Berechtigungen über den, von der Zentralen Rechteverwaltung angebotenen Selfservice des Rechtestammblatts bestätigen. Abschließend muss die Führungskraft die bestätigten Rechte für seine Mitarbeiter zertifizieren. Diese Führungskraft kann ebenfalls die bestehenden Berechtigungen seiner Mitarbeiter verwalten. Ursprünglich lag die fachliche und disziplinarische Verantwortung bei der Führungskraft, die die Rechte zertifizieren und verwalten konnte. <br>Bei der Anwendung von agilen Methoden verliert die Führungskraft die inhaltliche und fachliche Führung. Diese Führung steht im engen Zusammenhang zu Berechtigungen. Die Beurteilung von Berechtigungen durch die Führungskraft, wird daher erschwert. In dieser Arbeit werden Lösungsansätze vorgestellt, welche eine sinnvolle Rechteprüfung und -verwaltung beim agilen Arbeiten ermöglichen sollen. Die Lösungsansätze werden anhand einer Nutzwertanalyse gegenübergestellt und die daraus erlangten Erkenntnisse zu einem Soll-Konzept zusammengefasst.<br>
11.10.18;05.03.19;2019;extern;Bachelor;DE;Konzeption und prototypische Realisierung eines Kennzahlensystems für das Prozessmanagement eines IT-Dienstleisters in der Bankenbranche;Partnerunternehmen ist der zentrale IT-Dienstleister der Sparda-Banken, die Sparda-Datenverarbeitung eG (SDV-IT). Das Thema der Arbeit ist unternehmensintern im Vorstandsstab angesiedelt. Zu den Hauptschwerpunkten dieser Stabstelle gehört unteranderem das unternehmensweite Prozessmanagement. Um die darin verankerte Steuerung und Kontrolle der Prozesse vorzunehmen, bedarf es funktionierender Reporting-Mechanismen. Jedoch sind in der SDV-IT verwendeten Verfahren des Prozesscontrollings sehr schwerfällig, da lediglich individuell von Fachbereichen sporadisch Auswertungen vorgenommen werden. Zielsetzung der Arbeit ist es, ein zentrales Kennzahlensystem einzuführen, welches möglichst standardisierte und automatisierte Reporting-Verfahren nutzt, um aussagekräftige Prozesskennzahlen zu erheben.
12.10.18;01.02.19;2019;intern;Bachelor;DE;Agile Transformation - Outsourcing agiler Projektarbeit und dessen Einfluss auf das klassische Projektmanagement;Agile Transformation - Outsourcing agiler Projektarbeit und dessen Einfluss auf das klassische Projektmanagement<br><br>In dieser Abschlussarbeit wird sich mit dem Vergleich zwischen klassischem und agilem Vorgehen in einem Outsourcing auseinandergesetzt. <br>Eine neue Zeit mit neuen Anforderungen und Herausforderungen erfordert neue Herangehensweisen an bekannte Systeme. <br>Daher werden zunächst die die Ausgangssituation erläutert sowie die agilen und die klassischen Modelle vorgestellt.<br>Im Folgenden werden agile und klassische Ansätze verglichen, wobei Unterschiede sowie Vor- und Nachteile herausgearbeitet werden. <br>Im Kern der Arbeit geht es darum zu identifizieren, ob ein agiles Vorgehen bei Outsourcing, Vorteile gegenüber einem klassischen Vorgehen bietet. <br>Hierbei wird geklärt welche Outsourcingarten bei einem agilen Vorgehen praktikabel sind, inwiefern die agilen Werte Einfluss auf das Projekt haben und wie solche Projekte organisiert werden. Ebenfalls wird erläutert, welche Motive für ein agiles Outsourcing sprechen können und wie bei größeren Projekten vorzugehen ist. <br>Des Weiteren werden Empfehlungen für eine Strategiegestaltung, Providermanagement, Changemanagement und andere wichtige Faktoren besprochen. <br>Zuletzt wird auf die Auswirkungen von Agilität und Outsourcing auf das klassische Projektmanagement eingegangen. <br>
15.10.18;15.06.19;2019;intern;Master;DE;"Unauffällige Anonymisierung von Gesichtern in Bildern mit ""Generative Adversarial Networks""";"Die stetig voranschreitende Speicherung und Auswertung digitaler Bilder stellt für die Privatsphäre jedes Einzelnen eine immer größere Bedrohung da. Bisherige Technologien zur Anonymisierung von Gesichtern sind entweder nicht mehr effektiv oder führen zu starken Veränderungen der ursprünglichen Aufnahmen. Durch den Einsatz von ""Generative Adversarial Networks"" zur Anonymisierung von Gesichtern sind hingegen Techniken umsetzbar, die eine unauffällige Anonymisierung erlauben. Es werden zwei Konzepte zur Umsetzung dieser erarbeitet. Ein bestehendes Gesicht wird dabei entweder in eine anonymisierte Fassung transformiert oder durch ein künstliches Gesicht ersetzt.<br>Bei der Anwendung dieser beiden Konzepte auf ausgewählte Stichproben wird die Identifizierung einer Person merklich erschwert und meist unmöglich gemacht. Die erfolgte Manipulation der Gesichter bleibt im Vergleich zu bisherigen Techniken weitgehend verborgen. Dabei noch bestehende Herausforderungen und zukünftige Lösungsmöglichkeiten werden abschließend diskutiert."
15.10.18;15.03.19;2019;intern;Bachelor;DE;Evaluierung der Microsoft Azure Cloud Services im Kontext von Lehre, Forschung und Hochschulmanagement an der Technischen Hochschule Nürnberg;Ziel der vorliegenden Bachelorarbeit war es zu untersuchen, welche datenschutzrechtlichen Herausforderungen der Einsatz von Cloud Services in den Bereichen Lehre, Forschung und Hochschulmanagement mit sich bringt, welche Maßnahmen notwendig sind, um Azure Cloud Services an einer Hochschule einzuführen und welche Cloud Services das IT-Serviceportfolio der Technischen Hochschule Nürnberg sinnvoll ergänzen können und sich gut für ein Pilotprojekt eignen. Das Ergebnis der Arbeit ist eine Verfahrensbeschreibung über den Bezug von Azure Cloud Services über den Deutschen Forschungsnetz-Verein. Darüber hinaus wird beschrieben, welche kontextabhängigen Maßnahmen für den Einsatz von Cloud Services im Bereich Lehre, Forschung und Hochschulmanagement durchgeführt werden müssen. Im Rahmen von Interviews und Workshops mit Professoren der Technischen Hochschule Nürnberg wurden mehrere User Stories für mögliche Einsatzgebiete der Cloud Services erarbeitet, aus welchen zwei für die Umsetzung in einem Pilotprojekt ausgewählt wurden. Abschließend werden die vorbereitenden Schritte zur Umsetzung der Services innerhalb des Pilotprojekts skizziert.<br>Die Arbeit ist für alle diejenigen interessant, die Cloud Services in Hochschulen oder Universitäten etablieren möchten.
15.10.18;14.03.19;2019;intern;Bachelor;DE;Requirement Engineering für den Einsatz eines CRM Systems für die Hochschulbeziehungen zu kooperierenden Unternehmen und Alumni an der Fakultät Informatik und prototypische Umsetzung anhand einer geeigneten Software.;Das Ziel dieser Arbeit ist die Identifizierung und Optimierung von Customer-<br>Relationship-Management-Aktivitäten zur Beziehungspflege mit<br>Unternehmenskooperationen und Alumni an der Fakultät Informatik. Dazu<br>erfolgen eine Ermittlung und Analyse der Anforderungen für ein mögliches<br>Customer-Relationship-Management-System, welches hierfür zum Einsatz<br>kommen soll. Im Rahmen eines Requirements Engineerings werden die<br>bestehenden CRM-Tätigkeiten analysiert und zusammen mit den Stakeholdern<br>bewertet, um daraus Produktanforderungen für das geplante System abzuleiten.<br>Die Ermittelten und dokumentierten Anforderungen werden im Anschluss in<br>einem CRM-System prototypisch umgesetzt.
15.10.18;05.04.19;2019;extern;Master;DE;CNN-basierte Objekterkennung in Echzeit mit einem Smartphone;Inhalt der Arbeit ist die Analyse von CNN-basierten Applikationen sowie die Implementierung eines Prototyps zur Objekterkennung in Echtzeit. Der Prototyp wird umfassend hinsichtlich notwendiger Komponenten, Funktionsweise und Umsetzung beschrieben. Er wird für die Plattform Android entwickelt und verwendet das Framework TensorFlow Lite, sowie ein vortrainiertes Modell basierend auf dem Single Shot MultiBox Detector (SSD) Algorithmus. Ziel ist eine Anwendung, die Objekte in Echtzeit erkennt und entsprechend mit einem Label und einem Rahmen markiert. Darüber hinaus werden bestehende kommerzielle Anwendungen untersucht und mit den Ergebnissen des Prototyps verglichen.<br>In Kapitel 2 wird die Geschichte der Objekterkennung beschrieben und Herausforderungen, sowie wichtige Zusammenhänge der CNN-basierten Objekterkennung erläutert. Kapitel 3 beschäftigt sich mit der umfassenden Beschreibung der Funktionsweise neuronaler Netze und zeigt die wichtigsten Algorithmen zur Objektlokalisierung im Überblick. Kapitel 4 befasst sich mit Anforderungen an Smartphones, Herausforderungen der Applikationen und gibt einen Überblick über geeignete CNN-basierte Modelle für Smartphones. In Kapitel 5 werden bestehende Applikationen für die Plattformen Android und iOS getestet und mit dem in Kapitel 6 entwickelten Prototyp verglichen. Ein abschließendes Fazit gibt einen Überblick über die erzielten Ergebnisse und gibt einen Ausblick auf weitere Implementierungsmöglichkeiten.<br><br>
16.10.18;14.03.19;2019;intern;Bachelor;DE;Identifikation und Evaluation von relevanten Parametern bei der Fortbewegung in einer virtuellen Umgebung;In einer Benutzerstudie soll eine realistische und angenehme Fortbewegung in VR untersucht werden und welchen Einfluss zuvor definierte Parameter wie z. B. Schrittlänge, Laufge-schwindigkeit oder Winkeltreue zwischen Blick- und Laufrichtung darauf haben.<br><br>Das Ziel dieser Arbeit ist die Identifikation und Evaluation von relevanten Parametern bei der Fortbewegung in einer virtuellen Umgebung. Hierbei wird sich auf die gewohnte Fortbewegungsart des Menschen ? das Laufen ? als auch auf die Verwendung von Hilfsmitteln wie Controller beschränkt. Die gewonnenen Ergebnisse aus der Benutzerstudie sollen unterstützend eine Aussage darüber treffen, welche Fortbewegungsmethode den besten Kompromiss aus geistiger, körperlicher und zeitlicher Anforderung für den Benutzer bietet.<br><br>Die Messergebnisse zeigen, dass die Fortbewegungsart ausschließlich mittels Controller effizienter als der Einsatz einer Tretmühle ist. Hingegen liefert die Kombination von einem Controller und einer Tretmühle sowohl bei der Testlaufzeit, der Laufgeschwindigkeit als auch bei den Bewertungen durch die Probanden die besten Ergebnisse. Somit stellt diese nicht-natürliche Fortbewegungsart den besten Kompromiss aus den gewählten Anforderungen gegenüber der semi-natürlichen Fortbewegungsart mit der Tretmühle dar.<br><br>
19.10.18;04.02.19;2019;extern;Bachelor;DE;Konzeption und Entwicklung einer generischen Leerbehälterverwaltung für SAP-EWM-Systeme;In den meisten Softwareprojekten, die mit SAP-EWM realisiert werden, spielt der automatische Materialfluss (MFS) innerhalb eines Lagers eine zentrale Rolle. Ein Teilbereich des MFS behandelt die Verwaltung von leeren Transporteinheiten. Da leere Transporteinheiten über das Lager verteilt benötigt werden, ist Aufwand an Zeit und Ressourcen notwendig, um auftretende Bedarfe optimiert auszugleichen. Derzeit werden diese Anforderungen in projektspezifischen Lösungen umgesetzt. Das Ziel dieser Abschlussarbeit ist es, eine Leerbehälterverwaltung zu entwickeln, die generische Schnittstellen aufweist und sich so als eigenes SAP-Modul für verschiedene Lagerkonstellationen verwenden lässt. Über die implementierten Schnittstellen soll die Möglichkeit bestehen, benutzerdefinierte Algorithmen zur Laufzeit der Anwendung einzubinden. Die Ermittlung der Leerbehälter soll dabei auf Basis unterschiedlicher Auswahlstrategien erfolgen. Die Anforderungen an die zu entwickelnde Software ergaben sich durch Analyse eines Referenzsystems. Die einzelnen Komponenten der Leerbehälterverwaltung sind unabhängig voneinander einsetzbar. Konfigurationsmöglichkeiten sind an zentraler Stelle durch eigens dafür angelegte Datenbanktabellen gegeben. Die derzeitige Ausführung der Software bietet bereits Algorithmen zur Bedarfsermittlung, Depotauswahl, Leerbehälter-Ermittlung und für den Transport der Behälter. Die entwickelte Software wurde im Rahmen eines Kundenprojektes getestet und die Ergebnisse evaluiert.
23.10.18;14.03.19;2019;intern;Bachelor;DE;Evaluation von GraphQL als Alternative zum RESTful-API-Design;Das Ziel dieser Bachelorarbeit ist die Evaluation von GraphQL als Alternative zum RESTful-API-Design. GraphQL ist eine 2012 von Facebook entwickelte Abfragesprache, Spezifikation und Sammlung von Werkzeugen, welche den Betrieb eines einzelnen HTTP-Endpunkts ermöglicht, um Leistung und Flexibilität von Client-Server-Anwendungen zu optimieren. Zuerst soll ein Überblick über GraphQL-Werkzeuge und das Umfeld geboten werden. Wichtige Aspekte für Entwicklung von Web-APIs wie Dokumentation, Sicherheit und Caching sollen für GraphQL betrachtet, mit bestehenden Lösungen im RESTful-API-Design verglichen und bewertet werden. Anschließend soll an einer beispielhaften RESTful-API-Implementierung aufgezeigt werden, wie die Stärken von GraphQL genutzt werden können. Dabei kommt zum einen die Durchführung einer Migration in Betracht, zum anderen, wie man eine hybride Lösung finden kann, bei der REST und GraphQL nebeneinander verwendet werden können. 
24.10.18;24.03.19;2019;extern;Bachelor;DE;Analyse, Konzeption und Realisierung einer unternehmensweiten Application-Performance-Monitoring-Lösung am Beispiel des Produkts Ratenkauf der TeamBank AG;Die zunehmende Digitalisierung unserer Zeit spiegelt sich in Unternehmen wie der TeamBank AG vor allem im organischen Wachstum heterogener IT-Landschaften wider. Abhängig ihrer Kritikalität für eine Organisation, müssen die Systeme der IT-Landschaften höchste Sicherheits-, Stabilitäts- und Verfügbarkeitsanforderungen erfüllen. Um diesen Anforderungen gerecht zu werden, ist das traditionelle Monitoring als Vorkehrungsmaßnahme um ein Werkzeug zur Einbeziehung des Nutzererlebnisses für Endanwender zu ergänzen. Kernaufgabe dieser Bachelorarbeit ist demnach die Analyse und Konzeption einer unternehmensweiten Application-Performance-Monitoring-Lösung, die am Beispiel der Anwendung für das Produkt Ratenkauf der TeamBank realisiert werden soll. Der Fokus soll dabei primär auf der Überwachung von Performance auf Basis der Entwicklung von technischen und fachlichen Metriken im Zeitverlauf liegen. Im Rahmen dieser Arbeit wird aufgezeigt, welche Infrastrukturkomponenten für das Application-Performance-Monitoring (APM) benötigt werden und wie die Architektur für den Betrieb der APM-Lösung aussieht. Außerdem erfolgt ein Vergleich und die anschließende Auswahl der für das APM einzusetzenden Technologien. Im Kontext des Produkts Ratenkauf werden zudem die technischen und fachlichen Metriken herausgestellt und deren Visualisierung in Dashboards dargestellt.
29.10.18;29.03.19;2019;intern;Bachelor;DE;Anwendung einer Gamification-Mustersprache auf gamifizierte mobile Foodtracking-Applikationen zur Verbesserung der motivationalen Wirkung;"Das Ziel der Bachelorarbeit ist es, motivationale Probleme, welche bei bereits gamifizierten Anwendungen bestehen, zu identifizieren und die Anwendbarkeit der Gamification-Mustersprache aus dem Forschungsprojekt ""Empirische Analyse motivierender Spielelemente zur Entwicklung einer Gamification-Mustersprache"" auf die Analyse und Lösung von konkreten Problemstellungen in der Praxis zu überprüfen. Hierzu sollen gamifizierte Foodtracking-Applikationen hinsichtlich ihrer motivationaler Probleme analysiert werden, indem der bisherige motivationale Erfolg anhand Sekundärquellen und nach Kriterien zur Einschätzung der motivationalen Wirkung von Anwendungen aus der Fachliteratur bewertet wird. Im Anschluss sollen spezifische Spiel-Design-Elemente basierend auf der Mustersprache des EMPAMOS-Projekts zu Lösung der Probleme ausgewählt und die Eignung des aktuellen Entwicklungsstands der Mustersprache für diese Art von Aufgaben bewertet werden."
31.10.18;31.03.19;2019;extern;Bachelor;DE;Konzeption und Implementierung eines Ranking-Algorithmus für die Suche mit einem Case-Based-Reasoning-Ansatz und Kreuzvalidierung unterschiedlicher Ergebnismengen ;Ziel der Arbeit ist die Konzeption und Implementierung eines Ranking-Algorithmus für die Suche mit einem Case-Based-Reasoning-Ansatz sowie die Konzeption und Implementierung einer geeigneten Teststrecke. Die Ergebnisse eines Testlaufs ermöglichen Aussagen über die Qualität der Case-Based-Reasoning-Suche und den Erfolg der Migration auf eine neue Suchmaschinentechnologie. <br>In der Ist-Analyse wird sowohl der technologische Aufbau der Suchmaschine, als auch die einzelnen Verarbeitungsschritte einer Suchanfrage näher untersucht. <br>Bei der Konzeption des Ranking-Algorithmus ist der Aufbau der zweiten Suchanfrage und die Berechnung des Relevanzwertes eines Dokuments hervorzuheben. Für die Verwendung der Teststrecke hat sich die Leave-One-Out-Kreuzvalidierung als bestes Verfahren herausge-stellt. Als Kennzahl zur Bewertung werden der Mean-Average-Precision und der Normalized-Discounted-Cumulative-Gain verwendet. <br>Die Implementierung orientiert sich ebenfalls an der Zweiteilung zwischen Ranking-Algorithmus und Umsetzung der Teststrecke. Dabei wird auf gängige Design-Patterns in der objektorientierten Softwareentwicklung eingegangen und die Besonderheiten des Systems beschrieben. <br>Zentrale Erkenntnisse aus der Analyse sind die Notwendigkeit eines zweistufigen Suchprozes-ses aufgrund der Beschaffenheit der Fallbasis. Auch die Wichtigkeit eines möglichst präzisen Relevanzwertes bei der Ermittlung ähnlicher Problembeschreibungen, hat sich als kritischer Faktor herausgestellt.
01.11.18;01.04.19;2019;extern;Bachelor;DE;Konzeption, Entwicklung und Integration eines Animations-Tools für die grafische Annotation von Videos in einem Grafikzeichenprogramm;Diese Arbeit zielt darauf ab, ein Animations-Tool in das bestehende Grafikzeichenprogramm der SCHEMA Gruppe zu integrieren. Dieses Tool soll Technischen Redakteuren bei der Erstellung von Videos mit grafischen Annotationen unterstützen. Im Laufe der Arbeit werden zunächst die Potentiale von Videos in der Technischen Dokumentation erläutert. So sind vor allem Videos ohne Tonspur eine geeignete Erweiterung zur klassischen textuellen Dokumentation. Eine Analyse von verschiedenen Video- und Animations-Tools dient einer ersten Übersicht, welchen Anforderungen das Animations-Tool gerecht werden muss. Für die Integration wird weiter das Grafikzeichenprogramm hinsichtlich seiner Technologie untersucht. Neben zusätzlich definierten Benutzeranforderungen bilden diese Ergebnisse die Kriterien für die anschließende Konzeptentwicklung. <br>Ferner werden zwei Integrationskonzepte ausgearbeitet und durch eine prototypische Umsetzung vorgestellt.<br>Auch ein möglicher Export des Videos mit den animierten Annotationen wird untersucht. Den Ergebnissen zufolge lässt sich die Integration eines Animations-Tools in das bestehende Grafikzeichenprogramm durchführen. Die Einbettung eines Chromium-Webbrowsers ist hierfür ein vielversprechendes Konzept. Die Ausgabestrecke erfolgt mittels SVG und CSS-Animationen innerhalb einer HTML-Datei. Mit Hilfe der Ergebnisse dieser Arbeit kann eine Weiterentwicklung des Animations-Tools im Grafikzeichenprogramm für ein zukünftiges Produkt Release erfolgen.
01.11.18;01.04.19;2019;extern;Bachelor;DE;Erarbeitung und Bewertung von Vorgehensweisen zur Integration der vollständigen Jobrolle Test Engineer in ein agiles Team;Zur Steigerung der Qualität von Softwareprodukten, wurde in der DATEV eG die neue Jobrolle Test Engineer definiert. Ziel dieser Arbeit ist es für die DATEV eG eine Empfehlung zu erarbeiten, die aussagt, welche Vorgehensweise zur Integration der vollständigen Jobrolle Test Engineer in ein agiles Team verwendet werden sollte. Integration ist dabei mit dem Erwerb und Ausbau von Skills, die ein Mitarbeiter benötigt, um die Jobrolle Test Engineer in seinem Team übernehmen zu können, gleichzusetzen. Denn damit diese vollständig in ein Team integriert werden kann, muss sich mindestens ein Mitarbeiter dieses Teams, die dazu notwendigen Skills aneignen bzw. seine vorhandenen Skills ausbauen. Die vorliegende Bachelorarbeit betrachtet die folgenden vier Vorgehensweisen zum Erwerb und Ausbau von Skills: Gamification, Schulung, Pairing und Rapid Skill Acquisition. Die Empfehlung sollte unter Beachtung der Rahmenbedingungen und des Arbeitsumfeldes erfolgen. Hierzu wurden die vier Vorgehensweisen analysiert und das Meinungsbild bezüglich dieser von den Mitarbeitern ermittelt. Als Basis für die Evaluation wurde jeweils eine sechsstufige Likert-Skala gewählt, um die persönliche Meinung der Mitarbeiter gegenüber den Untersuchungsobjekten einordnen zu können. Zusätzlich wird die Pilotierung einer Vorgehensweise durchgeführt.
01.11.18;01.07.19;2019;intern;Master;DE;Die Umsetzung und Evaluierung einer kollaborativen VR-Anwendung für blinde Menschen;Blinde Menschen sind im Alltag mit vielen Hürden konfrontiert, die für sehende Menschen nicht relevant sind. Neue Wege zur Arbeit oder tägliche Besorgungen können zu unüberwindbaren Aufgaben werden. Deshalb werden diese Wege und der Umgang mit Hilfsmittel für die Orientierung mit sogenannten Rehabilitationstrainern trainiert, deren Verfügbarkeit leider sehr gering ist.<br>Aufgrund von neuen technologischen Möglichkeiten, soll in dieser Masterarbeit ein kollaboratives, virtuelles Training für blinde Menschen entwickelt und evaluiert werden. Ein Hauptaugenmerk liegt dabei auf dem kollaborativen Anteil, der durch die Hilfestellung zwischen Trainer und Lernenden repräsentiert wird. Daraufhin ist eine Unity-Anwendung entstanden, in der das Begehen einer virtuellen Welt mit bidirektionaler Kommunikation nach außen möglich ist. Somit kann sich der Trainer über seinen PC oder mobil über das Smartphone einwählen und kollaborative Hilfestellung leisten.<br>Diese Anwendung ist anschließend im Rahmen einer Vorstudie mit sehenden Menschen, unter dem Gesichtspunkt des positiven Effektes von Kollaboration, evaluiert worden.<br>Für eine Kohärenz zu blinden Menschen wird den sehenden Probanden, virtuell die Augen verbunden. Anhand von Kriterien zu Zeit, Wegstrecke, mentale Belastung und Usability ist die Anwendung mit zehn Probanden untersucht worden.<br>Die erhaltenen Testergebnisse zeigten einen signifikanten Unterschied für die Bedingung mit kollaborativer Hilfestellung zur Bedingung ohne Hilfe.
05.11.18;10.05.19;2019;intern;Bachelor;DE;DNA als Speichermedium für textuelle Informationen<br>Codierungsmethoden und experimentelle Ansätze ;Aufgrund des exponentiellen Wachstums aller weltweit erzeugten Daten, steigt der Bedarf an einem Speichermedium mit hoher Speicherkapazität, hoher Speicherdichte und langer Lebensdauer. Die DNA erweist sich als ein potenzielles Medium zur Datenspeicherung. Das Ziel dieser Bachelorarbeit ist, die bereits angewandten Codierungsmethoden für textuelle Informationen auf DNA (Desoxyribonucleinsäure) genauer darzustellen und zu analysieren, ob die DNA als Medium zur Datenspeicherung geeignet ist. Außerdem soll ein Überblick über die experimentellen Ansätze gegeben werden.  <br>Bevor die Codierungsmethoden erläutert werden, werden die theoretischen Grundlagen aufgeführt, um eine angemessene Einführung in das Thema zu erhalten<br>
09.11.18;09.04.19;2019;intern;Bachelor;DE;Inhaltsanalyse von sozialen Beratungsforen mit maschinellen Lernverfahren;Durch soziale Beratungsangebote werden jährlich Tausenden von Menschen bei der Bewältigung persönlicher oder familiärer Probleme geholfen. Neben der traditionellen Beratung stellt hierbei die Online-Beratung eine gute Alternative dar.<br> <br>Diese Arbeit befasst sich mit der Auswertung von Beratungsgesprächen des Online-Beratungsforums der Bundeskonferenz für Erziehungsberatung. Hierbei galt es Methodiken zur Auswertung der unstrukturierten Beratungstexte zu erforschen mit dem Ziel, Ansatzpunkte für Verbesserungen der Beratungsqualität zu ermitteln.<br> <br>Um dies zu erreichen wurden Verfahren aus dem Bereich der maschinellen Textanalyse eingesetzt. Diese Verfahren werden, neben inhaltsanalytischen Grundlagen, zunächst erläutert und anschließend anhand exemplarischer Fragestellungen durchgeführt und ausgewertet. Die Fragestellungen wurden hierbei auf Basis des Beratungsforums der BKE-Elternberatung sowie bestehender Forschungsarbeiten abgeleitet. <br> <br>Die Mehrheit der untersuchten Fragestellungen konnten, unter Einsatz von computergestützten Wörterbuchsuchen, Lesbarkeitsformeln und Vektorraummodellen, erfolgreich beantwortet und die eingesetzten Methodiken evaluiert werden. <br> <br>Ein besonderes Augenmerk lag bei dieser Arbeit auf der Feststellung von Konversationsphasen in den Forenbeiträgen. Hierbei wurde ein Konversationsphasenmodell anhand des Forums abgeleitet und der Versuch unternommen dieses in den, durch ein unüberwachtes Lernverfahren, bestimmten Konversationsphasen festzustellen.
13.11.18;22.04.19;2019;intern;Bachelor;DE;Prototypische Entwicklung eines Logistik-Sprachassistenten für ein Luftfahrtunternehmen;"This bachelor thesis describes the design and a prototypical implementation of a speech assistant for Lufthansa Technik. The implementation of the interface between in-house logistics and the company's cross-company customers is examined using a system for processing natural language called Dialogflow as an example.<br><br>After considering the basics of ""Natural Language Processing?, a general introduction to speech dialogue systems as well as the design of language assistants, I discuss the requirements of the considered assistant in detail. The scenarios relevant to Lufthansa Technik are analyzed in detail both functionally and non-functionally.<br><br>The implemented prototype of the speech assistant was created using Dialogflow, a Google deep learning platform for conversational communication and Natural Language Processing. In addition to describing the design and implementation of the assistant, I also explain key features of the software architecture of Dialogflow and the related frameworks Firebase and Node.js.<br><br>An evaluation was undertaken at Lufthansa Technik to show the strengths and weaknesses of the realization. I finish my thesis with some considerations about possible technical alternatives according to the present realization."
14.11.18;23.04.19;2019;intern;Master;EN;Drone Based 3D Reconstruction of Buildings Using SLAM;The goal of this master's thesis is to create three-dimensional reconstructions of buildings based on drone video recordings. For this purpose, simultaneous localization and mapping (SLAM) algorithms are used. LSD-SLAM is used as direct method and ORB-SLAM as feature-based method. <br>Using a presented processing pipeline, three-dimensional objects with a predominantly closed surface can be extracted and reconstructed from the input data. The pipeline consists of image preprocessing, the application of SLAM and post-processing the resulting point clouds using filters, sampling methods and surface reconstruction methods.<br>For high-quality results of ORB-SLAM, an approach for deriving surface textures is presented. The evaluation of data sets recorded under different conditions and from different buildings shows how the algorithms react to specific characteristics of the data sets, especially reflections, monotonous surfaces and strong exposure variations.
14.11.18;17.05.19;2019;intern;Master;DE;Drohnenbasierter Stereo-SLAM;Visual Simultaneous Localization and Mapping (VSLAM) behandelt das Problem, eine räumliche Karte einer unbekannten Umgebung aus Kameraaufnahmen zu erstellen und gleichzeitig die Position der Kamera in dieser Karte zu bestimmen. Ziel der Masterthesis ist es, bestmögliche Gebäuderekonstruktionen mit Hilfe von VSLAM zu generieren, um Wärmeaustritte an Gebäuden lokalisieren und visualisieren zu können. Hierfür wird eine mit einer Stereokamera ausgestattete Drohne verwendet. Neben einer Analyse zum aktuellen Stand der Technik des VSLAM-Problems in Verbindung mit Drohnen, Stereokameras und merkmalsarmen Umgebungen werden ausgewählte VSLAM-Verfahren getestet und evaluiert. Dies geschieht anhand der durch die Stereokamera erzeugten Gebäudeaufnahmen und der resultierenden dreidimensionalen Rekonstruktionen der VSLAM-Methoden mittels Punktwolken. Es erfolgt eine Gegenüberstellung der Ergebnisse dieser VSLAM-Algorithmen. Hierzu werden die Aufnahmen der Stereokamera, die als Eingabe für die VSLAM-Algorithmen dienen, mittels der von der Drohne bereitgestellten Schnittstelle abgegriffen. Die Evaluation der VSLAM-Verfahren hat gezeigt, dass keine brauchbaren Gebäuderekonstruktionen mit den verwendeten Bilddaten generiert werden können. Die Rotationen in den unstabilisierten Aufnahmen der Stereokamera führen zu Problemen bei der Rekonstruktion. <br>
15.11.18;17.06.19;2019;extern;Master;DE;Konzeption und prototypische Implementierung einer Testkette für automatische Abnahmetests innerhalb einer verteilten Anwendungsumgebung;"Das Ziel der vorliegenden Masterarbeit war die Erörterung der Frage, wie Abnahmetests eines komplexen verteilten Systems beschaffen sein müssen, um maximale Ausfallsicherheit und Fehlerfreiheit zu gewährleisten. Ein wesentlicher Fokus lag insbesondere auf der Automatisierung von Testvorgängen bzw. auf der bestmöglichen Einbindung manueller Teilprozesse in automatisierte toolgestützte Workflows. Am Ende der Arbeit ist eine Testkette entstanden, die alle typischen und relevanten Testarten abdeckt und passende Auswertungen für die unterschiedlichen Rollen innerhalb der Projektteams bereithält.<br><br>Für die Klärung, aus welchen konkreten einzelnen Testschritten die final festzulegende Testkette zusammengesetzt sein musste, wurde zuallererst der Begriff des Softwaretests näher beleuchtet und eine geeignete Klassifikation für diesen Terminus vorgestellt. Dabei wurden neben der allgemeinen Klassifikation der Testarten insbesondere auch manuelle und automatisierbare Testarten voneinander abgegrenzt. Da der Testprozess von außen betrachtet jedoch kein losgelöstes, singuläres Ereignis darstellt, sondern Glied einer Softwareproduktionskette ist, war es unabdingbar, auch die vor- und nachgelagerten Prozesse der verschiedenen Testarten zu betrachten. Dabei hat sich das Prinzip des ""DevOps"" als besonders relevant herausgestellt und wurde mit Bezug auf das Thema ""Testen"" im Detail untersucht.<br>[...]"
19.11.18;19.07.19;2019;extern;Master;DE;Konzeption und Entwicklung einer automatisierten Lagerreorganisation im SAP EWM;Die vorliegende Arbeit beschäftigt sich mit der Konzeption und Entwicklung einer automatisierten Lagerreorganisation in SAP EWM. Hierzu wird vorab das Problem der Lagerplatzzuordnung erläutert, um ein einheitliches Verständnis für die anschließende kritische Ist-Analyse zu schaffen. Angesichts der vorhandenen Datenmengen und Datenvielfalt ist die standardmäßige Lagerreorganisation des SAP EWM zu statisch ausgerichtet, um die steigenden Kundenanforderungen an ein Lagerverwaltungssystem zu erfüllen. Es folgt ein Einblick zum aktuellen Stand der Forschung über das Thema Lagerreorganisation und darauf aufbauend eine Konzeption für einen neuen Ansatz im SAP EWM. Dieser beruht auf einer regelmäßigen Produktklassifizierung, womit die Umlagerungsmaßnahmen auf Basis der aktuellen Nachfragehäufigkeit stattfinden. Für die Identifikation der umzulagernden Handling-Units kommt eine mehrdimensionale Bewertungsgrundlage zum Einsatz, die statische und dynamische Parameter, sowie die Profitabilität einer Umlagerung berücksichtigt. Dadurch können eindeutige Empfehlungen zur Umlagerung ausgesprochen werden. Mithilfe eines zweistufigen Optimierungsverfahrens erfolgt die Berechnung der optimalen Umlagerungsroute für die entsprechenden Handling-Units. Zum Abschluss wird die neue Lösung innerhalb einer Simulationsumgebung validiert. Die Ergebnisse zeigen, dass die Lagerreorganisation im Vergleich gegenüber eines normalen Lagerbetriebs eine Reduzierung der Pick-Distanz von bis zu 16% erzielen kann.
23.11.18;04.07.19;2019;intern;Bachelor;DE;Einsatz von Empamos-Spiel-Design-Entwurfsmustern zur Motivationssteigerung im Kontext des agilen Projektmanagements;Abstract<br><br>Motivation ist ein wichtiger Antrieb für Handlungen. Gamification versucht Motivation gezielt zu erzeugen und zu steuern, um somit Personen gezielt zu Handlungen zu bewegen. In dem Empamos-Projekt der TH Nürnberg wird eine Pattern-Language entwickelt, welche eine Hilfestellung geben möchte, um ein Gamification Konzept zu erstellen. Das Ziel dieser Arbeit ist es, den Arbeitsstand der Pattern-Language im Kontext zu den agilen Projektmanagementmethoden Kanban und Scrum anzuwenden. Die beiden agilen Projektmanagementmethoden besitzen bereits Gamification- Elemente sowie motivationale Defizite. Ich habe Die Pattern durch eine Analyse erarbeitet. Eine Auswahl an Defiziten habe ich mittels Interviews identifiziert. Anhand der Patterns wurden Ansätze erarbeitet, um die Defizite durch geeignete Erweiterung mit neuen Pattern abzubauen. <br>Ich habe in Kanban 27 und in Scrum 31 Pattern identifiziert. Aus den Interviews habe ich neun Defizite extrahiert. Zu sieben dieser neun Defizite kann der Arbeitsstand der Pattern-Language Ansätze geben, um sie abzubauen.<br>
27.11.18;27.04.19;2019;intern;Bachelor;DE;Analyse von Stellenanzeigen für Informatik-Absolventen mit Machine Learning;Die Stellenanzeigensuche in Onlinejobbörsen ist oftmals sehr zeitintensiv. Einen Filter für Absolventen gibt es nur bei einigen wenigen Jobbörsen und diese sind unzureichend umgesetzt. Die Schwierigkeiten bei der Stellenanzeigentextanalyse und -verarbeitung sind beispielsweise Mehrdeutigkeit, unterschiedliche Formatierung und Strukturierung. In dieser Arbeit werden die Klassifikation und die Cluster-Analyse aus Machine Learning auf die Stellenanzeigentexte angewendet. Der Klassifikator soll anhand der Stellenanzeigentexte eines typischen Jobs für Informatiker die Stellenanzeigen für Einsteiger und für Berufserfahrene klassifizieren. Aus drei Klassifikatoren hat der beste Klassifikator eine Korrektklassifizierungsrate von 91%. Zusätzlich werden eine Reihe von Datenanalysen durchgeführt und die Ergebnisse visualisiert dargestellt.
27.11.18;27.04.19;2019;extern;Bachelor;DE;Entwicklung eines Textanalysealgorithmus zur systematischen Sammlung von Bedrohungsmeldungen über Third-Party-Software im Internet;Im Bereich der Softwareentwicklung stellen Sicherheitslücken ein großes Risiko dar. Um dieses Risiko zu minimieren werden in sogenannten Software-Schwachstellen-Datenbanken offiziell anerkannte Sicherheitslücken gespeichert. Oft kursieren allerdings im Vorfeld schon Meldungen von Schwachstellen im Internet. So werden auch Personen auf diese aufmerksam, welche durch Ausnutzung der Sicherheitslücke nicht autorisierten Zugriff auf Daten erhalten können. Mit dem Problem der frühzeitigen Veröffentlichung von Software-Sicherheitslücken, beschäftigt sich die vorliegende Arbeit. Es wurde ein Textanalysealgorithmus entwickelt, welcher die wesentlichen Informationen aus offiziellen und inoffiziellen Software-Schwachstellen-Quellen kombiniert. Dabei wurden zunächst unterschiedliche Software-Sicherheitslücken-Quellen analysiert. Als repräsentativste Datenquellen haben sich dabei die NVD von NIST, das Online-Magazine heise und der Software Hersteller Microsoft herausgestellt. Darüber hinaus wurde ermittelt, welche Metadaten für die Erfassung von Sicherheitslücken relevant sind. Für die Unterscheidung zwischen Software-Schwachstellen-Meldungen und sonstigen Bekanntmachungen wurde der Textanalyseanalysealgorithmus um einen Klassifikator erweitert. Neben dem Naive Bayes Klassifikator wurde auch der Support Vector Machine Klassifikator umgesetzt. Für die Trennung der Meldungen erwieß sich der SVM als effektiver.
27.11.18;17.04.19;2019;extern;Bachelor;DE;Identifizierung und Analyse von verwendeter Third-Party-Software eines Unternehmens und<br>Entwicklung eines Tools zur automatisierten Benachrichtigung beim Bekanntwerden von<br>Sicherheitslücken;Software besteht zu einem großen Teil aus Komponenten, die von Drittanbietern stammen. Dies führt zwar zu einer Kosten- und Zeitersparnis, birgt aber auch viele Risiken. So ist durch eine Sicherheitslücke in einer Komponente die komplette Software gefährdet. Um dieses Risiko zu mindern, wird für ein IT-Unternehmen ein Tool entwickelt, welches im Internet nach Sicherheitslücken von Softwarekomponenten sucht und Mitarbeiter benachrichtigen kann. Dabei soll gezielt nur externe Software untersucht werden. Dazu wird die folgende Forschungsfrage gestellt: Wie kann man Third-Party-Software in Projekten identifizieren?<br><br>Um diese Forschungsfrage zu beantworten, ist eine Befragung durchgeführt worden, die sich an die Projektleiter von Kundenprojekten richtete. Die Antworten sollten Aufschluss darüber geben, welche Vorgehensweise sich am besten für die Identifizierung von Fremdsoftware eignet. Die Ergebnisse zeigten, dass in jedem Projekt die Dokumentation und Speicherung von Fremdsoftware unterschiedlich erfolgt.<br>So mussten verschiedene Wege erarbeitet werden, wie Fremdsoftware aus Repositories herausgelesen werden kann.<br>Anschließend konnte ein Algorithmus entwickelt werden, welcher für jede Fremdsoftware im Internet nach Sicherheitslücken sucht. Ist eine Sicherheitslücke vorhanden, wird der Projektleiter des betroffenen Projekts per E-Mail benachrichtigt.<br>Dazu wurden weitere Algorithmen entwickelt, die sich mit der Beschaffung von Mitarbeiter- und Projektinformationen beschäftigen.
28.11.18;26.04.19;2019;intern;Bachelor;DE;Konzeption und prototypische Implementierung eines OpenID Connect Identity Provider unter Verwendung der W3C WebAuthn API zur passwortlosen Authentifizierung;Das Ziel der vorliegenden Arbeit war der Entwurf eines OpenID Connect Identity Providers mit einer passwortlosen Authentifizierung auf Basis der W3C WebAuthn API und dessen anschließende Validierung durch eine prototypische Implementierung. Hierfür wurde zunächst die Entwicklung eines Konzepts zur Komposition der Technologien, dem OAuth 2.0 Protokoll mit der Authentifizierungsschicht OpenID Connect und der W3C WebAuthn API, benötigt. Des Weiteren mussten Konzepte für die Realisierung der funktionalen Bestandteile des Identity Providers entwickelt werden. Hierzu wurden nach Vorüberlegungen und der Beschreibung von Anwendungsszenarien die Definition der funktionalen und nicht-funktionalen Anforderungen an den zu konzeptionierenden Identity Provider durchgeführt. Im Anschluss wurde die Konzeption der Komposition der Technologien sowie der weiteren funktionalen Bestandteile des Identity Providers durchgeführt und somit deren theoretische Realisierbarkeit gezeigt.<br><br>Im Rahmen der folgenden prototypischen Implementierung wurde nach der Evaluation von bestehenden PHP-Bibliotheken der Entwurf des Identity Providers durchgeführt und durch die anschließende Implementierung die praktische Realisierbarkeit des konzeptionierten Identity Providers belegt.<br><br>Durch die abschließende Evaluation des Prototyps wurde die vollständige Erfüllung der initial definierten Anforderungen und im Rahmen der Validierung die Erfüllung der Erwartungen an die Sicherheit und Effizienz festgestellt. 
28.11.18;20.05.19;2019;intern;Bachelor;DE;Der Chatbot als Assistent für den Konsumenten im stationären Einzelhandel:<br>Konzeption und prototypische Implementierung<br>;Viele Kunden nutzen während des Einkaufs in einem Laden ihr Smartphone, um sich über die dort angebotenen Produkte zu informieren und bessere Kaufentscheidungen treffen zu können. Im Hinblick darauf ist das Ziel dieser Arbeit, einen prototypischen Einkaufsassistent-Chatbot zu entwickeln, der die selbstständige Informationsbeschaffung der Kunden erleichtern und sie beim Einkauf unterstützen kann. Hierfür wird zunächst ein Konzept des Chatbots erstellt und anhand dessen ein Prototyp implementiert.<br>Mithilfe eines Nutzertests und einer Umfrage wird schließlich die Nutzerfreundlichkeit und das Interesse an dieser Technologie ermittelt. Die Evaluation der Ergebnisse zeigt, dass ein Großteil der Probanden diesen Chatbot zur Hilfe beim Einkauf nutzen würde. Weiterhin konnten Verbesserungspotenziale identifiziert werden, die bei einer Weiterentwicklung des Chatbots zu berücksichtigen sind.
29.11.18;14.03.19;2019;intern;Bachelor;DE;Routenoptimierung für ein autonom fahrendes Segelboot - Implementierung und Validierung geeigneter Algorithmen;
29.11.18;14.03.19;2019;extern;Bachelor;DE;"Design und Implementierung eines Continuous Integration Prozesses für die Business-Intelligence-Software ""QlikView""";In modernen Unternehmen zählen Kennzahlen als wichtiges Steuerungsinstrument. Bei DATEV kommt hier unter anderem die Software QlikView zum Einsatz. In verschiedenen Abteilungen entstehen Statistiken über CPU-Verbräuche, Auslastungen und weitere wichtige Zahlen. Dabei läuft das Testen, Sichern alter Softwarestände der QlikView-Applikationen und das Bereitstellen auf der zentralen Serverplattform noch weitgehend von Hand. Mit Hilfe eines Continuous Integration Prozesses soll die Arbeit der QlikView-Entwickler zukünftig gestützt werden. Durch die Verwaltung der Sourcen in einer zentralen Verwaltung, sowie nachgelagerten, automatisierten Build-Abläufen werden die verschiedensten Auswertungen in einem zu definierenden CI-Prozess erzeugt und auf die entsprechenden Server geschoben. Die für den vollständigen Ablauf erforderlichen Skripte werden erstellt, getestet und auf ein geeignetes System übertragen.<br>Mit diesem Konzept wird die Grundlage für einen automatisierten und erweiterbaren Prozess geschaffen, die die Zeit bis zur Veröffentlichung einer neuen Version verkürzt und dynamische Anpassungen auf Basis des Source Code ermöglicht.
29.11.18;29.07.19;2019;extern;Master;DE;Modellierung und Implementierung eines Event-Mechanismus in einem verteilten Software-Framework<br>zur Testautomatisierung;Ziel dieser Arbeit war es, einen Event-Mechanismus zu entwerfen und prototypisch zu<br>implementieren, der die Verarbeitung von Ereignissen durchgehend in allen Teilen der<br>vorhandenen Testautomatisierungsoftware eines PROFINET-Stacks ermöglicht. <br>Diese Software wird verwendet, um einen PROFINET-Stack auf einer verteilten Testanlage,<br>bestehend aus mehreren Test-PCs und PROFINET Hardware, zu verifizieren.<br>Die Testautomatisierung besteht aus mehreren Servern und einem Client, welcher sich auf die<br>Test-PCs der Testanlage verbindet. Aktuell initiiert immer der Client die Kommunikation mit den Servern, was dazu führt, dass die Informationen, welche der Client hält, nicht immer die aktuellen Ereignisse<br>auf den Servern widerspiegeln, weswegen die Eventverabeitung implementiert werden soll.<br>Diese Arbeit entwickelt ein Konzept zur Verarbeitung von Ereignissen<br>in einem verteilten System und setzt diese anschließend prototypisch um.<br>Dieser Prototyp bildet die Grundlage für weitere Entwicklungen.<br>Durch Einführung dieses Event-Mechanismus können nun relevante Informationen<br>an interessierte Teilnehmer verteilt werden, ohne diese Information abfragen zu müssen.<br>Da sich die Anforderungen an Tests des PROFINET-Stacks kontinuierlich ändern, wurde darauf<br>geachtet, dass es einfach ist, auch neue unbekannte Eigenschaften zu überwachen.
30.11.18;14.03.19;2019;intern;Bachelor;DE;Untersuchung maschineller Lernverfahren für Frage-Antwort-Systeme;Frage-Antwort-Systeme sind eine spezialisierte Form von Information Retrieval-Systemen, deren Aufgabe es ist, in natürlicher Sprache gestellte Fragen zu beantworten. In dieser Arbeit wird aufgezeigt, wie diese Systeme aufgebaut sind, klassifiziert werden können und welche Ansätze für die Erstellung eines solchen Systems existieren. Insbesondere der Ansatz des maschinellen Lernens hat in den letzten Jahren deutlich an Bedeutung gewonnen, sodass diese Verfahren genauer untersucht wurden. Dafür wurden das Dynamic Memory Network und die Bidirectional Encoder Representations From Transformers analysiert und auf Basis dieser Modelle eigene Frage-Antwort-Systeme erstellt und evaluiert. Die untersuchte Implementierung des Dynamic Memory Networks erreichte in diesem Versuch lediglich eine Genauigkeit von etwa 45-55% Prozent bezüglich des bAbI-Datensatzes und erwies sich damit als nicht praktikabel. Das System mit Bidirectional Encoder Representations From Transformers hingegen erreicht SQuAD-Werte von bis zu 90%. Durch das multilinguale Modell ist dieses System auch in der Lage, die meisten deutschen Fragen zu beantworten. Aufgrund der Architektur und des Fine-Tunings anhand des SQuAD-Datensatzes funktioniert dieses Modell allerdings nur zuverlässig für Fließtexte und Fragen, deren Antworten sich im Text befinden.
01.12.18;01.05.19;2019;extern;Bachelor;DE;Analyse und Integration des iiRDS Standards zum Austausch intelligenter Informationen in der Technischen Dokumentation;"Zur kontextbezogenen Verteilung von Informationen wird ein für Maschinen lesbarer Kontext benötigt. Für die Beantwortung der Frage wie ein solcher Kontext beschrieben und mit der zugehörigen Information verknüpft werden kann, gibt es verschiedene Lösungsansätze. Im Teilbereich ""Content Delivery"" aus der Technischen Dokumentation wurde zu diesem Zweck der intelligent information Request and Delivery Standard (iiRDS) konzipiert. In dieser Arbeit soll geklärt werden, wie der iiRDS in bereits bestehende Software aus dem Bereich ""Content Delivery"" integriert werden kann. Zunächst definiert der iiRDS ein Vokabular zur Kennzeichnung von Inhalten mit Metadaten. Außerdem wird im iiRDS ein Paketformat definiert, das es erlaubt Inhalte mit den zugehörigen Metadaten zusammen zu verteilen. Um die Verwendung des iiRDS evaluieren zu können, wurde der SCHEMA ContentDeliveryServer (CDS) um einen Import für iiRDS-Datensätze erweitert. Diese Erweiterung ermöglicht es die Daten aus dem Paketformat des iiRDS in das Format des CDS zu überführen und den resultierenden CDS-Datensatz hochzuladen. Anschließend wurden einige Testdatensätze importiert und das Ergebnis des Imports analysiert. So konnten im Test alle Metadaten aus den iiRDS-Datensätzen ohne Verlust in den CDS übertragen werden. Diese Übertragung erfolgt anhand einer vom Nutzer des CDS vorher festgelegten Zuordnung. Der iiRDS konnte dabei allen Anforderungen aus der Technischen Dokumentation gerecht werden."
01.12.18;30.04.19;2019;extern;Bachelor;DE;Design eines Benutzer-Lifecycle-Prozesses mit Microsoft Identity Manager für Verzeichnisdienste;In der IT-Infrastruktur des Unternehmens DATEV eG existieren mehrere, voneinander unabhängige Verzeichnisdienste. Diese stehen administrierten Ressourcen, wie beispielsweise Computern und Benutzern, als Identitäts- und Authentifizierungsdienst zur Verfügung. Die Ressourcen werden in Gruppen verwaltet. Um den manuellen Aufwand der Synchronisation der Verzeichnisdienste zu reduzieren sowie einen durchgängigen Ressourcen-Lebenszyklus zu gewähren, wird ein Prozess konzipiert, welcher eine automatisierte Übertragung von Ressourcen und Gruppen ermöglicht. Dieser Ablauf wird anhand des Benutzermanagements und einer prototypischen Umsetzung evaluiert. Die Verwaltung von Benutzerobjekten umfasst neben der Übertragung von Attributen auch die Anlage, Aktualisierung sowie Löschung oder Deaktivierung. Bei der prototypischen Implementierung wird das Tool Microsoft Identity Manager analysiert und bewertet.
03.12.18;03.05.19;2019;extern;Bachelor;DE;Implementierungsanalyse ausgewählter Augmented-Reality Smart Glasses (ARSG) mit anschließender Konzeption und Realisierung einer Anbindung zu bereits vorhandenen, individuellen Webanwendungen über einen REST-Service;Die vorliegende Bachelorarbeit beinhaltet die Implementierungsanalyse ausgewählter Augmented Reality Smart Glasses (ARSG) mit anschließender Konzeption und Realisierung einer Anbindung zu bereits vorhandenen, individuellen Webanwendungen über einen REST-Service. Bei dieser Arbeit wird die Automotive-Branche in den Fokus genommen. Dementsprechend werden Erklärungen und Beispiele innerhalb eines Produktionswerkes stattfinden. In diesen Stätten werden alle laufenden, wie auch fehlerhaften Prozesse auf wenigen Monitoren dargestellt. Um als Mitarbeiter den aktuellen Stand der Prozesse einsehen zu können, muss dieser in regelmäßigen, zeitlichen Abständen den momentanen Arbeitsplatz verlassen, um auf einen der Monitore blicken zu können. Der Einsatz von ARSG soll den Aufwand verringern und einen zeitlichen Vorteil verschaffen. Dies schafft eine Möglichkeit mobil und mit möglichst geringer Ablenkung die fehlerhaften Prozesse unverzüglich angezeigt zu bekommen. Dadurch können ohne Umwege Gegenmaßnahmen eingeleitet werden. Das Ergebnis der Bachelorarbeit wird mit ausgewählten Mitarbeitern der Produktionsstätte eines namhaften Automotive-Unternehmens getestet. Es wird anschließend eine Evaluation stattfinden.
03.12.18;11.03.19;2019;intern;Bachelor;DE;Beschreibung und strukturierte Darstellung aktueller Trends im Bereich Lernende Organisationen;Lernende Organisation beziehungsweise organisationales Lernen sind Teil der erweiterten verhaltenswissenschaftlichen Entscheidungstheorie, die zu den Organisationstheorien zählt. Organisationales Lernen beschäftigt sich damit, wie der Wissenserwerb in Unternehmen umgesetzt werden kann. Als Möglichkeiten hierfür kommen unter anderem das Change- und Wissensmanagement in Frage. Als unterstützende Lernmethoden können Storytelling und Gamification genutzt werden. Ein möglicher Lerngegenstand, der mit den genannten Lernmethoden vermittelt werden könnte, ist Corporate Social Responsibility (CSR), die derzeit kulturellen Wandel in den Unternehmen nötig macht. CSR ist deshalb ein zentrales Thema in Organisationen, weil für Verbraucher wie auch Mitarbeiter Nachhaltigkeit in sozialer, ökonomischer und ökologischer Form ein zentrales Anliegen bildet.
06.12.18;13.05.19;2019;intern;Bachelor;DE;Analyse und Auswertung von Stellenausschreibungen durch Methoden des maschinellen Lernens;Mit der Hochschul-Jobbörse stellen mittlerweile 15 Partnerhochschulen in Bayern eine Online-Plattform für Stellenanzeigen zur Verfügung, um Studierende, Absolventinnen, Absolventen sowie Alumni mit erster Berufserfahrung und Unternehmen für beide Seiten gewinnbringend zusammen zu führen. Das Archiv der Hochschuljobbörse, beinhaltet eine Sammlung der ausgeschriebenen Stellenanzeigen jeder teilnehmenden Hochschule, der letzten Jahre. Ziel dieser Bachelorarbeit ist es herauszufinden welche Informationen sich durch Anwendung von maschinellen Lernalgorithmen und regelbasierten Analyseverfahren aus den Stellenanzeigen der Hochschuljobbörse gewinnen lassen. Dafür wird zunächst durch statistische Analyse der Jobtitel geprüft, welche Berufsklassen in den Datensätzen vorkommen. Anschließend werden die Stellenausschreibungen durch überwachte Lernverfahren den jeweiligen Berufsklassen zugeteilt. Aus den klassifizierten Stellenanzeigen werden dann die Qualifikationsanforderungen extrahiert und zum Schluss in Kategorien eingeteilt. Das Ergebnis der durchgeführten Analyse der IT-Stellenanzeigen sind Kompetenzprofile der jeweiligen Berufsklassen, die eine Übersicht über die am häufigsten genannten Anforderungen in den untersuchten Stellenanzeigen geben. 
11.12.18;10.05.19;2019;intern;Bachelor;DE;Benutzerschnittstelle zur Visualisierung von Gesichtserkennungsverfahren;Im Rahmen dieser Bachelorarbeit soll eine Benutzerschnittstelle zur Visualisierung<br>von Gesichtserkennungsverfahren entwickelt werden. Diese soll beispielsweise<br>in Lehrveranstaltungen zum Einsatz kommen, um die Funktionsweise<br>der Verfahren zu veranschaulichen. Das zu entwickelnde Tool soll<br>bereits trainierte künstliche neuronale Netze einbinden können. Es soll darüber<br>hinaus möglich sein, Bilder von Gesichtern einzulesen, zu verwalten, mit<br>Labeln (Namen bzw. Farben) zu versehen sowie den Abstand der Gesichter<br>im Merkmalsraum zu visualisieren. Hierfür soll das Verfahren T-distributed<br>Stochastic Neighbor Embedding (t-SNE) zum Einsatz kommen.<br>Bei dem Verfahren werden hochdimensionale Daten in zwei- oder mehrdimensionalen<br>Räumen abgebildet ohne dabei die Struktur der Daten zu verändern,<br>was eine hohe Nachvollziehbarkeit für das menschliche Auge ermöglicht.<br>Auf diese Weise kann man Ähnlichkeiten zwischen Gesichtern optisch<br>demonstrieren.<br>Innerhalb der Fakultät Informatik werden verschiedene Betriebssysteme<br>eingesetzt, daher sollte die Anwendung möglichst plattformunabhängig sein.
13.12.18;08.05.19;2019;extern;Bachelor;EN;Extraction, processing and visualization of real estate relevant information from planning permits <br>Part 1: Concept and development of a text-mining pipeline;Abstract<br><br>For developing a prototype which illustrates building developments in cities it is beneficial to extract relevant information automatically from planning permissions which are published on the websites of local authorities.<br>In this thesis, we describe text mining approaches of automatically identifying information in building permits such as postal addresses, permission date, file number and types of building developments. Our text mining pipeline is integrated by rule-based and machine-learning extraction method. By applying gazetteer, regular expression and syntactic rules, rule-extraction is accomplished. In machine-learning extraction, we use NER model from spaCy and trained it for our specific real-estate scenario.<br>The result of this pipeline will be used as input of visualization component which based on Geo-Framework like Google maps. <br>
13.12.18;13.05.19;2019;extern;Bachelor;DE;Extraktion, Aufbereitung und Darstellung immobilienwertrelevanter Informationen aus Baugenehmigungen.<br>Teil 2: Konzeption und Entwicklung einer Applikation zur Visualisierung auf einer digitalen Karte;Das Ziel der Arbeit ist es, Personen, welche an Immobilien oder Grundstücken interessiert sind, eine Möglichkeit zu bieten, eventuelle - durch Umgestaltungen im Umfeld bedingte - Wertänderungen von Immobilien bzw. Grundstücken leichter zugänglich zu machen.<br><br>Hierfür werden als Beispieldaten Amtsblätter von fünf ausgewählten Städten betrachtet und die darin befindlichen Baugenehmigungen genutzt.<br><br>In einer parallel entstehenden Bachelorarbeit werden die Inhalte der Baugenehmigungen mithilfe von Text-Mining-Methoden aufbereitet und immobilienwertrelevante Informationen extrahiert.<br><br>Diese immobilienwertrelevanten Informationen werden im Rahmen dieser Arbeit in einer für den Endbenutzer gut zugänglichen, strukturierten Form auf einer digitalen Karte visualisiert.<br><br>Dafür wird zunächst ein Darstellungskonzept entworfen, mithilfe dessen der Prototyp entwickelt werden kann. Zur Qualitätssicherung und Planung der Weiterentwicklung wird neben internen Komponenten- und Integrationstests auch ein externer Benutzertest unter einer Zahl von Mitarbeitern der Immowelt AG durchgeführt.
21.12.18;20.05.19;2019;extern;Bachelor;DE;Optimale Lagerplatzvergabe: Generierung von endlichen Automaten zur Unterstützung der performanten Suche bei der Dematic GmbH;Die Suche nach dem optimalen Lagerplatz ist eine elementare Aufgabe bei der Ein- und Auslagerung von Gütern in einem Warenlager. Damit der Zugriff auf die Güter eines Lagers möglichst effizient ist, werden endliche Automaten verwendet. Im eigenentwickelten Lagerverwaltungssystem der Dematic GmbH werden die endlichen Automaten manuell erstellt. Ziel der Arbeit ist die Ablösung der bisherigen manuellen Vorgehensweise zur Erstellung von endlichen Automaten durch einen Algorithmus. Die Phasen zur Entwicklung der Anwendung umfassen die Analyse, Konzeption, Umsetzung und die anschließende Bewertung der Ergebnisse.<br>Der Algorithmus für die Erstellung von endlichen Automaten wird sukzessiv in Form von Prototypen implementiert. Nach jedem Prototyp ergibt sich eine ablauffähige Anwendung, die einen Teil der Funktionalitäten wiederspiegeln. Im Rahmen der Konzeption werden für jeden der entworfenen Prototypen bestimmte Funktionen geplant. Die Phase Umsetzung umfasst die Implementierung des entsprechenden Programmcodes sowie die erforderliche Testaktivitäten. Nach jedem Prototyp werden die Ergebnisse des Algorithmus bewertet. Der in dieser Arbeit realisierte Generator kann verschiedene endliche Automaten mit unterschiedlich großen Ladeeinheiten erstellen.<br>
15.01.19;15.06.19;2019;extern;Bachelor;DE;Konzeption und Implementierung einer Schnittstelle zur automatischen Erkennung von Fehlermustern und deren Bereinigung bei der Siemens AG;Diese Arbeit behandelt ein Innovationsprojekt zur Erstellung von MIMIR im<br>Auftrag der Siemens AG. Das Ziel dieser Arbeit ist es, eine Schnittstelle von<br>THOR zu Splunk herzustellen, die es Support Mitarbeitern und weiteren<br>interessierten Nutzern erlaubt Suchpattern zu erstellen. Mit den Suchpattern<br>sollen Support Mitarbeiter durch automatisierte Behebung bestimmter Fehler<br>entlastet werden. Außerdem sollen für diese Suchpattern Analysen bereitge-<br>stellt werden, die die Fehlerhäufigkeit pro Zeiteinheit zeigen.<br>Um die Wünsche der Nutzer einzufangen, sind moderierte Interviews mit Key<br>Usern aus verschiedenen Bereichen veranstaltet worden. In diesen Interviews<br>konnten die Nutzer in einem gewissen, durch den Moderator gegebenen<br>Rahmen, User Stories erstellen. Auf Basis dieser User Stories wurde eine<br>Benutzerschnittstelle in Form einer Webanwendung, sowie Prozesse erstellt,<br>die das Programm mit den gewünschten Funktionen ausstatten.<br>Bei der Entwicklung der Schnittstelle zeigten sich Beschränkungen bei der<br>Abfrage in Splunk. Dem wurde in großen Teilen durch Umstrukturierung der<br>Architektur entgegengewirkt, jedoch war dies in einzelnen Punkten im zeitli-<br>chen Rahmen nicht möglich, wodurch die Produktivstellung der Anwendung<br>nicht erfolgt ist.<br>Im Rahmen dieser Bachelorarbeit wurde ein solides Grundgerüst erstellt, das<br>den Wünschen der Nutzer entspricht und nach Beseitigung der Beschränkun-<br>gen in der Siemens AG verwendet werden kann.
17.01.19;18.09.19;2019;intern;Master;DE;Gestaltungsoptionen für die IT-Governance und IT-Portfoliomanagement an Hochschulen;Die IT-Governance ist heutzutage ein zentraler Bestandteil der Corporate Governance, welche der Sicherstellung des effektiven Gebrauchs von IT zur Unterstützung der Unternehmensstrategie dient. Da die IT in den letzten Jahren auch an Bedeutung an Hochschulen gewonnen hat, werden große Anstrengungen unternommen, auch hierfür effektivere Entscheidungsstrukturen zu entwickeln. <br>Ziel der Arbeit ist es, Möglichkeiten zur Modellierung geeigneter IT-Governance-Strukturen aufzuzeigen und unter Beachtung ihrer Eignung für Hochschulen zu analysieren. Um diese Zielsetzung zu erfüllen, wurden bezüglich der Gestaltungsoptionen die IT-Governance-Literatur und -Studien ausgewertet sowie aktuelle Praktiken an Hochschulen untersucht, um auf diese Weise best practices ableiten zu können. <br>Als zentrale Ergebnisse der Arbeit zeigten sich, dass eine stärkere Einbindung des CIOs in die Entscheidungsstrukturen, sowie dessen Etablierung als zentraler Ansprechpartner für IT-Belange an der Hochschule empfehlenswert sind. Auch sind best practices aus IT-Governance-Frameworks wie ITIL hilfreich für effektivere Prozesse zur Entscheidungsfindung.
28.01.19;27.06.19;2019;extern;Bachelor;DE;Evaluation und Technologievergleich der Container-Orchestrierungstools Docker-Swarm, Kubernetes und Pivotal-Container-Services zur Skalierung des zentralen Buildsystems Jenkins;In der Abschlussarbeit gilt es zu untersuchen, welches Container-Orchestrierungstool sich für das horizontale Skalieren des Open-Source Buildsystems Jenkins am besten eignet. Die zur Auswahl stehenden Tools sind Docker-Swarm, Kubernetes und Pivotal Container Services. Um zu evaluieren, welche Technologie sich für die Datev eG am Besten eignet, wird ein Technologievergleich zwischen Docker-Swarm, Kubernetes und Pivotal Container Service durchgeführt. Hauptmerk wird dabei auf die Wartbarkeit und Administrierbarkeit gelegt. Zur Evaluation wird der Betrieb des Jenkins-Masters innerhalb eines Docker-Swarm Cluster und Kubernetes Cluster prototypisch umgesetzt.
31.01.19;30.06.19;2019;intern;Bachelor;DE;Konzeption und prototypische Implementierung eines Chatbots für die Themen W-LAN und VPN an einer Hochschule;Zu Beginn eines jeden Semesters treffen bei der IT-Support-Organisation mehrere Anfragen bezüglich Schwierigkeiten bei der Einrichtung einer Hochschulnetzwerkverbindung ein. Dabei handelt es sich überwiegend um wiederkehrende Fragen, die mithilfe eines digitalen Assistenten unterstützend sowie vollautomatisiert beantwortet werden können. Die Herausforderungen liegen in der dynamischen Vermittlung von explizitem Wissen sowie in der autonomen Erfassung von relevanten Systeminformationen des Nutzers bzw. der Nutzerin. Im Rahmen der vorliegenden Arbeit wurde eine mögliche Dialogstruktur für den Bereich WLAN und VPN realisiert. Ein mündliches Experteninterview diente der Analyse und der Konzeption. Das resultierende Konversationsmodell wurde prototypisch umgesetzt. Anschließend wurde zur Verifizierung eine quantitative Online-Befragung mit den Mitarbeitern des Support-Teams durchgeführt. Das Resultat der Beobachtung gibt Auskunft darüber, ob der Einsatz von Chatbots an der Hochschule tendenziell erfolgen kann.
31.01.19;28.06.19;2019;intern;Bachelor;DE;Entwicklung eines kontextbezogenen Wortvorschlagssystems unter Einsatz von Machine Learning;Das Ziel der Arbeit ist die Entwicklung eines kontextbezogenen Wortvorschlagssys-tems. Dieses soll anders als herkömmliche Tastaturen Informationen, wie den derzeitigen Gesprächspartner, die Uhrzeit sowie den Standort in die Wortvorschläge mit einbezie-hen. Für die Entwicklung werden zunächst vier bestehende Wortvorschlagssysteme ver-glichen und das geeignetste für den Anwendungsfall ausgewählt. Das ausgewählte Ver-fahren wird anschließend um kontextbezogene Informationen erweitert. Späterer Ein-satzzweck des Systems ist eine App, die Menschen mit einer Sprachbehinderung die Kommunikation erleichtern soll. 
11.02.19;11.07.19;2019;intern;Bachelor;DE;Verarbeitung von Projektaktivitätsdaten aus SW-Entwicklungsprozessen;Die Aufgabenstellung dieser Arbeit besteht darin, ein Auswertungssystem zu entwickeln, welches in der Lage ist, Projektaktivitätsdaten eines Projektmanagementsystem zu exportieren und diese in einer eigenen Datenhaltung zu speichern. Diese Daten werden anschließend ausgewertet und für den Benutzer visualisiert. Grundsätzlich soll die betriebswirtschaftliche Problematik der fehlenden Transparenz untersucht und die daraus resultierenden Anforderungen in einer Anforderungsanalyse dokumentiert werden. Die Datengrundlage der Projektaktivitätsdaten wird zudem auf ihre Aussagekraft überprüft wobei zu den Eingabedaten kritisch Stellung genommen wird. Da die Auswertung personenbezogene Daten beinhalten könnte, bedarf es ebenfalls einer Datenschutzprüfung. Nach dieser Prüfung wird das Auswertungssystem zunächst in einem Fachkonzept festgehalten und im Anschluss erfolgt eine ausführliche Abhandlung über die Bereitstellung der Datenhistorie des Team Foundation Servers. Nach einer detaillierten Beschreibung des Fachkonzeptes, soll die konkrete Umsetzung in ein IT-Konzept aufgezeigt werden. In einem letzten Schritt folgt die Evaluation des Auswertungssystems durch Mitarbeiter, um Nutzen, Umsetzbarkeit und Transparenz zu überprüfen.
11.02.19;29.07.19;2019;intern;Master;DE;Kompetenzentwicklung in MINT-Berufen - Ermittlung zukünftig notwendiger Kompetenzen mittels Machine Learning;Bei Bewerbungen auf verschiedene MINT-Berufe ist oft unklar, welche Kompetenzen für die Ausübung des jeweiligen Berufs erforderlich sind. Des Weiteren werden bei auf sich ähnelnden Positionen teilweise unterschiedliche Kompetenzen erwartet. Auch im Laufe der Zeit ändern sich die Erwartungshaltungen an einen Beruf. Daher stellt sich die Frage, welche Kompetenzen in Zukunft an MINT-Berufe gestellt werden könnten.<br>In Stellenbeschreibungen von Jobbörsen werden Kompetenzen beschrieben, die von Bewerbern erwartet werden. Aus alten Datensätzen von Stellenbeschreibungen lassen sich darüber hinaus Erwartungen extrahieren, die in bereits abgelaufenen Stellenanzeigen an die Bewerber gestellt wurden. Diese Forschungsarbeit beschäftigt sich daher zunächst mit der Identifizierung von Kompetenzen aus aktuellen und vergangenen Stellenbeschreibungen, um auf deren Basis mögliche zukünftige Kompetenzen ermitteln zu können. <br>Dafür wird zunächst ein gemeinsames Begriffsverständnis zwischen Leser und Autor geschaffen. Es werden die Begriffe Data Mining, Machine Learning und Kompetenz geklärt. Anschließend werden die notwendigen Arbeitsschritte erläutert, die für die Prognose der zukünftig notwendigen Kompetenzen nötig waren. Dazu gehören die Vorverarbeitung des vorliegenden Datensatzes sowie die Datenverarbeitung. Um eine möglichst genaue Prognose liefern zu können wird aus einem von zwei vorgestellten Machine Learning Modellen gewählt, auf dessen Basis dann die Vorhersage erfolgt. 
12.02.19;12.07.19;2019;extern;Bachelor;EN;Development of a distributed cloud-based system for crawling public real estate relevant data for a large German real estate portal;The purpose of this thesis is to conceive and implement a distributed web crawler information in cooperation with the company Immowelt AG. This web crawler is applied in the information retrieval stage to collect real estate information  such as building permissions from official journals published by city councils<br>This web crawler should perform better in terms of crawling quantity and quality comparing to the traditional single-thread crawler. This can be realized with the use of various technologies on the cloud platform such as as Amazon Web Services (AWS). Furthermore, the use of container technologies should be utilized to increase the flexibility of continuous deploy and scaling of the web crawler.<br>
14.02.19;11.10.19;2019;intern;Master;DE;Modellierung einer Customer-Journey-Map für die Informatik Fakultät der Technischen Hochschule Nürnberg  Georg Simon Ohm;Die Laufbahn eines Studierenden hat viele unterschiedliche Abschnitte. Schon in der Phase der Suche nach einem Studienplatz hat ein künftiger Studierender Berührungspunkte mit einer Hochschule oder Universität. Ziel dieser Masterarbeit ist die Modellierung einer Customer-Journey-Map für die Informatik Fakultät der TH Nürnberg. Hierzu wird zunächst der Student Lifecycle der Studierenden ausgearbeitet. Anschließend werden die Aktivitäten, Erwartungen und Berührungspunkte der Studierenden mit der TH Nürnberg identifiziert und abgebildet. Die jeweiligen Aktivitäten und Erwartungen sind stets aus der Sicht des Studierenden zu betrachten. Mithilfe der Customer Journey werden diese Berührungspunkte analysiert. Schwachstellen in den sogenannten Touchpoints werden dokumentiert und mögliche Verbesserungsvorschläge ausgearbeitet.
25.02.19;30.09.19;2019;intern;Master;DE;Entwicklung und prototypische Umsetzung von Konzepten für digitale Bildungsmaßnahmen zur Unterstützung benachteiligter Studierender;Ziel der Masterarbeit war es, Konzepte für digitale Bildungsmaßnahmen zur Unterstützung benachteiligter Studierender zu entwickeln und prototypisch umzusetzen. Hierfür wurden zunächst die Personengruppen der benachteiligten Studierenden ermittelt. Für die Personengruppen wurden die Benachteiligungen ausgearbeitet. Aus den Benachteiligungen wurden die spezifischen Förderbedarfe abgeleitet. Anschließend wurden für die spezifischen Förderbedarfe digitale Bildungsmaßnahmen aufgezeigt, um die benachteiligten Studierenden in der digitalen Hochschulbildung zu unterstützen. Abschließend erfolgte eine prototypische Umsetzung der entwickelten Konzepte zur Unterstützung der benachteiligten Studierenden in der digitalen Hochschulbildung.
27.02.19;27.07.19;2019;extern;Bachelor;DE;Konzeption und Evaluierung eines agilen Vorgehensmodells und Realisierung im Bereich Intralogistik bei der Dematic GmbH;Agile Methoden sind in der Regel wirtschaftlicher und für Kunden transparenter als lineare Vorgehensmodelle. Deren Hauptproblem besteht darin, dass aufgrund logisch abgegrenzter Abläufe flexible Änderungen an der Software in späteren Phasen nicht umsetzbar sind.<br>Die Dematic GmbH liefert intelligente Intralogistik-Lösungen für unterschiedliche Branchen und beschäftigt weltweit über 6000 Mitarbeiter.<br>Die Bachelorarbeit befasst sich mit der Untersuchung des bestehenden Vorgehensmodells der Softwareentwicklung im Java-Bereich. Um den Ist-Zustand zu ermitteln und Schwachstellen zu identifizieren, werden unterschiedliche Verfahren angewendet. Anschließend wird ein Konzept auf Basis der agilen Methode Scrum erstellt. Mit Hilfe einer Machbarkeitsstudie sowie anschließender Realisierung im Bereich Intralogistik wird evaluiert, ob zukünftig ein agiles Vorgehen angewendet werden soll.<br>
01.03.19;30.07.19;2019;intern;Bachelor;EN;Design and implementation of a customizable movie collection software program;The goal of the thesis is to develop a fully customizable movie collection software program that can be tailored to fully meet the user's requirements. <br>This is accomplished by first conducting a survey among users and film enthusiasts to find out which features are most important for them and then comparing the most popular programs on the market. <br>The results are evaluated and thereafter, the software is designed and implemented based on the results of the survey and the comparison. <br>At the end, an executable demo of the program is available and evaluated to verify if the software artifact meets the requirements set by the thesis.
01.03.19;31.07.19;2019;extern;Bachelor;DE;Konzeption und Implementierung eines Codegenerators zur Exportierung eines in EB-GUIDE erstellten Modells nach HTML5;Die vorliegende wissenschaftliche Arbeit behandelt die Erstellung sowie anschließende Implementierung eines Konzeptes das es ermöglicht, ein in EB GUIDE Studio - ein Tool zur Modellierung von Human-Machine-Interfaces - erstelltes Modell nach HTML5 zu exportieren, ohne dabei die bereits bestehenden Konzepte und Features von EB GUIDE aufzubrechen. Hierbei wurde ein JSON-Exporter sowie ein Codegenerator erstellt, der es ermöglicht JavaScript-Module aus dem exportierten Modell zu erstellen. Des weiteren wurde zur Exportierung der eigens entwickelten Skriptsprache EB GUIDE Script ein JavaScript Transpiler entwickelt welcher den bestehenden Skriptcode in JavaScript-Code umwandelt. Zur Ausführung des exportierten Modells im Browser, wurde eine eigene Laufzeitumgebung in JavaScript entwickelt welche die existierenden Features und Konzepte in EB GUIDE beachtet.
04.03.19;02.08.19;2019;extern;Bachelor;DE;Entwerfen einer Referenzarchitektur für die Entwicklung und den Betrieb von Microservices;Gegenstand der hier vorgestellten Arbeit ist der Entwurf einer Referenzarchitektur für die Entwicklung und den Betrieb von Microservices. Diese, in Form eines Schaubilds, festgehaltene Referenzarchitektur entstand durch die Analyse der für Microservices relevanten Bereiche. Gegenüber einem Monolithen bieten Microservices zwar einige Vorteile, bringen jedoch auch neue Herausforderungen und Komplexität mit sich. Ziel der aufgezeigten Architektur ist es, den Umgang mit Microservices zu vereinfachen. Im Rahmen eines Beispiels aus der Praxis wird die Realisierbarkeit der entstandenen Referenzarchitektur sichergestellt.
15.03.19;15.08.19;2019;extern;Bachelor;DE;Konzeption und Kodierung einer unkonventionellen optoelektronisch lesbaren Schrift;Das Ziel der vorliegenden Arbeit war es ein Konzept für eine eigenen maschinenlesbare optische Code zu erstellen. Dieser Code soll sich insbesondere durch eine ästhetische und unauffällige Erscheinung auszeichnen und auf Papier oder Folie gedruckt werden können. Zu Beginn wurden die Anforderungen und die möglichen Anwendungsszenarien dokumentiert. Anschließend wurden verschiedene bestehende Codes, wie zum Beispiel der EAN-13 Strichcode und der QR Code, analysiert.<br>Basierend auf verschiedenen Skizzen wurde eine Darstellungsmöglichkeit erarbeitet und die Kodierung von Daten konzipiert. Die Lösung hat eine Wellenform, trägt den Namen TimCode und kann bis zu 8 Byte an Daten abbilden. Es gibt mehrere Parameter um die genaue Darstellung zu beeinflussen und an die eigenen Wünsche anzupassen.<br>Außerdem wurde eine ein Python Skript geschrieben um den Code zu generieren. Um das Einlesen des Codes zu demonstrieren, wurde eine Android Anwendung erstellt. Die Bildverarbeitungsbibliothek OpenCV wird verwendet um das Kamerabild zu verarbeiten und auszuwerten. <br>Im Rahmen der Arbeit wurden auch die Lesegeschwindigkeit, Datenmenge und Ästhetik evaluiert. Zum Abschluss wurde noch ein Ausblick mit möglichen Verbesserungen und Erweiterungen gegeben.
15.03.19;15.08.19;2019;extern;Bachelor;DE;Entwicklung eines WebRTC-Dienstes mit dynamischer Netzwerktopologie;Ein Videokonferenzdienst kann nach verschiedenen Topologien aufgebaut sein. Weit verbreitet sind die direkte Peer-to-Peer Topologie Mesh, sowie die Sterntopologien Selective Forwarding Unit und Multipoint Conferencing Unit. Für unterschiedliche Anwendungszwecke kann jeweils eine andere Topologie sinnvoll sein. Deshalb wird im Rahmen dieser Arbeit untersucht, wie ein WebRTC Dienst entwickelt werden kann, der abhängig von der individuellen Videokonferenz die Topologie wechselt, um die bestmögliche Qualität zu erreichen. Die durchgeführten Wechsel der Topologie dürfen hierbei zu keiner Unterbrechung der Videokonferenz führen. Um diese Frage zu beantworten wird ein solcher WebRTC Dienst mit dynamischer Netzwerktopologie implementiert. Es werden die technischen Hürden der Entwicklung erläutert wie die automatische Wahl der Topologie und der unterbrechungsfreie Topologiewechsel. Abschließend werden Tests mit der entwickelten Software durchgeführt, die zeigen, dass die automatisch durchgeführten Topologiewechsel die Videoqualität verbessern. Auch dass der Wechsel zwischen den Topologien ohne Unterbrechung der Videoübertragung verläuft, wird durch Tests bestätigt.  
18.03.19;18.11.19;2019;intern;Master;EN;A Comparison of physically based Rendering Algorithms;This master thesis analyzes the current state of the art of physically based real-time rendering<br>and provides an implementation to compare different lighting models. In the individual<br>chapters the law of energy conservation and possible error terms are repeatedly addressed.<br><br>Physically based rendering has become more and more important in recent years and replaces<br>the previous exposure models to achieve a higher degree of realism. In order to discuss<br>these physically based approaches, first the basics of the physics of light and the theory of<br>microfacets are explained. Then five known shading algorithms of the past years are presented.<br>The differences and applications of these methods will be discussed. In order to additionally<br>analyze the lighting models from a technical perspective, two well-known applications, Blender<br>and Unreal Engine 4, are examined at code level. The use of the exposure models and their<br>implementation will be highlighted. Finally, the application PBRViewer, which was developed<br>in the context of this thesis, is presented. It allows to compare lighting models on a visual<br>level.<br><br>Disney?s principled shading model currently provides the most realistic results when using a<br>single lighting model. However, even this algorithm cannot realistically represent all materials<br>in all possible exposure scenarios. An example would be the representation of fur, hair and<br>clothing, which still have to be represented by specialized algorithms.
18.03.19;15.08.19;2019;intern;Bachelor;DE;Konzeptionierung und Evaluation der Einbindung eines Force Feedback Geräts in eine VR Umgebung;Haptische Wahrnehmung ist ein Teil der Mensch-Computer-Interaktion in einer virtuellen Realität. Es existieren Geräte, welche ein haptisches Feedback durch eine einfache Vibration ausgeben. Komplexere Geräte benutzen Mechanismen, die eine Gegenkraft als haptisches Feedback ausgeben. <br><br>In der vorliegenden Arbeit beschäftigt sich damit das kraft-reflektierende, haptische Gerät Phantom Premium 1.5 in die VR-Entwicklungsumgebung ''Unity'' einzubinden. Dazu wird ein System zum Austausch der Daten nach dem Client-Server Modell entwickelt, welches das haptische Gerät in Unity ansteuern soll. In einem Prototyp wird mithilfe der Virtual Reality Modeling Language haptische Objekte erzeugt, die in das mitgelieferten Software Toolkit importiert werden. In einem weiteren Versuch wird mit der Penalty Based Method und dem Hookschen Gesetz ein haptischer Render Algorithmus entwickelt, um ein haptisches Feedback zu erzeugen. Eine Evaluation wird im Rahmen dieser Arbeit nicht durchgeführt.
19.03.19;19.11.19;2019;extern;Master;DE;Performance-Analyse populärer Web-Frontend Frameworks;Ziel der Masterarbeit ist die Herausarbeitung eines gültigen Vergleichs dreier Frontend-Frameworks im Hinblick auf deren Performance. Diese werden am Beispiel einer exemplarischen Anwendung gegenübergestellt. Es wird hinterfragt warum Performance in moderner Webanwendungen essentiell ist und ein Überblick über bekannte und allgemeingültige Ansätze der Performance-Optimierung für Entwickler gegeben und deren Auswirkungen erfasst. Daraufhin werden passende Performance-Metriken und hilfreiche Tools gelistet. Anhand von Statistiken werden drei Frontend Frameworks ausgewählt, die im nachfolgenden für die Implementierung herangezogen werden. Die bestehende Anwendung wird dabei in Angular 7, React und Vue implementiert. Es werden die Besonderheiten des jeweiligen Frameworks herausgearbeitet, die Reimplementierung nachvollzogen, Gründe für deren performantes Verhalten untersucht und mögliche Optimierungen ans Licht gebracht. Im Nachfolgenden wird in einem Vergleich gegenübergestellt, welches Framework am besten bei der Performance abschneidet. Dies erfolgt über Synthetic Tests. Die zuvor erfassten Performance-Metriken dienen dabei als Maßstab und zum Nachweis der Optimierung. Ein letzter allgemeiner Vergleich der Front-End-Frameworks gibt Aufschluss darüber wann welches Framework am besten zum Einsatz kommen sollte und wie dessen Beliebtheit am Markt ist. Die Arbeit endet mit einer Zusammenfassung der Ergebnisse, Ausblick und Diskussion.
20.03.19;03.09.19;2019;intern;Bachelor;DE;Anwendung einer Gamification-Mustersprache zur Verbesserung der motivationalen Wirkung von Lehrveranstaltungen an Hochschulen;"Das Ziel der Bachelorarbeit ist es, motivationale Probleme von Lehrveranstaltungen an Hochschulen zu identifizieren und die Anwendbarkeit der Gamification-Mustersprache aus dem Forschungsprojekt ""Empirische Analyse motivierender Spielelemente zur Entwicklung einer Gamification-Mustersprache""  zur Lösung von konkreten Problemstellungen in der Praxis zu überprüfen. Hierzu werden die motivationalen Probleme der Lehrveranstaltungen analysiert und diese durch Kombination spezifischer Spiel-Design-Elemente aus der Mustersprache des EMPAMOS-Projektes zu bestimmten Spielelementkombinationen  gelöst. Dabei wird bewertet, wie sich der aktuelle Enwicklungsstand der Mustersprache für diese Problemlösung eignet. Zusätzlich wird ermittelt und beschrieben, wie sich die Spielelementkombinationen realisieren lassen."
21.03.19;21.08.19;2019;extern;Bachelor;DE;Entwicklung eines KI-basierten Answer Bots zur Lösung von Low-Touch-Tickets für ein<br>Helpdesk-System;Diese Bachelorarbeit befasst sich mit der Entwicklung des KI-basierten Answer-Bots. Dieser soll zu häufig auftretenden Supporttickets, geeignete Einträge aus der Wissensdatenbank finden, wobei für diesen Zweck Maschinelles Lernen eingesetzt wird. <br>Hierfür werden zunächst die notwendigen Grundlagen erläutert, bevor für diesen Anwendungsfall ein Konzept entwickelt wird. Bei der Konzeption des Answer-Bots wird ein weiteres Programm vorgestellt, dass mithilfe der Kosinus-Ähnlichkeit aus den gespeicherten Tickets und Einträgen der Wissensdatenbank einen markierten Datensatz erstellt. Bei der Implementierung werden verschiedene Methoden zur Erstellung der Merkmalsvektoren sowie zwei Lernalgorithmen zum Trainieren eines Modells miteinander verglichen. <br>Dabei erzielt eine Support Vector Machine mit Tf-Idf Gewichten als Merkmalsvektoren die besten <br>Ergebnisse, für den verwendeten Datensatz. Abschließend werden kurz mögliche Verbesserungen des Answer-Bots aufgezählt.
21.03.19;15.11.19;2019;intern;Master;DE;Räumliche Sonifikation für sehbeeinträchtigte Menschen in Form eines Augmented Reality Zeilenscanners;"Das Wissenschaftsfeld der Sonifikation bietet vielversprechende Ansätze, um die physiologischen und pathologischen Einschränkungen des menschlichen Körpers im Hinblick auf die audiovisuelle Wahrnehmung zu verbessern. Dabei werden räumliche Informationen von, sowohl physikalischen als auch virtuellen Objekten, im unmittelbaren Kontext des Nutzers als non-verbaler Sound wiedergegeben. Bei der konkreten Implementierung und akustischen Modellierung gibt es jedoch noch viele unterschiedliche Ansätze. Diese wissenschaftliche Arbeit widmet sich der Evaluierung eines sequentiellen Scanverfahrens in einer gemeinsamen Benutzerstudie unter Beteiligung von sehbehinderten und blinden Personen. Ziel ist es zu bestimmen, ob ein räumliches Verständnis besser durch die akustische Dimension der Frequenz, oder der Amplitude gefördert werden kann.<br>Das Scanverfahren wurde durch die Verwendung einer ""Microsoft HoloLens"" und eines ""RPLIDAR A2"" Laserscanners umgesetzt. Dieser Forschung gelang es herauszufinden, dass ein genaueres räumliches Verständnis durch Sonifikation anhand Frequenzänderung in signifikant kürzerer Zeit geschieht als durch eine Änderung der Amplitude. Die Benutzerfreundlichkeit des, mit der HoloLens umgesetzten, Zeilenscanners wurde höher eingestuft als die des LIDAR-Prototyps. Der Autor erhofft sich durch diese Antworten Erkenntnisgewinn, welcher insbesondere sehbehinderten Menschen zu Nutze kommen soll.<br>"
22.03.19;22.11.19;2019;intern;Master;DE;Analyse von E-Learning im Studium und empirischer Vergleich zu traditionellen Lehreinheiten zur Ableitung von Empfehlungen bezüglich des Einsatzes von E-Learning-Elementen;Während digitale Angebote an Hochschulen als Ergänzung zum traditionellen Unterricht bereits breiten Einsatz finden, sind E-Learning-Kurse als Alternative zum traditionellen Unterricht an Präsenzhochschulen seltener vertreten. In diesem Zusammenhang stellt sich die Frage, ob die Vorteile der Digitalisierung in diesem Bereich weniger ausschlaggebend sind und traditionelle Lehrmethoden im Vergleich zu einem besseren Lernergebnis führen, oder ob E-Learning-Kurse ein zumindest gleichwertiger Ersatz sein können. Zur Ermittlung für die Fragestellung relevanter Parameter ist ein möglicher Ansatz die Durchführung eines empirischen Vergleichs von zwei Studierendengruppen, die inhaltlich identische Lehreinheiten mit jeweils der anderen Lehrform erhalten. Durch eine Prüfung können die jeweiligen Lernerfolge quantitativ gemessen und unterschiedliche E-Learning-Elemente evaluiert werden. Um damit zusammenhängenden Faktoren berücksichtigen zu können, kann eine empirische Befragung zur Akzeptanz oder Erfahrung mit E-Learning erfolgen. Zudem können zur Erweiterung des Betrachtungsumfelds auch andere Studien einbezogen werden, die beide Lehrformen gegenüberstellen. Ziel ist es Potentiale und Hindernisse von E-Learning als alternative Lehrmethode im Hochschuleinsatz zu erfassen, um Rückschlüsse für die Entwicklung, Weiterentwicklung, Optimierung und Einsatzform neuer oder bestehender E-Learning-Angebote zu ziehen. 
22.03.19;22.11.19;2019;extern;Master;DE;Einsatz maschineller Lernverfahren zur Genre-Klassifizierung von Brettspielen;"Neben anderen Bereichen hat der Digitalisierungsprozess auch in der Brettspielindustrie begonnen. Dabei können maschinelle Lernverfahren helfen, effizient mit den großen Datenmengen umzugehen. Eine potentielle Aufgabe von maschinellen Lernverfahren besteht in der Erstellung und Zuweisung von Klassen. Hierfür findet sich im Genre eine mögliche Klassifizierungsart. Diese Arbeit hat das Ziel, Genre-Kandidaten aus den Spielen zu ermitteln und diese anschließend zuzuweisen. Dafür werden Verfahren aus dem Bereich Topic Modeling als Grundlage verwendet, wobei ausschließlich die Algorithmen LDA, HDP und LSA getestet wurden. Eine theoretische Auseinandersetzung mit pLSA wird jedoch zusätzlich beschrieben. Außerdem werden mehrere Modelle eines Algorithmus zusammen in einem Ensemble-Learning-Ansatz verwendet. Beim Topic Modeling entstehen gewichtete Wortlisten, die für verschiedene Themen stehen. Aus diesen Wortlisten können mit weiteren Verfahren Genres interpretiert und anstelle der Themen an die Spiele vergeben werden. In dieser Arbeit wird für die Themeninterpretation das Word-Embedding-Verfahren Word2Vec genutzt. Die entwickelten Methoden wurden für zwei Datensätze getestet. Zur Beurteilung der Ergebnisse daraus fanden in verschiedenen Phasen Evaluierungen beim Deutschen Spielearchiv Nürnberg statt. Bei der abschließenden Evaluierung erhielten die Ergebnisse eine durchschnittliche Bewertung zwischen ""Beschreibt das Spiel zum Großteil"" und ""Beschreibt das Spiel<br>vollständig""."
25.03.19;02.09.19;2019;intern;Bachelor;DE;Erstellung einer Webanwendung zur Visualisierung sozialwissenschaftlicher Texte;"In dieser Bachelorthesis wird das Thema Textanalyse, -aufbereitung und -visualisierung wissenschaftlich betrachtet. Es werden verschiedene Modelle und Methoden betrachtet und gezeigt, welche Visualisierungsmöglichkeiten für die Daten existieren und anhand welcher Variablen diese bestimmt werden. Außerdem lernt man Tools und Frameworks der Textvisualisierung zum selber ausprobieren kennen und sieht, welche davon für diesen Sachverhalt passend ausgewählt wurden.<br><br>Des Weiteren wird das Forschungsprojekt ""Computerunterstützte Analyse Sozialwissenschaftlicher Texte"" (Casotex) erläutert und näher auf das Teilprojekt ""Visuelle Analyse sozialwissenschaftlicher Texte"" (Casovis) eingegangen. Dieses wurde von der Fakultät Sozialwissenschaft, Fakultät Informatik und dem Institut für E-Beratung ins Leben gerufen. In dieser Bachelorarbeit erfährt man die Ziele, die Hintergründe und das Vorgehen dieses Projektes.<br><br>Es wird die Webanwendung Casovis beschrieben und alle dazugehörigen Anforderungen aufgeführt. Man sieht wie der aktuelle Stand der Anwendung ist und welche Funktionen vorhanden sind. Die Benutzung dieser wird auch erklärt. Außerdem wird darauf eingegangen welche Funktionen es in Zukunft noch geben wird."
27.03.19;27.11.19;2019;intern;Master;EN;Machine Learning Approaches to Emotion and Personality Detection in the Context of Social Counseling;
28.03.19;26.08.19;2019;extern;Bachelor;DE;HR-Cloud-Transformation -<br>Analyse zur Auswahl einer Digital Adoption Platform für SAP SuccessFactors in der Schaeffler Gruppe<br>;Für die Einführung von SAP SuccessFactors werden im Rahmen eines Harmonisierungsprojektes die Prozesse global an die Lösung angepasst. Folglich muss weltweit den Systemanwendern neues Prozesswissen und der Umgang mit der Software SAP SuccessFactors vermittelt werden. Die zukünftigen Nutzer der Software sollen durch den Einsatz einer geeigneten Digital Adoption Platform (DAP), die dem Benutzer interaktive Schritt für Schritt Touren durch die Prozesse zur Verfügung stellt, dabei unterstützt werden, sich das neue Prozesswissen und den Umgang mit einer neuen Software anzueignen. Außerdem soll der Anwender bei auftretenden Schwierigkeiten in einem Prozessschritt durch eine kontextbezogene Hilfe Unterstützung erhalten.  Dabei wurden im Rahmen der Bachelorarbeit die Anbieter Userlane und WalkMe im Hinblick auf ihre Eignung analysiert. Dargestellt wurde dabei der Ist- und Soll-Zustand, wie explizites HR-Prozesswissen im Unternehmen aktuell und zukünftig durch den Einsatz einer DAP bereitgestellt werden könnte. Zudem zeigten Experteninterviews, welche Potentiale interne Mitarbeiter bei einem Einsatz sehen. Außerdem wurden im Rahmen der Befragungen Anforderungen aufgenommen, die an eine DAP und den zugehörigen Anbieter bestehen. Durch den anschließenden Einsatz einer Nutzwertanalyse konnte die DAP identifiziert werden, die in Hinsicht auf den Leistungsumfang die Bedürfnisse des Unternehmens am besten erfüllen kann und eine Handlungsempfehlung für die Anbieterauswahl abgeleitet werden. 
29.03.19;29.08.19;2019;intern;Bachelor;DE;Benutzerfreundliche und optimierte Generierung von prozeduralen Gangsystemen mit dem Levelgraph-Verfahren<br>;
01.04.19;02.09.19;2019;extern;Bachelor;DE;Prototypische Implementierung eines interaktiven Analyse-Dashboards auf Basis des referenzierten DATEV-Jahresabschlusses  ;Externe Adressaten wie z.B Steuerberater benötigen aussagekräftige Berichte und Dashboards, um sich einen schnellen Überblick über die wirtschaftliche Lage ihrer Mandanten zu verschaffen und so eine tiefergehende betriebswirtschaftliche Beratung leisten zu können. Zielsetzung der Bachelorarbeit liegt darin, ein Dashboard auf Basis des referenzierten DATEV-Jahresabschlusses als Prototyp zu realisieren. 
01.04.19;01.09.19;2019;extern;Bachelor;DE;Entwicklung und Implementierung eines Konzepts für die Automatisierung von administrativen Prozessen des User-Managements für Unix-Systeme;Unternehmen der freien Marktwirtschaft sind stehts angehalten sich weiterzuentwickeln und auf neue Technologien und Innovationen zu reagieren. Dabei ist dies nicht ohne genaue Analyse ihrer internen Prozesse und zur Verfügung stehenden Möglichkeiten umsetzbar. Es gibt viele Technologien die Großes versprechen, dies aber auch nur unter speziellen Gegebenheiten liefern.<br>Das Ziel dieser Forschung ist es zu bestimmen, welche Möglichkeiten der Modernisierung einem Prozess der Administration zur Verfügung stehen und wie diese abhängig der Systemstruktur genutzt werden können. Dabei steht im Vordergrund den bisherigen Zustand der Systeme zu beachten und so nur wirklich sinnvolle Modernisierungen im Rahmen dieser Arbeit in Betracht zu ziehen.<br>Dazu wurde ein solcher Prozess in der Form der Rechtevergabe von UNIX-Systemen innerhalb der DATEV eG genauer untersucht. Mit einer Analyse des bisherigen Zustands und verbreiteten Umsetzungen konnte so entschieden werden, dass eine Automatisierung mit Hilfe der bereits eingesetzten Technologien als vielversprechendes Konzept gilt.<br>Eine anschließende Umsetzung zeigte auf, dass zwar viele Hürden durch verwachsene und veraltete Systeme in großen Systemlandschaft genommen werden müssen, diese sich aber durch klare Effizienz- und Effektivitätssteigerungen auszahlen. Neuere Technologien wurden als weitere Möglichkeiten angesehen, auf die Prozesse angewandt zu werden, benötigen aber zusätzliche, vertiefte Forschungen.<br>
01.04.19;01.09.19;2019;extern;Bachelor;DE;Konzeption und Implementierung effizienter, paralleler Datenzugriffe für einen C#-basierten Webdienst;Die DATEV eG bietet eine Desktopanwendung zur Erstellung der Finanzbuchführung von Unternehmen an. Analog dazu wird eine Webanwendung entwickelt, die die gleiche Funktionalität zur Verfügung stellt. Um die Wartung sowie die Weiterentwicklung der Komponente zu erleichtern, sollen die Datenzugriffe beider Anwendungen vereinheitlicht werden.<br><br>Das Ziel dieser Arbeit ist die Erarbeitung eines einheitlichen Konzepts für die Datenverwaltung sowie die Datenzugriffe, bei dem die Anforderungen beider Anwendungen zu berück-sichtigen und aufeinander abzustimmen sind. Angestrebt wird außerdem, durch das neue Konzept die Dauer der Datenermittlung zu reduzieren.<br><br>Dazu wurden zunächst die Systemarchitekturen sowie die aktuell umgesetzten Lösungen der Anwendungen analysiert. Auf Basis der Ergebnisse wurde ein Konzept für eine anwendungsübergreifende Datenverwaltung entwickelt und implementiert, die sowohl auf hochgradig parallelisierte als auch auf sequentielle Datenzugriffe ausgelegt ist.<br><br>Die nach der Umsetzung des neuen Konzepts durchgeführten Tests zeigen, dass die Ermittlungsdauer der Daten im Vergleich zur heutigen Umsetzung teilweise erheblich reduziert werden konnte. Bei keinem der Tests wurden eine erhöhte Vorgangsdauer festgestellt.<br><br>Die durch die Konzeption und Implementierung gewonnen Erkenntnisse werden bei Neu- und Weiterentwicklungen von Anwendungen der DATEV eG berücksichtigt und sofern sinnvoll, wiederverwendet.<br>
01.04.19;01.09.19;2019;intern;Bachelor;DE;Bestimmung von Dehnungsereignissen in polymerophischen Fasern anhand von OTDR-Daten;
01.04.19;29.08.19;2019;extern;Bachelor;DE;Konzeption und Implementierung eines Tools zum Auslesen von Energiezählern über das Modbus-Protokoll bei der ProleiT AG<br>;Es wurde ein Tool entwickelt mit dem es möglich ist, Energiezähler über ein bestehendes Netzwerk, mithilfe des Modbus-Protokolls auszulesen. Sowohl die Konzeptionierung als die Implementierung wurde behandelt. Dies geschah in Zusammenarbeit mit der Firma ProLeiT AG.
01.04.19;29.08.19;2019;intern;Bachelor;DE;Robotic Process Automation: Analyse von Erfolgspotenzialen anhand von ausgewählten Fallbeispielen; 
03.04.19;03.09.19;2019;intern;Bachelor;DE;Einsatz maschineller Lernverfahren zur Entitätserkennung in der Trendanalyse;Ziel der Arbeit ist die Konzeptionierung eines lernfähigen Prototyps, der aus Texten Entitäten erkennt. Diese Entitäten sollen in einem Wissensgraphen geschrieben werden. Anhand der Veränderung des Wissensgraphen lassen sich Trends ablesen. Erkannte Entitäten müssen disambiguiert, vereinheitlicht und verlinkt, sein, um möglichst viele Informationen aus bestehenden Wissensgraphen einzubeziehen. Der Prototyp soll als eigener Service betrieben werden können und aus frei verfügbaren Tools sowie Frameworks bestehen.<br>Kern des Projektes ist die Arbeitsgruppe Future Engineering. Teil dieser Gruppe ist die TH-Nürnberg, vorrangig mit der Fakultät BW. Ein weiterer Projektbeteiligter ist das Fraunhofer Institut SCS aus Nürnberg. Abschließend gehört Trivadis zur Arbeitsgruppe. Trivadis ist ein Beratungsunternehmen mit Hauptsitz in der Schweiz.<br>Der Prototyp misst sich mit dem Tool TextRazor. Dieses bietet NLP als kostenpflichtigen Service für größere Datenmengen an. TextRazor ist dem Prototyp in Quantität wie auch Qualität überlegen. Im Rahmen der Evaluation sind die folgenden Verbesserungsmöglichkeiten ableitbar. Um die Quantität zu verbessern, empfiehlt sich eine Aufteilung mehrgliedriger Entitäten in deren Bestandteile.<br>In der Disambiguierung ist der Prototyp 5 % besser als TextRazor. Die Zielstellungen, nur aus freien Tools und Frameworks zu, ist ebenfalls erreicht. Eine LernfähiLernfähigkeit ist durch die Trainierbarkeit der eingesetzten Tools Spacy und Flair gegeben.
03.04.19;03.09.19;2019;intern;Bachelor;DE;Big Data Log-File Analytics - Vom Batch zum Stream<br>Konzeption und prototypische Implementierung eines REST-Webservice zum Streaming von Messwerten der DATEV Programmstatistik<br>;Um Auswertungen über die Nutzung der DATEV-Software tätigen zu können, existiert die sogenannte Programmstatistik. Hierbei werden mit der Einwilligung des Kunden (Anwenders) die Nutzerdaten erfasst und im Rechenzentrum der DATEV gespeichert. Die Daten werden als LogFiles über eine HTTPS-Verbindung an den Trackingserver von Mindlab, einem externen Anbieter, gesendet und anschließend durch ein Batch-Verfahren in einem Datenbank-Cluster abgespeichert.<br>Das Ziel der Arbeit besteht darin, die Abhängigkeit vom Fremdanbieter abzuschaffen, indem der Tracker von Mindlab durch eine eigene Lösung, in Form eines Prototypen, ersetzt wird. Zusätzlich wird eine Streaming-Architektur konzeptioniert, die als Alternative zum bisherigen Batch-Verfahren dient. Im Rahmen einer Anforderungsanalyse wird zunächst evaluiert, welche Funktionalitäten der Prototyp abbilden soll. Weiterhin wird untersucht, welche Voraussetzungen zum Streamen von Daten bestehen. Die gesammelten An-forderungen werden durch ein Architekturkonzept abgebildet und anschließend die ver-wendeten Entwicklungswerkzeuge in der Implementierungsphase dargestellt.<br>Das Ergebnis ist ein Springboot-Webservice, der als Prototyp konzeptioniert und entwickelt wurde und die Entgegennahme von Nutzerdaten im JSON-Format sowie das Abspeichern der Nutzerdaten in einer Dokumentendatenbank ermöglicht. Weiterhin wurde eine Architektur konzeptioniert, die den Einsatz einer Kafka-Pipeline berücksichtigt, um die Messwerte bereitzustellen.
05.04.19;05.09.19;2019;intern;Bachelor;DE;Objekterkennung mittels neuronaler Netze zur Anwendung in der Robotik;"Das in dieser Arbeit behandelte Kernthema, das Erkennen von Objekten in Bilddaten, stellt ein komplexes Problem dar, weil geometrische Körper durch ihre Lage im Raum, deren Beleuchtung und der Abbildung von drei auf zwei Dimensionen viele unterschiedliche visuelle Darstellungen einnehmen können.<br>Das Ziel dieser Arbeit ist es, eine Software zu entwerfen und zu implementieren, die in der Lage ist Bilddaten mithilfe neuronaler Netze so auszuwerten, dass alle vorher trainierten Objekte mit einer für den praktischen Einsatz signifikanten Genauigkeit erkannt werden können. <br>Nach einer Einarbeitung in ""Convolutional Neural Networks"", ist geplant, diese zur oben beschriebenen Auswertung einzusetzen. Nach der Einarbeitung in ""Convolutional Neural Networks"", wird eine noch zu findende konkrete Referenzarchitektur gewählt.<br>Nach dem Training des Modells mit offen zugänglichen Bilddatenbanken, wie zum Beispiel dem Open Image Dataset, soll der Roboter dazu in der Lage sein, zweidimensionale Bilddaten an eine Schnittstelle, welche das Modell anspricht, zu senden und als Resultat die zugehörigen Objekt-Klassifizierungen zurückgeliefert zu bekommen.<br>Abschließend soll ein interaktives, inkrementelles Lernen implementiert werden. Dafür werden dem Roboter zu erlernende Objekte präsentiert, die dem Modell dann über ""Incremental Learning"" beziehungsweise ""Online Learning"" zugeführt werden."
08.04.19;08.09.19;2019;extern;Bachelor;DE;Konzeptionierung und Implementierung einer prototypischen, webbasierten Oberfläche zur elektronischen Prüfung von Eingangsrechnungen in Kooperation mit der DATEV eG;Durch die Digitalisierung der Arbeitswelt und ihrer Prozesse beschleunigen sich Arbeitsabläufe in Unternehmen zunehmend. Im Zuge dessen steht eine fehlerfreie Verarbeitung betrieblicher Dokumente im Fokus eines jeden einzelnen Unternehmens. Unter verschiedenen Dokumentenarten sind es vor allem Rechnungsdokumente, die für Firmen monetäre Verbindlichkeiten mit sich bringen. Damit ausschließlich syntaktisch und semantisch korrekte Rechnungen intern weiterverarbeitet werden, bedarf es einer softwarebasierten Lösung, welche die erforderlichen Arbeitsschritte für den Benutzer angenehm gestaltet und wenn möglich sogar automatisiert. <br>Im Rahmen dieser Arbeit wird deshalb eine webbasierende, prototypische Oberflächenanwendung für die DATEV eG konzipiert und anschließend implementiert, die sowohl die manuelle Prüfung, als auch exemplarisch die automatisierte Prüfung von Rechnungsdokumenten abbildet.<br>Durch die hinzugewonnenen Automatisierungsroutinen in der neu konzeptionierten Anwendung gewinnt die Lösung an Attraktivität für Unternehmen, deren Effizienz im Prüfungsworkflow durch diese Lösung gesteigert werden kann. Zusätzlich bietet eine webbasierende Lösung für Mitarbeiter in Unternehmen und Kanzleien neue Möglichkeiten, da der Rechnungsprüfungsprozess mobil verfügbar gemacht wird. Eine intuitiv gestaltete Oberfläche des Prototypen nach zeitgemäßen Usability Anforderungen trägt ebenfalls zu einem professionellen und zugleich effizienten Einsatz eines neu
09.04.19;06.09.19;2019;extern;Bachelor;DE;Migration einer nativen Desktopanwendung in eine Webanwendung: Konzeptionierung und prototypische Implementierung für das ERP-System v.Soft der Firma Vepos GmbH & Co. KG;Die vorliegende Arbeit wird in Kooperation mit der Firma Vepos GmbH & Co. KG verfasst, wobei deren eigene ERP Software v.Soft als Referenz dient. Die bisherige Version der Software besitzt einige signifikante Schwachstellen. Aus diesem Grund wird in der Arbeit die Migration von v.Soft in eine Webanwendung betrachtet. Zunächst wird die bereits vorhandene Software untersucht, wobei grundlegende Nachteile und daraus resultierende Problem kritisch betrachtet werden. Aus der Analyse der vorhandenen Schwachstellen wird die Notwendigkeit von neuer Technologie diskutiert. Während der Konzeptionsphase werden Anforderungen definiert, der Einsatz der verwendeten Designsprache vorgestellt und anwendbare Technologien verglichen. Die darauffolgende Implementierung besteht aus der Vorstellung der eingesetzten Technologie sowie der Umsetzung des Prototyps. Die Umsetzung der Anwendung besteht aus den beiden Komponenten Frontend und Backend. Für das Frontend wird zunächst eine grundlegende Anwendung entwickelt. Die entstehende Anwendung wird durch die Umsetzung von verschiedenen Masken erweitert. Das Backend stellt eine RESTful-API dar und verwaltet die Kommunikation zwischen Client und Datenbank. Als Resultat der Arbeit entsteht eine plattformunabhängige Webanwendung, die sowohl als Desktopanwendung als auch als Android-App vorliegt. Dadurch soll die theoretische Durchführbarkeit der Migration in eine Webanwendung bestätigt werden.
09.04.19;26.06.19;2019;intern;Master;EN;Exploring employee onboarding processes for captive offshoring initiatives ;The centralization of services provided by human resources teams allows companies to rely on measurable, standardizable talent acquisition and recruiting processes. Nevertheless, when responsibility for further training and engagement initiatives is transferred to the corresponding team who hires a new employee, different management perspectives may lead to several solution plans intended to accelerate productivity and improve long-term commitment of new employees. In the specific case of captive offshoring schemes, newly enrolled employees need close integration to the company, but they have limited access to resources. This thesis aims to review experience reports, scientific recommendations and successful approaches led by experienced captive offshoring teams, in order to identify main guidelines and suggest a process to unify these efforts. The obtained model is reviewed by a group of domain experts.
11.04.19;30.09.19;2019;intern;Master;DE;Konzeption eines Assistenzsystems zur Unterstützung von Studieninteressierten bei der Entscheidung für ein MINT-Studium;Damit es im nachgelagerten Studienverlauf nicht zum Studienabbruch kommt, wird auf Basis einer Anforderungserhebung und einer Analyse des aktuellen Beratungsangebotes der TH Nürnberg ein Assistenzsystem für Studieninteressierte konzipiert und prototypisch umgesetzt. Anschließend erfolgt eine Untersuchung der Prototypen in einem Testpanel, gefolgt von der Analyse der Versuchsergebnisse und einem Ausblick auf die weitere Umsetzung.<br><br>Ziel bei der Konzeption dieses Assistenzsystems war die Unterstützung von Studieninteressierten von in MINT-Studiengängen unterrepräsentierten Gruppen (z.B. Studierende aus nicht-akademischen Haushalten, Studierende mit Migrationshintergrund, ?), indem diesen bereits im Vorfeld des Studiums eine Einschätzung ermöglicht wird, ob bzw. unter welchen Voraussetzungen ein Studium im MINT-Bereich wahrscheinlich erfolgreich abgeschlossen werden kann.<br><br>Dazu wurden auf Basis wissenschaftlicher Studien sowie von Studierendendaten und Forschungsarbeiten der TH Nürnberg die Gründe für einen Studienabbruch und die Zusammenhänge zwischen einer Zugehörigkeit zu im Studienumfeld unterrepräsentierten Gruppen und dem Abbruch des Studiums untersucht. Unter Einbezug des vorhandenen Beratungsangebotes der TH Nürnberg erfolgte dann die Konzeption eines Assistenzsystems, das die bereits vorhandenen Angebote der Hochschule sinnvoll ergänzt und dadurch die Zielgruppe bereits in der Orientierungsphase vor einem Studium unterstützt.
11.04.19;29.11.19;2019;intern;Master;DE;Konzeption eines Frühwarn- und Assistenzsystems zur Bewahrung von MINT-Studierenden vor einem Studienabbruch;Um gefährdete Studierende vor einem Studienabbruch zu bewahren, sollen diese frühzeitig erkannt und durch geeignete Maßnahmen und Leistungen aktiv unterstützt werden. Der Fokus liegt auf Studierende in MINT-Studiengängen, die einer minderpräsentierten Studierendengruppe (z.B. Studierende aus nicht-akademischen Haushalten, mit Migrationshintergrund, ?) angehören. Hierfür soll ein Frühwarn- und Assistenzsystem konzipiert und prototypisch als webbasiertes Portal implementiert werden, indem sich Studierende über digitale Bildungsmaßnahmen, wie Beratungsangebote und Hilfeleistungen, informieren und bei Bedarf in Anspruch nehmen können.
11.04.19;11.09.19;2019;intern;Bachelor;DE;Nutzen und Grenzen von sozialen Netzwerkanalysen im Unternehmen;Die vorliegende Arbeit behandelt die Fragestellung, wie Unternehmen von sozialen Netzwerkanalysen profitieren können.<br><br>Es werden die Grundlagen der sozialen Netzwerkanalyse und ihre Einsatzmöglichkeiten in einem Unternehmen erläutert. Dabei erfolgt eine Vorstellung zentraler Konzepte dieser Methode sowie die Erklärung wichtiger Grundbegriffe.<br><br>Das Potenzial der sozialen Netzwerkanalysen wird anhand einiger Anwendungsszenarien erörtert und ihr Nutzen für ein Unternehmen wird dargestellt. Die Phasen einer organisationalen Netzwerkanalyse werden anhand zweier Verfahren aus der Fachliteratur beschrieben.<br><br>Anschließend werden die Datenerfassung, die Datenaufbereitung und die Analyse informeller Netzwerke behandelt und die Herausforderungen, die damit verbunden sind, dargelegt.<br><br>Abschließend wird eine exemplarische Analyse anhand einer fiktiven Fallstudie beschrieben, bei der die Zusammenarbeit innerhalb eines Thinktanks mithilfe der organisationalen Netzwerkanalyse untersucht wird.<br><br>Die Auswertung von Fachliteratur bildet die Grundlage für die Beantwortung der Fragestellung.
25.04.19;23.09.19;2019;extern;Bachelor;DE;Konzeption, prototypische Entwicklung und Implementierung eines Scrumpoker-Plugins für die Portal-Software Liferay;Im Rahmen dieser Bachelorarbeit wird ein Scrumpoker Plugin in Zusammenarbeit mit der Ancud IT-Beratung GmbH entwickelt. Dafür werden zwei verschiedene Tools untersucht, welche zum Schätzen von Anforderungen in der agilen Methode Scrum verwendet werden. Durch die Ist- und Schwachstellenanalyse haben sich Defizite herausgestellt, wodurch diese Tools in Projekten bei der Ancud nicht weiter genutzt werden konnten. Besonders die räumliche Trennung der einzelnen Teammitglieder stellt eine große Herausforderung dar. Anhand der gewonnenen Erkenntnisse werden Anforderungen definiert, die in dem eigens entwickelten Tool umgesetzt werden. Die Entwicklung des Tools basiert auf einem der Kernprodukte der Ancud IT, dem Liferay Portal. Die Version, die für die Umsetzung verwendet wird, ist die Liferay Portal CE 7.1 Version, welche zu Beginn der Bachelorarbeit die aktuelle Version ist. Für die Umsetzung wird auf das dynamische Komponentenmodell OSGi zurückgegriffen, welches eines der Kernbestandteile in der Entwicklung in Liferay darstellt. Verwendet wird in der Entwicklung ein Liferay Portlet sowie der Liferay Service Builder. Anhand eines geeigneten Datenbankschemas wird das Backend entwickelt. Das Frontend basiert auf Java Server Pages in Zusammenhang mit dem AUI und JQuery Framework. Der Austausch der Daten zwischen dem Frontend sowie dem Backend basiert auf dem Liferay Portlet Lifecycle.
25.04.19;25.09.19;2019;extern;Bachelor;DE;Entwurf und Realisierung eines Konzepts zur sicheren und zuverlässigen Integration einer Software-as-a-Service;Das Ziel der vorliegenden Bachelorarbeit war es, ein Konzept zur Integration einer Software-as-a-Service in die bestehende Infrastruktur der DATEV eG zu entwickeln. Dabei stand die Konzeption eines sicheren und zuverlässigen Integrationssystems im Zentrum dieser Arbeit. Hierfür wurden zunächst allgemeine Gefährdungen, die bei der Integration einer Software-as-a-Service zu berücksichtigen sind, identifiziert. Anschließend wurden die Anforderungen analysiert, die für ein sicheres und zuverlässiges Integrationskonzept erforderlich sind. Auf dieser Basis konnte ein Integrationssystem konzipiert werden, das den Gefährdungen entgegenwirkt. Zum Schluss wurde dieses Konzept anhand der vorher ermittelten Anforderungen evaluiert und eine Realisierungsmöglichkeit aufgezeigt. Es hat sich gezeigt, dass die identifizierten Anforderungen größtenteils im Rahmen des Konzepts erfolgreich berücksichtigt werden konnten, jedoch einzelne Maßnahmen in Form einer Softwarelösung realisiert werden müssen. Diese Realisierung wurde anhand eines Beispiels erläutert.
25.04.19;25.09.19;2019;extern;Bachelor;DE;Prototypische Entwicklung einer Webanwendung zur Administration projektspezifischer Hardware bei der e.solutions GmbH;Die e.solutions GmbH entwickelt Infotainment-Systeme für den Volkswagen-Konzern. Um die Systeme entwickeln und testen zu können, arbeiten die Mitarbeiter an ihrem Arbeitsplatz mit sogenannter projektspezifischer Hardware. Hierzu zählen jegliche Komponenten, die später in den Fahrzeugen verbaut werden. In der Vergangenheit ist es bei der Administration und Nachverfolgung dieser Hardware oft zu Schwierigkeiten gekommen. Im Rahmen dieser Arbeit wurden die Prozesse zur Administration der Hardware erfasst, analysiert und optimiert. Zur Unterstützung der Prozessabläufe wurde prototypisch eine Webanwendung entwickelt. Die Prozesse wurden dabei mithilfe der Business Process Model and Notation (BPMN) Spezifikationssprache dokumentiert. Zusätzlich sollte überprüft werden, ob die aktuelle Inventarsoftware zur unternehmensweiten Inventarisierung der Projekthardware durch eine geeignete Standardsoftware ersetzt werden kann. Diese Evaluation ist während der Arbeit relativiert worden, weil ein Team des Unternehmens bereits eine Standardsoftware namens Insight eingeführt hat. Die Standorte sind bezüglich des Einsatzes der Standardsoftware geteilter Meinung, weshalb für eine Einhaltung des zeitlichen Rahmens der Arbeit die Annahme getroffen werden musste, dass die Standardsoftware eingesetzt wird. Der resultierende Prototyp basiert auf dieser Annahme.
29.04.19;23.10.19;2019;extern;Master;DE;Klassifikation und Informationsgewinnung bei bankrelevanten Texten durch den Einsatz von maschinellen Lern- und Textanalyse-Verfahren;Banken und Finanzinstitute sind zahlreichen Regularien der deutschen und internationalen Behörden ausgesetzt. Damit diese nicht selbst nach neuen Regularien suchen müssen, wurde im Vorfeld dieser Arbeit bereits ein Webcrawler von Blue Reply erstellt. Diese Arbeit widmet sich der Weiterverarbeitung der gewonnen Daten und untersucht die Forschungsfragen, welche Informationen automatisch aus den Texten generiert werden können und wie gut sich die Texte klassifizieren lassen. Die Arbeit folgt in ihrem Ablauf dem CRISP-DM Model und legt besonderen Wert auf die Betrachtung unterschiedlicher Vorverarbeitungen und einer Vielzahl von Modellen. Die Ergebnisse werfen dabei vor allem die Frage auf, wie viel Vorverarbeitung wirklich nötig ist um die besten Ergebnisse erzielen zu können. Es konnte dabei nachgewiesen werden, dass jeder zusätzliche Vorverarbeitungsschritt bei bankrelevanten Texten die Ergebnisse der Verfahren und Klassifikatoren verschlechtert.
30.04.19;25.09.19;2019;intern;Bachelor;DE;Konzeption und prototypische Realisierung einer mobilen Webapplikation für Obdachlose;"Die steigende Anzahl an Obdachlosen in Nürnberg und fehlende digitale Angebote, die einen Mehrwert für die Obdachlosen schaffen, waren Ausgangspunkt eines IT-Projektes. Dieses wurde zusammen mit der Fakultät Informatik und dem Institut für E-Beratung durchgeführt, mit dem Ziel, eine Hilfe-App für Wohnungslose in Nürnberg zu entwickeln. Das daraus entstandene Konzept bildet die Grundlage der Bachelorarbeit. Dieses Konzept wurde mithilfe der nutzerorientierten Entwicklung weiterentwickelt und kritisch betrachtet. Auf Basis der daraus entstandenen Anforderungen wurde ein technisches Konzept entwickelt, das eine Grundlage für weitere Entwicklungen bietet. Zusätzlich wurde ein technischer Prototyp angefertigt, der eine modulare Software-Architektur anstrebt und eine Basis für eine weitere Entwicklung und Usability-Tests bietet. Die Arbeit ordnet sich in das Projekt ""Smart Inklusion für Wohnungslose"" (SIWo) des Instituts für E-Beratung der TH-Nürnberg ein und entstand in Zusammenarbeit mit diesem Institut. "
30.04.19;27.09.19;2019;extern;Bachelor;DE;Geruchsprädiktion aus Molekülstrukturen mittels Deep Learning;In unserem Alltag sind wir ständig von Gerüchen umgeben. Gerüche sind hochkomplex und sogar durch den technologischen Fortschritt fällt es uns schwer vorherzusagen, wie ein Molekül riechen wird. Bereits kleine Änderungen der Molekülstruktur können den Geruch verändern, welchen wir wahrnehmen. In vielen Bereichen wird Deep Learning bereits erfolgreich eingesetzt und bietet auch hier Potenzial. In den vergangenen Jahren wurde ein neuer Deep Learning Ansatz veröffentlicht, welcher Transformer genannt wird. Dieser unterscheidet sich von Recurrent Neural Networks und basiert auf die sogenannte Attention. In dieser Bachelorarbeit wird der Transformeransatz verwendet, um Gerüche anhand von Molekülstrukturen zu prädizieren. Diese Herangehensweise führt zu ähnlichen Ergebnissen, die durch andere Ansätzen erzielt wurden und bietet weiterhin Potenzial.
30.04.19;30.09.19;2019;extern;Bachelor;DE;Digitalisierung in der Landwirtschaft: Entwicklung einer App für die optimale Bearbeitung von Feldern;Die Zahl der Lohnunternehmer in Deutschland steigt immer weiter und in der Landwirtschaft ist kein standardisiertes Verfahren für die Aufgabenverteilung der Flächenbearbeitung vorhanden. Für die Felderidentifikation und -kommunikation soll eine App konzipiert und umgesetzt werden.<br>Um die Anwendung zu realisieren wurden verschiedene Programmiersprachen bezüglich der Erfüllung funktionaler Anforderungen verglichen und beurteilt. Anschließend wurden die Datenbank durch ein logisches Datenbankmodell, Userinterfaces durch Mockups und Programmlogiken und Userinteraktionen durch verschiedene UML-Diagramme konzeptioniert.<br>Auf Basis der Planung wurden die gestellten Anforderungen realisiert und abschließend die Qualität der Anwendung durch diverse Tests gesichert.<br>Das Ergebnis ist eine plattformunabhängige Anwendung, mit rufnummernbasierter Authentifizierung für Landwirte und Lohnunternehmer.<br>Der Landwirt ist nun in der Lage, seine Felder und Äcker zu verwalten sowie Maßnahmen zu erstellen. Jene Maßnahmen kann er an Lohnunternehmer senden, sodass diese die Aufgaben erledigen.
30.04.19;30.09.19;2019;intern;Bachelor;DE;Automatische Bewertung von Programmieraufgaben aus der Web-Entwicklung;Automatische Bewertung von Programmieraufgaben aus der Web-Entwicklung<br><br>Softwaretests und Testautomatisierung sind wichtige Bausteine moderner Softwareentwicklung. Gerade im Bereich der Web-Entwicklung gibt es zahlreiche Frameworks und Tools, die den Entwickler bei der Aufgabe, Softwaretests durchzuführen, unterstützen.<br><br>Im Rahmen der Ausbildung von Informatikern kommen häufig Programmieraufgaben zum Einsatz, die von den Studierenden zu lösen sind. Bei der anschließenden Bewertung der Aufgaben durch den Dozenten ergibt sich eine ganz ähnliche Situation. Die von den Studierenden entwickelte Lösung muss bestimmte Kriterien erfüllen, um positiv bewertet zu werden. Im Gegensatz zu den durchzuführenden Softwaretests außerhalb der Ausbildungssituation bestehen bei der Bewertung solcher Aufgaben jedoch gewisse Freiräume, die von automatisierten Test-Frameworks häufig nicht auf einfache Art und Weise abgedeckt werden können.<br><br>Daher wird in dieser Bachelorarbeit untersucht, inwiefern existierende Test-Frameworks, die für den automatisierten Test von Webanwendungen entwickelt wurden, dazu geeignet sind, die Bewertung von Programmieraufgaben im Rahmen der Lehre zu unterstützen. Dabei werden gewisse Test-Frameworks verglichen, Konzepte zur Umsetzung der Testfälle erarbeitet und anhand einer Aufgabenstellung implementiert, angewandt und die daraus resultierenden Ergebnisse ausgewertet und diskutiert.
01.05.19;30.09.19;2019;extern;Bachelor;DE;Analyse einer rechtskonformen Erhebung von personenbezogenen Nutzungsdaten auf mobilen Endgeräten und prototypische Implementierung am Beispiel der DATEV Programmstatistik;Die rechtlichen Aspekte sind ein wichtiger Punkt bei der Erhebung von personenbezogenen Nutzungsdaten in Softwareanwendungen. Welche Auswirkungen durch die gesetzlichen Rahmenbedingungen sowie technischen Einschränkungen im Umfeld mobiler Endgeräten für den Entwickler zu erwarten sind, klärt diese Arbeit. Zum einen werden die möglichen Datenquellen mobiler Endgeräte kategorisiert und zum anderen die Chancen sowie Risiken der Datenanalyse ermittelt. Die vorgeschlagenen Präventionsmaßnahmen sollen die bestehenden Risiken, wie beispielsweise den Datenmissbrauch, minimieren. Die Ergebnisse wurden gebündelt bei der Entwicklung einer prototypischen Implementierung angewendet. Zum Schluss folgt die Beschreibung der Umsetzung, wie die Erfassung der Einwilligung des Anwenders und die Datenerfassung sowie Datenübermittlung auf mobilen Endgeräten implementiert wurden. Der Prototyp wird künftig weiterentwickelt und soll letztendlich in den produktiven Apps der DATEV Verwendung finden.
01.05.19;30.09.19;2019;extern;Master;DE;Enterprise Digital Rights Management als Instrument zur Flexibilisierung von IT-Arbeitsplätze bei einem Software- und IT-Dienstleister - Analyse und Umsetzungskonzept bei der Firma DATEV eG;
01.05.19;31.10.19;2019;extern;Bachelor;DE;Konzeption und Entwicklung einer prototypischen Cross-Plattform-App zur Störungskommunikation im RZ-Umfeld;Bereits Xamarin ermöglicht, eine breite Basis geteilten C# und Codes auf den Zielplattformen iOS, Android und Windows 10 wiederzuverwenden, um Wartungsaufwand zu reduzieren. Xamarin.Forms, eine Weiterentwicklung des Cross-Platform-Frameworks von Microsoft, ermöglicht darüber hinaus die Auslagerung gemeinsamer UI-Logik. Während mittels nativer Entwicklung mit Xamarin - eine wohlüberlegte Softwarearchitektur vorausgesetzt - maximal 80% des Codes (Geschäftslogik und Datenzugriffsschicht), plattformübergreifend verwendet werden kann, da für jede Zielplattform ein eigenes User Interface programmiert werden muss, verspricht Xamarin.Forms, über diesen Anteil geteilter Logik hinauswachsen zu können, was anhand eines Prototyps demonstriert wird.<br><br>Inwiefern Xamarin.Forms inzwischen geeignet ist, UI-Elemente auf den verschiedenen Zielplattformen Android, iOS und Windows 10 anzusprechen, um einen höheren Anteil geteilten Codes erreichen zu können, soll eruiert und im konzeptionellen Teil dieser Arbeit eingebracht werden. Ziel des Praxisteils dieser Arbeit ist die Konzeption einer Cross-Platform-App zur Kommunikation von Störungsmeldungen innerhalb von Rechenzentren inklusive eines lauffähigen Prototyps, der als Proof-of-Concept der Möglichkeit herangezogen wird, Code für ein User Interface zielsystemübergreifend wiederzuverwenden. Geschildert wird ein Szenario, in dem der Einsatz von Xamarin.Forms gegenüber einer nativen Entwicklung für drei verschiedene Systeme vorzuziehen ist.<br>
02.05.19;30.09.19;2019;intern;Bachelor;DE;Entwicklung einer Bluetooth-gestützten Applikation zur Organisation und Kommunikation im Veranstaltungssegment;Diese Arbeit zeigt die prototypische Entwicklung einer Bluetooth-gestützten Applikation zur Kommunikation und Organisation im Veranstaltungssegment auf. Dabei werden zunächst die Grundlagen erörtert, anschließend Anforderungen erhoben, konzipiert, implementiert und evaluiert.
02.05.19;02.10.19;2019;intern;Bachelor;DE;Evaluation von Multi-Modell-Datenbankkonzepten zur Verwaltung polystrukturierter Daten;Das Ziel dieser Bachelorarbeit ist es, ein Evaluationsschema zu entwickeln, mit dem sich Multimodelldatenbanksysteme anhand von konkreten Anwendungsszenarien be-werten lassen. Hierzu wurde sich zunächst ein Anwendungsszenario überlegt, welches zum Speichern der Daten, mehrere Datenmodelle benötigt. Die verschiedenen Daten-modelle wurden dann auf ihre Vor- und Nachteile, sowie auf ihre möglichen Anwen-dungsgebiete untersucht. Es wurde sich daraufhin ein Marktüberblick über die ver-schiedenen Multimodelldatenbanken verschafft. Die Multimodelldatenbanksysteme ArangoDB, OrientDB, MarkLogic und MySQL wurden genauer im Hinblick auf Daten-modell, Transaktionen und Abfragesprachen untersucht. Schließlich wurde ein Bewer-tungsschema entwickelt. Anhand von dem überlegten Anwendungsszenario wurde das Bewertungsschema mit den untersuchten Multimodelldatenbanksystemen durchge-führt. Dabei hat sich herausgestellt, dass für den Anwendungsfall OrientDB die am bes-ten geeignete Multimodelldatenbank ist. Im Hinblick auf Performance, beim Laden und Abfragen von Dokumenten, sind die untersuchten Multimodelldatenbanken bei kleinen Datenmengen genauso schnell wie die Dokumentendatenbank MongoDB. Bei großen Datenmengen bricht die Performance allerdings stark ein.  
02.05.19;02.10.19;2019;extern;Bachelor;DE;Konzeption und prototypische Implementierung eines HA-Clusters als Infrastruktur eines mittelständischen Unternehmens.;Ziel dieser Arbeit ist es, ein vollständiges Konzept für eine hochverfügbare Clusterlösung zu entwerfen und mögliche Lösungen zu evaluieren. Dabei sind folgende schon bekannte Anforderungen zu berücksichtigen:<br>- Horizontale Skalierbarkeit<br>- Live Migration<br>- kein Single-Point-of-Failure<br>- Backup und Desaster Recovery<br><br>Ein weiteres Ziel ist die prototypische Umsetzung des Konzepts auf eigens dafür ausgesuchter Hardware.
07.05.19;07.10.19;2019;extern;Bachelor;DE;Analyse, Klassifizierung und Visualisierung von Daten zur Ermittlung von Optimierungspotenzialen bei der Sparda-Bank Nürnberg eG;Ausgangssituation<br>Mit der voranschreitenden Digitalisierung werden stetig mehr Daten generiert und gespeichert. Das Bankwesen ist davon ebenfalls betroffen. Um zu prüfen, ob und welche Daten über Optimierungspotenziale verfügen und wie es um die jeweilige Datenqualität steht, wird im Rahmen dieser Arbeit eine Datenanalyse bei der Sparda-Bank Nürnberg eG durchgeführt. <br>Problemstellung<br>Eine konkrete Datenanalyse zur Prüfung der Datenqualität sowie möglicher Optimierungspotenziale hat bisher nicht stattgefunden.<br>Zielsetzung<br>Das Ziel dieser Arbeit ist es, anhand von zwei Use-Cases zu prüfen, welche Daten für eine Analyse dieser Use-Cases in Frage kommen, wie es um die Datenqualität steht und welche Optimierungspotenziale daraus resultieren können.<br>Vorgehen<br>Für die Datenanalyse werden die Use-Cases definiert. Anschließend wird geprüft, welche Daten für die jeweiligen Use-Cases in Frage kommen, bzw. für Analysen verwertbar sind. <br>Die ermittelten Datensätze werden bereinigt, transformiert und anschließend in Microsoft Power BI für Visualisierungen geladen. Die Bereinigung und Transformation erfolgt mit dem Tool Jupyter Notebook. <br>Anhand der Resultate der Transformation und Visualisierung der Daten, werden mögliche Optimierungspotenziale sowie Handlungsempfehlungen vorgeschlagen.<br>Ergebnisse<br>Optimierungspotenziale und Handlungsempfehlungen werden u. a. für die Verbesserung der Datenqualität vorgeschlagen. Die Einführung eines Dashboards gehört auch zu einer der Empfehlungen.<br>
07.05.19;04.10.19;2019;extern;Bachelor;DE;Konzeption und Entwicklung eines E-Mailverificationsmicroservices für ein Data Providing System;Gegenstand dieser Arbeit ist die Konzipierung und Entwicklung einer Anwendung, wel-che E-Mail-Adresse verifiziert. Die Anforderungserhebung beschreibt die Anforderun-gen, die an das Gesamtsystem gestellt werden. Unter dem Einsatz der analysierten Techniken und unter Berücksichtigung der Anforderungen wird ein Konzept der An-wendung entwickelt. Dieses wird in der Programmiersprache Java mit den entspre-chenden Techniken implementiert. Es wird ein geeigneter Algorithmus der Prüfung der E-Mail-Adressen umgesetzt. Eine Validierung der Implementierung erfolgt mit Hilfe von verschiedenen Tests.
13.05.19;05.08.19;2019;extern;Bachelor;DE;Konzeption einer zentral verwalteten Linux-Server-Infrastruktur für ein hochskalierbares Umfeld;Eine Bedarfsanalyse hat die Notwendigkeit der Bereitstellung des Betriebssystems Linux ergeben. Der Betrieb des Betriebssystems erfordert eine zentrale Verwaltung. Mithilfe dieser Arbeit soll das Vorgehen zur Auswahl einer passenden Verwaltungssoftware dargestellt werden. Die Verwaltungssoftware soll verschiedene Aufgaben wie das Life-Cycle-Management, die Provisionierung, die Konfiguration und das Patch-Management von physischen und virtuellen Servern übernehmen. Mit der Arbeit soll geprüft werden, ob für den vorgesehenen Einsatzzweck eine passende Software zur Verfügung steht und ob diese auch in die vorliegende Infrastruktur integriert werden kann. Auch ist Bestandteil der Prüfung, wie das Verwaltungstool zur Skalierbarkeit der Umgebung beitragen kann und ob die Technik des Tools die gestellten Anforderungen auch in größeren Umgebungen erfüllen kann. Es konnte für den relevanten Einsatzzweck ein geeignetes Verwaltungstool gefunden werden, das alle Anforderungen erfüllen kann. Es handelt sich dabei um ein Open-Source-Produkt, das kostenlos genutzt werden kann und durch seine vielfältige Einsetzbarkeit die Integration in die vorliegende Infrastruktur ermöglicht. Die Bereitstellung von automatisierten Verfahren sorgt für die Beherrschung eines wachsenden Umfelds, jedoch erfordert die konzipierte Lösung eine wiederkehrende Anpassung der Infrastruktur des Verwaltungstools, um auf die Zunahme von verwaltenden Servern entsprechend reagieren zu können.
15.05.19;15.01.20;2019;extern;Master;DE;Effektive Datenintegration für verbesserte Geschäftsprozesse im Anwendungsfall einer intelligenten Zeiterfassung für Projektarbeit;
16.05.19;16.10.19;2019;extern;Bachelor;DE;Effiziente Überprüfung von Auftragsverarbeitern unter Zuhilfenahme von Prüfkatalogen;Effiziente Überprüfung von Auftragsverarbeitern unter Zuhilfenahme von Prüfkatalogen<br>Motivation der Arbeit:<br>Die neue Datenschutz-Grundverordnung (DSGVO) trat zum 25. Mai 2018 in Kraft. Mit der neuen<br>Verordnung werden die Regeln zur Verarbeitung personenbezogener Daten durch private<br>Unternehmen und öffentliche Stellen EU-weit vereinheitlicht werden. Dadurch soll einerseits der<br>Schutz personenbezogener Daten innerhalb der Europäischen Union sichergestellt, andererseits der<br>freie Datenverkehr innerhalb des Europäischen Binnenmarktes gewährleistet werden.<br>Die Ziele der DSGVO sind der Schutz der Grundrechte und Grundfreiheiten natürlicher Personen und<br>insbesondere deren Recht auf Schutz personenbezogener Daten (Art. 1 Abs. 2 DSGVO) und der freie<br>Verkehr personenbezogener Daten (Art. 1 Abs. 3 DSGVO).<br>Die vorangestellten Ziele sollen durch die in Art. 5 DSGVO festgelegten Grundsätze der Verarbeitung<br>personenbezogener Daten erreicht werden: Rechtmäßigkeit, Treu und Glauben, Transparenz,<br>Zweckbindung, Datenminimierung, Richtigkeit, Speicherbegrenzung, Integrität und Vertraulichkeit,<br>Rechenschaftspflicht.<br>Die Datenschutz-Grundverordnung wird das europäische Datenschutzrecht nicht völlig umwälzen,<br>weist aber eine Reihe von in der Praxis erheblichen Änderungen auf. Eine der wesentlichen Änderung<br>ist die stärker Fokussierung auf den technischen Datenschutz. Dieser ist sehr viel konkreter zu<br>beschreiben und eine korrekte Umsetzung nachzuweisen. Neu im Datenschutz ist auch der<br>risikobasiert
16.05.19;16.10.19;2019;intern;Bachelor;DE;Kursberechnungen und Steuerung eines autonomen Segelbootes;Diese Arbeit beschäftigt sich mit den Herausforderungen der Routenberechnung eines autonom fahrenden Segelbootes. Die Verwendung von Wind als einziges Antriebsmittel hat zur Folge, dass Aufgrund von Veränderungen der Windrichtung der Kurs immer wieder neu berechnet und angepasst werden muss. Dies macht Die Wegfindung beim Segeln prinzipell komplexer als bei anderen Fortbewegungsmitteln. Der Fokus dieser Arbeit liegt darin passende Algorithmen für die Routenberechnung zu finden und zu vergleichen, diese dann zu programmieren und zu implementieren und anschließend durch Testfahrten auf ihre Effizienz zu testen. Das autonom fahrende Segelboot soll in der Lage sein, entweder die schnellste oder die energieeffizienteste Route zu fahren. Die energieeffizienteste Route ist die Route, bei der das Segel und das Ruder möglichst wenig bewegt werden. Das Boot soll ebenfalls statischen Hindernissen ausweichen können. Zur Routenberechnung gehört der richtige Umgang mit Abdriften, Winddrehern und Böen, die Berechnung der Windrichtung unter Berücksichtigung des Fahrtwindes, sowie die Bestimmung des idealen Winkels des Segels zum Wind für die best mögliche Geschwindigkeit.
20.05.19;28.10.19;2019;intern;Bachelor;DE;Agiles Testen auf Weboberflächen - eine Guideline für Studenten;Die vorliegende Arbeit soll Studenten oder Quereinsteigern als Guideline dienen und das agile Testen auf Weboberflächen als standardisierten Prozess festhalten. <br><br>Neben den grundlegenden Begriffen und Methoden des Softwaretests werden auch praktische Beispiele anhand einer selbsterstellten Weboberfläche verdeutlicht.<br><br>Der Fokus dieser Arbeit liegt auf der Spezifikation und Ausführung von manuellen Testfällen.<br>
20.05.19;26.11.19;2019;intern;Bachelor;DE;Ideenmanagement: State of the Art;Ziel der vorliegenden Forschungsarbeit war, zwei zentrale General-Fragen zum Ideenma<br>nagement zu beantworten. Zum einen wie sich das heutige Ideenmanagement mit den sich<br>ständig wechselnden Anforderungen der digitalen und innovativen Marktdynamik in deut<br>schen Organisationen bewährt. Zum anderen Trends aufzuspüren, die in Zukunft für das<br>Ideenmanagement von Bedeutung sein können.<br>
20.05.19;18.01.20;2019;intern;Master;DE;Anonymisierung von natürlichsprachigen Texten;Ziel dieser Arbeit war die Erstellung eines Konzepts, das beschreibt, wie natürlich-<br>sprachige Texte sprach- und kontextunabhängig anonymisiert werden können. Um<br>das Konzept anschließend in der Praxis validieren zu können, sollte dieses ebenfalls<br>implementiert werden.<br>Das erstellte Konzept beschreibt dabei, welche Informationen in einem Text eine<br>Identifikation erlauben. Weiterhin besteht es aus zwei verschiedenen Phasen: zum<br>Ersten die Erkennung von sensiblen Informationen. Hierbei wird eine Kombination<br>aus regulären Ausdrücken, Wörterbüchern und Named Entity Recognition (NER)<br>genutzt. Zum Zweiten wird beschrieben, wie erkannte Informationen aus dem Text<br>entfernt werden können. Ferner definiert das Konzept drei verschiedene Stufen<br>der Anonymisierung, die je nach gewünschter Vertraulichkeit, verwendet werden<br>können.<br>Abschließend wurde das Konzept in der Programmiersprache Python implemen-<br>tiert. Die Evaluierung der Ergebnisse hat gezeigt, dass das Konzept dazu befähigt,<br>natürlichsprachige Texte weitestgehend zu anonymisieren. Weiterhin hat die Bewer-<br>tung ergeben, dass nicht alle Fälle von sensiblen Informationen automatisch erkannt<br>werden können. In diesen Fällen ist ein manueller Eingriff des Nutzers notwendig.<br>
23.05.19;30.09.19;2019;extern;Bachelor;DE;Interaktive Visualisierung von LKW-Komponenten mittels Augmented Reality;
23.05.19;23.10.19;2019;extern;Bachelor;DE;Business Process Optimization - Digitalisierung der Auftragsabwicklung innerhalb des Datenübergabeprozesses im Rahmen der Kündigung von DATEV-SmartIT / DATEVasp;"Im Rahmen dieser Arbeit wurde ein Geschäftsprozess der DATEV eG neugestaltet. <br><br>Nachdem der Kunde sein DATEV-Cloud-Sourcing-Produkt gekündigt hat, ist es ihm unter anderem wichtig, die Daten aus der Cloud übergeben zu bekommen. Der Datenübergabeprozess geht diesem Kundenwunsch nach. <br><br>Das konkrete Ziel dieser Arbeit war es, den manuellen Aufwand bei der im Datenübergabeprozess vorgesehenen Auftragsabwicklung durch Digitalisierungsmaßnahmen zu reduzieren.<br><br>Im ersten Abschnitt wurden die theoretischen Grundlagen zum Thema Geschäftsprozessmanagement dargestellt. Der Prozess wurde auf Basis der vorgestellten Modellierungssprache modelliert, um Verbesserungspotential aufzuzeigen. <br><br>Daraufhin wurde eine optimierte Auftragsabwicklung konzeptioniert, die die ermittelten Optimierungspotenziale umsetzt und frei von den zuvor erfassten Schwachstellen ist.<br>Dabei wurde auch diskutiert, ob es sinnvoll ist für die Digitalisierung des Prozesses eine eigene Software zu entwickeln oder der Einsatz von Standardsoftware genügt. <br><br>Nach der Realisierung erfolgte eine Evaluierung des Systems. Die Wirksamkeit der Optimierung wurde durch den Vergleich zum ""analogen Telefonprozess"" verdeutlicht. <br><br>Abschließend wurde ein Ausblick in die Zukunft gewährt. Hierbei wurden weitere mögliche Digitalisierungsansätze für den Datenübergabeprozess vorgestellt."
28.05.19;16.10.19;2019;extern;Bachelor;DE;Konzeption und Entwicklung einer Nachrichtenzentrale für ein plattformübergreifendes Mediaberatersystem mit Xamarin;Gegenstand dieser Arbeit ist die Konzeption und Entwicklung einer Nachrichtenzentrale für ein plattformübergreifendes Mediaberatersystem mit Xamarin. Zunächst wird die Entwicklung als native Anwendung der Verwendung des hybriden Frameworks Xamarin gegenübergestellt. Außerdem beinhaltet die Arbeit die Analyse des bestehenden Systems, aber auch von Techniken und Entwurfsmustern. Es wird auf die unterschiedlichen Funktionalitäten des Prism Frameworks und deren Verwendung eingegangen. Zusätzlich wird der Einsatz des Microsoft AppCenters zum Versenden von Benachrichtigungen untersucht und die Implementierung beschrieben. Abschließend werden die Komponenten- und Integrationstests mit dazugehörigem Mocking Framework erläutert.
28.05.19;25.10.19;2019;extern;Bachelor;DE;Untersuchung und Konzeptionierung des Einsatzes von IoT-Komponenten im ERP-System NAV;Die KUMAVISION versteht sich nicht nur als Anbieter von ERP-Systemen, sondern möchte ihren<br>Kunden eine umfassende Plattform zur Optimierung ihrer Geschäftstätigkeiten bieten.<br>Die Technologien aus dem Bereich IoT nehmen stetig zu. Wie sich die ERP-Lösung mit den Smart Devices verzahnen kann wurde analysiert.<br><br>Vorgehensweise:<br>- Untersuchung der Rahmenbedingungen<br>- Sammlung konkreter Möglichkeiten<br>- Betrachtung von Sicherheitsaspekten<br>- Erstellung einer Nutzwertanalyse<br>- Prototypische Umsetzung<br><br>Ergebnisse:<br>- Nutzung von Bilderkennung in dem Bereich der Produktion<br>- Konzeption eines maschinengestützten Handlagers<br>
17.06.19;30.01.20;2019;extern;Master;DE;Einfluss verschiedener Inertial- und Funksensordaten auf die Posenschätzung von Menschen mittels Rekurrenter Neuronaler Netze;In localization, tracking, and navigation applications, it is important to precisely determine human movements and predict their path to prevent accidents, avoid collisions, and to accomplish effective human-computer interaction. In such scenarios, position and orientation (pose) error of a few decimeters or degrees or a (temporary) failure of the entire localization system leads to the respective traffic participants being in an apparently offset pose. Especially in difficult situations, complementary sensor system, consisting of radio and inertial measurement unit (IMU) sensors, help to get information about the current pose over time. Recent research has shown that data-driven end-to-end learning methods such as Recurrent Neural Networks (RNNs) are much easier to model than Kalman filters, learn complex, non-linear motion patterns of humans, and successfully map even variable changes of the measurement?s environment in their architecture. Based on the DeepIO architecture, LSTM- and GRU-RNNs model the individual movement behavior of 14 training- and 1 test- subjects, despite a small amount of data (405 min). LSTM- and GRU-RNNs process the input sequences such that they generalize from known, elliptical trajectories to unknown, random trajectories. They simultaneously successfully predict, i.e., extrapolate, future motion data, internally smooth inertial sensors data affected by sensor noise, and interpolate subsampled radio signals.
18.06.19;18.02.20;2019;extern;Master;DE;Erkennung und Klassifikation von Mustern sowie Ähnlichkeiten innerhalb der UI-Texte bei einem ERP-System;Das Ziel dieser Arbeit ist es Muster und Ähnlichkeiten in den UI-Texten eines ERP-Systems zu finden, um einheitliche Texte zu gewährleisten. Der Fokus liegt hierbei jedoch nicht auf der Ähnlichkeit des Inhaltes, sondern auf der Struktur dieser Texte. Dazu wurde die Struktur der Sätze anhand der Ähnlichkeiten von Parse-Bäumen sowie einer TF-IDF Matrix, auf Basis syntaktischer N-Gramme von Wortarten, abgebildet. Aufgrund fehlender Klassenzuordnung wurde das unüberwachte Verfahren der Cluster-Analyse zur Mustererkennung ausgewählt. Zum Clustering wurden unterschiedliche Verfahren verwendet und die erhaltenen Clusterzuordnungen wurden abschließend mit internen Validitätsmetriken bewertet und verglichen. Dabei fand eine bewusste Auswahl der Algorithmen K-Means, DBSCAN und HDBSCAN* statt.<br>Da vorher keine Information zum Unterschied in den Mustern der Satzstruktur bekannt ist, beinhaltet die Selektion Verfahren zur potenziellen Ermittlung unterschiedlicher Cluster-Formen.<br>Durch die eingesetzten Verfahren, allen voran DBSCAN, konnten teilweise sinnvolle Clusterzuordnungen gefunden werden. Diese können in Zukunft zur Ermittlung von Texten mit Verbesserungspotenzial verwendet werden, um die Arbeit mit dem ERP-System für Anwender zu erleichtern.
20.06.19;20.02.20;2019;extern;Master;DE;Change-Controlling im IT Projektmanagement: <br>Qualitätssteigerung mithilfe von Data-Mining <br>;In dieser Masterarbeit wird die Fragestellung behandelt, wie Change-Management in ein IT-Projekt eingebunden werden kann. Dafür wird erforscht, welche Methoden, Techniken und Vorgehensmodelle es bereits in diesem Bereich gibt. Interessant ist auch, wie diese tatsächlich die bisher schlechte Erfolgsrate von Projektabschlüssen erhöhen können.<br>Das Ziel dieser Arbeit ist es deshalb Gründe für ein Scheitern von Change-Management zu identifizieren und anschließend anhand dessen herauszuarbeiten, wie ein solches Scheitern mittels Controlling und Data-Mining verhindert werden kann, sodass ein Mehrwert für das Unternehmen entsteht. Ein besonderes Augenmerk liegt hierbei auf dem Data-Mining und wie dieses im Change-Management sinnvoll eingesetzt werden kann.
28.06.19;21.11.19;2019;intern;Bachelor;DE;Analyse und Bewertung einer Mustersprache zur Beschreibung suchterzeugender Mechanismen in sozio-technischen Informationssystemen ;2. Fragestellung & Zielsetzung<br>Die Bachelorarbeit möchte drei, für diese wissenschaftliche Arbeit zentrale,<br>Fragen beantworten:<br>1. Weshalb sind gewisse Mechanismen suchterzeugend?<br>2. Kommen suchterzeugende Mechanismen in sozio-technischen<br>Systemen vor?<br>3. Kann man die identifizierten Mechanismen mit den Patterns (dt. Muster)<br>der Mustersprache Empamos beschreiben? Im Detail, verfügt die<br>Mustersprache genug Ausdrucksfähigkeit, um die erarbeiteten<br>Mechanismen zu charakterisieren?<br>Ziel der Arbeit ist es aufzuzeigen, weshalb bestimmte Mechanismen eine<br>suchterzeugende Wirkung besitzen.<br>Nach der Ausarbeitung wird betrachtet, ob die Mechanismen in soziotechnischen Systemen vorkommen.<br>Im selben Zuge wird die Zulänglichkeit der Mustersprache Empamos<br>daraufhin untersucht, inwiefern sie in der Lage ist, die suchterzeugenden<br>Mechanismen mithilfe der identifizierten Patterns zu beschreiben.
12.07.19;12.03.20;2019;intern;Master;DE;Deep-Learning Verfahren zur semantischen Segmentierung von Gebäudefassaden im sichtbaren und infraroten Bereich;In der vorliegenden Masterarbeit werden verschiedene Deep-Learning-Verfahren zur Semantischen Segmentierung von Gebäudefassaden betrachtet. Um neben den RGB-Aufnahmen der Fassaden zusätzlich deren Infrarot-Daten zu verarbeiten, werden zwei Convolutional Neural Networks entwickelt, die mit verschiedenen Fusionierungsvarianten arbeiten. Die Netzarchitekturen basieren auf der Encoder-Decoder-Struktur des State of the Art Frameworks DeepLab.<br>Die Architektur, die die Bildkanäle in zwei Netz-Strömen separat verarbeitet, kann dabei bessere Ergebnisse erzielen als die Architektur, die die Kanäle der RGB- und Infrarot-Daten gemeinsam verwendet. Als Erweiterung wird zudem Deep Generalized Max Pooling integriert und eine Variante untersucht, die dem Klassenungleichgewicht des Datensatzes entgegenwirkt. Zur Schärfung der Kanten wird eine Methode betrachtet, die auf dem Bilden von Edge Maps mithilfe des Sobel-Operators basiert. <br>Die Evaluierung erfolgt über einen projektspezifischen RGB-Infrarot-Fassadendatensatz, der im Rahmen der Arbeit annotiert wird. Insbesondere die Ergebnisse der Experimente ohne Erweiterungen bestätigen den Mehrwert der Infrarot-Daten. Allen Versuchen werden Trainingsvorgänge auf der Basis eines vortrainierten Modells gegenübergestellt, die durch die Feinabstimmung des Modells auf den Datensatz eine deutlich höhere Performance erreichen können.
15.07.19;15.03.20;2019;intern;Master;DE;Zeitliche Synchronisation von Video-Streams aus unterschiedlichen Spektralbereichen;Das Ziel der vorliegenden Masterarbeit war es, die zeitliche Differenz von zwei Videos aus unterschiedlichen Spektralbereichen mit Hilfe von Machine Learning zu berechnen. Die Datenbasis bestand aus Videoaufnahmen des infraroten und des für den Menschen sichtbaren Spektrums, die von einer Drohne aufgenommen wurden. Für die Beantwortung der Forschungsfrage, ob Machine Learning eingesetzt werden kann, um die zeitliche Differenz von Videos aus unterschiedlichen Spektralbereichen zu berechnen, wurde ein Prototyp konzipiert, implementiert und schließlich evaluiert. Im Rahmen der Konzeption wurde sich für ein Siamese Network mit Convolutional Neural Networks zur Berechnung der zeitlichen Differenz entschieden. Die Ergebnisse bestätigen, dass es möglich ist mit Ansätzen des Machine Learnings die zeitliche Differenz von Videos aus unterschiedlichen Spektralbereichen zu berechnen. Die zeitliche Differenz konnte mit einer Präzision von 0,5 Sekunden kalkuliert werden. Im Gegensatz zur ursprünglichen Annahme führte die zusätzliche Berechnung des optischen Flusses nicht zu einer Verbesserung der Ergebnisse. Hierbei war die Idee, durch die Berechnung des optischen Flusses die Unterschiede der Spektralbereiche zu minimieren und die Ergebnisse dadurch zu verbessern.
18.07.19;18.03.20;2019;intern;Master;DE;Anonymisierung von Drohnen-Videoaufnahmen;"Die im Mai 2018 in Kraft getretene Datenschutz-Grundverordnung stuft Videoaufnahmen in ein ""Verarbeitungsvorgang mit hohem Risiko"" ein. Betroffene Personen müssen bei fehlender Zustimmung durch eine Form des ""eingebauten Schutzes"" unkenntlich gemacht werden. Demzufolge wird ein System aufgebaut, das Gesichter automatisch detektiert und anhand von einfachen und Pseudo-Anonymisierungstechniken unkenntlich macht. <br><br>Die Arbeit orientiert sich an Drohnen-Videoaufnahmen im infraroten und sichtbaren Spektrum. Zu diesem Zweck werden verschiedene State-of-the-Art-Detektoren betrachtet. Während traditionelle Ansätze meist die Technik des gleitenden Fensters oder Pyramidenabbildungen anwenden, greifen moderne Methoden oft auf Deep-Learning-Algorithmen mit Convolutional Neural Networks zurück. Neben dem Einsatz von einfachen Filtern, werden bei der komplexeren Pseudo-Anonymisierung häufig Generative-Adversarial-Network-basierende neuronale Netze genutzt. Die höchsten Average-Precision-Werte konnte in beiden Spektren der Dual Shot Face Detector vorweisen. Zur Wahrung der Privatsphäre muss die Kombination aus einfachen Techniken angewandt oder auf die Pseudo-Anonymisierung zurückgegriffen werden. Aufgrund nicht überzeugender Ergebnisse einer Heatmap in Kombination mit einem Segmentierungs Generative Adversarial Network, wird die Delaunay-Triangulierung genutzt. Das Flickern in den resultierenden Videos wird am besten durch die Glättung der Merkmalspunkte durch den Kalman-Filter reduziert."
24.07.19;19.11.19;2019;intern;Bachelor;DE;Unterstützung von Führungsaufgaben im Informationsmanagement durch ausgewählte Aspekte der Unternehmensmodellierung<br>Anforderungen im Allgemeinen und Umsetzung speziell bei ARIS, MEMO und SOM;Wesentliches Ziel dieser Bachelorarbeit ist es, Potentiale der Unternehmensmodellierung zur Unterstützung der Anforderungen an die Führungsaufgaben im Informationsmanagement aufzuzeigen. Zu diesem Zweck wird anhand von Fachliteratur bestimmt, was unter Informationsmanagement und Unternehmensmodellierung zu verstehen ist. Dabei erfolgen eine wissenschaftliche Einordnung und Erklärung theoretischer Grundlagen. Aus dieser Begriffsbestimmung werden Anforderungen an die Führungsaufgaben des Informationsmanagements abgeleitet, die dafür genutzt werden, aufzuzeigen, welche Unterstützungsmöglichkeiten ausgewählte Aspekte der Unternehmensmodellierung im Allgemeinen und speziell bei den Konzepten Architektur integrierter Informationssysteme (ARIS), Multi Perspective Enterprise Modeling (MEMO) und Semantisches Objektmodell (SOM) bieten. Hierfür wird bei den Konzepten eine Evaluation durchgeführt, um darzustellen, wie mit diesen Konzepten die Anforderungen an die Führungsaufgaben unterstützt werden können. <br>
16.08.19;16.04.20;2019;intern;Master;DE;Fuzzy Budgetplanung mithilfe von Chatbots unter Verwendung der Methodik Computing with Words;
20.08.19;20.01.20;2019;intern;Bachelor;DE;Einführung von SAP Enable Now als unternehmensinterne e-Learning-Lösung: Kritische Betrachtung und Gestaltungsvorschläge;Ziel dieser Arbeit ist es, die Einführung einer e-Learning-Lösung (SAP Enable Now) kritisch zu betrachten und die Chancen herauszuarbeiten, die sich für die verschiedenen Bereiche eines Unternehmens ergeben. Die Einführung von SAP Enable Now ist in mehreren Bereichen denkbar. Die bisher verwendete unternehmensinterne e-Learning-Software kann dadurch abgelöst werden, die Erstellung von SAP-Dokumentationen wird durch die zusätzlichen Funktionen erleichtert und eine Entlastung für Routineanfragen im IT-Support werden erwartet. Das Tool soll eine einheitliche Plattform für e-Learning und Wissenstransfer realisieren. Die Arbeit analysiert den Nutzen des Systems, in welchen Bereichen ein Einsatz sinnvoll ist und in welchen Arbeitsbereichen dadurch verbesserte Prozesse erzielt werden können. Im Zuge dessen wurden verschiedene Methoden des Change Managements, eine Prozessanalyse und eine Kosten-Nutzen-Analyse zur Bewertung eingesetzt. Zusätzlich wurde an einer Lösung zur Audio-Erstellung gearbeitet und eine Reporting-Lösung entwickelt.
27.08.19;27.01.20;2019;extern;Bachelor;EN;Business process analytics with Celonis at Fresenius Medical Care -<br>Applicability of business analysis software for sustainable process optimisation;The study evaluates the applicability of the business process mining software Celonis at Fresenius Medical Care for sustainable process optimisation. Numerous large companies are already using the process mining software from Celonis and are convinced by this technology. The practical application at Fresenius Medical Care will now be used to analyse whether Process Mining can generate added value. Therefore, an internal survey had been conducted to capture stakeholder expectations. Besides, reports in the area of procure-to-pay have been implemented and evaluated with process experts. After the usage of Celonis within a business environment, it was revealed that Process Mining provides a new level of process transparency, but quantifiable value creation can be achieved only with downstream activities. Furthermore, Process Mining demands a shift of end-users mindset to use the potential of this technology entirely. The Celonis environment is continuously being developed, and this work is only a snapshot of the current situation at Fresenius Medical Care.
01.09.19;17.02.20;2019;intern;Bachelor;DE;Kontextbezogene Informationsbereitstellung für Studierende in den Räumlichkeiten einer Hochschule;Die vorliegende Bachelorarbeit befasst sich mit der kontextbezogenen Informationsbereitstellung an einer Hochschule. Dabei wurden Use-Cases mit Hilfe von Rechercheergebnissen entwickelt und durch eine Studierendenbefragung evaluiert. Auf Basis der Umfrageergebnisse wurden anschließend drei Use-Cases auf Basis des Content-Management-Systems umgesetzt. Zusätzlich wurde eine auf das CMS zugeschnittene DSGVO-konforme Erklärung erstellt.
03.09.19;07.06.20;2019;im Ausland;Master;EN;Classification of User Traits Based on Social Media Content Using Machine Learning;Image content shared on social media platforms provides a rich data source for research.<br>Various studies have addressed the connection between a user?s traits and their social<br>media content. This thesis explores the relationship between gender, age and Big Five<br>personality traits of 182 university students from Germany and their Instagram image<br>data. In regards to both image features as well as image content, significant differences<br>between genders as well as preferences related to age and personality traits emerged.<br>In a second step, gender, age and personality traits are predicted using machine learning<br>classification and regression methods. Results and performance measures are compared<br>with findings from previous studies and possible reasons for discrepancies are<br>provided. This work is the first of its kind to focus on data from European Instagram<br>users as well as predict age from Instagram image features and content on a fine-grained<br>level. Possible areas of application for the findings at hand are discussed and ethical implications<br>regarding the approach are addressed.
04.09.19;08.06.20;2019;extern;Master;DE;Erstellung von Softwaremetriken in der Automatisierungstechnik (Arbeitstitel) ;Ziel dieser Masterarbeit ist es, eine statische Code-Analyse als Verfahren und Prototyp zu entwickeln, die Entscheidern einen tiefergehenden Einblick in die Software ihrer Automatisierungsprojekte gibt. Dafür bietet das sogenannte TIA Portal, das Engineering-Framework in der Fertigungs- und Prozessautomatisierung der Siemens AG, eine Programmierschnittstelle, mit deren Hilfe die Softwarebestandteile eines Projekts automatisiert analysiert werden können. Die Entwicklung der statischen Code-Analyse bedient sich dabei Konzepten des Compilerbaus, der Softwaremessung und der Informationsextraktion aus Quellcode. Der Entwurf des Prototypen basiert auf Mitteln des User Experience Engineering und Konzepten der objektorientierten Programmierung.
16.09.19;01.03.20;2019;extern;Bachelor;DE;"Wandel der Anforderungen an die Informatik im Zeitalter von Industrie 4.0 am Beispiel eines ""Custom Visuals"" in Microsoft Power BI";"Diese Arbeit untersucht den Wandel und die Anforderungen an die Informatik im Verlauf der Zeit vor dem Hintergrund von Industrie 4.0. Die Veränderungen werden aus verschiedenen Blickwinkeln detailliert untersucht. Der Wandel erfolgte nicht nur in der Zuliefererindustrie, sondern auch im Schulunterricht und in der IT-Organisation. Der Fokus des Wandels in der Informatikgeschichte wird auf die klassischen Anwendungen und den Berufen bzw. Tätigkeiten des Wirtschaftsinformatikers gelegt. Der klassische Informatiker hat früher programmiert und heutzutage übernehmen viele Informatiker oder die sogenannten ""Citizen Developer"" schon vorhandene Entwicklungsumgebungen und erstellen damit Systeme und Anwendungen. Office 365 bietet viele Anwendungen, die auch ohne Programmierkenntnisse genutzt werden können. Citizen Developer sind Endnutzer, die an neuen Programmen arbeiten und ohne professionelle Unterstützung von Programmierern nicht arbeiten können.<br><br>Um den Wandel im Digitalisierungszeitalter zu erfragen wird folgende wissenschaftliche Frage formuliert: ""Wie haben sich die Anforderungen an die Informatik im Zeitalter von Industrie 4.0 gewandelt?"" <br>Diese wissenschaftliche Frage wird durch zwei Forschungsfragen detailliert beantwortet. Das Praxisbeispiel umfasst eine Erstellung eines Custom Visuals in Microsoft Power BI. Es wurde eine benutzerdefinierte Visualisierung auf Basis des Maturity Indexes erstellt."
17.09.19;21.01.20;2019;extern;Bachelor;DE;Maschinelle Identifikation von Verhaltensmodellen automatisierter Produktionsanlagen;Die Montage- und Prüfanlage Rollenhülse des Praxispartners Schaeffler besteht aus 23 Stationen, die alternierend diverse Montage- und Prüfaufgaben beinhalten. <br>Erfassbar sind stationsbezogene, diskrete Steuerungssignale, die dem Zustand eines Sensors bzw. Aktors entsprechen.<br>Die Automatisierung dieses Systems wird durch die Variation der Werte der Steuerungssignale erreicht<br>Beispielsweise kann der Näherungssensor 10A A73.0 (Station 10 Ausgang + individuelle  Bezeichnung) einen Gegenstand detektieren oder auch nicht (true /false).<br>Die Modellbildung und Überwachung des Systems gestaltet sich sehr komplex und die Überwachungslogik ist durch menschliche Experten manuell implementiert.<br>Die Lösung des Problems ist hierbei die Realisierung einer selbstlernenden, modellbasierten Zustands- und Prozessüberwachung.<br>
01.10.19;01.03.20;2020;extern;Bachelor;EN;Refactoring legacy .NET architectures towards asynchronous event-driven communication;Architectural refactoring can be used for behavior preserving software transformation. One such transformation is the introduction of asynchronous event-driven communication in synchronous applications. The basis for architectural refactoring is up-to-date architectural views which - when dealing with legacy software - are often missing. By exemplarily conducting such a transformation, this thesis explores options for architects and developers working with synchronous legacy .NET codebases to systematically analyze their software and introduce an event-driven architecture. To this end, architectural analysis tools available within the .NET ecosystem and an improvement method will be presented and used.
01.10.19;19.11.19;2020;intern;Bachelor;DE;Plastikmüll in unseren Ozeanen - Untersuchung verschiedener technologischer Ansätze zur Eindämmung der Meeresverschmutzung;Um das in den letzten Jahrzehnten entstandene Problem der Meeresverschmutzung einzudämmen, werden in dieser Arbeit technologische Entwicklungen nach ihrer Technik und ihrem Nutzen untersucht, die vorhandenen Meeresmüll aufsammeln, filtern und entfernen können. Darüber hinaus wird eine Online-Umfrage zum Ausmaß der Meeresverschmutzung durchgeführt. Zielgruppe für diese Befragung sind professionelle Tauchschulen, die qualitative Fragen zur aktuellen Lage der Verschmutzung sowie zur zukünftigen Hilfe durch Technik beantworten. Abschließend wurden ausgewählte Technologien mit Hilfe einer Nutzwertanalyse evaluiert. Es wurde ein Fazit aus den Ergebnissen gezogen und gezeigt, dass Technologien zwar helfen können, aber letztendlich noch mehr Aufklärung nötig ist und die Politik in der Pflicht ist.
01.10.19;28.02.20;2020;extern;Bachelor;DE;Konzeption und Entwicklung von Eingabemöglichkeiten für die flexible Abfrage von Informationen aus workflowgestützten Prozessen in einem Content-Management-System;In dieser Arbeit sollte ein Konzept gefunden und entwickelt werden, mit dem man Abfrage-Eingaben in einem Content-Management-System (CMS) für Anwender erleichtern kann. Als Software-Grundlage für das Konzept wurde das CMS SCHEMA ST4 (ST4) verwendet. Innerhalb von ST4 gibt es einen Workflow Designer, mithilfe dessen Workflows erstellt werden können, für die Informationen aus ST4 über STPath abgefragt werden können. STPath ist eine Obermenge von XPath und damit ebenfalls eine Abfragesprache für XML-Dokumente. Zur Unterstützung für die Konzeptentwicklung eines Editors wurden verschiedene Editoren auf Hilfestellungen für Nutzer untersucht. Ein Ergebnis der Recherche war, dass bei den Hilfestellungen der Editoren, für die kein XML-Dokument gebraucht wird, am häufigsten eine Syntaxhervorhebung implementiert wurde. Für den STPath-Editor im Workflow Designer wurde im Rahmen dieser Arbeit eine farbige Syntaxhervorhebung der Editoreingabe umgesetzt. Die Analyse für die eingegebenen Ausdrücke wurde so implementiert, dass man sie sowohl für XPath als auch für Obermengen von XPath verwenden kann. Zusätzlich wurde die Hervorhebung von Klammerpaaren implementiert. Anhand von Testdurchläufen wurde unter anderem festgestellt, dass durch die Hervorhebung der Syntaxelemente das Finden eines Fehlers im getesteten Ausdruck im Durchschnitt rund neun Sekunden weniger dauert. Durch den Zeitgewinn wird das Erstellen eines Ausdruckes effizienter und verringert die Frustration bei Anwendern.
01.10.19;20.02.20;2020;intern;Bachelor;EN;Is machine learning viable to predict short-term market reactions after business report releases?;Reading and understanding the text of annual reports is related with a considerable amount of work. This thesis examines a way to process the text automatically by predicting whether the report will lead to a positive or negative market reaction. The business reports are embedded using BERT. With the resulting embedding vectors and the market reactions a Naive Bayes, a kNN classifier, a SVM and a BLSTM were trained. The classification accuracy of 69.3% with the SVM leads to the conclusion that stock market prediction with machine learning is possible.
01.10.19;01.03.20;2020;extern;Bachelor;DE;Automatisierte Provisionierungsmechanismen für Laufzeitumgebungen von Legacy z/OS Anwendungen mit IBM Cloud Provisioning and Management for z/OS am Beispiel der Rechnungsschreibung bei DATEV eG;"Ziel dieser Arbeit ist es, zu bestimmen, ob die Bereitstellung von Laufzeitumgebungen für<br>legacy z/OS Anwendungen über einen cloud nativen, Platform-as-a-Service Ansatz bei DA-<br>TEV e.G. möglich ist. <br>Es werden folgende Forschungsfragen gestellt:<br>? Ist es möglich, den Bereitstellungsprozess für z/OS Anwendung bei DATEV e.G. mit<br>Hilfe des ""IBM Cloud Provisioning and Management for z/OS""-Tools an cloud native<br>Prozesse anzunähern?<br>? Erzeugt die Nutzung von ""IBM Cloud Provisioning and Management for z/OS"" einen<br>Mehrwert bei den Stakeholdern, also den Entwicklerteams und den Administratoren-<br>teams?<br><br>Dafür wurde anhand einer Beispielanwendung von der DATEV e.G. das Tool ""IBM Cloud Provi-<br>sioning and Management for z/OS"" untersucht. Es wurden zwei vorhandene Möglichkeiten<br>aufgezeigt, eine davon implementiert. Für ein Meinungsbild bezüglich Mehrwertes und Ak-<br>zeptanz des Tools, wurden Interviews mit Stakeholdern durchgeführt. Diese Bild zeigt, dass<br>in dem Tool eine Chance auf Verbesserung der aktuellen Prozesse gesehen wird.<br><br>Ergebnis war auch, dass die implementierte Variante nicht optimal für den Praxiseinsatz bei<br>DATEV e.G. ist, aber eine wichtige Basis für die automatisierte Bereitstellung von Lauf-<br>zeitumgebungen für z/OS Anwendungen darstellt. Weiterführende Forschung könnte darauf<br>aufbauend Variante zwei untersuchen und Möglichkeiten einer weiteren, praxisgeeigneteren Optimierung des z/OS Bereitstellungsprozesses aufzeigen."
01.10.19;01.03.20;2020;extern;Bachelor;EN;Automatic Speech Recognition for Quality Audits in Phone Conversations;Banks receive a large number of customer calls every day. In order to maintain a high level of service quality, some of these phone calls are periodically audited by specialists. This thesis investigates the automatic transcription and retrieval of information from conversational speech corpora, by implementing a speech recognition and indexing pipeline, that helps to perform quality audits in a financial institution automatically. A domain-specific data set is created by manually transcribing a small portion of the bank's call center recordings. <br>A speaker-independent acoustic model is trained from publicly available resources and combined with domain-specific language models built from the manually transcribed data. <br>After the creation and indexing of automatic transcripts, relevant speech segments are retrieved by applying individual search queries. <br>Word confusion networks are indexed and queried, in addition to the 1-best transcript. Experiments are conducted for two specific use cases on the subject of account opening and securities trading, to evaluate the speech recognition performance, as well as the retrieval quality of the search queries. This work shows that improvements in the retrieval quality are possible by exploiting the additional information available in word confusion networks. <br>Even though the word error rates of the speech recognition component remain quite high, the system is able to produce useful search results.
01.10.19;13.02.20;2020;extern;Bachelor;DE;Kann ein datengetriebenes Word Embedding-Modell einen redaktionellen Thesaurus für Query Expansion ersetzen?;Zwecks der Verbesserung von Suchergebnissen wird im Kontext des Information-Retrievals bei DATEV Query Expansion eingesetzt. Als domänenspezifische Datenquelle steht dafür ein redaktioneller Thesaurus zur Verfügung, in dem unterschiedliche semantische Konzepte hinterlegt sind. Die Pflege des Thesaurus und dessen kontinuierliche Aktualisierung erfolgt manuell und erweist sich als ressourcenaufwendiger Prozess. Daher ist das Ziel der vorliegenden Arbeit zu evaluieren, wie gut sich semantische Konzepte aus dem Thesaurus mit Word-Embeddings-Techniken automatisch konstruieren und unterscheiden lassen. Dafür sind vier Word-Embeddings-Modelle mit fastText auf Basis von Daten aus dem Servicebereich trainiert worden. Nach Art der semantischen Relation, wie z.B. Synonymie oder Hyponymie, ist die Güte der Embeddings dieser Modelle anhand von Word Similarity, Mean Absolute Error und <br>Thesaurusabdeckung ermittelt worden.<br>Das Wikipedia-Korpus-basierte Modell, das mit Service-Daten nachtrainiert wurde, hat beste<br>Ergebnisse bei der Thesaurusabdeckung über alle semantischen Relationen demonstriert.<br>Die Evaluationsergebnisse haben gezeigt, dass unter Beachtung von Auswirkungen auf Performance<br>sich nur ein kleiner Teil des Thesaurus konstruieren lässt. Die Unterscheidung nach<br>der Anzahl an relevanten semantischen Konzepten lässt sich mit Hilfe von topn-Parameter<br>und Similarity-Score bedingt beeinflussen.<br>Die Güte des Modells kann im weiteren Downstream Task evaluiert werden. 
01.10.19;01.03.20;2020;extern;Bachelor;DE;Entwicklung eines Backup-/Restore-Werkzeuges für Multiserver-Installationen von Steuerungssoftware verfahrenstechnischer Anlagen;Diese Bachelorarbeit widmet sich der Entwicklung eines Werkzeugs zur Sicherung und<br>Wiederherstellung von Datenbanken im Umfeld des Plant iT Prozessleitsystems der<br>Firma ProLeiT.<br>Problem: Das Sicherungs- und Wiederherstellungswerkzeug Project Saver existiert es<br>bisher nur für den Produktbereich Prozessleitsystem (PCS, Process Control System),<br>nicht aber für andere Produktbereiche. Ferner ist die Benutzeroberäche nach heutigen<br>Maÿstäben unästhetisch und wurde ohne Berücksichtigung von Aspekten der Usability<br>entwickelt. Ziel ist es daher, die Anwendbarkeit des Project Savers zu erweitern und<br>die Benutzeroberäche zu modernisieren. Zudem sollen die Architekturvorlagen Volere<br>und arc42 analysiert und bewertet werden.<br>Für die Anforderungsanalyse und den Architekturentwurf der geplanten Software sollen<br>die Architekturvorlagen Volere bzw. arc42 verwendet werden. Diese werden anhand<br>der Entwicklung analysiert und bewertet. Im Anschluss an die Implementierung wird<br>die Usability der Anwendung geprüft. Hierfür wird das Usability Engineering Team<br>der Firma ProLeiT zu Rate gezogen. Des Weiteren werden ein Funktionstest und ein<br>Performance-Test durchgeführt.<br>Resultat der Entwicklung ist die fertige Anwendung. Diese kann sowohl durch einfaches<br>Kopieren als auch per Setup bereitgestellt werden. Vor der Auslieferung wird die Anwendung jedoch noch von dem Quality Assurance Team der Firma ProLeiT ausführlich<br>getestet.<br>Die Architekturvorlagen Volere und arc42 wurden überwiegend positiv (cont.)
01.10.19;01.03.20;2020;extern;Bachelor;DE;Konzeption und prototypische Realisierung von automatisierten Tests für hybride Anwendungen;Im Unternehmen bestehen Infrastrukturen, um in den jeweiligen Bereichen (On-Premises und Webanwendungen) isoliert Unit-Tests bzw. Integrationstests durchzuführen. Allerdings sind diese Tests stets homogen, d. h. es besteht keine Möglichkeit hybride Schnittstellentests durchzuführen, die sowohl On-Premises- als auch Webanwendungsteile zugleich abdecken. Es soll ein Konzept entwickelt werden, das es ermöglicht, Schnittstellen zwischen OnPremises- und Webanwendungen im Rahmen des Entwicklungsprozesses kontinuierlich zu testen. Das Konzept beinhaltet Informationen zu der Vorgehensweise der Testausführung und der einheitlichen Ablage der Testergebnisse. Idealerweise können bestehende Technologien/Tests ohne große Anpassungen in die Lösung eingebunden werden. Es soll ein Prototyp realisiert werden, der erste Durchläufe mit bestehenden Technologien ermöglicht. Anhand eines Beispiels wird die Verwendung der erarbeiteten Lösung veranschaulicht.
01.10.19;01.03.20;2020;extern;Bachelor;DE;Aufbau einer Integrationsarchitektur für  ein Auslastungsanalysetool in Grafana;Im Rahmen der Digitalisierung steigt bei vielen Organisationen die Anzahl der Komponenten ihrer IT-Infrastruktur stark an. Dies geht mit einer erhöhten Komplexität der IT-Landschaft einher, was eine ganzheitliche Überwachung dieser mit traditionellen Überwachungstools erschwert. Im Rahmen der vorliegenden Arbeit soll eine Anwendung mit einer neuartigen 3D-Visualisierung, die das oben geschilderte Problem zu lösen versucht, in das Auslastungsanalysetool Grafana integriert werden. Das Ziel dieser Arbeit ist es zu untersuchen, inwiefern sich eine Integrationsarchitektur für Grafana konstruieren lässt, welche einerseits einen adäquaten Grad der Integration in Grafana ermöglicht, aber gleichzeitig eine angemessene Performanz und die Erweiterbarkeit der Architektur für ähnlich gelagerte Anwendungsfälle sicherstellt. Im Anschluss an die Umsetzung wird die fertige Architektur auf die geforderten Eigenschaften hin untersucht.
01.10.19;02.03.20;2020;extern;Bachelor;DE;KPIs eines Zertfikatsmanagement-Systems;Für das automatisierte Zertifikatsmanagement im Unternehmen wurde der Certificate Proxy (CertProxy) entwickelt. Mit Hilfe eines Administrationsprogramms wird automatisiert ein Client-Skript auf zahlreichen Servern ausgeführt. Durch dieses Skript wird ein Zertifikatsantrag erstellt und an den Certificate Proxy weitergeleitet. Der Proxy validiert die Anfrage und durchläuft verschiedene Security-Constraints. Bei erfolgreichem Durchlauf sendet der Proxy die Anfrage zur Zertifizierungsstelle. Diese händigt das Zertifikat über den Proxy an den Client aus.\Damit mehr Transparenz im System entsteht, sollen die relevanten Prozesse analysiert und ausgewertet werden. Anhand der Auswertungen sollen Key Performance Indicators (KPIs) definiert und anschließend auf einem Dashboard veranschaulicht werden. 
01.10.19;01.03.20;2020;extern;Bachelor;DE;Konzeption und Entwicklung einer Web-Applikation zur Visualisierung medizinischer Bilddaten auf HTML5 Clients durch server-seitiges Rendering;Microsoft stellt mit dem plattformübergreifenden Open Source Framework ASP.NET Core eine Technologie bereit, um Web-Applikationen zu entwickeln, welche durch Cloud Computing verfügbar gemacht werden können. Es erlaubt auch den Aufruf von Funktionen aus Software-Bibliotheken, die mit den Programmiersprachen C und C++ entwickelt wurden. Dadurch sollte es möglich sein, parallelisierbare Berechnungen durch die von NVIDIA bereitgestellte CUDA-Plattform, welche die Entwicklung von GPU-beschleunigten Anwendungen erlaubt, zu realisieren. Zudem bietet die Open Source-Bibliothek SignalR die Unterstützung der WebSocket-Technologie für ASP.NET Core-Anwendungen, um performante Datenverbindungen und Streaming-Szenarien zu ermöglichen. Um die Realisierung einer Web-Applikation mit hinreichender Leistungsfähigkeit durch den Einsatz der oben genannten Technologien zu zeigen, wurde im Rahmen dieser Bachelorarbeit ein System zur dreidimensionalen Visualisierung medizinischer Bilddaten konzipiert und entwickelt. Auf dem Server werden mit Hilfe von CUDA Volumendaten von DICOM-Dateien, welche von einem PACS abgerufen werden, auf ein zweidimensionales Bild durch Volume Rendering abgebildet. Das erstellte Bild wird anschließend durch Einsatz einer ASP.NET Core-Applikation über eine SignalR-Verbindung für Clients verfügbar gemacht. Für die Darstellung und Interaktion mit dem berechneten Modell auf der Client-Seite wird eine Angular-Applikation als grafische Benutzeroberfläche eingesetzt.
02.10.19;02.03.20;2020;intern;Bachelor;DE;Voll ausgearbeiteten Business Model Canvas, mit einer abschließenden Go/No-Go Analyse für einen Demonstrator.;Die vorliegende Bachelorarbeit beschäftigt sich mit der Entwicklung eines Ge-schäftsmodells für die Stottertherapie im Kontext des DVG. Als Ausgangslage dient ein bereits in der Entwicklung befindlicher Algorithmus, der nach gestotterten Silben in einer Sprachaufnahme auswerten kann.<br>Ziel dieser Arbeit ist es zu konzipieren, in welcher Form dieser Algorithmus in eine digitale Gesundheitsanwendung integriert werden kann, um so einen Mehrwehrt für potenzielle Kunden zu liefern und für gesetzlich Krankenversicherte eine Deckung der Kosten durch die Krankenkasse zu erhalten. Anhand der Methode der Customer Discovery werden verschiedene potenzielle Geschäftsmodelle erarbeitet.<br>Die folgende Bachelorarbeit beginnt mit Grundlagen zum Thema Stottern. Anschlie-ßend wird das Ecosystem rund ums Thema Stottern aufgezeigt. Im Anschluss wird die Erarbeitung des Geschäftsmodells und das finale Geschäftsmodell aufgezeigt. Abschließend wird noch ein Produktentwurf inklusive möglicher Preisgestaltung vor-gestellt.
02.10.19;09.01.20;2020;extern;Bachelor;DE;Adaptive EB GUIDE Studio 6 mit Machine Learning: Prototypische Implementierung eines Plugins zur Datensammlung und Vorhersage der nächsten Modellierungsschritte;Die vorliegende wissenschaftliche Arbeit behandelt die prototypische Implementierung eines Plugins zur Datensammlung und Vorhersage der nächsten Modellierungsschritte in EB GUIDE Studio 6.8. Hierbei wurde zunächst ein Plugin entwickelt, welches die Datensammlung der aktuellen Aktionen des Modellierers ermöglicht. Anschließend wurde mithilfe des Plugins ein Datensatz erstellt, welcher für das Training eines rekurrenten neuronalen Netzwerks verwendet wurde, welches Sequenzen lernen und auch Vorhersagen treffen kann. Dieses in Python selbst erstellte neuronale Netz wurde schließlich in den Quellcode von EB GUIDE Studio 6.8 in C# integriert und in das vorher implementierte Plugin zur Sammlung der Daten eingebunden, wo letztendlich eine erfolgreiche Vorhersage der nächsten Benutzeraktionen gelungen ist.
02.10.19;02.03.20;2020;extern;Bachelor;DE;Analyse und Überarbeitung des Graphical User Interfaces von EB GUIDE Studio 6 zur Steigerung der Usability;Die vorliegende wissenschaftliche Arbeit behandelt die Analyse und anschließende, teilweise Überarbeitung des User Interfaces von EB GUIDE Studio 6, mit der Zielsetzung dessen Usability zu verbessern.<br>Um dies zu erreichen, wird sich an den einzelnen Iterationsschritten des Human-Centered Design Process orientiert.<br>Für die Identifizierung der Schwächen im Interface werden Modellierer innerhalb der Zielgruppe bei ihrer täglichen Arbeit beobachtet und befragt.<br>Für drei dieser Schwächen werden, nach allgemein gültigen Gestaltprinzipien, Verbesserungen erarbeitet, welche teilweise mithilfe eines Prototyping Tools und teilweise, im bestehenden Projekt, mit C# und WPF umgesetzt werden.<br>Die zu bearbeitende Testaufgabe wird so ausgelegt, dass die Nutzer, während des Tests, mit allen eingearbeiteten Verbesserungen interagieren.<br>Um vergleichbare Werte zu erhalten, wird die Aufgabe von je fünf Nutzern mit dem bestehenden und dem überarbeiteten Interface durchgeführt.<br>Bei der Messung der Usability, wird bei der Auswertung der Tests auf die Effizienz und Fehlerrate der Nutzer geachtet.<br><br>Nach einer Iteration des Design Process wird deutlich, dass die Anpassungen die Usability teilweise erhöht haben, die Verbesserungen jedoch noch Schwächen enthalten, die Nachbesserung verlangen.<br>Hierfür können, aufbauend auf der, durch diese Arbeit bereit gestellten Grundlage, weitere Iterationen des Design Process durchgeführt werden, bis die Verbesserungen die Benutzeranforderungen hinreichend erfüllen.
04.10.19;04.03.20;2020;intern;Bachelor;DE;Auswirkungen der Digitalen Transformation auf den operativen Beschaffungsprozess bei einem Industrieunternehmen;Durch die vierte industrielle Revolution haben viele Unternehmen eine klare Vision für das<br>zukünftige Geschäft mit Blick auf den Einsatz von IT.<br>Industrie 4.0 bedeutet vor allem: neuartige Produktionsverfahren (z. B. 3D-Druck) und<br>Arbeitswelten. Neue Techniken, wie beispielsweise das Internet der Dinge (IoT) sollen<br>dabei mit zentralisierten und virtuellen Speicher den Benutzer bei seiner Tätigkeit<br>unterstützen.<br>Um die Veränderungen darzulegen wird in dieser Bachelorarbeit näher auf den operativen<br>Beschaffungsprozess eingegangen.<br><br>Beginnend wird die Siemens AG, speziell die Gas-und-Power-Division, näher beschrieben. Anschließend folgen eine Begriffsabgrenzung sowie die Beschreibung des Beschaffungsprozesses, damit der Leser einen Einblick in das Thema bekommt. Nach dem Beschaffungsprozess werden die vorhandenen Tools analysiert und in einer Matrix die Vor- und Nachteile visualisiert. Im dritten Kapitel wird durch Durchführung einer Literaturrecherche ein neues Gestaltungspotenzial näher beschrieben. Dies wird durch die Vorstellung von SAP Ariba für die operative Beschaffung geschehen. Außerdem werden dem Leser Trends, die in Beschaffungsabteilungen zum Einsatz kommen können mit Hilfe eines Beispiels erklärt. Im vierten Kapitel werden die Herausforderungen und Auswirkungen der Digitalen Transformation hervorgehoben. 
07.10.19;05.03.20;2020;extern;Bachelor;DE;Konzeption und Entwicklung eines Systems zur automatisierten Installation und Konfiguration von z/Linux Systemen;Auch in der heutigen Zeit werden Mainframes von vielen Unternehmen als zentrales System verwendet. Durch den Hypervisor z/VM und der Portierung des Linux-Kernels auf die Architektur des Mainframes, kann auf diesem eine große Anzahl an Linuxsystemen konsolidiert werden. Um diese effizient zu verwalten, werden häufig Konfigurationsmanagementtools eingesetzt. Der Support des bisher eingesetzten Tools Puppet wurde vom Hersteller der auf dem Mainframe betriebenen Linux-Distribution eingestellt. Deshalb wurde im Rahmen dieser Bachelorarbeit in Kooperation mit der Firma T-Systems Client Services ein neues Tool, für die Verwaltung der z/Linux Umgebung, eingeführt. Hierfür wurden die Tool Ansible und SaltStack nach einer Analyse miteinander und mit Puppet verglichen. Anschließend wurde das am besten geeignete Tool ausgewählt, um in einer Proof-of-Concept Umgebung ein Konzept zu entwickeln und einige grundlegende Konfigurationen für die Systeme dieser Umgebung implementiert. 
07.10.19;07.03.20;2020;extern;Bachelor;DE;Verbesserung der Prognosegenauigkeit für die Ressourceneinsatzplanung als Erweiterung einer ERP-Branchenlösung ;Die relevanten Geschäftsprozesse eines Unternehmens können mit dem ERP System Microsoft Dynamics NAV abgebildet werden. Für Projekte wurde von der KUMAVISION AG eine Branchenlösung entwickelt, um diese um die Anforderungen von Projektdienstleistern zu erweitern. <br><br>Innerhalb dieser Lösung gibt es einen Projektstrukturplan, in dem die anfallenden Arbeiten anhand von Arbeitspaketen strukturiert dargestellt werden. Zusätzlich gibt es einen Projekt Forecast, der eine rollierende Planung darstellt, und eine Ressourcenplanung. <br><br>Der Aufwand der in einzelnen Arbeitspaketen anfällt wird aktuell entweder gleichmäßig über den Zeitraum verteilt oder gar nicht.<br><br>Für eine bessere und effizientere Ressourcenplanung ist es aber notwendig so genau wie möglich zu wissen, wann wieviel Arbeit anfällt. Deswegen ist es wichtig zu wissen, wie sich der Aufwand auf die Monate/Wochen/Tage verteilt. <br><br>Das Ziel dieser Arbeit wird folglich darin bestehen, die bisherige Projektlösung um die für die Integration eines zeitlich auswertbaren Aufwandes benötigten Funktionen zu erweitern. <br><br>Hierzu müssen zunächst die relevanten, im ERP-System abzubildenden Anforderungen ermittelt werden. <br>Danach wird aus diesen Anforderungen ein SOLL Konzept erstellt. <br>Zum Schluss wird auf die Umsetzung des vorher erarbeitenden Konzeptes näher eingegangen mit dem Schwerpunkt auf den Herausforderungen und Besonderheiten bei der Kodierung.<br><br>
08.10.19;17.02.20;2020;extern;Bachelor;EN;Improving containment of linux-based container platforms;The protection against escapes from containers solely based on their encapsulation mechanisms is often insufficient against advanced attacks.<br>It is however possible to use existing security enhancements of the host system to add further levels of protection for the host system and against other containers.<br>Examples for current security enhancements include the use of Seccomp/Berkeley Packet Filters, user namespaces or Mandatory Access Control systems like AppArmor and SELinux.<br>The bachelor thesis is about Mandatory Access Control systems used for additional isolation of containers, and is developed together with the security team of SUSE Linux GmbH, focusing research on improving security of Kubernetes-based clusters.<br>After a comparison of the possible security enhancements an AppArmor profile for CRI-O is written, and its protection against different attack scenarios that are based on previous vulnerabilities is evaluated.<br>Over all, the developed profile does protect against certain attacks, but writing an own profile specifically designed for each containerized application should still be encouraged, since they often provide better protection and can also be used in combination with the created generic daemon profile.
08.10.19;08.03.20;2020;intern;Bachelor;EN;Abstractive Text Summarization of Meetings;This work analyzes how a state-of-the-art pretrained neural network?such as Google?s Bidirectional Encoder Representations from Transformers (BERT)?can be finetuned to the task of abstractive text summarization in the context of business meetings.<br><br>As part of this work, a Transformer network is developed that uses BERT as its encoder and a plain decoder. It is trained on the AMI Meeting Corpus as well as the ICSI Meeting Corpus. To circumvent the high memory usage of BERT at long sequence lengths and the fact that BERT is pretrained with a maximum sequence length of 512, the summarization is performed using a two-step approach. First, the network is trained to summarize a set of dialogue acts into a single sentence of the meeting?s abstractive summary. Afterward, a whole meeting is split up by its topics, and all the dialogue acts of a topic are fed into the trained network as its input. The concatenated outputs of the Transformer for every topic comprise the final summary.<br><br>This research shows that a data-driven approach is feasible in theory. However, the results have a strong bias toward the context of the meeting, and cross-corpus validation on AMI and ICSI shows a very poor performance. This indicates that far more training data is necessary for practicable results outside of a very topic-specific context like the scenario meetings of the AMI corpus.
10.10.19;29.01.20;2020;extern;Bachelor;EN;Vergleich der Analytics APIs einer Cloudplattform mit maschinellen Lernverfahren anhand einer Trendanalyse;"The market of renewable energy generation and therefore also the business rivalry in this<br>sector is increasing enormously in the 21st century due to the climate change and its consequences.<br>In order to make economic decisions to stay competitive in this field, it is of great<br>importance to precisely predict and interpret business data, such as the energy generation.<br>The cloud-platform ""MindSphere? recently released a service, providing the possibility to<br>predict future values of data stored in the cloud, which is evaluated in this thesis based<br>on the previously described example of the prediction of energy generation. The so-called<br>""Trend Prediction Service? is compared to own implementations for the prediction of energy<br>data, using algorithms of the python library ""scikit-learn? in order to assess whether and to<br>what extend the use of the MindSphere service makes sense. After introducing the methods<br>and describing experiments used for both implementations, the variants are compared in<br>terms of their performance, user-friendliness, accessibility, compactness and result quality.<br>Generally, it can be found that the performance and result quality provided by the ""Trend<br>Prediction Service? of MindSphere are not as high as the quality of all models trained with<br>""scikit-learn? while the second solution lacks in user-friendliness. Lastly, alternatives to both<br>implementation strategies and possible future research fields are discussed."
11.10.19;24.04.20;2020;intern;Bachelor;DE;Virtueller Assistent für Studierende - eine Möglichkeit zur Hilfestellung für Studierende der TH Nürnberg<br>;Diese Arbeit beschäftigt sich mit der Möglichkeit und der Frage nach dem Bedarf Studenten der Fakultät Informatik bei der Informationssuche von studienbezogenen Daten mit einem virtuellen Assistenten zu unterstützen. Im Zuge dieser Arbeit wurde ein Chatbot mit dem Framework von Rasa entworfen, der Anfragen von Studierenden annehmen kann und die gesuchten Informationen als Link ausgibt. Es stellte sich heraus, dass von Seiten der Studierenden ein großer Bedarf besteht die Informationssuche zu erleichtern. Es konnte festgestellt werden, dass ein virtueller Assistent sich als zentraler Einstiegspunkt zur Informationssuche eignet und den Suchaufwand stark reduzieren kann.
11.10.19;11.03.20;2020;extern;Bachelor;DE;Adaption einer Kommentarfunktion für eine Multi-User-Webanwendung;Ziel der Arbeit ist es, das Feature der SCHEMA-ST4-Kommentarfunktion in eine moderne Webanwendung zu überführen.<br>Im XML-Redaktionssystem lassen sich textuelle Anmerkungen zu Inhalten erstellen. In dessen neuer Fassung sollen die Funktionalitäten nun mithilfe von neuen Bedienmetaphern umgesetzt werden.<br>In der momentanen Version sind die Nutzer stark entkoppelt. Es gibt keine Möglichkeit zu sehen, ob ein weiterer Nutzer zeitgleich einen Kommentar erstellt oder ändert. Erst beim Auftreten eines Konflikts wird darauf hingewiesen und der Nutzer aufgefordert, die Seite neu zu laden. <br>In Zukunft soll für die Redakteure und Reviewer ersichtlich sein, ob gerade an Kommentaren gearbeitet wird. Hierfür soll der Applikation eine Echtzeitkomponente hinzugefügt werden. Möglichkeiten hierfür bietet beispielsweise das WebSocket-Protokoll, das Long-Polling und Server-Sent Events. Die Vor- und Nachteile werden erarbeitet und anschließend wird die passende Alternative ausgewählt. <br>Desweiteren soll das User Interface optimiert werden. Hierfür werden Regeln des UI Designs zur Hilfe genommen. Anschließend werden verschiedene Komponenten auf Webseiten untersucht die im Annotations-Tool Verwendung finden. <br>Mithilfe dieser Ergebnisse wird dann das User Interface gestaltet. <br>Anschließend wird der Prototyp unter Berücksichtigung der Ergebnisse dieser Arbeit implementiert. Abschließend werden die gesammelten Anforderungen überprüft und ein Ausblick auf die Weiterverwendung des Prototypen gegeben.
13.10.19;13.03.20;2020;intern;Bachelor;DE;Merkmalsbasierte Wiedererkennung von Objekten mit Anwendung für die Robotik;Im Rahmen dieser Arbeit werden merkmalsbasierte Verfahren des maschinellen Sehens zur<br>Objektwiedererkennung auf Robotersystemen untersucht. Die Herausforderung besteht dabei,<br>Objekte auch aus verschiedenen Blickwinkeln und Perspektiven, sowie unter verschiedenen<br>Lichtverhältnissen zu erkennen. Ziel ist es durch Vorverarbeitung durch Gaußfilter,<br>merkmalbasierte sowie histogrammbasierte Verfahren mithilfe von OpenCV eine wiederverwendbare<br>C++-Bibliothek zur Objektwiedererkennung zu implementieren. Die Grundfunktionalität<br>soll anschließend auf einer Testanwendung auf dem Robotersystem Pepper demonstriert<br>werden. Damit sollen Objekte gelernt und wiedererkannt werden. Zum Erlernen<br>eines Objektes wird dieses in der Kameramitte platziert und durch ein Sprechkommando mit<br>einem Textlabel versehen. Zur Wiedererkennung werden Objekte zunächst zweidimensional<br>betrachtet. Aus der zweidimensionalen Darstellung der Objekte werden durch SIFT- bzw.<br>SURF-Verfahren Merkmale ermittelt und anschließend Merkmalskorrespondenzen zu den<br>abgespeicherten Objekten gebildet. Das Textlabel des Objektes mit den meisten Korrespondenzen<br>wird als Ergebnis ausgegeben. Um Objekte auch aus verschiedenen Blickwinkeln zu<br>erkennen, werden außerdem histogrammbasierte Verfahren angewendet. Als Ergebnis soll eine<br>echtzeitfähige Lösung entstehen, die als Softwarebasis für zukünftige Forschungsprojekte,<br>wie z.B. die visuelle Selbstlokalisierung von Robotern, dienen könnte.
14.10.19;14.03.20;2020;extern;Bachelor;DE;Nutzung von Low-Code-Plattformen für die effiziente Entwicklung betriebswirtschaftlicher Anwendungen bei DATEV;Die vorliegende Bachelorarbeit wurde in Zusammenarbeit mit DATEV eG durchgeführt. Ziel der Arbeit ist die Untersuchung, welche marktrelevanten Low-Code-Plattformen für einen potentiellen Einsatz bei DATEV geeignet sind. Hierfür wird anhand einer konkreten Plattform analysiert, wie mit der Low-Code-Technologie entwickelt wird. Zudem erfolgt eine Bewertung verschiedener Plattformen hinsichtlich eines möglichen Einsatzes bei DATEV. Voraussetzung für die Nutzung dieser Plattformen ist die Erstellung moderner serviceorientierter Anwendungen, die plattformunabhängig sind und auf verschiedenen Zielsystemen gehostet werden können. Diese Voraussetzung liegt bei der Bewertung im Fokus.
14.10.19;12.03.20;2020;extern;Bachelor;DE;Untersuchung unterschiedlicher Machine-Learning-Modelle in der Risikoanalyse zur Gewichtung von Vorabanmeldungen in der Bundeszollverwaltung.;Die Bachelorarbeit behandelt die Untersuchung von unterschiedlichen Machine-Learning-Modellen im Bereich der Risikoanalyse in der Bundeszollverwaltung. Dabei wird untersucht, ob mittels des maschinellen Lernens die Gewichtung der Vorabanmeldungen (für die Einfuhr von Waren) realisierbar ist. Ein mit Risikoregeln hinterlegtes System erzeugt für die eingehenden Vorabanmeldungen Hinweise für die weitere Bearbeitung durch das Zollkriminalamt. Die für die Erarbeitung der Bachelorarbeit relevanten Daten werden vom ITZBund bereitgestellt. Hierbei werden Informationen aus bereits durchgeführten Kontrollen repräsentiert, die Hinweise dazu geben, welche Risikoregeln zu einem tatsächlichen Fund geführt haben und welche nicht. Mit Hilfe dieser Daten werden Modelle entwickelt und Vorhersagen über die Trefferwahrscheinlichkeiten unterschiedlicher Regelmuster getroffen. <br>Mittels der Forschungsergebnisse konnten die aufgestellten Thesen, die die Grundlage dieser Arbeit bildeten, beantwortet werden.<br>
14.10.19;14.03.20;2020;intern;Bachelor;DE;Analyse von Drohnentechnologien zur Digitalisierung von Prozessen in der Bauwirtschaft - Zukunftschancen in Anbetracht von Kosten und Nutzen;
14.10.19;30.01.20;2020;extern;Bachelor;DE;Ortsbezogene Visualisierung ausgewählter Datensätze zum Visual Data Mining in der virtuellen Realität;Die weltweiten Datenbestände nehmen Jahr für Jahr stetig zu. Mit dem rasanten Wachstum werden die Strukturen innerhalb der Daten stets komplexer und unübersichtlicher. So gibt es schon viele Ansätze zur Datenvisualisierung, um eine bessere Interpretation der Daten bieten zu können. Dabei wird jedoch hauptsächlich auf zweidimensionale Visualisierungsmöglichkeiten, wie beispielsweise Balken- oder<br>Liniendiagramme, zurückgegriffen. Daher werden in dieser Arbeit die Möglichkeiten und Vorteile von Visualisierungen mit zusätzlicher räumlicher Dimension untersucht. Können komplexere Daten durch eine dreidimensionale Visualisierung einfacher dargestellt werden? Ebenfalls wird aufgezeigt, welchen grundsätzlichen Mehrwert grafische Datenaufbereitungen besitzen. Anhand bestimmter Anforderungen wurden angebotene Visualisierungstools getestet. Durch die Analyse und der Bewertung konnte festgestellt werden, dass keines der Tools alle benötigten Anforderungen erfüllt. Deshalb wurde eine eigene Anwendung programmiert, die alle Anforderungen umsetzt.
14.10.19;15.06.20;2020;im Ausland;Master;EN;Exploiting data-mining attributes of positive customer satisfaction survey replies in the telecommunication industry;Communication Providers get thousands of customer survey-responses every month which is far to much for manual review and evaluation.<br>Therefore this thesis discusses modern natural language processing tools for customer-survey-comments of communication providers, <br>with the goal of finding new customer insights to generate business value from previously uninspected feedback.<br><br>The primary goal of  this thesis is to find negative sentiment and criticism in positively labelled survey-responses, to gain further information on the customers needs and concerns. <br>A secondary goal is to give an overall view on text-data preprocessing and natural language processing in this domain. <br>The key finding of this work is that on a manually labelled sample of surveys, the chosen approach of a majority voting system for finding feedback finds with a excellent precision and reasonable recall very negative comments. <br>Thus, the classifier enables any customer satisfaction team to look into newly marked comments for inspection with an efficient use of their time.<br><br>Contents of this work include latent dirichlet allocation, sentiment analysis, text preprocessing and summarization, as well as an overview of the net promoter score and its criticism.<br>In addition to the final measured metrics and used configuration, the optimization and tuning process is shown and reasoned about.
14.10.19;12.03.20;2020;extern;Bachelor;DE;Die Analyse und Optimierung von Human Computer Interaction in einem komplexen Autokonfigurator für Neufahrzeuge.;Diese Bachelorarbeit beschäftigt sich mit der Analyse und Optimierung der Mensch-Computer-Interaktion in einem komplexen Autokonfigurator (e:c:car) für Neufahrzeuge. <br>Das Ziel dieser Bachelorarbeit ist es, das Benutzerverhalten der Autokonfigurator-Webanwendung genauer zu untersuchen und dabei Problemfelder zu finden, die in der Zukunft mithilfe von Optimierungsmaßnahmen behoben werden können. Um die Analysen des Konfigurators durchführen zu können, wurden zunächst die theoretischen Grundlagen der Mensch-Computer-Interaktion untersucht. Das Thema ist sehr facettenreich und beschäftigt sich nicht nur mit den technischen Aspekten der Informationsverarbeitung, sondern auch mit der menschlichen Wahrnehmung der Daten. Es lässt sich sagen, dass die Kommunikation zwischen Menschen und Computer enorm wichtig ist und in der heutigen Arbeitswelt einen sehr hohen Stellenwert hat. Darüber hinaus wurde die Webanalyse der Webanwendung sowie die Analyse der Konfigurationspfade durchgeführt. Die Analysen haben die Entwicklungsmöglichkeiten und das Verbesserungspotenzial des Konfigurators aufgezeigt. Die theoretischen Grundlagen der Webanalyse sowie die aktuellen Methoden zur Optimierung der Webperformanz spielten eine sehr wichtige Rolle. <br>Die Forschungsergebnisse haben es ermöglicht, Optimierungsmaßnahmen einzuführen, die die Benutzerfreundlichkeit der Webanwendung in Zukunft deutlich steigern sollen.
15.10.19;14.03.20;2020;extern;Bachelor;DE;Konzeption und Implementierung einer Webapplikation zur Erfüllung der materiell-rechtlichen Nachweispflicht der Umsatzsteuer-ID für innergemeinschaftliche Lieferungen bei der DATEV eG;Zum Zeitpunkt des grenzüberschreitenden Leistungsaustauschs zwischen zwei Unternehmen innerhalb der EU muss durch den Leistungserbringer sichergestellt werden, dass die UST-ID des Leistungsempfängers gültig ist. Erst dann können die Leistungen durch das rechnungsstellende Unternehmen steuerfrei erbracht werden. Bisher konnte die Inanspruchnahme der Steuerbefreiung auch bei ungültiger USt-ID nicht untersagt werden. Aufgrund neuer gesetzlicher Vorgaben ist es daher notwendig, dass eine dauerhafte Nachweismöglichkeit der Gültigkeit der USt-ID ohne Manipulationsgefahr geschaffen wird. Ansonsten besteht das Risiko, dass bei unvollständigem bzw. fehlendem Nachweis die in Anspruch genommene Steuerbefreiung im Prüfungsfall versagt wird. Daher wurde ein System für die DATEV entwickelt, welches hingegen der bisherigen gesetzlichen Vorschriften bereits bei Anbahnung des innergemeinschaftlichen Leistungsaustauschs zwischen Unternehmen die USt-ID des Leistungsempfängers prüft und die konsistente Speicherung der angefragten USt-ID?s ermöglicht. <br>Um auf diesen Prüfmechanismus zugreifen zu können, wurde ein SOAP Schnittstelle vom Informationsaustauschsystem MIAS der EU-Kommission an programmiert. Mittels einer serverseitigen REST API wurden die An- und Abfragen über einen RESTful Webservice und dessen POST- und GET-Methoden realisiert. Dadurch erfolgte die Kommunikation und Datenübertragung zwischen dem Fontend (Angular), der REST-API und der Datenbank.<br>
15.10.19;14.03.20;2020;intern;Bachelor;DE;Herausforderungen im internationalen agilen Projektmanagement mit Fokus auf Vietnam und Deutschland;Das Ziel dieser Arbeit ist das Aufzeigen und die Analyse der Herausforderungen für agile Projekte mit mehreren verteilen Teams bzw. Teammitglieder in internationaler Umgebung. Dadurch kann die Vorbereitung für die Projektmitglieder geplant und durchführt werden, um die Projekte erfolgreich umsetzen zu können. Zu Beginn werden die grundlegenden relevanten Themenbereiche des Projektmanagement dargestellt. Das Projektmanagement wird aus zwei Blickwinkeln betrachtet: Im Kontext der internationalen Zusammenarbeit und im Kontext der agilen Methoden. Die Arbeit analysiert die typischen Vorteile bzw. Herausforderungen und Lösungsansätze in Bezug auf agile Projekte mit Teams bzw. Teammitglieder, die aus Vietnam und Deutschland kommen. Mithilfe einer quantitativen-empirischen Forschung mittels einer Online-Befragung werden die Herausforderungen in internationalen agilen Projekten in der Praxis zu erläutern und anschließend mit den bekannten Herausforderungen aus der Literaturanalyse in einen Kontext zu setzen. So werden Theorie (Literaturanalyse) und Praxis (Praktische Erfahrungen der Teilnehmer aus der Umfrage) miteinander verglichen. Abschließend wird eine Empfehlung auf weitere mögliche Forschung vorgegeben. 
15.10.19;30.01.20;2020;extern;Bachelor;DE;Konzeption und systemtechnische Implementierung eines Kennzahlensystems im Einkauf der Carl Schlenk AG;Die vorliegende Arbeit wurde in Zusammenarbeit mit der Firma Carl Schlenk AG durchgeführt. Diese ist ein international erfolgreicher Hersteller von Metallpigmenten, -pulver und -folien mit Stammsitz in Barnsdorf. In der Bachelorarbeit werden Kennzahlen im Einkaufsbereich mittels eines Kennzahlensystems in einen logischen Zusammenhang gebracht. Berücksichtigung finden strategische und zweckmäßigerweise auch operative Kennzahlen. Die für deren Berechnung benötigten Daten werden systemtechnisch aus den entsprechenden Quellsystemen erhoben, transformiert und unter Einbezug des Kennzahlensystems mit Hilfe des Business-Intelligence-Tools QlikView abgebildet. Ziel soll es sein, dem Einkaufsmanagement durch eine optimale Nachvollziehbarkeit und Visualisierung der Ergebnisse einen hohen Erkenntnisgewinn zu ermöglichen, um daraus Maßnahmen abzuleiten. 
15.10.19;12.03.20;2020;intern;Bachelor;DE;Virtueller Assistent zur automatisierten Erstellung von Immobilieninseraten;Problemstellung dieser Arbeit: Bisher entstehen Immobilieninserate häufig über <br>manuell auszufüllende Web-Formulare. Zunächst wird dieser Ist-Stand bzw. <br>die aktuelle Vorgehensweise zur Inseratserstellung per Web-Formular betrachtet, <br>um sie später einer eigenen prototypischen Lösung gegenüberstellen zu können. <br>Die Arbeit soll untersuchen, ob und wie eine automatisierte Füllung oder <br>Erstellung von Immobilieninseraten unter Nutzung von Spracherkennung möglich ist. <br>Es werden verschiedene Aspekte der Thematik betrachtet. <br>Eine prototypische Implementierung zur automatisierten Füllung von Immobilieninseraten<br>per Sprache wird umgesetzt. Anschließend wird der Prototyp erweitert. Es wird <br>eine generalisierte prototypische Implementierung geschaffen, die die Sprachfunktionalität für <br>beliebige Webformulare mit bestimmtem HTML-Aufbau ermöglicht.<br>Die Vor- und Nachteile der Erweiterung werden aufgezeigt.<br>Abschließend wird die Zielerreichung dieser Arbeit betrachtet und ein Fazit gezogen.
15.10.19;11.03.20;2020;extern;Bachelor;DE;Konzeption und Realisierung automatisierter Qualitätsprozesse für maßgeschneiderte Kundenlösungen: Testautomatisierung bei Customizing Personalwirtschaft in der DATEV eG;Maßgeschneiderte Kundenlösungen mit Wartungsverträgen werden manuell getestet, um mögliche Fehler frühzeitig erkennen und beheben zu können. Um zukünftig die regelmäßigen Tests effizienter zu gestalten und somit die Anzahl der Wartungsverträge, die mit den Kunden geschlossen werden können, zu erhöhen, soll der Prozess mit Hilfe einer Testautomatisierung optimiert werden.<br>Das Ziel dieser Bachelorarbeit ist es, ein Konzept zu entwickeln und anhand einer bestehenden Lösung den Prozess so zu automatisieren, dass der Aufwand für Teammitglieder während des Testens minimiert werden kann.<br>Nach der Umsetzung soll ein mit einer Testautomatisierung optimierter Prozess vorhanden<br>sein, der auch auf zukünftige Lösungen bei Wartungsverträgen anwendbar ist.
15.10.19;20.07.20;2020;extern;Master;DE;Automatisierte Echtzeit-Lösungsmitteilung bei Maschinenmeldungen innerhalb verschiedener Produktionslinien;Seit ihrer öffentlichen Bekanntgabe gewinnt die Industrie 4.0 an Popularität und ist heu-<br>te ein essenzieller Treiber der modernen Industrie. Die Optimierung der Produktion ist<br>dabei ein wesentlicher Aspekt. Ein Anwendungsfall ist die Ermöglichung schneller und<br>richtiger Handlungen bei Auftreten von Maschinenfehlern. In Zusammenarbeit mit endo-<br>bit software solutions und der Robert Bosch GmbH soll ein Softwaremodul konzipiert<br>und realisiert werden, das eine Lösungsmitteilung für Maschinenmeldungen binnen einer<br>Sekunde für eine Produktionslinie bekannt gibt.<br>Dazu wurde eine Analyse von Datenhaltungen zur performanten Abfrage und flexiblen<br>Speicherung durchgeführt, bei der sich MongoDB als geeignet herausstellte. Die Ver-<br>zögerung der SQL-Abfrage an den Bestand von 6 Millionen Fehlercodes wurde mittels<br>PL/SQL um rund 50% verringert. Es wurden Ansätze der Cross-Plattform-Entwicklung<br>einer App zur Lösungsmitteilung sowie Konzepte der Gamification untersucht. Als geeig-<br>net ergaben sich das Framework Ionic und ein Gamification-Konzept mit einem kurzen<br>und mittelfristigen Ziel.<br>Bei einer Linie mit 15 Stationen konnte das Ziel einer Verzögerung von unter einer<br>Sekunde erreicht werden, während dies bei 78 Stationen nicht eingehalten werden konnte.<br>Es wurde ein Konzept zur Motivation der Nutzer zur Behebung von Maschinenstörungen<br>umgesetzt. Dieses könnte in zukünftigen Forschungen in einer produktiven Umgebung<br>mit einer Nutzerstudie untersucht werden.
15.10.19;05.02.20;2020;extern;Bachelor;EN;Improving Real Estate Valuation using Side Information and Advanced Machine Learning Techniques;In this thesis, we introduce and compare two advanced machine learning approaches to enhance real estate valuation. Since the price of a property is strongly influenced by its surroundings in addition to the qualitative and quantitative features, we also aggregate supplemental publicly available information to provide machine learning models with insights about the neighborhood of a property. We partition the surroundings of a property into micro and macro location. To provide more information for the macro location, we aggregate labor market data from the Federal Employment Agency, statistical data from the Federal Statistical Office and crime statistics from the Federal Criminal Police Office. For the micro location we define three radii 100~m, 250~m and 500~m and extract features for these three radii using the Points of Interest of OpenStreetMap. After we aggregate the data, we have to preprocess it and combine it into data sets. Next, we compare two stacked machine learning approaches against each other and perform hyperparameter tuning for each considered model. After evaluating the results, we can conclude that stacked machine learning models are superior to each single model in every respect and that the use of additional macro location information leads to the best observed improvements in property valuation.
16.10.19;16.06.20;2020;intern;Master;EN;A Single Database Solution for Complex Production Pipelines;Contemporary media production includes areas such as data or product visualization, graphic design, game design, or visual effects.<br>Complex projects include a variety of software products and media data formats.<br>A production pipeline must be able to deal with a variety of media assets and the dependencies between these assets.<br><br>This thesis presents a systematic approach to dealing with media assets and asset dependencies in a production pipeline.<br>This approach is based on the idea of systematically reducing data redundancy.<br>Reducing redundancy has consequences for the layout of media asset data formats and pipeline design.<br><br>The presented approach is implemented as a system consisting of a database server, a file server, and a plugin of an industry-standard DCC application.<br>Essential, reusable components were implemented as C++ libraries.<br>A production example demonstrates the use of the system and shows that the system is capable of performing all critical tasks of a pipeline.<br>
16.10.19;15.03.20;2020;extern;Bachelor;DE;Effiziente Aufbereitung von Energiemanagement-Daten durch Integration eines Elastic Stacks;Während des Betriebs der Energiemanagement-Software IngSoft InterWatt fallen große<br>Mengen zeitaufgelöster Verbrauchsdaten an. Im Rahmen dieser Arbeit soll durch die Integration<br>eines Elastic Stacks die Verarbeitung von Energiedaten effizienter gestaltet und<br>beschleunigt werden, insbesondere das Laden von Daten für graphische Auswertungen.<br>Zudem soll die Verwendung des Elastic Stacks für Datenimport und -visualisierung<br>untersucht werden.<br>Hierzu wurde Elasticsearch mittels .NET-Client an das Software-System angebunden. Die Abbildung der Energiedaten in Elasticsearch erfolgte durch geeignete Indizes, Typen und<br>Mappings, bereits existierende Verbrauchsdaten importierte die Elastic Stack Komponente<br>Logstash. Ein Konzept zur Synchronisation von SQL-Datenbank und Elasticsearch<br>wurde erfolgreich umgesetzt, Visualisierung und Analyse der Daten übernahm die<br>Software Kibana.<br>Messungen an einem Testsystem zeigten, dass Elasticsearch zwar länger zum<br>Laden der angeforderten Daten als der ursprünglich verwendete SQL-Server benötigte, trotzdem<br>bietet Elasticsearch eine Reihe Vorteilen. So ist davon auszugehen, dass Elasticsearch<br>durch die Beantwortung von Leseanfragen den SQL-Server entlastet und Sharding sowie<br>Replikation horizontales Skalieren bei wachsenden Datenmengen erlauben. Weitere Untersuchungen<br>könnten zeigen, ob durch eine Veränderung des Datenmodells sowie Sharding<br>und Replikation eine Verringerung der Verarbeitungszeit von Elasticsearch erreicht werden<br>kann.
16.10.19;16.03.20;2020;intern;Bachelor;DE;Entwicklung, Implementierung und Evaluierung eines WebGL-basierten Volumen-Raycasters;Für die Darstellung, Bewertung und Analyse volumetrischer Daten, wie sie z.B. in der medizinischen Bildgebung anfallen, ist die direkte Volumendarstellung unerlässlich. Die dabei verwendeten Algorithmen werden in der Regel plattformspezifisch implementiert, um möglichst hohe Darstellungsgeschwindigkeiten zu erreichen. Die WebGL-Programmierschnittstelle erlaubt es dabei, die verwendete Grafikhardware des ausführenden Systems plattformunabhängig zu nutzen. Hierfür wurde ein WebGL-basierter Volumen-Raycaster entwickelt, um die Eignung dieser Technologie für direkte Volumen-Rendering-Verfahren festzustellen. Dabei wurde insbesondere auf eine nachvollziehbare und wiederverwendbare Implementierung geachtet.
17.10.19;17.03.20;2020;extern;Bachelor;DE;Konzeption und Implementation einer Contact-Center-Umgebung für einen Kundenservice;Diese Bachelorarbeit thematisiert die Konzeption und Implementierung einer Contact-Center-Umgebung in einem mittelständischen Unternehmen. Die Arbeit soll für zukünftige Contact-Center-Implementationen als technischer Leitfaden dienen, weswegen auf Best Practices eingegangen und die Anwendbarkeit dieser bewertet wird.<br><br>Nachdem in den Grundlagen auf diverse Voice over IP (VoIP)-Protokolle eingegangen und die Architektur von Cisco Unified Call Manager (CUCM) und Unified Contact Center Express (UCCX) beschrieben werden, folgt die Anforderungsanalyse. In dieser wird anhand der funktionalen Anforderungen die Grundlage für die Implementation geschaffen.<br><br>In der Implementation werden die im Soll-Konzept entwickelten Punkte umgesetzt. Zusätzlich gibt es allgemeine Erklärungen zu der Funktionsweise der beiden proprietären Systeme, CUCM und UCCX. Anschließend wird ein Verhaltenstest durchgeführt, wofür eine Liste mit den zu erwartenden Ergebnissen erstellt wurde. <br><br>Zuletzt werden die Ergebnisse beschrieben, diskutiert und ein Fazit gezogen. Es zeigt sich, dass Best Practices nicht in jedem Fall anwendbar sind. Es ist wichtig, dass Best Practices analysiert und je nach Ergebnis auf die eigenen Gegebenheiten angepasst werden sollten. Auch erfolgt die Steigerung der Produktivität nicht einfach mit der Implementierung eines Systems automatisch. Die Kundenservice-Mitarbeiter müssen lernen, mit der neuen und komplexeren Umgebung in der richtigen Art und Weise umzugehen.
17.10.19;17.03.20;2020;extern;Bachelor;DE;Entwicklung und Automatisierung von Testfällen für das Batteriemanagementsystem einer Starterbatterie<br>;Das Ziel der vorliegenden Bachelorarbeit ist es, Testfälle für den Softwaretest der High-Level-Software eines Batteriemanagementsystems zu entwickeln, zu dokumentieren und mithilfe von Testskripten zu automatisieren. Grundlage für diesen Testprozess sind ein vorliegendes Konzept mit einer Testumgebung sowie die Softwareanforderungen aus dem Lastenheft zur Bestimmung des Batteriezustands. Um die Softwareanforderungen einzugrenzen ist eine Priorisierung nach dem MoSCoW-Verfahren durchgeführt worden. Das Resultat der Priorisierung zeigt, dass die Bestimmung des Batterieladezustands die höchste Priorität hat. Für die Entwicklung der Testfälle wurden die priorisierten Softwareanforderungen einer Analyse unterzogen. Eine Testspezifikation dokumentiert die entwickelten Testfälle schrittweise und dient als Basis für die Automatisierung, bei der die Testfälle auf Skriptcode abgebildet wurden. Ergebnisse der Arbeit sind die Testspezifikation und die Testskripte, die für einen nachfolgenden Softwaretest eingesetzt werden können.
17.10.19;17.03.20;2020;extern;Bachelor;DE;Gesten- und Audioerkennung zur Steuerung einer intelligenten Jukebox ;Moderne leistungsstarke und preiswerte Single-Board-Computer ermöglichen eine Vielzahl von Anwendungen für Künstliche Intelligenz (KI). Dank zahlreicher Open-Source-Projekte und -Bibliotheken, die die mathematischen Grundlagen für unterschiedliche maschinelle Lernverfahren bereitstellen, ist es für Softwareentwickler möglich, KI-Methoden in die eigene Software zu integrieren. Mit dieser Vielzahl an Möglichkeiten stellt sich die Frage, welche davon zu einem bestimmten Problem am besten passt. Es ist ebenso von Interesse herauszufinden, welche Verfahren bzw. Software-Bibliotheken oder API auf einem eingebetteten System mit den begrenzten Speicher- und Leistungskapazitäten für die Anwendung in Echtzeit umsetzbar sind. Während die Spracherkennung mit dem Einsatz von Programmierschnittstellen als eine Lösung aus dem Regal betrachtet werden kann, wird für die Gestenerkennung mit anwendungsspezifischen Gesten ein individueller Ansatz benötigt.<br><br><br>Diese Arbeit setzt sich mit dem Aufbau und der prototypischen Entwicklung einer intelligenten Jukebox auseinander. Es wird ebenso untersucht, wie hochwertig die Anwendung der Sprach- und Gestenerkennung auf einem Embedded-Single-Board-Computer sein kann und mit welchem Aufwand deren Einsatz verbunden ist.
17.10.19;17.03.20;2020;intern;Bachelor;DE;Konzeption und Realisierung einer RRT*-Bahnplanung; 
17.10.19;17.03.20;2020;extern;Bachelor;DE;Die Fernsignatur als Ersatz für Unterschriften im Rahmen der digitalen Transformation: Eine Machbarkeitsstudie für die DATEV eG;Die vorliegende Bachelorarbeit betrachtet die Fernsignatur im Rahmen der Wirtschaftsprüfung und Steuerberatung und die daraus resultierenden Anwendungsszenarien. Zukünftig werden Prozesse innerhalb der Kanzlei bzw. zwischen Berufsträgern und Mandanten oder Institutionen zunehmend digitalisiert und ohne Medienbruch realisiert. Bereits seit 1997 existiert hierfür das Signaturgesetz und die Signaturverordnung in Deutschland. Bis 2014 war jedoch die einzige elektronische Signatur, die mit einer händischen Unterschrift gleichzusetzen ist, an eine Signaturkarte und ein Lesegerät gebunden. Im Zuge der eIDAS-Verordnung trat eine EU-weite Regelung in Kraft, die den Einsatz von Fernsignaturen gesetzlich ermöglichte. Dadurch entfallen für den Anwender die Hardwarekomponenten Signaturkarte und Lesegerät. Jedoch muss weiterhin eine Identifizierung des Anwenders erfolgen und es wird zukünftig ein Mobiltelefon benötigt.<br><br>Ziel der Bachelorarbeit war eine Analyse der Anwendungsszenarien und eine Handlungsempfehlung für die Umsetzung bzw. Integration der Fernsignatur in die Softwareanwendungen der DATEV eG. Hierfür wurden ein Interviewleitfaden erstellt und Experteninterviews durchgeführt. Die interviewten Experten - ein Wirtschaftsprüfer, zwei Steuerberater, der Vorstand eines Signatursoftware-Herstellers und eine Mitarbeiterin der DATEV eG - ermöglichen eine praxisnahe Einschätzung und einen Rückschluss auf eine entsprechende Handlungsempfehlung für die DATEV eG.
17.10.19;14.03.20;2020;intern;Bachelor;EN;Deployment of margin based loss functions and attention mechanism on the x-vector concept for speaker recognition and diarization;Machine learning has had a huge impact on IT during the past ten years as many<br>problems could be solved with it more efficiently than with conventional methods.<br>Two tasks that could profit from this development are speaker diarization (SD) and<br>speaker identification (SID). For these tasks, the new Deep Neural Network (DNN)<br>based x-vector systems have lately been proven to perform equally well or even better<br>than the conventional i-vector based systems. Two improvements on SID and SD were<br>identified previously and are proposed to be implemented in this work. The first is using<br>an angular softmax loss function as drop in replacement for the combination of softmax<br>loss and probabilistic linear discriminant analysis (PLDA). The second is replacing the<br>statistic polling layer inside the DNN with an attention network. Eventually, the<br>performance of both systems will be compared with the conventional implementations.<br>As an additional step experiments on x-vector based DNN will not be made using<br>the Kaldi framework. Instead Kaldi will only be used to generate the mel frequency<br>cepstral coeficients (MFCCs) and for post-processing such as the PLDA. The rest of<br>the SID or SD process is implemented using the PyTorch machine learning library. The<br>performance of the implementation tested on SID show an improvement when using<br>angular softmax. However, it could not be shown that angular softmax could replace<br>PLDA. Furthermore, it is shown that the attention mechanism brings improvements<br>only
18.10.19;25.02.20;2020;extern;Bachelor;DE;Analyse von Abhängigkeiten in der Softwareentwicklung der DATEV eG im Geschäftsfeld der Personalwirtschaft und Konzeptionierung von Maßnahmen zur Reduzierung der Durchlaufzeiten von Projekten;Bei der Zusammenarbeit der Komponententeams in der Abteilung LODAS/RZ-Lohn entstehen wechselseitige Abhängigkeiten, die zu höheren Warte- und Liegezeiten führen. Indem die Liege- und Rüstzeiten bei den Initiativen verringert werden, sollen die Durchlaufzeiten reduziert werden. Dadurch soll ein Mehrwert für die Kunden geschaffen werden, da die Software in kürzerer Zeit auslieferungsfertig ist. Ziel der Bachelorarbeit ist es, aufbauend auf ein bereits bestehendes Board, welches die Abhängigkeiten zwischen den beteiligten Teams sichtbar und steuerbar macht, weitere Maßnahmen herauszuarbeiten, die das Board effizient unterstützen können. So soll eine effektive Projektarbeit ermöglicht werden und zudem der Qualitätssicherung ein höherer Stellenwert zugeschrieben werden.
20.10.19;20.03.20;2020;extern;Bachelor;DE;Automatisierte Einordnung von Unternehmen in Wirtschaftszweige anhand deren Internetpräsenz;Die vorliegende Bachelorarbeit gibt einen Einblick in die Möglichkeit der automatisierten Einordnung und Klassifikation von Unternehmen in die Klassifikation der Wirtschaftszweige von 2008.<br>Die Basis für das Vorhaben der Klassifikation, stellen hierbei die Internetauftritte der Unternehmungen dar. Die Klassifikation soll einen Anhaltspunkt zur Vorselektierung von relevanten Unternehmen aus der definierten Wirtschaftsklasse bieten. Um diese Aufgabe zu ermöglichen, wurde zunächst ein geeigneter Trainingsdatensatz, mittels der Methodik des Web Scrapings, erstellt. Im Anschluss an diesen Schritt bildeten die extrahierten Daten die Trainingsgrundlage für verschiedene Algorithmen des maschinellen Lernens.<br><br>In dieser Arbeit wurde dabei die Methodik des überwachten maschinellen Lernens angewandt. Diese stellt die Algorithmen zur Erstellung eines Entscheidungsbaumes, der logistischen Regression, des mulitnomiellen Naive Bayes, der Support Vector Machine, sowie des Perzeptrons gegenüber. Dabei wird auch deren Performanz berücksichtigt.<br>Bei den Daten wurde zudem der Unterschied der einzelnen Modelle unter der Verwendung der Term Freqency Inverse Document Frequency (TFIDF) gegenüber der Verwendung von 300 dimensionalen Dokumentenvektoren untersucht.<br><br>Die Untersuchung stellte heraus, dass das Modell der TFIDF, unter der Verwendung der Support Vector Maschine, die für den Anwendungsfall beste Alternative darstellte. Diese ermöglichte eine Vorhersage mit einer Accuracy von 88%.
21.10.19;18.03.20;2020;extern;Bachelor;DE;Vorselektion eines externen Dienstleisters zur Weiterentwicklung der Einkaufsdigitalisierung bei der Nürnberger Versicherung;Das Ziel der vorliegenden Bachelorarbeit war es, eine Vorselektion von externen Dienstleistern für ein neues Einkaufssystem in Form einer Shortlist für die NÜRNBERGER Versicherung zu identifizieren sowie die Erstellung eines Konzepts für eine neue Einkaufsinfrastruktur. In Anlehnung an die Vorgehensweise von De Boer et al. konnte mit dem Anbietervorauswahlprozess die passenden potenziellen externen Dienstleister ausgewählt und eine Shortlist aufgrund der NÜRNBERGER Anforderungen erstellt werden. Diese Vorauswahl konnte mit den Methoden Lieferantengesprächen (inkl. Use Cases), RFI-Fragenkatalogen und einer Bewertungsmatrix erstellt werden. Für die Datenerhebungen der Ist-Situation und für das Soll-Konzept wurde die Einkaufsabteilung mit den Methoden Interviews, Workshops, Fragebögen und Arbeitsplatzanalysen befragt. Die Ergebnisse dieser Abhandlung waren die Erstellung des Soll-Konzepts, die Erstellung der Shortlist und der Kosten-Nutzen-Analyse des strategischen Beschaffungsprozesses als Grundlage für den Business Case. Die Bachelorarbeit ist für Einkäufer, Studierende der Wirtschaftsinformatik sowie für Stakeholder im Bereich des Ausschreibungs- und Anbieterauswahlprozesses interessant. Auf Basis dieser Arbeit kann mit der Endauswahl der externen Dienstleister begonnen werden.
21.10.19;14.03.20;2020;intern;Bachelor;DE;Bewertung bekannter Ad-hoc-Routing-Protokolle zur prototypischen Realisierung einer mobilen Messenger-Applikation;Ziel dieser Arbeit ist die Erstellung einer Messenger-Applikation, welche unabhängig von Internet und Mobilfunk arbeiten kann. Dafür muss ein geeignetes Routing-Protokoll gefunden werden.<br>Es werden verschiedene Routing-Protokolle miteinander verglichen und deren Arbeitsweise untersucht.<br>Anschließend wird mithilfe des gewählten Protokolls ein Prototyp einer Android-Applikation erstellt.
21.10.19;14.03.20;2020;extern;Bachelor;DE;Entwicklung eines Konzepts zur deutschlandweiten Einführung von Business Intelligence bei der Geschäftseinheit Regionalnetze der DB Netz AG;"Mit dem Projekt ""Einführung von Tableau"" sollte Business Intelligence (BI) bei der Geschäftseinheit (GE) Regionalnetze der DB Netz AG eingeführt werden. In dem Projekt fehlte jedoch der strategische Ansatz sowie das nötige Know-how, weshalb das Projektziel nicht erreicht wurde. Das Ziel der Bachelorarbeit ist daher die Entwicklung eines Konzepts zur deutschlandweiten Einführung von BI bei der GE Regionalnetze. Dazu werden die folgenden Forschungsfragen gestellt:<br><br>Wie kann ein Vorgehensmodell auf die betriebliche Praxis angepasst und für die Einführung von BI angewandt werden? Wie kann eine Organisation zur Bündelung der BI-Aktivitäten aussehen? Wie lassen sich innerhalb dieser Organisation Anforderungs- und Änderungsmanagement umsetzen? Welche Möglichkeiten gibt es, um einen deutschlandweiten Rollout einer BI-Plattform durchzuführen?<br><br>Um die Forschungsfragen zu beantworten wurde in Fachliteratur zu BI und Analytische Informationssysteme recherchiert. Die Recherche ergab die Empfehlung zur Entwicklung einer BI-Strategie. Hierfür wird ein Vorgehensmodell bereitgestellt. Zur Organisation und Bündelung der BI-Aktivitäten wurde das Konzept des Business Intelligence Competency Center vorgestellt und auf die GE Regionalnetze angepasst. Für das Anforderungs- und Änderungsmanagement wurde die Nutzung eines Systems und die Aufnahme von Anforderungen durch Power-User empfohlen. Zudem erwies sich die funktionsorientierte Sukzessiv-Strategie als beste Vorgehensweise zur Einführung von BI."
22.10.19;14.03.20;2020;intern;Bachelor;DE;Untersuchungen zur Modellierung in der Spracherkennung: Auswirkungen der phonetischen Modellierung im Deutschen auf die Wort- und Silbenfehlerrate;Diese Arbeit befasst sich mit der automatischen Spracherkennung.<br>Sie beinhaltet einen Einstieg, in dem die theoretischen Grundlagen von Spracherkennungssystemen und Grapheme-to-Phoneme-Konvertern erläutert werden.<br>Ein besonderes Augenmerk liegt auf der Phonetischen Modellierung.<br>Im praktischen Teil der Arbeit wird evaluiert, wie effektiv eine Modellierung von Silben in Bezug auf die Wort- und Silbenfehlerrate eingesetzt werden kann.
24.10.19;24.03.20;2020;extern;Bachelor;DE;Entwicklung eines automatisierten Integrationstestverfahrens für graphische Benutzeroberflächen auf Automotive-HMI-Bedienelementen;Die vorliegende Bachelorarbeit befasst sich mit der Entwicklung einer Testsoftware, mit der die Automatisierung des Integrationstests von Steuergeräten eines Automobils ermöglicht werden soll. Ziel dieser Software ist es, Testfälle generieren zu können, welche die Auswertung von Attributen des zu testenden Steuergeräts oder das Simulieren von berührungsbasierten Events auf ebendieses abwickelt.<br>Für die Realisierung dieser Arbeit wurde ein Konzept der Testsoftware entworfen, welches anschließend auf eine spezifische Fallstudie der Firma Preh GmbH angewandt wurde. Das resultierende Konzept soll es ermöglichen, Testfälle für HMI-Software mit vergleichbaren Schnittstellen entwickeln zu können. Voraussetzung ist dabei jedoch, dass das System zur Laufzeit über eine Debug-Umgebung mit dem verbundenen Rechner kommunizieren kann. <br>Weiterhin werden Anforderungen an die Testsoftware gestellt, kategorisiert und nach der MoSCoW-Methode priorisiert. Im Anschluss an die Aufstellung des Konzepts, sowie an die erfolgreiche Implementierung der Testsoftware für die Fallstudie wird die gesamte Arbeit und ihre Ergebnisse reflektiert. Abgeschlossen wird diese Bachelorarbeit mit einem Ausblick für Verbesserungen. Dazu wird Bezug zur Restbussimulation genommen, um die Testmöglichkeiten der Software auf Bussysteme, wie zum Beispiel CAN, zu erweitern.
25.10.19;29.04.20;2020;extern;Bachelor;DE;Behavior Driven Development im Bankenumfeld - Konzeption und Implementierung eines Prozesses zur Testautomatisierung auf Basis des PHP-Frameworks Behat;Die betreuende Firma dieser Arbeit stellt für Bankunternehmen Intranet-Plattformen bereit. Zur einfacheren Zusammenarbeit zwischen Entwicklern und Fachexperten soll Behavior Driven Development über das PHP-Testframework Behat zum Einsatz kommen. Mit diesem können auch Mitarbeiter ohne besondere IT-Kenntnisse Behavior-Driven-Tests im sogenannten Gherkin-Format formulieren. So können die Fachexperten beim Definieren neuer Anforderungen selbst Tests schreiben, welche automatisch ausgeführt werden und ein Reporting beinhalten. Um Behat und die gewünschten Funktionalitäten sinnvoll zu integrieren, wurde im Rahmen der Bachelorarbeit ein Prozess von der Anforderung bis zur Auslieferung der Software konzipiert und implementiert, in welchen Behat vollständig eingebunden ist. Hierzu wurden in der Arbeit eine graphische Oberfläche zum Verwalten der Tests, ein Versionsverwaltungssystem, ein Automationsjob sowie lokale und zentrale Testsysteme umgesetzt. 
25.10.19;07.04.20;2020;intern;Bachelor;DE;Analyse der Entscheidungsfaktoren unterrepräsentierter Gruppen bei der Wahl von MINT-Studiengängen durch Methoden des maschinellen Lernens;Trotz steigendem Bedarf nach MINT-Absolventen bleibt die Frauenquote in diesen Fächer gering. Das Ziel dieser Arbeit ist es, die Entscheidungsfaktoren bei der Wahl des Studiengangs herauszufinden, zu analysieren und daraus eine Handlungsempfehlung für die Hochschule abzuleiten. Dazu soll folgende Forschungsfrage untersucht werden: Welche Entscheidungsfaktoren fließen bei unterrepräsentierten Gruppen bei der Wahl des Studiengangs mit ein?<br>Zur Erweiterung der Datengrundlage wird eine Online-Umfrage durchgeführt. Anschließend werden die Daten durch Werkzeuge der Textanalyse und maschinelle Lernmethoden wie Sentiment Analyse aufbereitet, analysiert und ausgewertet.<br>Aus den Ergebnissen lassen sich die wichtigsten Faktoren bei der Wahl des Studiengangs ablesen. Darauf aufbauend können Konzepte gestalten werden, um diese Entscheidungsfaktoren zu beeinflussen.
25.10.19;22.03.20;2020;extern;Bachelor;DE;Gegenüberstellung der Materialflusstechnologien SAP EWM MFS und Dematic MFS - Technische Analyse, Kundenbefragung und Konzeption eines Tools für die Anforderungsanalyse bei Neukunden;Ausgangspunkt dieser Bachelorarbeit ist ein systematischer Vergleich der Materialflusstechnologien<br>von SAP EWM MFS in der Standardversion mit den Eigenentwicklungen des<br>Dematic MFS. Basis ist eine technische Analyse anhand einer typischen Lagerkonstellation<br>und den wichtigsten Kundenanforderungen. Diese werden bei Kundenbefragungen<br>ermittelt und sollen verdeutlichen, welche Komponenten aus den beiden MFS-Systemen in<br>welchen Situationen eher vorgezogen werden. Anhand dieser Erkenntnisse wird ein Tool zur<br>Anforderungsanalyse entwickelt, mit dessen Hilfe Neukunden die passende Technologie oder<br>Technologiekombination vorgeschlagen werden kann, damit die bestmögliche Lösung aus<br>Kunden- und Entwicklersicht entsteht.
27.10.19;14.03.20;2020;intern;Master;DE;Identifikation von Entscheidungsfaktoren auf die Studienwahl in der Fachrichtung MINT auf Basis von Datenerhebungen in Form von Befragungen und deren statistischer Auswertungen;Ziel dieser Arbeit ist die Identifikation von Einflussfaktoren auf die Entscheidung für oder gegen ein MINT-Studium. Hierzu erfolgte neben einer Betrachtung aller Studierenden in den Hypothesen eins bis zehn eine Fokussierung auf unterrepräsentierte Gruppen in den Hypothesen elf bis 21. <br>Zur Datenerhebung wurde eine Online-Befragung durchgeführt. Die Auswertung und Analyse erfolgte mit deskriptiven Statistiken, wie Häufigkeitsberechnungen und den Assoziationsmaßen Chi Quadrat sowie Cramer?sche V. <br>Als generelle Einflussfaktoren auf die Studienfachwahl konnten das persönliche Interesse sowie Zukunftserwartungen vollständig bestätigt werden. Teilweise nachgewiesen wurde der Einfluss durch das soziale und schulische Umfeld, durch finanzielle Aspekte, Zugangsvoraussetzungen, den Hochschulstandort, Erwartungen und Einschätzungen bezüglich der MINT-Studiengänge sowie persönliche Informations- und Inspirationsquellen. Hinsichtlich eines besonderen Einflusses auf die Entscheidung für ein MINT-Studium durch unterrepräsentierte Studierendengruppen konnten Teilbereiche aus vier überprüften Entscheidungsfaktoren bestätigt werden. Dies betraf Erwartungen und Einschätzungen bzgl. MINT-Studiengängen hinsichtlich Frauen, die familiäre Situation im Zusammenhang mit Studierenden der ersten Generation, das soziale Umfeld im Bezug zu Studierenden mit Migrationshintergrund und finanzielle Aspekte in Verbindung mit finanzschwachen Studierenden.
31.10.19;14.03.20;2020;intern;Bachelor;DE;Entwicklung eines grundlegenden sensomotorischen Prozesses für das Greifen und Verlagern einfacher Objekte auf dem Robotersystem Pepper;In dieser Arbeit geht es darum dem Robotersystem Pepper den grundlegenden Prozess des Greifens und Verlagerns eines einfachen Objektes beizubringen. <br><br>Der erste Schritt im Prozess der Implementierung soll die Erkennung einfacher Gegenstände mit Hilfe der Kombination aus einem Farberkennungs-und Kreiserkennungsalgorithmus sein. <br>Für die weiteren Schritte wird zur Bewegungskontrolle des Roboters eine Image Based Visual Servoing Steuerung verwendet.<br>Anhand der vorher programmierten Objekterkennung soll der Roboter dann den Raum nach einem Zielgegenstand in Form eines Balles absuchen und auf diesen zusteuern. <br>Dort bleibt er in Greifdistanz davor stehen. Der Gegenstand soll dann mit dem eye-to-hand System gegriffen werden. Sind diese Schritte erfolgt, soll der Roboter sich wieder etwas zurück bewegen und den Raum erneut absuchen, um die Zielmarkierung zu finden. <br>Hat er das Ziel entdeckt, soll er auf dieses zusteuern und in Greifdistanz davor stehen bleiben. Der Roboter soll dann den Ball auf die Markierung legen (eye-to-hand System).<br><br>Resultat der Arbeit ist, dass der Roboter Pepper in naher Distanz (1.5m) den Ball erkennt, darauf zusteuert und diesen greifen kann. Dieses Ergebnis kann als Grundlage für weitere Forschungen und Projekte im Game-Tech-Labor verwendet werden. 
31.10.19;31.03.20;2020;extern;Bachelor;DE;Konzeption und prototypische Umsetzung einer minimalen API-Management Umgebung um Unternehmen aus dem Finanzsektor den Einstieg in die API Economy zu erleichtern.;Viele Unternehmen im Finanzsektor öffnen ihre IT-Landschaft, um sich im aktuellen Onlinemarkt zu integrieren. Dabei werden Application Programming Interfaces veröffentlicht. Das Veröffentlichen der APIs erweitert die Angriffsfläche der Unternehmen. Ohne zusätzliche Absicherung können Angreifer die Schwachstellen der Infrastruktur ausnutzen (vgl. S.111 [De 17]). Um den Problemen entgegenzuwirken, kann man bereits etablierte API-Management-Produkte verwenden. <br><br>Das Ziel dieser Bachelorarbeit ist es eine Wissensbasis für den Themenbereich API-Management zu schaffen und eine prototypische API-Management-Umgebung umzusetzen. Zu diesem Zweck werden die Anforderungen von Unternehmen des Finanzsektors an eine API-Management-Umgebung mit Hilfe verschiedener Methoden des Requirement-Engineerings erarbeitet. Auf Basis der ermittelten Ergebnisse werden die Schlüsselfunktionalitäten einer minimalen API-Management-Umgebung identifiziert und ein API-Developer-Portal konzipiert. Dieses wird in Form eines Click-Prototyps umgesetzt. Zusätzlich wird ein in Frage kommendes API-Management-Produkt evaluiert. Auf dem Produkt aufbauend wird eine API-Management-Umgebung erstellt. Die fertige Umgebung wird auf der Container-Plattform der Firma adorsys bereitgestellt und anschließend im Rahmen der Umsetzung von Entwicklern durch einen Usability-Test auf das Erfüllen der Anforderungen geprüft.<br>
01.11.19;01.04.20;2020;extern;Bachelor;DE;Konzeptionierung und Implementierung eines Webservice für ein MES System von verfahrenstechnischen Anlagen ;In automatisierten Produktionsanlagen entstehen täglich Unmengen an Informationen.<br>Dazu gehören Daten zu Aufträgen, zu Materialbewegungen, zu Lagerbeständen und<br>viele mehr. Dadurch entsteht die Problematik, dass die entscheidenden Informationen<br>oft nicht mehr erkannt werden können, was die Produktivität und Effizienz negativ<br>beeinflussen kann. Die Aufbereitung, Analyse und Überwachung der Daten im korrekten Kontext ist essentiell für die optimale Steuerung von Produktionsanlagen. Hierzu<br>werden oft MES-Systeme eingesetzt, welche die einzelnen Prozesse sichtbar und vor<br>allem nach verfolgbar machen. Um diese Anwendungen zentral bedienen zu können<br>muss eine geeignete Schnittstelle für das MES-System existieren.<br>In dieser Arbeit wird das Konzept und die Implementierung eines Webservice vorgestellt, welcher die Kommunikation eines MES-Systems mit der Datenbank gewährleistet<br>und für die korrekte Abarbeitung der anfallenden Daten aus diesem System sorgt. Der<br>Service soll den Grundstein dafür legen, weitere Anwendungen erstellen zu können, die<br>rein im Web laufen und über HTTP-Requests mit diesem kommunizieren können.
04.11.19;16.03.20;2020;intern;Bachelor;DE;Prototypische Entwicklung eines Empfehlungssystems zur Unterstützung von Absolventen bei der Job-Suche;"In der Bachelorarbeit mit dem Titel ""Prototypische Entwicklung eines Empfehlungssystems zur Unterstützung von Absolventen bei der Job-Suche"" geht es grob darum, dass mithilfe von verschiedensten Tools ein prototypischer Chatbot konzeptioniert wurde. Der Bot soll Studenten in den finalen Semestern bei der Job findung helfen. Er gibt basierend auf den Antworten der Studenten Berufe aus welche für eben diese passen könnten. Aktuell ist der Prototyp auf Twitter erreichbar. "
04.11.19;04.04.20;2020;extern;Bachelor;DE;Steigerung der Kundenservice-Exzellenz durch KI-basiertes Output-Management ;Am Anwendungsbeispiel des Kundenservice der N-ERGIE AG, Sitz in Nürnberg, wird geprüft, ob durch den Einsatz maschineller Lernverfahren im Output Management die Kundenservice Exzellenz gesteigert werden kann.<br>Kundenservice Exzellenz beschreibt hierbei zum einen einen wirtschaftlichen Einsatz der für einen positiven Kundenkontakt verwendeten Ressourcen, als auch die allgemeine Qualität, welche dem Kunden geboten wird, um diesem ein positives Erlebnis im Kontakt mit dem Unternehmen bieten zu können.<br>Als mögliche Verfahren wurde hierbei die Klassifikation mittels Methoden aus dem supervised Learning in Absprache mit der N-ERGIE AG identifiziert.<br>Mithilfe der Klassifikatoren NaiveBayes, SupportVector Machines und dem k-Nearest-Neighbor-Algorithmus<br>werden an den Kunden ausgehende Nachrichten kategorisiert. Hierfür wurden über 1300 Kundenschreiben vorklsasifiziert. Ein seitens der N-ERGIE AG bereitgestellter Gesprächsleitfaden dient hierbei als Grundlage, um die Nachrichten im Sinne des Kundenservice zu kategorisieren und die identifizierten Modelle zu trainieren. <br>Mithilfe der Metriken Accuracy, Precision, Recall und F1-Score wird die Güte der Klassifikation bewertet.<br>Abschließend wird mithilfe eines User-Interfaces geprüft, ob neue E-Mails durch die Modelle eine hinreichende Klassifikation Erfahren.<br>Es stellt sich heraus, dass durch einen Einsatz dieser Methoden unnötige Fehler wie Fehlerhafte Nachrichten oder fehlender Pflicht-textbestandteile vermieden werden können.
08.11.19;13.05.20;2020;extern;Bachelor;DE;Integration des User Centered Design in das Model-Based Systems Engineering für die Entwicklung gebrauchstauglicher Cyber-physischer Systeme.;In einer immer stärker werdenden Vernetzung unseres Lebens, besitzen die heutigen entwickelten Produkte eine zunehmende Produktkomplexität. Neben den mechanischen und mechatronischen Komponenten enthält ein sogenanntes Cyberphysisches System (CPS) Softwarekomponenten. Auf Grund der zusätzlichen Komponenten sind Unternehmen gefordert, eine interdisziplinäre Produktentwicklung als Prozess zu implementieren. Dabei müssen nicht nur die funktionalen Eigenschaften und die stetig steigende Komplexität des Produktes berücksichtigt werden. Der Umstand der Gebrauchstauglichkeit, wie Nutzer zukünftig mit Hilfe des Systems effektiv und effizient ihre Ziele erreichen können, muss ebenfalls berücksichtigt werden. Wird allerdings bei der Entwicklung der Nutzer vergessen, steigt die Wahrscheinlichkeit einer Abneigung des Nutzers gegenüber dem Produkt. <br>Entgegenwirken kann hier die Gestaltungsmethode des Human-Centered Design. Dabei wird der Nutzer eines Produktes mit seinen Zielen, Einstellungen und Eigenschaften in den Fokus des Entwicklungsprozesses gestellt.
13.11.19;13.04.20;2020;extern;Bachelor;DE;Einführung von ITIL Operation Prozessen im Service Desk;Der Titel der Arbeit lässt bereits erkennen, was im Folgenden erarbeitet wird. In dieser Arbeit wird insbesondere darauf eingegangen inwieweit durch die Effektivitätssteigerung des Problem Managements das Incident Management entlastet werden kann, ohne die Effizienz zu beeinträchtigen. <br>In der Theorie des IT Service Managements (ITSM) wurde im Jahr 2011 die dritte Version des IT Infrastucture Library Frameworks veröffentlicht. Dieses hat das Ziel ITSM Prozesse innerhalb des Unternehmens zu optimieren, um somit eine effizientere und effektivere Arbeitsweise zu gewährleisten. Dies wird zu Beginn der Arbeit erläutert und für ausgewählten Prozesse spezifiziert. Außerdem wird auf die ISO 20000 Zertifizierung eingegangen und die standardisierte Notation BPMN 2.0 aufgezeigt.<br>Für das Unternehmen SanData ist die betriebliche Umsetzung, in der sich die Theorie unter Einflüssen der Praxis beweisen muss, entscheidend. In dieser Arbeit werden die einzelnen Prozesse durch Workshops erarbeitet und die Ergebnisse erläutert. Abschließend werden ein Fazit sowie ein Ausblick darüber gezogen.
14.11.19;17.07.20;2020;intern;Bachelor;EN;Automatic image recognition in upload filters ? computing of transparent decisions (XAI), with the help of Deep Learning methods.;
14.11.19;04.05.20;2020;intern;Bachelor;EN;IT-based Automatic Text Summarization with the Use of Textgeneration Methods;Text Summarization can be a powerful tool to reduce the amount of time for reading documents, articles or even research papers. The thesis is divided into a larger state of the art part and a shorter prototype part. The state of the art part examines the concepts of text generation and text summarization with the focus on my prototype. Most concepts are introduced in order to fully understand how my prototype is able to achieve the text generation, except for some advanced thinking outside the box concepts, which cannot be applied by me, because it would exceed this thesis. My prototype is trained on the Amazon-fine- food-reviews from www.kaggle.com and the results are evaluated on the Rouge and BLEU scores. In the end, I further introduce some performance enhancements.
18.11.19;19.08.20;2020;intern;Master;DE;Entwicklung eines optimierten Punkte-Containers für das k-nearest-neighbor-Problem;In dieser Arbeit wurde untersucht, wie das K-Nearest-Neighbor-Problem im dreidimensionalen Raum unter Verwendung des Euklidischen Abstandes als Abstandsmaß effizient gelöst werden kann. Neben der Antwortzeit für eine Abfrage ist die Antwortzeit für das Einfügen von Punkten in den Punktecontainer wichtig.  Unter den untersuchten Strukturen hat sich der K-D-B-Tree als die effizienteste Struktur herausgestellt. Als Wert für die Kapazität einer Region Page wurde 4 gewählt, 64 für die Kapazität einer Point Page. Die Strategie zum Teilen eines Knotens teilt eine Point Page bei der Überlauf zyklisch nach der Höhe des Baumes, Läuft der Elternknoten des übergelaufenen Blattknotens ebenfalls über, wird dieser nach derselben Achse geteilt, dies setzt sich solange fort, bis der der Elternkoten des aktuell betrachteten Knotens nicht überläuft. Als Verfahren für das Durchführen einer K-Nearest-Neighbor-Abfrage dient eine Adaption des Henrich-Verfahrens auf den K-D-B-Tree.
19.11.19;17.03.20;2020;intern;Bachelor;DE;Erkennung und Kartographierung beweglicher Objekte am Beispiel eines mobilen Roboters;Entwicklung eines Verfahrens zur Erkennung beweglicher Objekte mit Hilfe eines Lidar-Scanners auf einem mobilen Roboter. Ziel ist es, durch Literaturrecherche zu prüfen, ob ein SLAM-Verfahren existiert, der für die Erkennung von dynamischen Objekten optimiert ist. Falls ein optimiertes Verfahren vorhanden ist, wird dieses für den 'Carbot' Roboter implementiert. Anderenfalls wird der bisherige SLAM-Algorithmus (ICP) soweit weiterentwickelt, dass dynamische Objekte erkannt und kartographiert werden können.
19.11.19;24.05.20;2020;extern;Bachelor;DE;Verortung von Platinenbauteilen durch Parsen von Schaltplänen anhand eines Embedded Evaluation Boards;Die vorliegende Bachelorarbeit verfolgt das Ziel die Konfiguration eines Evaluation Boards für den Entwickler zu erleichtern sowie teilweise zu automatisieren. Die Unterstützung fokussiert sich insbesondere auf die Darstellung einzelner Pinbezeichnungen des Mikrocontrollers und den damit verknüpften Bauteilen des Evaluation Boards.<br>Um dieses Ziel zu erreichen, gilt es relevante Informationen aus dem entsprechenden Schaltplan zu entnehmen und in einer geeigneten Form aufzubereiten und anschließend darzustellen.<br>Hierfür werden zunächst Methoden der Mustererkennung verwendet, um die benötigten Informationen aus dem Dokument zu extrahieren. Die Ergebnisse dieser Ansätze entsprechen jedoch nicht den Erwartungen und werden verworfen.<br>Um eine korrekte Abbildung des Schaltplanes zu erreichen, wird dieser direkt aus dem XML-Format geparst und danach strukturiert in Form einer XML-Datei abgelegt.<br>Die Darstellung der aufbereiteten Daten erfolgt durch eine mobile Anwendung, welche für die Verwendung auf einem Tablet geeignet ist.<br>In dieser wird das Evaluation Board mithilfe der Objekterkennung erfasst und anschließend das erstellte XML-Dokument deserialisiert, um dem Entwickler detaillierte Informationen bezüglich des Evaluation Boards darstellen zu können.
20.11.19;14.03.20;2020;intern;Bachelor;DE;Identifikation und Analyse von Misserfolgsfaktoren beim Einsatz von Gamification ;
20.11.19;13.03.20;2020;intern;Bachelor;DE;Konzeption und Evaluation einer Testumgebung zur Erkundung virtueller taktiler Karten;Für Menschen mit Sehbehinderung ist es schwierig sich in neuen Umgebungen zurechtzufinden.<br>Eine Möglichkeit für den Aufbau eines mentalen Bildes ist der Einsatz von taktilen Karten.<br>Die Herstellung dieser ist jedoch sehr zeitaufwendig.<br>Virtuelle taktile Karten nutzen haptisches Feedback, um taktile Karten mithilfe von VR-Technologien virtuell darzustellen.<br>Diese Arbeit beschreibt Anforderungen und ein Konzept zum automatischen Erstellen von virtuellen taktilen Karten.<br>Eine Benutzerstudie für einfache geometrische Grundrisse kam zu dem Ergebnis, dass die Darstellung virtueller taktiler Karten mithilfe von Datenhandschuhen prinzipiell möglich ist.<br>Die Präzision der Technik und Handhabung der Geräte kann jedoch durch weitere Forschung verbessert werden.
20.11.19;14.03.20;2020;intern;Bachelor;DE;Einsatz maschineller Lernverfahren zur automatischen Erkennung psycho-sozialer Kategorien in Forenbeiträgen;Die Menschen nutzen unterschiedliche Beratungsmöglichkeiten, um persönliche Probleme zu bewältigen und richtige Entscheidungen zu treffen. In den letzten Jahren wurde in vielen Kontexten Online-Beratung eingesetzt. Als Kommunikationsform kann E-Mail-Beratung, Chatberatung oder Beratung in Foren genutzt werden. In den Beratungsforen können zu gegebener Problemstellung des Ratsuchenden sowohl die professionellen Berater als auch andere Forenbenutzer Ratschläge erteilen. <br>Professionelle Berater setzen etablierte Beratungsmethoden und -techniken ein. Die Untersuchung der Vorgehensweise auch anderer Berater und ihres Beitrags zur erfolgreichen Beratung könnte zur Verbesserung der Beratungsstrategien von professionellen Beratern eingesetzt werden.<br>Ziel dieser Arbeit ist es zu untersuchen, ob und in welchem Umfang die Maschine die vorgegebenen psycho-soziale Kategorien in den Beiträgen der Berater erkennen kann. <br>Um Ziel zu erreichen, wurden zunächst die Grundlagen der Textanalyse und die Klassifizierungsalgorithmen erläutert. Danach wurden die überwachten maschinellen Lernverfahren zur automatischen Kategorisierung der Beiträge eingesetzt und bewertet. Abschließend wurden die Ansatzpunkte für die Verbesserung ermittelt.<br><br>
21.11.19;14.03.20;2020;extern;Bachelor;DE;Evaluation verschiedener Tools zum automatisierten Einrichten einer skalierbaren Testinstanz sowie Prüfung der Testergebnisse zur Qualitätsverbesserung des bpanda-Produkts der MID GmbH;Das Ziel dieser Bachelorarbeit ist die Implementierung eines Testsystems mit Hilfe einer Last- und Performancetestsoftware. Mit diesem System lässt sich die Qualität des Produkts Bpanda bewerten. Bpanda ist dabei eine Cloud-Anwendung für das Prozessmanagement im Unternehmen. <br>Im Rahmen dieser Arbeit soll eine Nutzwertanalyse durchgeführt werden um eine Auswahl zwischen verschiedene Last- und Performancetestsoftwares zu treffen.<br>Diese Software soll in der Lage sein, die vordefinierten Datenmenge in einer bestimmten Zeit zu erzeugen. <br>Nach der Auswahl der Software sowie die Durchführung von Tests soll bestimmt werden, ob die vordefinierten Datenmenge aktuell vom Bpanda-Produkt erarbeitet werden konnten oder nicht. 
22.11.19;22.04.20;2020;extern;Bachelor;DE;Optimierung einer Webanwendung zur Verbesserung der Termintreue in der Schaeffler AG im Rahmen eines Six-Sigma-Projekts;Bei der Zentralisierung des Transportmanagements entsteht eine Informations- und Kommunikationslücke zwischen dem Customer Service, zuständig für Aufträge einzelner Werke und dem Transport Management, zuständig für die Transporte zu Kunden für die Schaeffler Gruppe. Um diese Wissenslücke zu schließen gibt es das Avisierungstool. Hier legt der Customer Service Lieferungen an und das Transportmanagement kann für die Lieferungen dem Spediteur beauftragen, den Kunden die anstehenden Lieferungen mitteilen und das Verladebüro des jeweiligen Werks benachrichtigen, welche Sendungen voraussichtlich abgeholt werden. Im Rahmen der Bachelorarbeit sollen wichtige Ergänzungen hinzugefügt werden. Ob diese Veränderungen zu Verbesserung der Termintreue im Werk Lahr führen soll mit einem Six Sigma Prozess gemessen werden. Hierzu wird die Termintreue vor und nach der Veränderung beobachtet.
25.11.19;14.03.20;2020;intern;Bachelor;DE;Analyse der IT-Strategien der bayrischen Hochschulen und der Studierendenanforderungen für die Entwicklung der IT-Strategie der Technischen Hochschule Nürnberg;Der Einsatz von Informationstechnologie (IT) ist heutzutage in fast jedem Lebensbereich vertreten. Ein Beispiel liefern deutsche Hochschulen, an denen IT zur Erfüllung zahlreicher Aufgaben angewendet wird. <br>Um die IT-Unterstützung der Hochschulen effektiv und effizient auszurichten, werden externe und interne Umfeldanalysen durchgeführt. Die Aufgabe der Umfeldanalyse ist es, dem IT-Management für ihre IT-Strategieentwicklung, wichtige Informationen über die Stakeholder und die Trends der stetig wachsenden Branche zur Verfügung zu stellen.<br>Im Rahmen dieser Arbeit wurde eine Umfeldanalyse für eine Aktualisierung der IT-Strategie der Technische Hochschule Nürnberg durchgeführt. Aufgrund des großen Umfangs einer vollständigen Analyse beschränkt sich die vorliegende Arbeit auf zwei Bereiche, das interne und externe Umfeld. Als externes Umfeld wurden dabei die staatlichen Hochschulen in Deutschland, mit Hauptfokus auf das Bundesland Bayern, untersucht. Die Analyse des internen Umfelds bezog sich auf die Studierenden der Technischen Hochschule Nürnberg. <br>Die untersuchten Fragestellungen, abgeleitet aus den Zielen der Umfeldanalyse, konnten unter Einsatz einer strategischen Wettbewerbsanalyse für das externe Umfeld, sowie mit den Methoden der empirischen Sozialforschung für das interne Umfeld, teilweise beantwortet und die eingesetzten Methoden evaluiert werden.
28.11.19;28.05.20;2020;extern;Bachelor;DE;Erstellen eines prototypischen Systems zur Empfehlung von Finanzmarktnachrichten auf Basis von Benutzerdaten;Die vorliegende Bachelorarbeit untersucht, wie Finanzmarktnachrichten auf Basis von Benutzerdaten empfohlen werden können und wie dieses Empfehlungssystem als firmeninterner Dienst zur Verfügung gestellt werden kann.<br><br>Im Rahmen dieser Arbeit wird aufgrund fehlender Nachrichtennutzungsdaten ein alternativer Ansatz mit der Prognose der Kaufwahrscheinlichkeit von Aktien als Ersatz für den Empfehlungswert verwendet. Es wird geprüft, ob dieser Ansatz gute Ergebnisse liefern kann, welche der ausgewählten Algorithmen für diesen Ansatz die passendsten Empfehlungen liefert und wie das endgültige Produkt in die Systemlandschaft integriert werden kann. Zur Prüfung der Algorithmen wird eine Simulationsstudie mit unterschiedlichen Klassifizierern und verschiedenen Datensatzkombinationen aus Nutzer, Objekt und Attributen durchgeführt. Zur Bewertung werden die verschiedene Metriken und die Laufzeiten gewichtet verwendet.<br><br>Die Arbeit zeigt, dass die Prognose der Kaufwahrscheinlichkeit für Aktienempfehlungen verwendet werden kann. Aus der Studie lässt sich ableiten, dass Neuronale Netze und Random Forests gute Metrikwerte und gleichzeitig gute Laufzeiten bieten, wohingegen der Gaussische Prozess zwar die besten Metrikwerte aber eine der schlechtesten Laufzeiten hat. Die Verwendung der Attribute hat die Metriken minimal verschlechtert, woraus sich schließen lässt, dass es nicht relevant ist, ob die verwendeten Attribute oder Attribute im Allgemeinen eingesetzt werden.
02.12.19;13.06.20;2020;extern;Bachelor;DE;Evaluierung und Vergleich verschiedener Open Source DeepLearning-Frameworks;"Ein Ziel der Arbeit ist es, einen Einblick zu gewinnen, welche DL-Frameworks aktu-ell im Umlauf sind und wie diese verwendet werden. Daraus soll ein Vergleichskata-log für verschiedene Anforderungen erstellt und die Frameworks mithilfe dieser Kri-terien analysiert werden. Dies soll die Entscheidungsphase bei der Einführung ei-nes KI-Frameworks für ein Unternehmen verkürzen. <br>Vergleiche verschiedener Frameworks existieren bereits (siehe zum Beispiel die Winterausgabe des iX-Developer Fachmagazins mit dem Thema ""Machine Learn-ing""). Viele der im Netz im Umlauf befindlichen Vergleiche sind jedoch häufig mehr für den privaten Interessenten geeignet als für eine betriebliche Entscheidungshil-fe. Diese Arbeit soll sich auf einen vergrößerten Kriterienkatalog stützen, welcher zum Beispiel die unterstützen Sprachen oder die Anforderungen an die Infrastruk-tur eines Unternehmens enthält. Weitere exemplarische Kriterien wären das benö-tigte Know-how für die Entwickler und den Betrieb, sowie die Unterstützung durch die Community des jeweiligen Frameworks. Zusätzlich sollen die zur Verfügung gestellten Algorithmen, die Performance und die Einsteigerfreundlichkeit analysiert und bewertet werden."
02.12.19;15.06.20;2020;extern;Bachelor;DE;Evaluierung eines Standards in der industriellen Softwareentwicklung für Robotikanwendungen;
02.12.19;27.04.20;2020;intern;Bachelor;DE;Konzeption und Entwicklung eines Web-Crawlers zur Ermittlung von Veröffentlichungen<br>von Professoren der TH Nürnberg;Im Rahmen dieser Arbeit wurde ein funktionierender Web-Crawler implementiert, der Publikationen von Autoren der Technischen Hochschule Nürnberg sammelt. Das System bezieht die Veröffentlichungsmetadaten aus drei Quellen und persistiert diese in einer eigenen Datenbank. Für die Vermeidung von Duplikaten werden probabilistische Matching-Algorithmen eingesetzt, die sowohl Autoren als auch Publikationen vergleichen und harmonisieren. Als Schnittstelle für die Nutzer der Daten, beispielsweise die Hochschulkommunikation und -entwicklung, besteht eine Webanwendung, welche die Metadaten anzeigt und eine Suchfunktionalität bereitstellt. Des Weiteren wurde im Rahmen der Bachelorarbeit ein Betriebskonzept erarbeitet, welches das Deployment der einzelnen Softwarekomponenten via Docker umsetzt. Die regelmäßige Ausführung wird zudem mit Hilfe eines Cronjobs ermöglicht, sodass wöchentlich neue oder geänderte Publikationen gesammelt und eingepflegt werden. Auf diese Weise bleibt der Datenbestand aktuell.
02.12.19;29.04.20;2020;extern;Bachelor;DE;Design und Umsetzung eines Windows Programms zum Auslesen und Interpretieren von Diagnosedaten über das UDS Diagnose Protokoll eines CAN Steuergerätes in C#;Diese Arbeit beschäftigt sich mit dem Entstehungsprozess einer Anwendung im Auto-<br>mobilbereich. Ziel ist die Entwicklung eines firmeninternen Diagnosetools in C#. Dieses<br>kommuniziert aufbauend auf dem Unified Diagnostic Services Protokoll (UDS) mit einem<br>KFZ Steuergerät. Das Kommunikationsmedium ist hierbei das Controller Area Network<br>(CAN) Bussystem. Mithilfe des ISO Transportprotokolls sollen diverse Diagnosedienste<br>an das Steuergerät gesendet werden. Diese werden nach Erhalt ausgeführt und eine ent-<br>sprechende Antwort zurück gesandt. Rückgaben werden entgegengenommen, interpre-<br>tiert und passend dargestellt. Hierzu gehört neben einer passenden Benutzeroberfläche<br>auch die optionale Erzeugung einer HTML Datei mit den Ergebnissen. Im Rahmen der<br>Arbeit werden die Dienste Fehlerspeicher löschen und Fehlerspeicher lesen implementiert.
12.12.19;16.06.20;2020;intern;Bachelor;DE;Untersuchung aktueller maschineller Lernverfahren zur Erkennung von Emotionen in Beratungsverläufen;"Im Rahmen dieser Arbeit wurde untersucht, mit welcher Qualität sich Wörterbuchverfahren zur Emotionsanalyse in Forentexten einsetzen lassen und welche Probleme dabei identifiziert werden können.<br><br>Für weitgefasste, oberflächliche Analysen, wie Unterschiede vom durchschnittlichen Emotionsgehalt <br>zwischen verschiedenen Foren konnten Erfolge erzielt werden.<br>Der Versuch, Bezeichner wie ""sehr hoher"" oder ""mittelhoher"" Emotionsgehalt durch Vergleich mit dem gesamten Datensatz abzuleiten, war nicht erfolgreich.<br><br>Eines der drei verwendeten Wörterbücher, das nur durch automatische Übersetzung aus dem Englischen entstanden ist, konnte im Vergleich zu den anderen beiden keine zuverlässigen Ergebnisse liefern.<br>Die anderen zwei Wörterbücher waren im Gegensatz dazu von deutschsprachigen Experten kuriert. <br><br>Als Probleme konnten in dieser Arbeit unter anderem die niedrige Textqualität von Forentexten identifiziert werden. Darüber hinaus wird gerade in Foren für psychische Probleme teilweise eine domänenspezifische Sprache verwendet, die die Wörterbücher nicht immer abbilden. Auch die Betrachtung einzelner Worte ohne Berücksichtigung des Kontexts gehört zu den Nachteil dieses Verfahrens."
12.12.19;31.10.20;2020;extern;Bachelor;DE;Einführung von Business Intelligence Lösungen in mittelständischen Unternehmen: Requirements Engineering, Prozessentwicklung und Tool-Auswahl.;
13.12.19;14.03.20;2020;extern;Bachelor;DE;Entwicklung einer GUI zur Konfiguration von IoT Systemen mit RDF Graphen;"Das Ziel der Bachelorarbeit ist es, den Einsatz von Geräten, aus dem Bereich Internet der Dinge (IoT), zu vereinfachen. Berücksichtigt werden hierbei nur IoT-Geräte, welche Daten zur Kommunikation über das Hypertext Transfer Protocol versenden und mit dem, vom World Wide Web Consortium eingeführten, SOSA Vokabular beschreiben. Umgesetzt wird dies, durch die Implementierung einer grafischen Oberfläche auf der mit Ziehen und Ablegen von Blöcken, das Application Programing Interface (API) eines IoT-Systems bedient wird. Als konkretes Anwendungsszenario wird ein System zur Verwaltung eines Postbehälterkreislaufs genutzt. Anwender sollen in der Lage sein, ohne Fachwissen, durch Anordnen von grafischen Elementen Abfragen, in der Abfragesprache SPARQL, zu schreiben. Dabei sollen sie Bedingungen für den Postbehälterkreislauf festlegen können wie beispielsweise ""Behälter ist an Poststelle X"", ""Behälter hat Standort X verlassen"" oder ""Behälterstandort seit Y Stunden unbekannt"". Zusätzlich sollen Anwender, abhängig von diesen Bedingungen, Aktionen ausführen können. ZB. könnte die Anwendung eine Nachricht ausgeben, wenn eine Bedingung erfüllt ist. Diese Aufgaben werden abschließend in einer Evaluation von der Zielgruppe durchgeführt. Dabei wird die implementierte Anwendung hinsichtlich der Bedienbarkeit ohne oder mit nur wenig Fachwissen anhand der System Usability Scale, einem standardisiertem Fragebogen, bewertet. Die Anwendung erreicht hier einen überdurchschnittlichen Wert von 81.4."
17.12.19;20.04.20;2020;intern;Bachelor;DE;Didaktische Aufbereitung eines autonom fahrenden Modellfahrzeuges auf Basis einer Arduino Plattform;In dieser Bachelorarbeit wird ein autonom fahrendes Roboterauto (Artur) basierend auf dem UNO AT 328 R3 und dem Mega AT 2560 R3 (+ESP8266 WiFi-Modul) auf der Arduino-Plattform gebaut, das mit einer geeigneten Sensorik ausgestattet wird. Durch mechanische Notendschalter im vorderen und hinteren Bereich des Roboters wird die Sicherheit gewährleistet.<br>Zusätzlich wird eine Konzeption zu einer Lernbaukasten für die Altersgruppe ?Sekundarstufe 1? konstruiert, mit dem die Problematiken in dem Themenbereich ?autonomes Fahren? vorgestellt werden. Eine softwaretechnische Konzeption und Umsetzung eines Vorprototyps (BB09) auf der Basis von Artur macht einen wesentlichen Teil der Abschlussarbeit aus. Die Programmiersprache basiert auf C und umfasst C++-Erweiterungen. Die Arduino-IDE stellt alle notwendigen Tools zur Verfügung.<br>Die Herausforderung besteht bei einem solchen Projekt darin, die Bauteile selber zu planen, zu bestellen und zusammenzubauen. Die Empfindlichkeit der Sensoren hat in unterschiedlichen Umgebungen Auswirkung auf die Funktionsfähigkeit, die durch intelligente Auswertungsalgorithmen verbessert werden kann. Im Zusammenhang damit werden unterschiedliche Ressourcen benötigt. Dazu zählen beispielsweise zusätzlicher Programmcode, mehr Komplexität zwischen den Softwareblöcken und mehr Datenspeicher.<br>Im nächsten Schritt sollte eine künstliche Intelligenz in den Entscheidungsprozess involviert werden.
20.12.19;14.03.20;2020;intern;Bachelor;DE;Künstliche Intelligenz im strategischen Einkauf: Transformation von Geschäftsprozessen am Beispiel eines Prototypen.;
21.01.20;26.07.20;2020;extern;Bachelor;DE;"Erweiterung einer App um eine Nutzerauthentifizierung am Beispiel ""Das Telefonbuch""";"Die IT2Media GmbH entwickelt im Auftrag der Deutsche Tele Medien GmbH eine kostenlose iOS- und Android-Applikation mit dem Namen ""Das Telefonbuch?, in der jegliche Firmen und Personen einen Telefonbucheintrag erhalten, die gegen eine Eintragung nicht widersprochen haben.<br>In dieser App werden alle vorhandenen Daten zu einem Telefonbucheintrag angezeigt. Im Moment ist das Buchen von weiteren Zusatzinformationen oder Service-Funktionalitäten für einen Telefonbucheintrag über die App nicht möglich. Damit solche Transaktionen in der Zukunft über die Applikation geführt werden können, wird eine Nutzerauthentifizierung benötigt.<br>Das Ziel dieser Arbeit ist das Entwickeln eines mobilen Prototyps, welcher mit einem Server kommuniziert, der es dem User ermöglicht, sich schnell und leicht innerhalb der App anzumelden, um zukünftig gebührenpflichtige Services und weitere Zusatzinformationen für seinen Eintrag in der Applikation zu buchen. Derzeit existieren keine User-Accounts, um eine Anmeldung durchzuführen. Dazu wurde der Ist-Zustand der mobilen Applikation ""Das Telefonbuch? analysiert und die verschiedenen existierenden Kaufprozesse geschildert, die momentan genutzt werden, um diese Transaktionen zu tätigen. Auf Basis der erfolgten Analyse des Ist-Zustands wurde ein Konzept für die Authentifizierung der User entwickelt, die in der Zukunft für die App entwickelt wird.Neben dem Konzept und dem Prototypen soll auch ein Backend-System entwickelt werden, welches für die Authentifizie<br><br>"
29.01.20;01.08.20;2020;intern;Bachelor;DE;3D Kartografierung mit einer Time-of-Flight-Kamera;Damit sich ein Roboter in einer ihm fremden Umgebung orientieren kann, muss er diese erst erkunden. Allein durch die Daten seiner Sensoren soll er gleichzeitig seine Umgebung Kartografieren, als auch seine räumliche Lage und Orientierung bestimmen. In der Forschung wird diese Herausforderung auch als Simultaneous Localization and Mapping (SLAM) bezeichnet.<br>Hiefür können Time-of-Flight Kameras eingesetzt werden. Das sind Digitalkameras, die in den Pixeln statt der Farbinformation die Entfernung eines Objektes erfassen. Damit kann pro Aufnahme eine 3D Punktwolke dieses  Ausschnittes generiert werden. Setzt man diese mit einem SLAM Verfahren richtig zusammen, ensteht eine<br>dreidimensionale Karte der Umgebung.<br>Diese Arbeit erläutert die Funktionsweise von SLAM Systemen, die nur mit Bilddaten aus einer Time-of-Flight Kamera versorgt werden. Im Auswahlprozess wurde sich für das ORB SLAM 2 System entschieden und dieses für die 3D Kartografierung mit einer dichten Punktwolke erweitert.<br>Mittels einer JavaRos Schnittstelle wurde versucht, die SLAM Implementierung in die Bugbot-Plattform zu integrieren.
29.01.20;29.09.20;2020;intern;Master;DE;Einsatz von dynamischen Multilevel-Multitheory-basierten Modellen zur Analyse digitaler Wissensnetzwerke am Beispiel einer interdisziplinären wissensintensiven Organisation;Die digitalen Infrastrukturen moderner Unternehmen stellen Mitarbeiterinnen und Mitarbeitern mehrere IT-Applikationen zur Verfügung, die bei Nutzung zur Entstehung informeller digitaler sozialer Netzwerke neben der formellen Aufbauorganisation führen. Diese im Organisationskontext entstandenen Netzwerke sind ? trotz zahlreicher Theorien und statistischer Werkzeuge ? nicht erschöpfend erforscht. Dabei können solche Netzwerke wertvolle Einblicke in die Wissensaustausche sowie Unternehmensstrukturen und -dynamiken gewähren.<br><br>Mit dieser Arbeit sollen anhand des Wissensnetzwerks einer interdisziplinären wissensintensiven Organisation Hypothesen zur Netzwerkdynamik und -struktur aufgestellt und mithilfe eines dynamischen Multilevel-Multitheorie-basierten Modells auf mehreren Netzwerkebenen simultan geprüft werden. Dabei wird überprüft, inwiefern dieses Modell ein ganzheitliches Verständnis eines Netzwerks ermöglicht und inwiefern es eine Grundlage für das Erkennen von Stärken und Schwächen liefert.<br><br>Zunächst soll eine Literaturrecherche im Bereich der Netzwerkanalyse mit Fokus auf modellbasierte Analysen stattfinden. Darauffolgend werden die Daten des Wissensnetzwerks erhoben, systematisiert und formatiert. Anschließend soll das Netzwerk mithilfe des ausgewählten Modells analysiert und nach Stärken und Schwächen untersucht werden. Abschließend werden eine Zusammenfassung zu dem Modelleinsatz und ein Ausblick auf die Perspektiven der Modellierung gegeben.
31.01.20;09.09.20;2020;extern;Master;DE;Empfehlung von Führungsmethoden in der Softwareentwicklung unter Einbeziehung unterrepräsentierter Gruppen;Im Bereich der Softwareentwicklung haben sich in den letzten Jahren die agilen Führungsmethoden immer mehr etabliert. Leadership wird immer wichtiger für Personen mit Führungsverantwortung. Hinzu kommt, dass die Diversität in der Gesellschaft zu einer immer größeren Vielfalt an Personen in der Softwareentwicklung führt. Diese Personengruppe besteht aus verschiedenen Clustern unterrepräsentierter Gruppen. Dazu zählen insbesondere Alleinerziehende, ältere Personen, Arbeiterkinder bzw. Bildungsaufsteiger, Frauen, Menschen mit Behinderung, Personen mit Migrationshintergrund und Quereinsteiger. Diese unterrepräsentierten Gruppen stellen unterschiedliche Ansprüche und setzen unterschiedliche Schwerpunkte bezüglich der Führungsrollen. Um dies beurteilen zu können, wird eine Umfrage durchgeführt. Hierbei werden die Antworten bezüglich der verschiedenen Führungsausprägungen analysiert. Besonderheiten jeder Gruppe werden in jedem Bereich näher betrachtet. Anschließend wird eine zusätzliche Expertenbefragung auf Grundlage der Umfrage durchgeführt. Die erste Frage an die Experten zielt darauf ab, die Akzeptanz der Rolleninhaber genauer zu hinterfragen. Die zweite Frage ermittelt die Meinung der Experten zur persönlichen Mitbestimmung bei Neueinstellungen im Team und deren Rolleninhaber. Anschließend werden die Expertenantworten mit den Umfrageergebnissen zusammengeführt und die Besonderheiten der einzelnen unterrepräsentierten Gruppen herausgearbeitet.
01.02.20;30.09.20;2020;intern;Master;DE;Echtzeit-Raytracing mit modernen GPUs;Diese Arbeit beschäftigt sich mit der Implementation und Evaluation eines Raytracingalgorithmus auf Basis zweier Methoden zur Hardwarebeschleunigung.<br>Zunächst werden zwei Applikationen konzipiert und entwickelt, welche anschließend mithilfe von Benchmarks auf Unterschiede in der Performance verglichen werden.<br>Die Grundlage hierfür ist zum einen NVIDIA RTX und zum anderen die Computing-Schnittstelle CUDA, welche in der Industrie bereits produktiv im Einsatz ist.<br>Die Messergebnisse bestätigen, dass die Hardwarebeschleunigung der NVIDIA Grafikkarten einen signifikanten Sprung der Performance für Anwendungen der Computergrafik ermöglichen.<br>Allerdings deuten einige Messergebnisse darauf hin, dass dieser Vorteil für eigens definierte Geometrie verloren geht.<br>Für Anwendungen, welche die Geometrie nicht auf eine Ansammlung von Dreiecken zurückführen können, wird den hier vorgestellten Messergebnissen zufolge weiterhin CUDA die schnellere und flexiblere Alternative darstellen.
10.02.20;10.07.20;2020;intern;Bachelor;DE;Ein System zum visuellen Navigieren in Räumen am Beispiel System Pepper;
13.02.20;31.07.20;2020;extern;Master;EN;Accessing NoSQL-Databases in Exasol using Virtual Schemas;In this thesis we present an Exasol Virtual Schema adapter for DynamoDB. This adapter allows users to access document data that is stored in a DynamoDB from inside of the Exasol analytical database.<br>It abstracts over the different interfaces so that users can access the document data using Exasol's regular SQL interface.<br>This thesis work provides generic design and implementation of the adapter that is extensible for other document databases.<br>In contrast to the state of the art solutions this adapter is highly scalable over multiple cluster nodes.<br>We show that on a cluster with four nodes, the loading of external data is more than six times faster than using existing solutions.<br>For creating an Exasol like data access, the adapter maps the document structure to a relational table model.<br>Therefore we introduce the Exasol Document Mapping Language, that let users define this mapping in a convenient way.<br>Unlike the comparable solutions, we also present a concept for handling data that was modeled using the single table design pattern, that is very popular for DynamoDB database design.
13.02.20;13.10.20;2020;extern;Master;DE;Ermittlung der Wertschöpfung im System Engineering durch Anwendung der im Supply Chain Management vorhandenen Methoden;Ziel dieser Forschungsarbeit ist die Entwicklung eines Modells zur Bewertung der Wertschöpfungskette in einem Unternehmen basierend auf den Prinzipien einer schlanken und agilen Wertschöpfungskette. Der Fokus liegt hier auf erfolgreichem Prozessmanagement in Unternehmen aus dem Bereich des Systems Engineering. Zusätzlich wurde eine gesonderte Version mit allgemein gültigen Kriterien ausgearbeitet, die für alle Unternehmen anwendbar ist. Zur Ermittlung der wichtigsten Prinzipien und Schwerpunkte wurde eine Expertenbefragung online durchgeführt und ausgewertet. Die wichtigsten Ergebnisse sind der Fokus auf den Kundenerfolg, kontinuierliche Verbesserung der Prozesse, Zusammenarbeit und Vereinfachung entlang der Wertschöpfungskette, Verschwendungsreduktion und Flexibilität der Wertschöpfungskette. Basierend auf diesen Punkten wurden im Hinblick auf Kundenorientierung Kundenanforderungen durch eine unternehmensinterne Befragung erhoben und diesen Prinzipien zugeordnet sowie gewichtet. Es entstand ein Punktesystem basierend auf Kennzahlen, die die Hauptkriterien beschreiben. Das Gesamtmodell liegt in Form einer Excel-Datei vor und kann zur internen Messung der Qualität der Wertschöpfungskette verwendet werden.
17.02.20;17.07.20;2020;extern;Bachelor;DE;Prototypische Umsetzung einer Anwendung zur Durchführung, Dokumentation und Auswertung der Reifegradmodell-Bewertung im BMW Werk Regensburg;"Der Prozess der Reifegradmodell-Bewertung im BMW Werk Regensburg wird aufgrund des hohen manuellen und zeitlichen Aufwands, der wenig benutzerfreundlichen Durchführung sowie der eingeschränkten Auswertungsmöglichkeiten als nicht zufriedenstellend angesehen. Daraus ergab sich der Bedarf, diesen mit Hilfe der Digitalisierung effektiver und effizienter zu gestalten. Das Ziel dieser Arbeit bestand darin, eine digitale Lösungsmöglichkeit auf Basis von Oracle APEX zu erarbeiten, deren Effektivität und Effizienz sowie deren Übertragbarkeit auf das Mini-Werk Oxford zu überprüfen. Als wissenschaftliche Grundlage diente die Design Science Research, welche die Entwicklung eines Artefakts zur Lösung eines Problems aus der beruflichen Praxis zum Ziel hat. Dieses Artefakt gilt es mittels geeigneter Methoden zu entwickeln, regelmäßig zu evaluieren und einer breiten Öffentlichkeit zugänglich zu machen. Ausgehend von einer Ist- und Schwachstellenanalyse wurden die Anforderungen an eine Anwendung zur Reifegradmodell-Bewertung in Form von User Stories entwickelt. Darauf folgten Konzeption, Implementierung sowie Test und Evaluation. Die im Rahmen dieser Arbeit entwickelte Anwendung ""PS RGM"" wurde von der relevanten Zielgruppe als effektiv und effizient angesehen, was die Ergebnisse einer Umfrage bestätigt hat. Die Anwendung wird bereits zur diesjährigen Durchführung der Reifegradmodellbewertung eingesetzt und soll künftig auf das gesamte BMW-Netzwerk ausgeweitet werden. "
18.02.20;03.11.20;2020;intern;Master;DE;Analyse der Ist-Situation und der Stakeholder-Anforderungen an ein Dokumentenmanagementsystem und Ableitung der technischen Systemanforderungen am Beispiel der TH Nürnberg;Das Ziel dieser Arbeit ist festzustellen, welche Anforderungen die Technische Hochschule Nürnberg an ein neues Dokumentenmanagementsystem hat. <br>Dazu stellt sich die Frage, welche Anforderungen aus dem aktuellen Dokumentenmanagementsystem der Technischen Hochschule Nürnberg entstehen und welche weiteren Anforderungen die Technische Hochschule Nürnberg stellt.<br>Um die Anforderungen zu ermitteln wurde ein Requirements Engineering durchgeführt. Nachdem mit einer IST-Analyse ein Überblick über die im Dokumentenmanagement vorhandenen Inhalte gewonnen wurde, folgte die Ermittlung der Stakeholder und ihrer Anforderungen durch einen Fragebogen. Mit Hilfe von Interviews und E-Mails konnten die Anforderungen verfeinert werden. Aus diesen fachlichen Anforderungen wurden die technischen Anforderungen abgeleitet.<br>Das Requirements Engineering hat ergeben, dass die im aktuellen Dokumentenmanagementsystem gespeicherten Inhalte zum großen Teil in Zukunft in anderen Systemen abgelegt werden sollen. Es wurden einige neue Anforderungen ermittelt, darunter eine Ablage für elektronische Studierendenakten, eRechnungen und die Registratur. <br>Das Ergebnis ist eine Dokumentation der fachlichen und der technischen Anforderungen in Form von User-Storys. Auf dieser Basis kann die Technische Hochschule Nürnberg ein für sie passendes Dokumentenmanagementsystem auswählen. Um einen objektiven Vergleich von Produkten zu ermöglichen, wurden die Herstelleranforderungen in einer Bewertungsmatrix zusammengefasst.
01.03.20;04.11.20;2020;extern;Master;EN;Cooperative Behavior in a Multi-Agent Reinforcement Learning System for Reactive Scheduling in Flexible Manufacturing;Production systems have become increasingly complex in recent years. This must also be considered in the design of a scheduling system including the expectation to be able to instantly react to unforeseen events. There is a large research gap with regard to reactive scheduling systems that can handle the challenges of future manufacturing systems. <br>This work continues prior research of Siemens to develop a reactive scheduling system<br>using reinforcement learning. In the baseline system, agents are used to control products<br>through a simulated manufacturing system. <br>First, a concept was developed which allows the agents to process multiple consecutive operations in the same module if it benefits their optimization goal. Second, it was shown that with a suitable job specification encoding and training strategy, the agents are able to generalize the job specifications used during training and also correctly schedule unseen jobs. In addition, the implemented encoding was shown to allow the agents to handle job specifications of arbitrary formats. Third, regarding global optimization, it was demonstrated that global rewards can effectively be used to make the agents more cooperative and to optimize for a global optimization goal such as reaching a minimal total makespan. Overall, these promising results confirm the eligibility of reinforcement learning to solve complex scheduling tasks in practical applications.<br>
01.03.20;05.09.20;2020;intern;Bachelor;EN;design and implementation of a natural language inspired domain specific languague formalizing the specification of extract-transform-load scenarios for non-programmers;This thesis aims at designing and implementing a domain specific language as close as possible to natural language (English) capable of specifying ETL-jobs. To accomplish this, firstly,<br>appropriate design principles shall be taken into account according to [Fowler and Parsons, 2011].<br>Furthermore findings on English syntax and semantics shall be taken into account. An implementation of the DSL in form of a parser that outputs some form of configuration file(s)<br>shall be realised as parser combinator in JavaScript. To enhance usability of the DSL suitable syntax highlighting and code completion capabilities could be implemented probably as<br>extension for the code editor Visual Studio Code (also in JavaScript on top of the language<br>server protocol).<br>This work is not a cooperation between my employer and me. Rather do I utilize an abstract<br>problem drawn from workexperience as an example for the overall topic.
10.03.20;14.09.20;2020;intern;Bachelor;DE;Entwicklung eines patternbasierten Game-Design-Prozesses auf Basis generischer Design-Misfit-Graphen;"Ziel ist es, herauszufinden, ob und wie die in Alexanders  ""Notes on the Synthesis of Form"" beschriebene Heuristik auf den bereits bestehenden Problemgraphen bei Empamos angewendet werden kann. Ziel ist also, die im Buch beschriebene Methodik von Christopher Alexander anzuwenden. Die Probleme sollen designtechnisch so dargestellt werden, dass Spieleentwicklern ein Schritt-für-Schritt-Vorgehen an die Hand gegeben wird, welches ihnen hilft, die während der Spieleentwicklung entstehenden Entwurfsprobleme zu lösen."
13.03.20;20.09.20;2020;intern;Bachelor;DE;Untersuchen der Folgen von Digitalisierung, Fachkräftemangel und demographischen Wandel auf Unternehmen der IT-Branche - Literaturstudie und eine Gegenüberstellung von Lösungsmöglichkeiten<br>;Digitalisierung, Fachkräftemangel und demographischer Wandel. Drei Schlagworte die im heutigen Sprachgebrauch zunehmend zu finden sind und welche die Arbeitswelt in allen Bereichen vor große Herausforderungen stellt. Ziel der Arbeit ist es auf die Digitalisierung, den Fachkräftemangel und den demografischen Wandel einzugehen und deren Folgen für die Unternehmen der IT-Branche aufzuzeigen. Innerhalb der Arbeit werden zudem Lösungsansätze vorgestellt und diese mittels einer Nutzwertanalyse gegenübergestellt. Des Weiteren zeigt eine für die Arbeit durchgeführte Onlineumfrage die gegenwärtige Ist-Situation, wie die Unternehmen der IT-Branche die Digitalisierung, den Fachkräftemangel und den demographischen Wandel für sich einschätzen.   
15.03.20;15.11.20;2020;extern;Master;DE;Clustering von Berufen anhand der Identifikation von Ähnlichkeiten;Diese Arbeit beschäftigt sich mit dem Clustering von Berufen anhand der Identifikation von Ähnlichkeiten. Die Vorgehensweise hierzu umfasst verschiedene Methoden des Data-Mining ? insbesondere der Cluster-Analyse ? sowie der natürlichen Sprachverarbeitung. Nach einer umfassenden Vorverarbeitung der vorliegenden Datenbestände werden relevante Merkmale identifiziert, die Ähnlichkeit zwischen Berufsgruppierungen anhand dieser Features ermittelt und eine kombinierte Distanzmatrix als Grundlage für den nachfolgenden Clustering-Prozess generiert.<br>Zur Clusterbildung werden zwei Verfahren verglichen: Das Clustering mit DBSCAN-Algorithmus sowie die Clusterbildung mithilfe eines hierarchischen bzw. agglomerativen Verfahrens. Die hierbei generierten Cluster werden abschließend durch einen Nachverarbeitungsprozess auf den Kontext dieser Arbeit angepasst. 
20.04.20;20.09.20;2020;extern;Bachelor;DE;Neukonzeption, Usability Evaluierung, Entwicklung und iterative Verbesserung eines Features für ein Projektvermittlungsportal;"Die benutzerfreundliche Gestaltung von Webseiten spielt eine immer bedeutendere Rolle im<br>Entwicklungsprozess. Da viele Unternehmen jedoch in dem Glauben sind, dass frühzeitiges<br>Entwerfen und Testen einer Software einen höheren Zeit- und Kostenaufwand mit sich<br>bringt, wird sich dagegen entschieden.<br>In dieser Arbeit sollen neue Feature für das ""Suppliance Tool"" der Suppliance AG identifiziert,<br>konzipiert und anschließend prototypisch implementiert werden. Dabei stellt sich<br>die Frage, welche Features dabei helfen, die Nutzung des Tools zu erleichtern. Es soll demonstriert<br>werden, welche Vorteile eine Entwicklung durch Berücksichtigung von Usability<br>Richtlinien mit sich bringt."
20.04.20;20.09.20;2020;extern;Bachelor;DE;Entwicklung einer performanten und linguistisch hochwertigen query auto completion ;Als query auto completion wird das Vorschlagen von möglichen Suchanfragen bei der Eingabe einiger Buchstaben in eine Suchleiste verstanden. Im Optimalfall wird dabei an oberster Stelle in der Vorschlagsliste die Suchanfrage, welche zur Zufriedenstellung des Informationsbedürfnisses des Suchenden führt, angezeigt. Dies kann dem Anwender dabei helfen, Rechtschreibfehler zu vermeiden, Tastenanschläge zu reduzieren und neue Schlüsselwörter zur Suche seines Problems zu identifizieren. Somit kann die Einführung einer query auto completion sowohl zum schnelleren Suchen als auch zu besseren Ergebnissen für den Anwender führen. Vorsicht ist bei der Qualität der Vorschläge geboten, da eine schlecht implementierte query auto completion den Anwender zu schlechten Suchergebissen führen kann. Im Rahmen dieser Bachelorarbeit wird eine query auto completion für die Internetseite der DATEV e.G. entwickelt. Hierbei wir das Augenmerk einerseits auf die Performance der Implementierung und andererseits auf die Qualität der Vorschläge gelegt.<br>Um die bestmögliche Lösung für eine query auto completion für die Internetseite der DATEV e.G. zu finden, werden verschiedene Ansätze zur Ermittlung der vorzuschlagenden Suchanfragen implementiert und verglichen. Darüber hinaus werden verschiedene Rankingverfahren auf ihre Tauglichkeit bei einer query auto completion untersucht.
20.04.20;31.08.20;2020;extern;Bachelor;DE;Adaption eines SoC an ein SIMATIC-Peripheriesystem unter Echtzeit-Aspekten;Für ein neues Konzept soll ein SIMATIC-Peripheriesystem mit einem SoC, der als Betriebssystem eine Linux-Distribution verwendet, erweitert werden. Dazu muss grundlegende Software entwickelt und erprobt werden.<br>Ziel dieser Arbeit ist es, einen Treiber in Form eines Linux-Kernel-Moduls zu entwickeln, der die zyklische und azyklische Kommunikation mit dem SIMATIC-Peripheriesystem übernimmt. Zusätzlich ist eine C-Bibliothek zu entwickeln, mit der man in einem Anwendungsprogramm einfach auf die Daten des Peripheriesystems zugreifen kann. Abschließend gilt es zu untersuchen, welche Echtzeitkriterien für den zyklischen Datenaustausch zwischen dem Peripheriesystem und einem Raspberry Pi 3 erreichbar sind.<br>Die Schnittstelle des Treibers zum User-Space wurde mittels Gerätedateien umgesetzt. Das Linux-System verwendet für den Zugriff auf das SIMATIC-System die proprietäre Schnittstelle sSLI. Die C-Bibliothek für den Anwender abstrahiert das Arbeiten mit den Gerätedateien des Treibers. Für eine möglichst allgemeine Aussage bzgl. der Echtzeitfähigkeit wurde diese Untersuchung mit einem entworfenen Worst-Case-Szenario durchgeführt. Es hat sich gezeigt, dass harte Echtzeit mit dem angestrebten Übertragungsintervall von 4 ms mit der verwendeten Hardware nicht möglich ist. Weiche Echtzeit mit einer Übertragung von min. 99% der zyklischen Daten ist möglich. In den Tests reduzierte der Preempt-RT Patch die Anzahl der verpassten zyklischen Daten.
20.04.20;20.09.20;2020;intern;Bachelor;DE;Automatische Generierung von Titeln und Abstracts;In der vorliegenden Bachelorarbeit soll erörtert werden, inwiefern es möglich ist, aus dem Abstract einer Abschlussarbeit den dazugehörigen Titel zu generieren. Hierfür soll das Bidirectional Encoder Representations from Transformers (BERT) Model von Google verwendet werden. Das BERT Modell kann mit mehreren Sprachen umgehen, darunter auch Deutsch. Als Datensatz für das englische System werden die Abstractbooks der Interspeech Konferenz der letzten 5 Jahre verwendet. Bei dem Datensatz in Deutsch handelt es sich um eine Sammlung von 935 Abschlussarbeiten der Fakultät Informatik. Es soll evaluiert werden, ob BERT für den gegebenen Zweck das passende Model ist. Für das Training wird das BERTSUM Modell verwendet, das speziell für Textzusammenfassungen ausgelegt ist. Die Evaluierung wird mit Recall-Oriented Understudy for Gisting Evaluation (ROUGE) und Word Error Rate (WER) durchgeführt. Die Ergebnisse von ROUGE und WER zeigen, dass BERT diese Aufgabe nicht ohne weitere Anpassungen bewältigen kann. Es werden noch mehr Experimente und Anpassungen im Nachgang dieser Arbeit benötigt, um eine genauere Aussage zu treffen.
20.04.20;21.09.20;2020;intern;Bachelor;DE;Paralinguistische Analyse mittels Residual und Time Delay Neural Network;"Die vorliegende Arbeit befasst sich mit einer paralinguistischen Analyse mittels zweier Typen künstlicher Neuronaler Netze (KNN), dem Residual Neural Network (ResNet) und dem Time Delay Neural Network (TDNN). Dabei werden folgende Fragen beantwortet: Wie präzise können die Daten durch die verschiedenen neuronalen Netze klassifiziert werden? Welcher Netzwerktyp eignet sich auf Basis der vorhandenen Daten besser für die Klassifikation von Sprachdaten? Bei Durchführung der Analyse werden vier bereits vorhandene und gelabelte Datensätze analysiert und kategorisiert. Der erste Datensatz beinhaltet dabei Sprachdaten alkoholisierter und nüchterner Personen, der zweite umfasst den Dialekt, der dritte und vierte den Akzent von Personen. Mit Hilfe des Alkoholdatensatzes und des<br>Dialektdatensatzes werden mehrere neuronale Netze trainiert. Anschließend werden durch<br>die trainierten Netze Embeddings erzeugt, um auf dieser Basis weitere Klassifikatoren zu<br>trainieren und deren Genauigkeit zu bestimmen. In der Alkoholerkennung wird zudem eine<br>Analyse nach einzelnen Kategorien durchgeführt. Dabei wird davon ausgegangen, dass bei<br>anspruchsvolleren Aufgaben (z. B. das Vorlesen von ""Zungenbrechern"") eine höhere balancierte Genauigkeit als bei einfacheren Aufgaben (z. B. das Vorlesen von Nummern)<br>erreicht wird. Mit Hilfe des Akzentdatensatzes werden vortrainierten neuronalen Netzen<br>Embeddings erzeugt und anschließend durch Dimensionsreduktionsmethoden die Dimension der Embedding-Vektoren auf ..."
20.04.20;20.09.20;2020;intern;Bachelor;DE;Visualisierung der in einer Hochschule eingesetzten IT-Systeme in Form von IT-Bebauungsplänen und Ableitung von Handlungsempfehlungen;An Hochschulen kommen heutzutage immer mehr IT-Systeme zum Einsatz. Durch diese immer größer werdende Flut an IT-Systemen geht allerdings der Überblick über die IT-Landschaft verloren.<br>Um den Überblick wiederherstellen zu können werden im Rahmen dieser Arbeit zwei IT-Bebauungspläne für die Technische Hochschule erstellt. Außerdem wird geprüft ob mithilfe dieser Pläne Redundanzen in der IT-Landschaft einer Hochschule aufgedeckt und Handlungsempfehlungen zu deren Beseitigung ausgesprochen werden können.<br>Um den wiederhergestellten Überblick auch fortlaufend gewährleisten zu können beschäftigt sich diese Arbeit zudem mit der Frage, welche EAM-Tools sich für den Einsatz an der Hochschule eignen.<br>Bei der Analyse der erstellten Bebauungspläne fiel auf, dass die Erkennung einer Redundanz allein durch einen Bebauungsplan nicht möglich ist. Hierfür werden weitere Beschreibungen zu den einzelnen Systemen benötigt. Allerdings konnte festgestellt werden, dass Bebauungspläne die Transparenz einer IT-Landschaft entscheidend erhöhen.<br>Im Anschluss werden im Rahmen dieser Arbeit zwei kostenlose Enterprise Architecture Management Tools vorgestellt und anhand einer prototypischen Umsetzung und eines festgelegten Kriterienkatalogs gegeneinander evaluiert. Hierbei ging das Tool ADOIT:CE als der Sieger hervor. Es wurde die Empfehlung ausgesprochen dieses Tool sukzessive auf mehr Fakultäten und Abteilungen zu erweitern und hochschulweit einzusetzen.<br>
20.04.20;27.11.20;2020;extern;Master;DE;Evaluation von State-of-the-Art-Ansätzen der Relation Extraction zur Erzeugung von Knowledge Graphen;Diese Masterarbeit ist Teil des Forschungsprojekts Future Engineering des Fraunhofer Instituts Supply Chain Services und der Technischen Hochschule Nürnberg, welches sich mit der automatisierten Wissensextraktion aus unstrukturierten Textdaten beschäftigt. Die Arbeit behandelt dabei die Frage, welcher der aktuellen State-of-the-Art-Ansätze im Bereich der Relation Extraction die beste Möglichkeit der Verwendung zur Erzeugung eines Knowledge Graphen im Rahmen des Future-Engineering-Projekts bietet. Zur Beantwortung dieser Frage wurde eine Auswahl verschiedener State-of-the-Art-Ansätze im Bereich der Relation Extraction evaluiert. Dies geschah durch den Vergleich der Ansätze mit Hilfe von Evaluationsszenarien auf Basis unterschiedlicher Datengrundlagen. Dazu wurde ebenfalls ein eigener Trainings- und Evaluationsdatensatz aus Daten des Future-Engineering-Projekts erzeugt. Zusätzlich wurde ein Prozess zur einheitlichen Verwendung unterschiedlicher Relation-Extraction-Ansätze mit nicht annotierten Daten definiert. Die Ergebnisse dieser Arbeit liefern Erkenntnisse über die Probleme und spezifische Verhaltensweisen der betrachteten Relation-Extraction-Ansätze und erlauben eine Bewertung über die Eignung der Ansätze zur Erzeugung von Knowledge Graphen im Future-Engineering-Projekt. Dabei lassen sich deutliche Unterschiede in den Ergebnissen erkennen, wobei der Ansatz R-BERT die besten Resultate aufweist und sich für den Einsatz in der Praxis empfehlen lässt.
20.04.20;20.12.20;2020;extern;Master;DE;Auditive Landmarken für blinde Menschen zur Integration in VR-Umgebungen;Diese Arbeit identifiziert in virtuellen Umgebungen automatisch Bereiche, die für blinde Menschen wichtig sind. In diesen Bereichen werden für eine virtuelle Trainingsumgebung auditive Landmarken platziert. Insbesondere ist die Identifizierung von Treppen relevant. Die Arbeit zeit auf, wie das Modelle vorverarbeitet werden müssen, damit relevante Bereiche erkannt werden können. Zur Klassifizierung von Objekten wurden zwei Ansätze genauer untersuchen. Die Erkennung kann durch semantische Segmentierung durchgeführt werden. Außerdem wurden Lösungsansätze evaluiert und bewertet, die mit machine learning arbeiten. 
20.04.20;20.12.20;2020;intern;Master;EN;Cloud Based Systems for AI Driven Computer Vision Applications;Developments in machine learning, in particular deep learning, have achieved outstanding results in the field of computer vision, e.g., object recognition and classification as well as face and text recognition.<br>This thesis presents a comprehensive study of the potential of cloud-based solutions for the development and operation of computer vision applications.<br>The focus is on the challenges associated with artificial intelligence methods.<br>Conceptual considerations of infrastructure and platform services are illustrated by selected cloud services from Amazon, Microsoft, and Google.<br>That includes virtual development environments, storage and database systems, and specialized services to develop and deploy machine learning algorithms.<br>Furthermore, production-ready computer vision algorithms for direct integration into applications will be presented by comparing five leading providers' services.<br>Finally, the use of computer vision at the edge of the cloud (e.g., Edge Computing) will be explored, showing how collaborative cloud-edge systems can reduce network utilization and latency.
20.04.20;20.12.20;2020;intern;Master;DE;Klassifikation psycho-sozialer Äußerungen mittels tiefer neuronaler Netze;Durch die zunehmende Beliebtheit und Nutzung öffentlicher Onlineberatungsforen stehen heutzutage noch nie dagewesene Mengen an frei einsehbaren Daten über Beratungsgespräche im Internet zur Verfügung. Eine manuelle qualitative Inhaltsanalyse dieser Daten ermöglicht es, Stärken und Schwächen im Vorgehen bei Onlineberatungsgesprächen aufzudecken. Da diese manuellen Untersuchungen jedoch sehr zeitaufwendig sind und ein umfangreiches Wissen benötigt wird, ist es häufig nicht möglich, qualitative Inhaltsanalysen auf großen Datenmengen durchzuführen.<br>Um diesem Problem entgegenzuwirken, werden in dieser Arbeit die Einsatzmöglichkeiten neuronaler Klassifikationsverfahren zur automatisierten Kategorisierung psycho-sozialer Aussagen von Onlineberatenden untersucht. Neben einer einfachen Support Vector Machine als Baseline wurden hierzu insgesamt fünf neuronale Modelle in unterschiedlichen Ausprägungen erzeugt, in ihrer Güte bewertet und mit der Klassifikationsleistung menschlicher Codierenden verglichen.
20.04.20;20.12.20;2020;extern;Master;EN;Using the optical signals produced by the ranging system of a modern LiDAR device to estimate mirror positions in real-time;[shortened]<br><br>A significant factor for the quality of a LiDAR system is its accuracy.<br>Many devices have small errors in their distance measuring as well as in the trajectory prediction.<br>These errors are often fatal when using the system in a high-security environment like autonomous driving.<br>In cooperation with a german LiDAR startup (Blickfeld), online, internal calibration methods should be evaluated during run-time.<br><br>This research includes an overall error estimation, which is done using a checkerboard calibration technique on distorted data.<br>Several concepts are thought of and experimented with, using different marker patterns within the device's enclosure with various materials and other ideas like passive illumination with IR-LEDs.<br><br>The most useful techniques in this topic proved to be image-processing algorithms, especially for edge detection (e.g., Sobel-Kernels) and smart aggregation of the sensor's data.<br><br>The results suggest that it is possible to detect markers at the borders of the field of view of such a device.<br>Still, that calibration is bound to factors like fabrication precision, which could not be reached within this thesis's scope.<br>In general, a lot of parameterization needs to be done on the LiDAR, and a slight change in these parameters can already yield different results.<br>These factors make it almost impossible to calibrate the given LiDAR device during runtime.
20.04.20;20.09.20;2020;extern;Bachelor;DE;"""Entwicklung und Verifizierung von Testkonzepten für Machine Learning Modelle am Beispiel von Datendrifts in den Eingangsdaten eines Modells""";This thesis describes the development and verification of test concepts with which machine learning models can be tested. It is shown how data drifts have a negative impact on the reliability of machine learning models and how data drifts can be detected by drift detectors.<br>This is demonstrated practically by training machine learning models with a data set from the industry. Afterwards predictions for another data set, which contains data drifts, are made. The experiment shows that machine learning models predict less reliably on input data, that contains data drifts, compared to input data, which does not contain data drifts. Drift detectors are used in the experiment to show how they can be applied to show differences in the value distribution of two data sets.<br>Based on these results, it can be seen that it is necessary to perform data-related tests on machine-learning models before their deployment in order to improve the reliability of their predictions.
20.04.20;20.12.20;2020;intern;Master;EN;Scrutable Responsive Web Design;Responsive Web Design (RWD) is an essential tool for the realization of user interfaces. The user experience can be significantly supported by this approach - but also impairments are possible. As a cause, the adaptations of the user interface associated with responsive behavior can be mentioned. If these adaptations do not correspond to the user's expectations, this can leave a negative impression on the user. This situation is made more difficult by the fact that responsive behavior is not very standardized. This thesis aims to create such a standard. For this purpose, the effect of RWD is formally examined. For this purpose, representative web pages are selected which reflect the typically implemented responsive behaviors and likely also the user expectations.  On this basis, a user study is conducted in which the user's behavior with a responsive user interface is examined. An online survey, a preference test in the form of an interview, a first-click test, and an operation test were performed with German participants. Based on the test results, it was found that the realization of a standard is not possible. Nevertheless, basic findings were compiled in the form of a guideline. This guideline contains information that can help to make the design of responsive websites more user-friendly.
20.04.20;20.09.20;2020;extern;Bachelor;DE;Analyse zur effizienten Kopplung heterogener Systemlandschaften unter der besonderen Berücksichtigung der Datentransformation;Im Rahmen der Bachelorarbeit wird die effiziente Kopplung heterogener Systemlandschaften analysiert. Spezialisiert auf kleine und mittelständische Unternehmen im Kontext der Digitalisierung, wird die Relevanz des effizienten Datenaustauschs sowie die Einordnung des Datenaustausches in den betrieblichen Rahmen (Stammdaten, Bewegungsdaten) behandelt. Es sollen Datenaustauschformate im Bereich B2B (CSV, EDIFACT, Fortras, BMEcat etc.) verglichen, sowie die Besonderheiten von INHOUSE-Formaten (auch zum innerbetrieblichen Datenaustausch) dargestellt werden. Der Fokus der Arbeit liegt auf dem generischen Ansatz des Datenaustausches der anhand des Common<br>Data Models von Microsoft abgebildet wird. Es sollen Stärken, Schwächen sowie Grenzbereiche dieser Plattform analysiert und ausgearbeitet werden.<br>
20.04.20;31.03.21;2020;intern;Bachelor;DE;Prototypische Implementierung eines Chatbots zur Administration einer Wissensdatenbank;Das Ziel der vorliegenden Arbeit ist es, die Frage zu beantworten, ob Conversational User Interfaces für die Administration von Wissensdatenbanken geeignet sind.<br>Dazu wird ein Chatbot-Prototyp mit dem Framework Rasa zur Administration der Wissensbasis eines bereits bestehenden Chatbots entwickelt. Grundlage der Entwicklung bilden eine durchgeführte System- sowie eine Anforderungsanalyse mit dem Ziel, die Funktionalitäten des Systems aufzudecken und das System nach außen abzugrenzen.<br>Basierend auf den Ergebnissen der Analysen wird ein Konzept für den Prototypen ausgearbeitet, welches beschrieben und anschließend implementiert wird. Dabei werden sowohl der Design- als auch der Entwicklungsprozess erläutert. Die Tauglichkeit des Chatbots für das vorliegende Anwendungszenario kann in einer ausführlichen Evaluation des Prototypen bestätigt werden.<br>
20.04.20;20.12.20;2020;intern;Master;DE;Integration eines zentralen Assistenzsystems in Webanwendungen;Die Nutzung von Assistenten in Form von Sprachassistenten und Chatbots nimmt zu. Ein Grund dafür ist, dass sich die virtuellen Helfer zunehmend auf Smartphones und Smart Devices befinden. Ein weiterer Grund ist, dass sie zum aktuellen Stand der Technik alltagstauglich Aufgaben erledigen können, wie Nachrichten formulieren, Wecker stellen und Smarthome-Geräte steuern. Das Anwendungspotenzial wird jedoch noch nicht vollständig genutzt. Die Idee ist daher Assistenten mit Webanwendungen zu verknüpfen, um die Anwendungsfälle zu erweitern und Vorteile für die Nutzung von Webanwendungen zu bieten, wie einen barrierefreieren Zugang. Ein Problem für Betreiber von Webanwendungen mit angebundenem Assistenzsystem ist die große Menge an zu unterstützenden Assistenten auf dem Markt. Ein paar Beispiele sind die Sprachassistenten Alexa, Siri und der Chatbot Telegram Bot. Das Ziel der Arbeit ist es dieses Problem durch die Integration eines zentralen Assistenzsystems in Webanwendungen zu lösen. Das entworfene Konzept der Arbeit sieht dazu vor, dass vorhandene Schnittstellen von Webanwendungen zur Anbindung des Assistenzsystems verwendet werden. Zusätzlich wird das zentrale Assistenzsystem von intelligenten Agenten bei der Ausführung von Aufträgen unterstützt. Durch eine Verknüpfung der genannten Technologien ergibt sich folgender Weg für einen Auftrag in menschlicher Sprache. Ein Befehl in menschlicher Sprache wird über angebundene Kommunikationskanäle zu einer Schnittstelle übermittelt, ... 
20.04.20;20.09.20;2020;extern;Bachelor;DE;Evaluierung einer Simulationsumgebung für die Erzeugung von Umgebungsdaten für den Test von ADAS-Systemen;
20.04.20;20.09.20;2020;intern;Bachelor;DE;Implementierung einer erweiterbaren Webanwendung zur interaktiven Textvisualisierung;Durch die stetig steigende Menge an digital verfügbaren Textdaten steigt auch das Interesse an der effektiven Auswertung ebendieser. Der Themenbereich der computergestützten Datenanalyse bietet unterschiedliche Verfahren an, welche unter anderem zur Extraktion verborgener Zusammenhänge und Informationen genutzt werden können. Im Bereich der Sozialberatung kann von solchen Verfahren stark profitiert werden, da die Analysen meist händisch durchgeführt werden. Deshalb wurde in dieser Bachelorarbeit eine Webanwendung zur interaktiven Textanalyse und -visualisierung entwickelt. Sie stellt die Schnittstelle zu einer vorhandenen Datenbasis dar, mit der unter anderem ausgewählte Diagramme erstellt werden können. Der Fokus der Entwicklung lag auf der erweiterbaren Softwarearchitektur der Anwendung, welche auf etablierten Designprinzipien basiert. Im Laufe der Arbeit konnte somit eine Grundlage für die besprochenen Erweiterungsmöglichkeiten geschaffen werden.
20.04.20;20.09.20;2020;intern;Bachelor;DE;Emotionsanalyse von automatisch übersetzten Texten mithilfe maschineller Lernverfahren;maschineller Lernverfahren wurde bereits mehrfach mit vielversprechenden Ergebnissen im englischsprachigen Bereich angewandt. Im Deutschen gibt es allerdings kaum Bemühungen, Emotionen in Texten zu erkennen und auch keine verwendbaren Datensätze. Für das CaSoTex Projekt der Technischen Hochschule Nürnberg soll die Emotionsanalyse im Deutschen durchgeführt werden, um Emotionen in deutschsprachigen Beiträgen innerhalb Beratungsforen erkennen zu können.<br><br>Das Erkennen der Emotionen in dieser Arbeit erfolgt deshalb auf vom Englischen ins Deutsche übersetzten Texten. <br>Es werden vier englischsprachige Datensätze (ISEAR, Märchentexte, TEC und SemEval-2018) mittels eines hierarchischen Emotionsmodells kombiniert. Die Übersetzung der Daten ins Deutsche erfolgt automatisch mit Google Translate. Die durch die maschinellen Lernverfahren zu erkennenden Emotionen sind 5 der 6 Basisemotionen von Ekman: Angst, Freude, Traurigkeit, Wut und Erstaunen. Als Baseline dient die Implementierung mithilfe einer Support Vector Machine, welche im Deutschen eine Accuracy von 58,2% und im Englischen von 61,1% erzielte. Eine Verbesserung der Accuracy erreichte das maschinelle Lernen mit BERT. Im Deutschen wurde damit eine Accuracy von 64,1% und im Englischen von 69,5% erreicht. Dies zeigt, dass die Emotionsanalyse im Deutschen schlechtere Ergebnisse erzielt.
20.04.20;20.09.20;2020;extern;Bachelor;DE;Mehrwert eines virtuellen Assistenten zur Nutzung von Microsoft Dynamics 365 Business Central: Analyse geeigneter Frameworks, Konzeption und prototypische Realisierung;In Kooperation mit der KUMAVISION AG soll ein virtueller Assistent erstellt werden, der an das ERP-System Microsoft Dynamics 365 Business Central (BC) angebunden wird. Dieser soll Mitarbeitern eines Unternehmens bei ihren Aufgaben assistieren. Dabei wird untersucht, welchen Mehrwert ein virtueller Assistent mit BC hat.<br>Im virtuellen Assistenten sollen zunächst möglichst einfache Funktionen erstellt werden, um Daten und Sachverhalte aus dem System abzurufen. Dann sollen wiederkehrende Prozesse im System bequemer durchzuführen sein, indem deren Abbildung durch den virtuellen Assistenten assistiert wird. Die Untersuchung des Mehrwerts eines solchen virtuellen Assistenten wird anhand der Ressourcenplanung durchgeführt. Dafür wird zunächst der Prozess darin beschrieben, welche Defizite und Schwachstellen die aktuelle Lösung hat und daraus die Anforderungen für den virtuellen Assistenten erstellt.<br>Folglich wird eine Analyse erstellt, welche Botframeworks in Frage kämen, um auf ihren Funktionsumfang sowie insbesondere auf die Integrierbarkeit mit BC zu prüfen. Das Ergebnis dieser Analyse soll das geeignetste Framework sein. Dann wird eine Konzeption für den virtuellen Assistenten erstellt, um eine prototypische Umsetzung zu realisieren.<br>Abschließend wurde eine kritische Reflexion des Ergebnisses gemacht. Dabei zeigt sich, dass der Mehrwert eines virtuellen Assistenten in den einfachen Aufgaben liegt. Für die Zukunft wird überlegt, für welche Bereiche dieser noch genutzt werden kann.
20.04.20;04.09.20;2020;intern;Bachelor;DE;Progressive Web Apps -<br>Möglichkeiten und Grenzen moderner Web-Anwendungen;"Die vorliegende Arbeit untersucht die Technologie der Progressive Web Apps anhand von zwei Imple-mentierungen. Zunächst werden die Möglichkeiten und Grenzen moderner Web-Anwendungen auf der Grundlage einer technischen Umsetzung als Web-App untersucht. Diese ist mit JavaScript und node.js als Laufzeitumgebung realisiert. Als Gegenstück, um die nativen Grenzen der PWA-Technologie zu erforschen, wird ebenso eine Implementation in Java als Android App dokumentiert und beschrieben.<br>Das Anwendungsszenario für beide Fallstudien ist ""Instagram-Klon, ein Fotoalbum der TH Nürnberg"".<br>Bei PWA?s eröffnet sich der Gedanke der Plattformunabhängigkeit für mobile Applikationen, da die Programme vom Browser interpretiert werden und die Lauffähigkeit auf verschiedenen Zielsystemen gewährleistet ist. Ebenso stellt dies die Untersuchungsfrage der Arbeit dar, ob die Technologie den nativen Apps, um deren App Stores und Gerätehersteller, auf gleicher Höhe begegnen kann und inwieweit die Performance einer im Browser ausgeführten App mit einer nativen Umsetzung, über Android Studio, zu vergleichen ist.<br>Das Ergebniskapitel befasst sich mit der Erläuterung der Unterschiede in der Systemarchitektur, das ist zum Beispiel die maschinen-nahe Kompilation in Java Byte Code, sowie einer Gegenüberstellung von Java und JavaScript. Außerdem wird die PWA-Tauglichkeit verschiedener Browser-Anbieter erörtert und ein wesentlicher Kernfaktor der Technologie, das Progressive Enhancement, anhand der Apps untersucht."
20.04.20;20.09.20;2020;extern;Bachelor;DE;Metriken als Mittel zur Verbesserung von agilen Teamprozessen am Beispiel eines Softwareentwicklungsteams bei DATEV eG;In der vorliegenden Arbeit wird ein Experiment betrachtet, das im Auswerten-Team eingeführt und anhand einer Metrik verfolgt wurde. Es war das Ziel, die Lead- und Cycle Time durch die Begrenzung paralleler Arbeit zu optimieren. Dabei wurde ein Work-In-Progress Limit von eins pro Person eingeführt, welches der Theorie zur Folge die Durchlaufzeiten verbessern kann. Es stellte sich die Frage, ob ein WIP Limit die Durchlaufzeiten beeinflusst. Das Experiment wurde vom 08. Juni 2020 bis zum 28. August 2020 durchgeführt und am Ende eines Fragebogens und einer Metrik ausgewertet. Es konnte konstatiert werden, dass die Lead Time im Auswerten-Team nicht beeinflussbar war, weil sie am Anfang zu sehr variiert. Jedoch konnte bei der Cycle Time ein positiver Einfluss gemessen werden. Die Gründe dafür waren mitunter, dass sich bei der Arbeitsweise die Fokussierung und die Effizienz der Mitarbeiter verbesserten. Diese positiven Effekte wurden durch die Befragung der Teilnehmer am Ende des Experiments bestätigt.
20.04.20;20.12.20;2020;extern;Master;DE;Visualisierung der Customer Journey in einer Online-Bank: Abbildung sämtlicher Website-Interaktionen in Form eines Netzwerkgraphen;Ziel dieser Masterarbeit ist es, die komplexe Struktur der Website einer großen deutschen Direktbank und seiner Unterseiten auf eine übersichtliche Art und Weise in Form eines Netzwerkgraphen mit einer Echtzeitdatenanbindung als Dashboard darzustellen. Augenmerk der Visualisierung sind hierbei die Customer Journeys sowie das Benutzerverhalten, die sich aus den Online-Kundenaktivitäten ableiten lassen. Dabei ist es nicht nur das Ziel, die besuchten Seiten anzuzeigen, sondern zu erforschen, in welcher Art und Weise Netzwerke am besten dargestellt und diese auf die wesentlichen Informationen heruntergebrochen werden können. Zudem soll erörtert werden, inwiefern Darstellungsweisen aus anderen Forschungsgebieten wie der Medizin auf den genannten Anwendungsfall übertragen werden können.
20.04.20;20.09.20;2020;intern;Bachelor;DE;Intelligente Analyse des betriebswirtschaftlichen Jahresabschlusses: Konzeption und prototypische <br>Implementierung;In ihrer Funktion der Informationsvermittlung und als Instrument der Rechenschaftslegung für Bilanzadressaten und -empfänger bedienen Jahresabschlüsse vielfältige und oftmals widersprüchliche Interessenlagen und es kann sowohl zur Überschneidung von Interessentengruppen kommen als auch keine eindeutige Zuordnung interner sowie externer Adressaten getroffen werden. Nach einem manuellen Aufbau von multifunktionalen Informationssystemen wird neben dem OLAP- und DWH-Konzept eine zusätzliche Softwarelösung erforderlich, um Medienbrüchen im Zusammenhang mit vertikaler Integration entgegenzutreten. Im Rahmen der Arbeit erfüllt diese Aufgabe das dokumentenorientierte, verteilte Datenbanksystem HCL Notes. Dabei steht der Lotus Domino Server im Mittelpunkt in den dazu sämtliche relevanten Anwendungen und Systeme über Extraktion und Transformation integriert werden. Somit ermöglicht das vorbezeichnete Konzept über den Einsatz von HCL Notes die Datenerfassung, deren Sortierung und Filterung sowie jede beliebige Darstellung. Um den Aufbau multidimensionaler Controlling-Systeme innerhalb des betrieblichen Rechnungswesens zu stützen, könnten künftig KI-getriebene Lösungen entscheidende Impulse im Rahmen des externen Rechnungswesens (Jahresabschluss) oder für Branchen-, Trend- und Wettbewerbsanalysen geben. Gleiches gilt für die auf ihnen gründenden Software-Ansätze und einhergehenden Algorithmen, um das Controlling und die Weitergabe von adressatenspezifischen Informationen zu vereinfachen.
20.04.20;20.01.21;2020;intern;Master;DE;Auswahl und Implementierung von Explainable-Artificial-Intelligence-Frameworks für einen Klassifikator im Text Mining;Die grundlegende Problemstellung dieser Arbeit ist, es die Frage zu beantworten, wie Black-Box-Verfahren besser beurteilt werden können. Es soll offengelegt werden, was die Entscheidung der Vorhersage eines Spiel-Design-Elements bei einem Text beeinflusst.<br>Hierzu wurde eine systematische Suche nach Methoden durchgeführt und anschließend XAI-Frameworks detailliert untersucht, die den Anforderungen der Systemumgebung entsprachen. Die Untersuchung ergab, dass fünf der Frameworks angewendet werden sollten. Dabei nutzen zwei der Frameworks die Erklärungstechnik der Merkmalsrelevanz und drei der Frameworks die kontrafaktische Erklärungstechnik. Neben der Implementierung der Frameworks wurde zusätzliche eine Darstellungskomponente geschaffen, um die generierten Ergebnisse präsentieren zu können.<br>Eine Experten-Evaluierung zeigte, dass beide Merkmalsrelevanz-Frameworks ähnliche Ergebnisse liefern. Zudem ergab die Evaluierung der kontrafaktischen Algorithmen, dass eines der Frameworks geringfügig bessere Ergebnisse als die anderen Frameworks erzielt.<br>Diese Arbeit stellt ein Novum dar. Die Ergebnisse offenbaren, dass es mittels der implementierten XAI-Frameworks möglich ist, die semantische Ausgestaltung von Spiel-Design-Elementen in einzelnen Spielanleitungen zu erfassen.
20.04.20;18.09.20;2020;extern;Bachelor;DE;Konzeption einer Informations-Cockpit-Architektur für missionskritische Systeme;In dieser Arbeit wird eine leicht erweiterbare Architektur für ein Informations-Cockpit vorgestellt. Diese wird in Form eines Architekturbildes dargestellt. Grundlage für die Architektur ist die Containerisierung der einzelnen Bestandteile auf der Serverseite mittels Docker. Der Client, basierend auf Angular, ist über einen aktuellen Browser erreichbar. Grundlage für die Architektur sind Anforderungen und Konzepte, welche im Rahmen dieser Arbeit diskutiert werden. Die Architektur stützt sich dabei auf Payara als Applikationsserver für Java, Redis als Key-Value-Datenbank, Traefik als interne Lastenverteilung sowie einem auf Gunicorn und Flask basierenden Analyse Service zur Aggregierung von Daten. Die Kommunikation zwischen dem Client und dem Server wird mit REST und JSON realisiert. Ein Prototyp der Architektur zeigt die Funktionsfähigkeit.
22.04.20;22.12.20;2020;extern;Master;DE;Vergleich von traditioneller und End-to-End Modellierung sowie Regel und Slot-basierte Ansätze für Sprachassistenten im juristischen Kontext.;ie Deutsche Anwaltshotline AG (DAHAG) bietet Kunden die Möglichkeit mit einem Anwalt zu telefonieren. Wenn kein Anwalt verfügbar ist, beantwortet ein Sekretariatsservice den Anruf, um einen Rückruf mit dem Kunden zu vereinbaren. Dabei müssen verschiedene Kundendaten, wie beispielsweise Name und Telefonnummer, erfragt werden.<br>Dieser Service funktioniert jedoch nicht gut. Für eine solche abgeschlossene Aufgabe bietet sich ein Sprachassistent an.<br>Deshalb stellt sich die Frage, welcher Ansatz für ASR- und Dialogsysteme sich am besten im juristischen Kontext eignet.<br>Dafür werden in dieser Arbeit traditionelle und End-to-End ASR-Ansätze sowie regel- und slotbasierte Dialogsysteme miteinander verglichen.<br>Zum Vergleich der ASR-Modelle werden beide Ansätze auf Basis des Common Voice Datensatzes trainiert und anhand von aufgenommen und transkribierten Sekretariatsanrufen evaluiert.<br>Die Gegenüberstellung wird mithilfe von Word Error Rate und Slot Error Rate durchgeführt. Dabei stellt sich heraus, dass traditionelle Ansätze, auf Basis von HMM-DNN etwas besser abschneiden. Allgemein erkennen ASR-Ansätze Nummern sehr gut, Namen hingegen nicht.  <br>Auf Grundlage dieser Erkenntnisse wurde ein Prototyp entworfen, welcher ausgebaut in der Praxis angewendet werden kann.
29.04.20;29.12.20;2020;intern;Master;DE;Automatische Generierung von synchronisierten Liedtextdateien zu korrespondierenden Audioinhalten auf Basis vorhandener Liedtexte aus dem Internet;Eine Vielzahl an Streaming-Diensten und Anwendungen zur Musikverwaltung integrieren Songtextanzeigen in die Benutzeroberfläche des Musik-Players. Dabei wird häufig neben der normalen eine zusätzliche zeitsynchrone Darstellung verwendet. Der Nutzer kann somit den Text zum aktuell gesungen Vers live mitverfolgen (Karaoke-Prinzip). Diese zeitgenauen Darstellungen existieren oftmals nur bei bekannten Titeln. Ziel dieser Arbeit war daher die Konzeptionierung und Implementierung eines automatisier- ten Karaoke-Automaten, der im Rahmen einer Offline-Nutzung eingesetzt werden kann. Hier hat sich mitunter das LRC -Dateiformat durchgesetzt, das neben den eigentlichen Songtext- versen noch den Zeitstempel für den gesungenen Text einer korrespondierenden Audiodatei im MP3 oder FLAC -Format enthält. Notwendige Verfahren aus der Automatischen Spracherkennung wurden mit Hilfe des Open- Source-Toolkits Kaldi modular in eine Entwicklungspipeline integriert. Grundlage bildete ein vorab vorhandenes akustisches Kaldi-Modell, das mit Telefonmitschnitten trzu spätai- niert wurde. Für Musikstücke aus dem Genre Hip-Hop (Sprechgesang) konnten u.a. bessere LRC -Resultate erzielt werden, als mit Titeln aus anderen Genres. Schlechtere Ergebnisse gab es häufiger bei Musiktiteln, die ausschließlich Gesang beinhalteten und deren Songtextkorpus verhält- nismäßig kleiner war, gepaart mit einer geringeren Wortvariabilität.
29.04.20;29.09.20;2020;intern;Bachelor;DE;Konzeption und prototypische Umsetzung der<br>In-App-Werbung am Beispiel der Notenapp;Die Notenapp ermöglicht es Schülern, aber auch deren Eltern, den Schulalltag einfacher und effizienter zu planen. Der digitale Schulassistent bietet verschiedene Module an, die von der Gestaltung eines Stundenplans, einem Prüfungsplaner mit Notenmanagement, einem papierlosen Hausaufgabenheft bis hin zur Berechnung des aktuellen Gesamtnotendurchschnitts reichen. <br>Ein standardisiertes Verfahren zur In-App-Werbung ist die Basis für eine Finanzierungsstrategie der Notenapp. Hierbei spielen eine effektive Umsetzung eines Werbebudgets und ein Konzept zur automatisierten Integration der Werbung innerhalb der App eine Rolle. In dieser Arbeit werden bereits auf dem Markt existierende Lösungen zur Integration und Verwaltung von In-App-Werbung im Gegensatz zur Entwicklung eines eigenen Konzepts diskutiert und evaluiert. Letztendlich soll ein einfaches Verfahren entstehen, mit dem eine Finanzierungsgrundlage über zukünftige Kooperationspartner umgesetzt werden kann.
01.05.20;28.09.20;2020;intern;Bachelor;EN;Deep learning assisted vulnerability detection and classification in C/C++ source code;New possible security issues and exploits in software programs appear every day and<br>regularly have disastrous consequences for both users and software companies. These<br>can cause a wide variety of damages, including downtime of critical business systems,<br>identity theft and unauthorized access to financial accounts and information. Apart<br>from incorrect configuration and rare hardware issues such scenarios are often caused<br>by vulnerable code mistakenly inserted by software developers. Since the best way to<br>prevent this is to catch possibly faulty code as soon as possible in the development cycle,<br>static code analysis tools have seen rising popularity over the last decades.<br><br>With the recent hype in machine learning and particularly deep learning, work has also<br>gone into applying these methods to automatically detect such vulnerabilities, often with<br>promising results. This work aims to implement and compare multiple types of neural<br>networks for this task and in a second step, distinguish and classify vulnerabilities of<br>different kinds. Training and detection will happen on function level using well-known<br>Natural Language Processing methods.
01.05.20;28.09.20;2020;intern;Bachelor;DE;Prozessoptimierung, Automatisierung durch Software-Roboter oder Outsourcing: Entwicklung eines Handlungsrahmens für Einkaufsleiter zur digitalen Transformation der betrieblichen Beschaffung.;Ergebnis dieser Arbeit soll ein Entscheidungspattern sein, welches dazu beiträgt, aufgrund finanzieller und struktureller Kennzahlen einen Handlungsrahmen für Einkaufsleiter zu schaffen, in dem sie einen Prozess outsourcen, automatisieren oder die Kompetenz im eigenen Unternehmen behalten können. Das Entscheidungspattern soll Empfehlungen für das weitere Vorgehen geben, auf welche Art und Weise der Prozess am effektivsten durchgeführt werden kann. 
01.05.20;15.11.20;2020;extern;Master;DE;Konzeption und prototypische Implementierung eines Blockchain-basierenden Systems zur Sicherung des Urheberrechtes sowie dem Übertragen und Überprüfen von Nutzungsrechten an digitalen Bildern;Niemals zuvor war es so einfach Informationen zu teilen, wie in der heutigen Zeit. So werden über das Internet täglich Milliarden von Bilder versendet, heruntergeladen oder anderweitig zugänglich gemacht. Dies geschieht jedoch oft zum Nachteil der Bild Urheber, denn das Urheberrecht stößt im digitalen Bereich an seine Grenzen. Das Ziel der Arbeit ist zu prüfen, ob die Konzeption eines Systems zur Sicherung des Urheberrechtes, sowie dem Übertragen und Überprüfen von Nutzungsrechten an digitalen Bildern mittels Blockchain Technologie möglich ist. Um diese Frage zu beantworten, ist im Zuge der Arbeit das Konzept zu einem solchen System erarbeitet worden. Dies wurde daraufhin prototypisch mittels der Smart Contract Plattform Ethereum implementiert. Wobei auch ein Augenmerk aus die Bildverarbeitung im Zuge von komprimierten Hashes gelegt, die einen Bildvergleich ermögliche. Wichtige Evaluationsmetriken wurden anschließend identifiziert und ausgewertet. Dabei wurde festgestellt, dass die Blockchain Technologie sowie Smart Contract ein hohes Potenzial bieten. Jedoch sind die technischen Voraussetzungen noch nicht gegeben, um den Prototyp im konzipierten Maße zu betreiben.
01.05.20;31.12.20;2020;extern;Master;DE;Fehlerklassifizierung und Entwicklung einer Software zur Prävention von Produktivitätsverlusten bei vollautomatisierten Bestückungslinien;Im Zuge der konzernweiten Standardisierung wird im Fertigungsbereich der Continental Automotive GmbH in Regensburg ein neues Fertigungsmanagementsystem integriert. Neben dem enormen Verbesserungspotenzial verbergen sich in den neuen Prozessen noch viele Fehlerquellen und Störungen, welche zu Linienstillständen führen. <br><br>Das wesentliche Ziel der Arbeit ist es, diese Fehler zu klassifizieren. Um recht-zeitig fehlerhafte Aufträge erkennen zu können, soll auf Basis eines erarbeiteten Maßnahmenkonzepts ein automatisierter Service und ein Tool zur Selbstkontrolle entwickelt werden. Die erarbeiteten, softwaregestützten Maßnahmen sollen dazu beitragen, den Prozess der Fehlererkennung und der Fehlerbeseitigung bei Fertigungsaufträgen so weit wie möglich zu automatisieren. Sollte sich dieses Vorgehen bewähren, kann dieses Konzept auch für andere Produktionssysteme innerhalb von Continental verwendet werden. <br><br>Die Fehler konnten durch eine dokumentierte Fehlerliste erfolgreich klassifiziert werden. Durch den verwendete Diagrammtyp zeigte sich klar der Mensch als Ursachenschwerpunkt. Bei der Erarbeitung des Maßnahmenkonzepts wurde der Fokus deshalb auf die menschlichen Fehler gelegt. Eine ausführliche Phase der Anforderungsanalyse führte zu einer sehr effizienten Konzeptentwicklung. Die prototypische Implementierung und eine erste Evaluierung zeigten, dass die entwickelten Software-Lösungen und das damit verbundene Vorgehen als erfolgreich eingestuft werden kann. <br>
01.05.20;30.09.20;2020;intern;Bachelor;DE;"""Entwicklung und Untersuchung künstlicher neuronaler Netze zur Erstellung von Lastprognosen für Gebäude""";Um eine effiziente Gebäudesteuerung zu realisieren, werden möglichst genaue Vorhersagen benötigt. In dieser Arbeit wird der Ansatz untersucht diese Lastprognosen mit Hilfe künstlicher neuronaler Netze zu erstellen. Es wird dabei auf die Abschätzung des Bedarfs an Elektrischer Energie, Trinkwarmwasser und Heizenergie eingegangen. Die Lastprognosen sollen für einen Zeitraum von 24 Stunden in die Zukunft mit Zeitintervallen von 15 Minuten erstellt werden. Aus den Prognosen sollen sowohl kurzfristige als auch langfristige Entscheidungen abgeleitet werden. Zur Erstellung dieser Modelle werden reale Messwerte aus acht Reihenhäusern verwendet. Es werden sowohl univariate als auch multivariate Vorhersagen unter Einbeziehung aller erhobenen Verbrauchswerte untersucht. Für eine weitere Verbesserung der Prognosen wird zusätzlich eine Abhängigkeit in Bezug auf Wettereinflüsse untersucht. Als Wetterdaten kommen Außentemperatur und Sonneneinstrahlung zum Einsatz. Die Ergebnisse der künstlichen neuronalen Netze wurden mit denen autoregressiver Modelle verglichen. Nach Gegenüberstellung und Auswertung beider Methoden zeigen sich deren Stärken und Schwächen. Durch die gegebenen Daten konnte keine Abschätzung zukünftiger Lastspitzen getroffen werden. Auch spielten Wetterdaten und Wetterprognosen für den Bedarf an Elektrischer Energie und rinkwarmwasser keine Rolle. Eine spürbare Auswirkung der Wetterdaten zeigte sich lediglich im Bezug auf die Prognose der Heizleistung.
02.05.20;02.01.21;2020;extern;Master;EN;Neural Architecture Search for Industrial Environments with Multi-Constraint Optimization on a Neural Network-Based Image Analysis;The research goal is to investigate the suitability of neural architecture search (NAS) in an industrial environment with a focus on multi-constraint optimization. <br>Special attention is paid to constraints like the training environment, the possibilities of result transfer to industrial hardware components, a limitation of inference times and the integration of a specific search space for neural network based image analysis. For this purpose, basic concepts of artificial neural networks are introduced at the beginning of this thesis, followed by a summary of current research in the areas of architectural search. Subsequently, a concept for the use of NAS in an industrial environment is developed and experimentally implemented. The final step is the validation of this concept on a real industrial dataset.
05.05.20;05.01.21;2020;intern;Bachelor;DE;Implementierung eines Telegram-Chatbots zur Automatisierung eines Verständlichkeitstests basierend auf dem Post-Laryngektomie Telefon Tests;Im Rahmen dieser Arbeit wurde ein Chatbot entwickelt, der basierend auf früheren Arbeiten einen Post-Laryngektomie Telefon Verständlichkeitstest durchführen kann. Nach einer kurzen Einführung in die heutigen technologischen Fortschritte und die möglichen Vorteile, die im medizinischen Bereichen genutzt werden können, wurde der PLTT im Detail erklärt. Desweiteren wurden die Komponenten der Architektur des genutzten Spracherkennungssystems näher erläutert und mit dem früheren System verglichen. Um die Reproduzierbarkeit der früheren Ergebnisse zu belegen, wurden die gleichen Berechnugsgrundlagen und Experimente durchgeführt. Belegt wurde durch die Korrelationskoeffizienten nur die relative Performanz vom früheren und aktuellen Spracherkennungssystem, jedoch nicht die absolute. Ebenfalls liegt eine sehr niedrige Korrelation zwischen Mensch und Maschine vor. Anschließend wurde der Ablauf eines PLTT Schritt für Schritt erklärt. Abschließend wurden mangelnde Bereiche aufgelistet und Verbesserungsvorschläge aufgezählt. <br>
07.05.20;06.01.21;2020;intern;Bachelor;DE;Konzeption und Implementierung eines gamifizierten Systems zur Generierung von Trainings- und Testdaten für die Erkennung von Spieldesignelementen in Brettspielanleitungen;Im Forschungsprojekt EMPAMOS (empirische Analyse motivierender Spielelemente) der TH Nürnberg werden, in Zusammenarbeit mit dem Deutschen Spielearchiv Nürnberg, motivierende Spieldesignelemente erforscht. Das Vorgehen beinhaltet mehrere Schritte: es werden Brett- und Gesellschaftsspiele gespielt, deren Spieldesignelemente untersucht und zum Schluss mit einer Mustersprache beschrieben. Auf deren Grundlage sollen angewandte Forschungsprojekte realisiert werden, die motivierende Spielideen und Gamification-Lösungen entwickeln und testen. Es werden dazu Spielanleitungen digitalisiert und analysiert. Ein Schritt in diesem Vorgehen ist, verschiedene Spieldesignelemente in den Spielanleitungen von Brett- und Gesellschaftsspielen zu suchen und mit Tags zu markieren, um Trainings- und Testdaten zu erstellen. Da dieses Tagging von Spieldesignelementen zu Spielen eine langwierige und repetitive Arbeit ist, bietet sie die Möglichkeit Methoden zur Gamifizierung anzuwenden. Es werden basierend auf der EMPAMOS Gamification-Methode drei Gamification-Konzepte erarbeitet. Eine davon soll anschließend implementiert werden.
08.05.20;05.03.21;2020;intern;Master;DE;Entwicklung eines Framework zur semi-automatisierten Informationsextraktion für Knowledge Graphen;Das Thema dieser Arbeit ist die Konzeption und Umsetzung eines Frameworks für die semi-automatisierte Informationsextrahierung unstrukturierter Daten, zur Generierung eines Knowledge Graphen (dt. Wissensgraph). <br><br>Die generelle Entwicklung eines Knowledge Graphen ist mit erheblichem manuellem Aufwand eines Domänenexperten verbunden. Um diese  zukünftig zu semi-automatisieren und somit zu vereinfachen, vereint das Konzept dieser Arbeit die Methoden der maschinellen Sprachverarbeitung mit dem Expertenwissen des Anwenders der jeweiligen Domäne. Die Herausforderung dabei ist, das Framework domänenunabhängig zu gestalten.<br><br>Basierend auf dem Framework wird eine Webanwendung realisiert, mit der das halbautomatische Verfahren von einem Experten der jeweiligen Domäne gesteuert wird. Aus unstrukturierten Daten werden in der Anwendung kontextunabhängige Vorschläge zu den einzelnen Bestandteilen eines Knowledge Graphen generiert und zur Bewertung als auch zur Bearbeitung bereitgestellt. <br>Das Ergebnis ist eine domänenunabhängige Webanwendung, die den Domänenexperten durch den Prozess der Erstellung eines Wissensgraphen leitet und am Ende der Bearbeitung einen vollständigen Knowledge Graphen bereitstellt.<br>
12.05.20;23.08.20;2020;intern;Bachelor;DE;Die Wirkung verschiedener Cookie Consent Banner-Darstellungsformen auf<br>das Verhalten von Webseitenbesuchern;
13.05.20;13.10.20;2020;extern;Bachelor;DE;Konzeption und Implementierung eines Content Management Systems und Integration in das bestehende Webportal eines Beratungs- und IT-Dienstleistungsunternehmens;"Ziel der Bachelorarbeit ist die Betrachtung existierender Content Management Systeme (CMS) im Hinblick auf Faktoren, wie Technologien, Aufbau, Trends, Anpassbarkeit an ein bestehendes Portal und nachträgliche Implementierbarkeit. Anhand der Erkenntnisse soll ein passgenaues CMS für das Webportal ""adessini"" konzipiert und schließlich implementiert werden. Erschwert wird die Suche nach einem passenden System durch die Tatsache, dass das Webportal bereits produktiv verwendet wird und über ein eigenes Java Backend, Angular Frontend und eine MySQL Datenbank verfügt. Das CMS ermöglicht technisch nicht versierten Administratoren des Webportals Inhalte zu veröffentlichen, ohne tiefergehendes HTML-Wissen zu besitzen. Dadurch wird eine Entlastung der Entwickler erreicht und zugleich die kontinuierliche Bereitstellung von neuen Inhalten ermöglicht. "
15.05.20;15.10.20;2020;extern;Bachelor;DE;Beispiele zur Umsetzung ausgewählter Empfehlungen von Sicherheitsstandards für Kritische Infrastrukturen im Sektor Wasser & Abwasser;Unternehmen aus der Wasserbranche erbringen als Kritische Infrastruktur (KRITIS) für die Bevölkerung zwingend notwendige Leistungen wie die Aufbereitung und Versorgung mit Trinkwasser. Durch den Einsatz von Automatisierungs- und Steuerungssystemen sowie die Vernetzung derer bieten Anlagen ein Ziel für Hacker und Schadsoftware. Dadurch ist eine gleichbleibend hohe Qualität und Stabilität der zu erbringenden Leistung gefährdet.<br><br>Damit Unternehmen im Sektor Wasser, sowie allgemein im Bereich von KRITIS, einen geeigneten Schutz ihrer Systeme gegenüber Cyberangriffen bieten, gibt es Sicherheitsanforderungen seitens des Bundesamt für Sicherheit in der Informationstechnik (BSI) sowie von internationalen Normen wie der DIN ISO/IEC 27000 Reihe. Diese gelten als Empfehlung, bei Unternehmen im Bereich KRITIS sind diese teilweise verpflichtend umzusetzen.<br><br>Einige Anforderungen lassen sich dabei durch Softwarelösungen umsetzen, z.B. durch Asset-Inventory-Systeme, Monitoring-Lösungen oder Anomalieerkennung. Eine einzelne Software-Lösung allein reicht jedoch nicht aus, um alle Anforderungen zu erfüllen. Eine Kombination aus unterschiedlichen Software-Paketen, die sich im besten Falle ergänzen, ist daher zu empfehlen. Des Weiteren ist die Expertise der Mitarbeiter für die Implementierung, aber auch Beurteilung im Falle von Cyberangriffen sowie zur Einleitung von Gegenmaßnahmen notwendig.
15.05.20;27.11.20;2020;intern;Bachelor;DE;Software-gestützte, kollaborative Planung pädagogischer Events;Pädagogische Eventplanung, also die Gestaltung einer kindgerechten Veranstaltung, findet meist nur im Rahmen herkömmlicher Kinderbetreuungsstellen, wie zum Beispiel Kindergärten oder Kindertagesstätten statt. In solchen Einrichtungen bestehen meist feste Teams mit regelmäßigen Besprechungsterminen und planbaren An- sowie Abwesenheiten der einzelnen Teammitglieder. Diese Kalkulierbarkeit fällt bei eigenständigen Anbietern für Kinderbetreuung oder ehrenamtlichen Teams in verschiedenen Jugendorganisationen weg. Das liegt daran, dass es sich hierbei in der Regel um große, lose Teams handelt. Um bei solchen Angeboten die pädagogische Qualität einer herkömmlichen Betreuungsstelle zu erreichen, ist es notwendig, gewisse Bestimmungen einzuhalten. Außerdem kollaborieren für Veranstaltungen meist unterschiedliche Teammitglieder, basierend auf deren Qualifikation und Verfügbarkeit. In dieser Arbeit soll anhand eines konkreten Anwendungsfalls das Potenzial untersucht werden, das die Digitalisierung von Planungsabläufen im Kontext dieser Problemstellung innehält.<br>Dazu werden zunächst die besonderen Anforderungen aus der Pädagogik in Zusammenarbeit mit relevanten Stakeholdern eines Start-ups zur professionellen Kinderbetreuung erarbeitet.  Darauf basierend werden konzeptuelle Ideen erörtert und ein Prototyp implementiert. Um die Einsatztauglichkeit des Prototypen bewerten zu können, soll zudem eine Evaluation innerhalb des Start-ups mit anschließender Ergebnisdiskussion stattfinden.
15.05.20;15.10.20;2020;extern;Bachelor;EN;Enablement of Kubernetes Based Open-Source Projects on IBM Z;Open-source projects are developing software with freely available source code. These communities are running automated tests against every code change in order to guarantee the best software quality. These tests should be able to run on different architectures. It is difficult to test software for essential hardware without access. Therefore, the s390x architecture used in IBM Z has to be emulated on x86 for chosen open-source projects and included in their CI/CD pipeline. That should run with fast deployment methods in the emulator QEMU. Kubernetes is used as a containerized example project as the foundation for instituting applications. Another open-source project, Apache Cassandra, is applied to represent tests on the application layer in the Kubernetes stack. <br>Additionally, minimal system requirements have to be analyzed for the setup inside of the CI/CD infrastructure of both projects concerning the minimization of disk space, memory and CPU usage for deployments. <br>Finally, the automated emulation of both projects will be integrated into the test infrastructure, so that these projects are enabled for the s390x architecture of IBM Z systems. Overall, this method can be a model for further open-source projects in the future.
18.05.20;18.10.20;2020;intern;Bachelor;DE;Agiles Lernen an der Technischen Hochschule Nürnberg ? Konzeption von agilen Handlungsempfehlungen für die Technische Hochschule Nürnberg;Die vorliegende Arbeit behandelt die Fragestellung, wie ein agiles Konzept am Beispiel der Technischen Hochschule Nürnberg aussehen kann.<br>Es werden die theoretischen Grundlagen zu agilen Methoden bzw. zum agilen Lernen näher erläutert. Darauf basierend erfolgt eine theoretische Literaturanalyse des agilen Lernens im Hochschulkontext. Insbesondere wird in diesem Teil der Arbeit das Regelwerk für das agile Lernen aufgestellt, das anschließend mithilfe von Experteninterviews evaluiert wird. Des Weiteren werden die Herausforderungen bei der Durchführung agiler Lehrpraktiken dargestellt.<br>Abschließend werden basierend auf den Erkenntnissen Handlungsempfehlungen anhand von zwei Fallstudien aufgezeigt. Die erste Fallstudie bezieht sich dabei auf eine Lehrveranstaltung im agilen Umfeld, die zweite auf die Studienbegleitung im agilen Umfeld.<br>
18.05.20;01.02.21;2020;extern;Master;EN;A feasibility study on RNN-supported Kalman filters: recurrent neural networks for position estimation on the example of radio signals;"In line with the current developments in the context of 5G, localization methods based on radio frequency (RF) positions have come into focus again. The localization problem has been solved by model-driven filtering methods such as Kalman filters as well as by data-driven methods such as recurrent neural networks. These state of the art methods allow to predict more accurate positions. However, both approaches are subject to the following limitations and require a lot of effort (time/resources) to make them usable. <br>In this work, models for predicting human motion based on RF positions are evaluated.<br>Both simulated and real-world data are used for the studies. As a proposal for a model, the LSTM-KF is introduced as an example RNN-Supported Kalman Filter. <br><br>Several studies are conducted to evaluate the usefulness of the LSTM-KF for determining RF position data.  Experiments to optimize the model for testing on real-world data are conducted, by generating optimized simulated data and combining real and simualted trajectories. Two methods for ""inBatch"" and ""pureBatch"" data augmentation are tested. The results show that the LSTM-KF hybrid architecture provides similar prediction accuracies as the baseline LSTM, and better than the KF. Furthermore, it can be observed that the LSTM-KF architecture has lower susceptibility to changing error behavior. The data augmentation methods have been sucessfully used to improve accuracy on real-world data."
25.05.20;25.10.20;2020;intern;Bachelor;DE;"""Herausforderung Covid 19: Gestaltung von IT-Beratungsprojekten unter den Rahmenbedingungen einer Pandemie""";Das Ziel dieser Forschung ist es, den Status Quo der Corona Krise, aus Sicht der IT-Beratungsbranche aufzuzeigen und daraus Problemfelder, Verbesserungspotentiale und zukunftsorientierte Chancen für die Gestaltung von IT-Beratungsprojekten abzuleiten. Zur Beantwortung der Forschungsfragen, wurde sowohl quantitative Forschungsarbeit in Form einer Umfrage als auch qualitative Experteninterviews innerhalb der Capgemini Deutschland GmbH durchgeführt.<br>Die Studie zeigt, dass die COVID-19 Pandemie trotz Problemfeldern und Verbesserungspotentialen, vor allem die Chance einer rascheren Digitalisierung innerhalb der deutschen Kunden von Capgemini eröffnet. <br>Es zeigt sich, dass die Aussicht für die Gestaltung von IT-Beratungsprojekten positiv ausfallen könnte, wenn die aktuellen Kenntnisse über Problemfelder während IT-Beratungstätigkeiten, überdacht und interne sowie externe Verbesserungspotentiale ausgeschöpft werden.<br>
26.05.20;26.10.20;2020;intern;Bachelor;DE;Entwicklung eines Konzeptes zur Überführung von browserbasierten Anwendungen im Bankenumfeld in ein OpenShift-Cluster;Immer mehr Unternehmen setzen bei ihrer IT-Infrastruktur auf Cloud Computing. Ein wichtiges Grundkonzept bei dieser Art von IT-Betrieb ist die Containerisierung. Container ermöglichen den einfachen Betrieb von Anwendungen in der Cloud, da sie die Flexibilität und Portabilität sowohl in der Entwicklung, als auch in der Produktion erhöhen. Um den Betrieb einer Vielzahl von Containern zu bewerkstelligen, werden Plattformen wie Kubernetes und OpenShift benötigt.<br>Es existieren mehrere gängige Technologien und Werkzeuge, mit denen die Bereitstellung von Anwendungen bewerkstelligt werden kann. Das Ziel der Arbeit ist, diese miteinander zu vergleichen und deren optimalen Anwendungsfälle zu erarbeiten. Dazu werden die typischen Einsatzgebiete der Container-Plattformen in Kategorien eingeteilt. Das Konzept der Operatoren ermöglicht den vollautomatischen Betrieb von Anwendungen in der Cloud. Es werden verschiedene Frameworks verglichen, welche als Basis für einen Operator dienen. Zusätzlich wird im Rahmen der Arbeit ein Operator implementiert, um eine mögliche Umsetzung zu demonstrieren.
27.05.20;27.10.20;2020;extern;Bachelor;DE;Konzeption einer Personaleinsatzplanung zur Prozessoptimierung des firmeninternen Projektmanagements ;Das Ziel der Arbeit ist es, die Anforderungen des Unternehmens an die Personaleinsatzplanung zu erheben und eine Anwendung zu konzipieren, die diese umsetzt. Es wird bei einer systematischen Feststellung des IST-Zustands begonnen, bei dem Mitarbeiter verschiedener Positionen mittel Online-Umfrage befragt wurden. Die Anforderungen wurden iterativ anhand eines Ausschnitts der Nutzergruppe ermittelt. Zur visuellen Veranschaulichung und Erarbeitung des Konzepts wurde ein UX Prototyp erstellt. Die Ergebnisse der Umfrage ergaben einen Bedarf einer zentralen Personaleinsatzplanung, mit integrierter Verwaltung der Mitarbeiterprofile. Dieser Aspekt wurde in die Konzeption einbezogen und am Ende der Arbeit bewertet. Das Feedback der Evaluation des Prototypen, am Ende der Arbeit, zeigte ein hohes Interesse der Teilnehmer an einer zentralen Personaleinsatzplanung.
27.05.20;12.02.21;2020;extern;Master;DE;Entwicklung einer REST-API für das Dokumenten-Management-System der DATEV eG;"REST ist in aller Munde. Unternehmen wie DATEV entwickeln langfristige Strategien, Softwarelösungen mit Hilfe dieser Technologie zu öffnen und zu vernetzen. Bevor die Öffnung jedoch erfolgen kann stellt sich die Frage ""Wie wird eine robuste REST-Schnittstelle für eine bestehende On-Premise Anwendung entworfen?"". Kern einer jeden REST-Schnittstelle ist das Ressourcenmodell, welches in der Wahrnehmung der Verwender einer Benutzeroberfläche gleich kommt. Daher soll in dieser Arbeit ein allgemeingültiger von DATEV losgelöster Transformationsprozess eines Domänenmodells in ein robustes Ressourcenmodell vorgeschlagen werden. Dieser Prozess kann sowohl für den vollständigen Neuentwurf als auch für die Erweiterung eines bestehenden Ressourcenmodells angewendet werden. Der vorgeschlagene Prozess wird im Anschluss bei dem Entwurf der DATEVConnect für Dokumentenmanagement-API praktisch erprobt und abschließend evaluiert. "
28.05.20;28.01.21;2020;extern;Master;DE;Threat Modeling - Ausarbeitung verschiedener Bedrohungsmodellierungen und deren Integration in die agilen Entwicklungsprozesse der DATEV;"In der DATEV werden durch das Manifest ""Agile Security"" verschiedene Sicherheitsaspekte bereits in den Entwicklungsprozess involviert. Die Anwendung einer Bedrohungsmodellierung ist ein Teil davon. Demnach werden Bedrohungsanalysen durchgeführt, welche aber bisher nicht nach einem Leitfaden ablaufen und auch kein Standard in der Entwicklungs-Guideline sind. Daher werden diese nur vereinzelt und nicht einheitlich ausgeführt. Um Software-Schwachstellen vorab zu identifizieren, statt nur Sicherheitslücken nachjustieren zu können, wird ein Konzept für die Bedrohungsmodellierung benötigt. Der beschriebenen Ausgangslage in der DATEV entsprechend wird folgende Forschungsfrage gestellt: Ist es möglich eine Bedrohungsmodellierung effektiv in den Entwicklungsprozess der DATEV zu integrieren? Dementsprechend wird eine Übersicht von vorhandenen Bedrohungsmodellen erarbeitet, jeweilige Probleme identifiziert und gegenübergestellt. Des Weiteren werden Gespräche mit Sicherheitsexperten geführt, um diese als zusätzliche Beratung zur Seite zu nehmen. Parallel dazu werden spielerische Ansätze, sogenannte Gamification-Ansätze, für eine Bedrohungsmodellierung DATEV-intern durchgeführt. Es werden Gespräche mit relevanten Stakeholder geführt, um ein notwendiges Gesamtverständnis für die Konzepterstellung zu erarbeiten. Es wird anhand der erlangten Informationen und in Zusammenarbeit mit Sicherheitsexperten ein generisches Konzept erarbeitet, welches in Zukunft auf verschiedene Anwendungsbereiche "
29.05.20;29.10.20;2020;intern;Bachelor;DE;Analyse technologischer Lösungen zur Bekämpfung der Riffverschmutzung;Die Arbeit handelt von der Analyse technologischer Lösungen zur Bekämpfung der Riffverschmutzung.<br>Die technologischen Lösungen bestehen spezifischer gefasst aus Internet-Kampagnen, welche auf <br>einer globalen Skala digital die Ursachen und Konsequenzen der Riffverschmutzung bekämpfen. Die <br>zweite der drei Technologien stellt Dive Against Debris dar. Dieses von einer gemeinnützigen <br>Organisation entwickeltes Programm bietet Tauchern die Möglichkeit, während des Tauchgangs Müll <br>von Riffen aufzusammeln, diesen einzuschicken und zu dokumentieren. Die letzte Lösung heißt <br>Biorock. Diese Lösung umfasst eine Methode zum manuellen Aufbau von Riffen durch Platzierung von <br>menschengemachten Strukturen im Meer, durch welche Strom geleitet wird. Dies induziert <br>Korallenwachstum.<br>Nachdem theoretische Grundlagen wie das Ökosystem Riff und die Ursachen und Konsequenzen der <br>Riffverschmutzung erklärt wurden, folgt eine Beschreibung der drei Technologien anhand von vier <br>bestimmten Kriterien: Ökologische Effizienz, ökonomische Effizienz, sozialer Mehrwert und <br>anfängliche Startschwierigkeit.<br>Anhand dieser Kriterien wird im späteren Verlauf der Arbeit eine Nutzwertanalyse durchgeführt, die <br>bestimmt, welche der Technologien am meisten Potenzial hat, Riffverschmutzung zu bekämpfen. Nach <br>der Durchführung der Nutzwertanalyse und unter Einbezug von Ergebnissen eines Fragebogens kommt <br>die Arbeit zum Ergebnis, dass Biorock unter den genannten Kriterien die beste Lösung darstellt.
31.05.20;02.11.20;2020;intern;Bachelor;DE;Ausgewählte Aspekte des Risikomanagement bei internationalen agilen Projekten mit Fokus auf Türkei und Deutschland ;"Im Rahmen dieser Bachelorarbeit soll untersucht werden, welche<br>Herausforderungen in agilen Projekten in Zusammenarbeit mit der Türkei bestehen.<br>Diese werden anhand des Kulturmodells von Hofstede überprüft. Mit dieser Analyse werden<br>typische Eigenschaften der deutschen und türkischen Kultur sowie die Unterschiede<br>der beiden Länder dargestellt. Zusätzlich wird aus dem agilen Projektmanagement der<br>Scrum-Prozess genauer erläutert, weil einige Aspekte des Risikomanagementprozesses<br>implizit dort auftreten. Die Beobachtung vermittelt einen Einblick, an welchen Stellen<br>des Scrum-Prozesses das Risikomanagementprozess angewendet wird. Zudem wird ein<br>kurzer Überblick über Risikoarten in Projekten gegeben und es werden Empfehlungen<br>für Projektleitende aufgeführt, wie diese mithilfe der Risikosteuerung aus dem Risikomanagementprozess<br>interkulturelle Risiken vermeiden können. Dafür wurde die Risikostrategie<br>""Risikoverminderung"" angewendet. Der Schwerpunkt der Arbeit ist die empirische<br>Untersuchung, mit der untersucht wird, ob die Scrum-Methode aus dem agilen Projektmanagement<br>in der Türkei angewendet werden kann. Außerdem soll erforscht werden, ob<br>eine effektive Risikokommunikation trotz kultureller Unterschiede gewährleistet werden<br>kann."
02.06.20;31.01.21;2020;extern;Master;DE;Rendering Glyphs on the GPU with OpenGL;Mit der zunehmenden Digitalisierung von Fahrzeugen erhalten neue Konzepte wie Head-up-Displays oder Augmented Reality Einzug in die Automobile.<br>Diese Technologien erfordern die textuelle Darstellung von Informationen für Navigations- und Assistenzsysteme in einer dreidimensionalen Umgebung und in Echtzeit.<br>Klassische Texture-Mapping-Ansätze haben hierbei den Nachteil, dass jedes Skalieren, Drehen und Bewegen von Text eine Neuberechnung der Textur auf der CPU erfordert.<br>Aus diesem Grund wird für diese Anwendungen ein GPU-basierter Ansatz gesucht.<br>Die beiden Textrendering-Ansätze, multi-channel signed distance fields und Slug, wurden mit Glyphen aus OpenType-Fonts und Vektorgrafiken als mögliche Lösungen untersucht.<br>Daher wurde der Slug-Algorithmus um einen Präprozessor für kubische Bézier-Kurven und die Unterstützung mehrfarbiger Glyphen erweitert.<br>Die Experimente haben gezeigt, dass sowohl der Slug-Algorithmus als auch die multi-channel signed distance fields für dieses Text-Rendering-Szenario geeignet sind.<br>Allerdings ist der Slug-Algorithmus nicht performant genug und hängt zudem stark von der Größe und Komplexität der darzustellenden Glyphen ab.<br>Daher wird der Ansatz der multi-channel signed distance fields als Lösung für das Echtzeit-Textrendering in einer dreidimensionalen Umgebung in Betracht gezogen.
11.06.20;09.11.20;2020;extern;Master;DE;Evaluation eines Modells zur Priorisierung von Geschäftsprozessen bezüglich des Automatisierungspotenzials am Beispiel der prototypischen Implementierung im Bereich von Robotic Process Automation;Ziel dieser Arbeit ist die Erstellung eines Modells zur Bewertung der Automatisierungstauglichkeit von Geschäftsprozessen, anhand dessen automatisierbare Prozesse im Unternehmen identifiziert werden. Das Framework dient als Entscheidungsgrundlage für die Verantwortlichen, um Prozesse priorisiert zu automatisieren oder davon auszuschließen. Durch die prototypische Implementierung der Roboter mittels der Technologie Robotic Process Automation soll der Erfolg der Automatisierung gemessen werden. In einer Literaturrecherche werden Ansätze und Kriterien für die Automatisierungstauglichkeit ermittelt, welche als Basis für die Modellaufstellung verwendet werden. Drei Geschäftsprozesse aus dem Unternehmen werden anhand des ausgewählten Rating-Modells bewertet und eine Entscheidung für die Automatisierung abgegeben. Durch eine prototypische Implementierung wird das Bewertungsmodell zusätzlich evaluiert und Empfehlungen für die Optimierung des Modells aufgeführt. Im Ergebnis hat sich gezeigt, dass das theoretische Bewertungsmodell um die Besonderheiten des Unternehmens ergänzt werden muss. Ein standardisiertes Datenformat, ein transparent definierter Prozessdurchlauf und eine häufige Ausführung des Prozesses sind zentrale Erfolgskriterien für eine Automatisierung durch Robotic Process Automation. Die Roboter erbringen eine hohe Zeitersparnis und arbeiten effektiver verglichen mit der manuellen Durchführung. Die Prozessqualität steigert sich durch die Prozessautomatisierung.
12.06.20;10.11.20;2020;extern;Bachelor;DE;Weiterentwicklung des Prozesses des Bestandsmanagements im IT-Infrastruktur Controlling der DATEV eG;Die Abschlussarbeit gibt einen Überblick über den aktuellen Prozess des Bestandsmanagements des Rechenzentrums der DATEV eG. Das Bestandsmanagement des IT-Infrastruktur Controllings verwaltet alle Hard- und Softwarekomponenten und überwacht diese während ihres kompletten Lebenszyklusses. Adressaten der erhobenen Daten sind interne Stakeholder. Durch diese Arbeit soll das Tätigkeitsprofil eines Bestandsmanagers transparent dargestellt und das Verständnis der relevanten Prozesse intern erhöht werden. Somit ist die Bachelorarbeit für alle Stakeholder und Entscheidungsträger der DATEV eG, welche in Kontakt mit dem Rechenzentrum stehen, interessant.<br><br>Zum Bestandsmanagement zählen die Prozesse Bestandsführung, Abnahme der Komponenten, Rechnungsfreigabe sowie Verschrottung. Diese werden in der Abschlussarbeit dargestellt, überprüft und durch Handlungsempfehlungen optimiert. Für die Datenerhebung der IST-Analyse waren Beobachtungen und das Wissen der Prozessbeteiligten grundlegend. Die Handlungsempfehlungen wurden durch eine Analyse des bestehenden Ablaufes und auf Basis der Anforderungen der Stakeholder erstellt.<br><br>
15.06.20;15.02.21;2020;extern;Master;EN;Automatic Detection of emotional Hotspots in Meetings;The automated determination of relevant information from meeting recordings is a challenging task.<br>Several studies have shown that the involvement and emotion detection can be helpful for the recognition of important events in meetings.<br>Regions of high involvement are also referred to as hotspots.<br>Previously developed hotspot and emotion recognition systems utilized textual and acoustic information.<br>However, only acoustic information is used in this thesis for a more realistic scenario since meeting transcripts are usually not available.<br>Several machine learning models were trained on the ICSI meeting corpus, the MOSEI, and the IEMOCAP datasets with the goal of finding a suitable approach to develop hotspot and emotion recognition systems, which solely use acoustic information.<br>Moreover, various approaches were examined to improve the performance of the developed recognition systems, including transfer learning, data augmentation, and the combination of multiple models.<br>The achieved results show that the X-Vector architecture and the transfer learning approach can be used to train hotspot and emotion recognition systems that perform notably well.<br>SpecAugment and VAD were the overall best performing data augmentation techniques.<br>Lastly, there are indications that the additional information of an emotion detection system is beneficial for the training of a hotspot detection system.
17.06.20;17.11.20;2020;extern;Bachelor;DE;DATEV-Cloud-Sourcing: Analyse und Optimierung der Produktwechselprozesse;Das Ziel dieser Abschlussarbeit besteht darin, ein prozessuales Konzept mit Optimierungsmaßnahmen für Produktwechselprozesse zu erstellen. Die Prozesse des Produktwechsels werden erfasst, auf Schwachstellen untersucht und gegebenenfalls auch Optimierungsvorschläge erarbeitet.<br><br>Dabei wird zunächst der aktuelle BPM-Workflow analysiert. Danach werden zahlreiche Interviews mit den involvierten Mitarbeitern durchgeführt und die Checklisten für Wechselprozesse überprüft. Die Erarbeitung eines Soll- Konzeptes diente der verbesserten Darstellung der Produktwechselprozesse. Die erstellten Modelle können als Basis für die Implementierung eigener BPM-Workflows verwendet werden. Am Ende dieser Abschlussarbeit werden alle vorgeschlagenen Verbesserungsmaßnahmen zusammengefasst. Die Umsetzungsprüfung dieser Maßnahmen erfolgt mittels einer Aufwand-Nutzen-Analyse.<br><br>Die Ergebnisse der Abschlussarbeit sollen den Vorgesetzten als Entscheidungsgrundlage dienen. Unabhängig von der Entscheidung, welche Verbesserungsmaßnahmen umgesetzt werden, kann das Ergebnis dieser Bachelorarbeit zum einen für die Dokumentation der Produktwechselprozessen und eine Einarbeitung der neuen Mitarbeiter verwendet werden. Zum anderen können die erarbeiteten Ergebnisse als Informationsquelle und Grundlage für weitere zukünftige Prozessoptimierungen verwendet werden.
01.07.20;09.02.21;2020;extern;Master;EN;Search term Optimization for Federated Search;Im 21. Jahrhundert ist das Finden, Sammeln, Verarbeiten und Analysieren von Informationen zu einem bestimmten Thema durch die riesige, verteilte Architektur des Internets sowie die einfache und schnelle Verteilung von Daten zu einer Herausforderung geworden. Die Data Fusion Platform von Traversals Analytics and Intelligence GmbH vereinfacht eine gleichzeitige Suche auf mehreren Plattformen und die Analyse der angereicherten Suchergebnisse. Allerdings hängt die Qualität der Suchergebnisse von der Qualität der verwendeten Suchbegriffe ab. Das Ziel dieser Thesis ist es, die Suchbegriffe zu optimieren um durch Erweiterung der nächsten Suchanfrage genauere Suchergebnisse zu erhalten. Dies wurde durch die Modifikation und Erweiterung der Data Fusion Platform Architektur erreicht. Im Detail werden Suchbegriffe generiert, die Relevanz der Suchbegriffe ermittelt sowie Suchbegriffe empfohlen. Die Generierung solcher Suchbegriffe erfolgte durch die Erstellung von Bag-of-words, Term frequency-inverse document frequency und fastText Modellen. Die Bewertung der Relevanz der Suchbegriffe wurde anhand des Klickverhaltens der Benutzer durch QueryClickLogs ermittelt. Schließlich wurden ähnliche Suchbegriffe im Frontend empfohlen und konnten zur Erweiterung der nächsten Suchanfrage verwendet werden.
01.07.20;18.12.20;2020;extern;Master;EN;Design and Implementation of a Chatbot Prototype in the Context of a Blended Learning Portal;up2date solutions GmbH already has a learning management system called U2D Semiro for managing participant data and handling various administration processes. This system is to be expanded to include a new blended learning approach, which also integrates an intelligent chatbot.<br>The aim of this thesis is to develop a chatbot prototype for this new blended learning portal. As the chatbot is intended to serve as a learning aid and supporter for the user, it is important to take general chatbot design principles into account. Also, in this thesis it should be evaluated whether it is possible that the chatbot can interact not only actively but also proactively with the user.<br>The chatbot should be available to users in several areas. The functions of the chatbot include providing motivation to the learner, answering and asking questions and suggestions regarding other courses as well as matchmaking with other users. Therefore, the chatbot should also be able to take the context of the user into account, so that it can intervene at the appropriate time.
01.07.20;19.12.20;2020;intern;Master;DE;Konzeption und Entwicklung einer Benutzeroberfläche für die prozedurale Generierung von virtuellen Indoor-Welten mittels des Levelgraph-Verfahrens;Prozedurale Levelgenerierung ist ein wichtiger Aspekt der Spieleentwicklung. Für diesen Themenbereich wurde ein inkrementelles halbautomatisches Verfahren namens Levelgraph entwickelt, mit dessen Hilfe 2D/3D Flur- und Raumsysteme durch eine iterative prozedurale Verarbeitungskette konstruiert werden können. Der Algorithmus wird dabei durch eine komplexe und umfangreiche Parametermenge gesteuert, für die Vorwissen im Bereich der Graphentheorie und Leveldesign vorausgesetzt und lange Einarbeitungszeit benötigt wird. Dieses Verfahren kann über ein in der Game-Engine Unity bereits entwickelten prototypischen Plugin angewendet werden. Auf dieser Grundlage wird in dieser Arbeit eine Oberfläche in Unity entwickelt, welche die Einstellung der Parameter sowie die Anwendung und Steuerung des Verfahrens für Anwender ohne technisches Expertenwissen ermöglicht. Zur verständlichen sowie nachvollziehbaren Darstellung der oben genannten technischen Parameter werden diese umfassend analysiert und überarbeitet. Darauf aufbauend wird in dieser Arbeit ein Konzept erstellt und anschließend als grafische Benutzeroberfläche (prototypisch) umgesetzt. Mittels der prototypisch realisierten grafischen Benutzeroberflächen wird im Rahmen dieser Arbeit außerdem eine Benutzerstudie hinsichtlich der Usability durchgeführt. Das Ergebnis dieser Arbeit ist ein Unity-Plugin, welches von Leveldesignern für die Generierung von 2D/3D-Flur- und Raumsystemen effizient genutzt werden kann.
02.07.20;02.12.20;2020;extern;Bachelor;DE;Entwicklung einer effizienten Parallelisierungsstrategie zur Rekonstruktion von 3D Volumendaten mit Multi-GPU Systemen;Ziel dieser Arbeit ist die Entwicklung und Implementierung einer Softwarearchitektur, welche eine effiziente Rekonstruktion von Volumendaten aus Röntgenaufnahmen auf Multi-GPU Systemen ermöglicht. Als Rekonstruktionsalgorithmus wird die gefilterte Rückprojektion für Kreis- und Helixaufnahmegeometrien verwendet. Hierfür wird ein Überblick über die Algorithmen sowie über die OpenCL-API, welche zur Programmierung der Grafikkarten verwendet wird, gegeben.<br>Der Haupteil befasst sich mit einer Analyse der bestehen Lösung und der Beschreibung der neuen Architektur. Die Evaluation wurde mit simulierten Datensätzen mit verschiedenen Aufnahmeparametern durchgeführt. Im Vergleich zur bestehenden Lösung erzielt die Implementierung der neue Architektur geringere Laufzeiten.
09.07.20;09.12.20;2020;extern;Bachelor;DE;Visualisierung von (Code-)Analyse Daten mittels Graphdatenbanken;"Im Rahmen meiner Bachelorarbeit sollen unterschiedliche 2D Visualisierungen mittels einer Web-Anwendung evaluiert werden. Grundlage für die Visualisierung sind Codeanalyse Daten, die in einer Graphdatenbank gespeichert sind. Diese Daten werden über eine .NET Core Server-Anwendung per REST API bereitgestellt. Die Evaluation soll zeigen, in wie weit die verschiedenen Ansichten eine Codeanalyse unterstützen können.Unter den 2D Visualisierungen, die im Rahmen der Bachelorarbeit bearbeitet sind, sind TreeMaps, Circle-Packing, Chord-Diagramm, und Tree. Hierzu muss eine Implementierungsstrategie und 2D Engine ausgewählt werden, die mehrere tausend Objekte flüssig darstellen kann. Im Rahmen der Arbeit soll die bestehende REST API des Servers entsprechend den Anforderungen angepasst werden und ein webfähiger Client mittels TypeScript und JavaScript implementiert werden. Für die Implementierung der Visualisierung wird die JavaScript-Bibliothek ""D3.js"" benutzt und für das User Interface  (UI) wird die JavaScript-Bibliothek ""React.js""   verwendet."
15.07.20;15.12.20;2020;intern;Bachelor;DE;Konzeption und prototypische Umsetzung eines Segeltrimm-Assistenten auf Basis von NMEA2000-Daten;Ziel dieser Arbeit ist die Konzeption und Entwicklung einer prototypischen Applikation<br>(App), welche auf Basis von NMEA2000-Daten eine visuelle Darstellung empfohlener<br>Trimmeinstellungen des Haupt- und des Vorsegels auf einem Segelboot ausgibt. Zur<br>Datenbereitstellung dient ein Einplatinencomputer, der unter Einsatz eines Adapters, der<br>als Schnittstelle zwischen NMEA2000- und seriellen Daten die Sensordaten eines<br>Segelbootes empfängt. Für einen plattformunabhängigen Einsatz der App, wird die<br>Entwicklung mittels eines Cross-Plattform Frameworks realisiert werden. Als Resultat der<br>Implementierung, liefert die App dem Anwender visuell aufbereitete Daten und gibt<br>grafische Empfehlungen für einen passenden Segeltrimm aus.
28.07.20;02.03.21;2020;extern;Master;DE;Domänenwissen-basierte Erkennung komplexer Ereignisse in Messdaten verteilter Sensoren;Mit der zunehmenden Verbreitung digitaler Sensoren wächst auch die generierte Datenmenge stetig an. Gerade der Einsatz von Sensornetzen ermöglicht, dank einer Vielzahl verteilter Sensoren, eine großflächige Überwachung von Gebieten. Erhobene Daten enthalten Informationen über Vorgänge der realen Welt und können Rückschlüsse auf komplexe Abläufe liefern. Deren Erkennung wird vereinfacht, wenn vorab eine Zuordnung der Messdaten zu bestimmten komplexen Ereignissen erfolgt. Grundlage hierbei ist Domänenwissen, über welches die Kombinations- und Interpretationsweise der Messdaten und die resultierenden Ereignisse definiert werden können.<br><br>Ziel dieser Arbeit ist die Entwicklung und Implementierung einer Anwendung, welche basierend auf Domänenwissen und Messdaten verteilter Sensoren abstrakte Ereignisse ableiten kann. Aufgrund der vielfältigen Einsatzszenarien liegt das Augenmerk auf einer hohen Flexibilität und einer einfachen Verwendungs- und Integrationsweise in bestehende Systeme. Hierbei wird auch eine Schnittstelle entwickelt, welche die Verwendung bestehender Komponenten als Teil des Erkennungsablaufs ermöglicht. Die Funktionsfähigkeit der Anwendung wird abschließend in verschiedenen Szenarien evaluiert.<br>
14.08.20;14.01.21;2020;extern;Bachelor;DE;Entwicklung einer touch orientierten Oberfläche nach MVVM für die Auftragsliste;Das Ziel dieser Arbeit ist es eine neue Oberfläche für die Auftragsliste zu erstellen. Die Auftragsliste ist hierbei ein Teil eines Prozessleitsystems. Die neue Oberfläche soll in C# WPF geschrieben und nach dem MVVM-Muster aufgebaut werden. Die erstellte UI soll darauf ausgelegt sein auf einem Windows-Tablet mittels Toucheingaben bedient zu werden. Außerdem soll bei der Erstellung des Backends der Anwendung besonders auf Modularität geachtet werden.<br><br>Für die Umsetzung des Layouts der Oberfläche konnte sich auf ein vorhandenes Konzept gestützt werden. Zuvor musste dieses aber hinsichtlich der Grundsätze aus der ISO 9241-110 Norm verifiziert werden, da es sich bei diesem Konzept nur um einen ersten Entwurf handelte. Im Konzept wurden kleinere Kritikpunkte gefunden, welche ausgebessert wurden. Aufbauend auf das verifizierte Konzept konnte ein konkreter Plan für die Umsetzung der Oberfläche in C# WPF ausgearbeitet werden. Zugehörig zum zuvor vorhandenen UI-Konzept gab es eine Testanwendung, welche bereits in C# WPF geschrieben war. In dieser waren schon Grundstrukturen, wie grundlegende Datenbankabfragen, vorhanden. Aufbauend auf dieser Anwendung, wurde ein Konzept für die Datenstrukturen und das Zusammenspiel dieser im Backend der Anwendung ausgearbeitet. Abschließend wurde die erarbeitete Anwendung noch einigen Tests unterzogen.<br><br>Das Ergebnis ist ein erster Schritt der Neuentwicklung der Auftragsliste, auf welche in Zukunft weiter aufgebaut werden wird. 
16.08.20;15.04.21;2020;intern;Master;EN;Prototypical Development of an Interactive, Dynamic AI System for Music Generation and Accompaniment Based on Existing Datasets;The topic of the master thesis covers the development of a system that generates suitable music for accompaniment based on an player input in real time with the help of an AI. For this purpose, the challenges that arise for the construction of such a system are discussed. With awareness of these, experiments were conducted based on the MusicVAE model. Aspects like sequence length, prime sequence and history were investigated. Furthermore, a genre conditioned MusicVAE model was implemented and evaluated. Finally, based on A.I. Duet, a real time client-server application for improvisation and accompaniment was presented using the resulting model.
01.09.20;01.02.21;2020;intern;Bachelor;DE;Null Safety in modernen Programmiersprachen;Ein häufiger Laufzeitfehler bei Anwendungen ist der NullPointerError, welcher vor allem durch unaufmerksames Programmieren entsteht.<br>Da viele Compiler die Zusammenhänge von Null-Zuweisungen und Dereferenzierungen nicht statisch erkennen können, bleiben diese Fehler bis zur Laufzeit unbemerkt.<br>Deswegen kommen immer mehr Programmiersprachen mit ihren eigenen Konzepten auf, um Programmabstürze durch leere Referenzen zu vermeiden.<br><br>Diese Arbeit untersucht die allgemeinen Möglichkeiten, wie moderne Programmiersprachen Null Safety zu Compilezeit umzusetzen können oder bereits umsetzen.<br>Dabei wird im Detail auf die Null Safety in Java und Kotlin eingegangen und überprüft, wie eine Übersetzung nach Kotlin ein Java-Programm null-sicherer machen kann.<br><br>Diese Übersetzung wird klassenweise zuerst durch eine automatische Konvertierung von Android Studio und dann durch manuelle Anpassungen zu einem kotlin-idiomatischen Code durchgeführt.<br>Daraus resultierend wird eine stichpunktartige Guideline angefertigt, die das allgemeine Vorgehen bei einer null-sicheren Übersetzung von Java nach Kotlin beschreibt.
01.09.20;01.02.21;2020;intern;Bachelor;DE;Konzeption einer Gamification - Lösung für das Qualitätsmanagement;Da die Qualität von Produkten und Dienstleistungen einen entscheidenden Wettbewerbsfaktor darstellt und für Zertifizierungen erforderlich sein kann, entscheiden sich viele Unternehmen für die Einführung eines Qualitätsmanagementsystems. Eine klassische Aufgabe beim Aufbau von Qualitätsmanagementsystemen ist die Dokumentation der Prozesse. Diese Teilaufgabe wird von den betroffenen Personen aufgrund des hohen Aufwands oft als demotivierend wahrgenommen. Insofern stellt sich die Frage, wie Mitarbeiter zu dieser Tätigkeit motiviert werden können. Gamification ist ein vieldiskutierter Trend der zunehmend Einzug in die Arbeitswelt findet. Darunter versteht man den Einsatz von Spielelementen in nicht-spielerischen Kontexten. Gamification wird zur Steigerung der Motivation eingesetzt, mit dem Ziel eine Verhaltensänderung herbeizuführen. Um diesen Mehrwert zu generieren, ist es jedoch erforderlich die Bedürfnisse und Präferenzen der Zielgruppe zu kennen.<br>Ziel der Arbeit ist die Konzeption einer Gamification-Lösung für die Einführung eines Qualitätsmanagementsystems. Hierbei sollen die Mitarbeiter eines Betriebs dazu motiviert werden, sich aktiv bei der Dokumentation von Prozessen zu beteiligen. Die Vorgehensweise zur Erstellung des Konzepts orientiert sich an einem Gamification-Designprozess, im Rahmen dessen eine Analyse des Kontexts und der Nutzer erfolgt, um eine angepasste Lösung zu entwickeln.
03.09.20;03.02.21;2020;extern;Bachelor;DE;Software-Lifecycle Management bei der Datev eG: Konzeption und Implementierung einer maßgeschneiderten Lösung;Ziel dieser Arbeit ist die konstruktive Überarbeitung der bereits bestehenden Software-Lifecycle Management Prozesse und Rollen der DATEV unter Einbezug der technologischen Entwicklungen und den neu geschaffenen Funktionen durch einen sogenannten Software Cataloges. Zudem soll ein technischer Einblick in die Funktionsweise und die zukünftigen Einsatzszenarien durch mögliche Erweiterungen des Software Cataloges gegeben werden.
07.09.20;07.02.21;2020;extern;Bachelor;DE;Konzeption und prototypische Überführung von Jenkins-Pipelines in ein Kubernetes-Umfeld sowie Rückführung der Ergebnisse;Das Ziel der vorliegenden Bachelorarbeit war es, ein Konzept zur Überführung von Jenkins-<br>Pipelines in Tekton-Pipelines zu erstellen. Diese Pipelines werden in einem Kubernetes-<br>Cluster ausgeführt. Das Konzept wurde anhand der prototypischen Überführung einer<br>standardisierten Maven-Pipeline angewendet.<br><br>In diesem Konzept wurde besonderer Wert darauf gelegt, keine Änderung für den<br>Endanwender herbeizuführen. Demnach soll keine Änderung am Vorgehen beim Start und<br>bei der Auswertung der Pipeline erforderlich sein. Hierfür ist es nötig, die Ergebnisse der<br>Tekton-Pipeline auf den Jenkins zurückzuführen sowie den Start der Pipeline gleich zu<br>gestalten. Ein weiterer wichtiger Punkt ist, die Konfigurierbarkeit der Pipeline weiterhin zu<br>gewährleisten.<br><br>Die Rückführung konnte durch die Verarbeitung von CloudEvents mittels eines RESTServices<br>gestaltet werden. Dieser sendet alle notwendigen Informationen an den Jenkins,<br>welcher diese sichert und anschließend darstellt.<br><br>Der Start der Pipeline wird über den Aufruf einer Webhook, welche durch tekton-triggers<br>bereitgestellt wird, ermöglicht. Diese Webhook kann sowohl manuell über den Jenkins als<br>auch automatisch bei Änderungen am Repository durch Bitbucket aufgerufen werden.<br><br>Die Konfigurierbarkeit wurde durch eine dynamisch erzeugte ConfigMap erreicht. Diese wird<br>auf Basis einer Datei im Git-Repository eines jeden Projektes, welches die Pipeline nutzt,<br>erstellt.
07.09.20;12.03.21;2020;intern;Master;DE;Prototypische Konzeption und Implementierung eines Chatbots zur Unterstützung von Studierenden und Studieninteressenten;Diese Arbeit befasst sich mit der prototypischen Konzeption und Implementierung einer Chatbot-Anwendung zur Unterstützung von Studierenden und Studieninteressenten. Die Anwendung wurde in Zusammenarbeit mit psychologischen Fachkräften an der TH Nürnberg realisiert. Beginnend mit der Aufgabenstellung und der Erfassung der Anforderungen, werden zunächst die technischen Grundlagen zur Realisierung einer solchen Anwendung dargelegt. Dabei wird insbesondere auf das Natural Language Understanding (NLU), die Typisierung von Chatbots, sowie auf das Chatbot-Framework Rasa eingegangen. Zudem werden die Studiengangstests der Technischen Hochschule Nürnberg, sowie das zugehörige Interventionsangebot zur Unterstützung der Nutzer erläutert. Die zentrale Aufgabe der Chatbot-Anwendung besteht darin, zwischen den Studiengangstests und dem Interventionsangebot individuell zu vermitteln und den Prozess langfristig zu begleiten. Auf diesen Erkenntnissen aufbauend, wird das Softwaredesign der Chatbot-Anwendung, sowie die anschließende Realisierung erörtert. Dabei wird der Fokus insbesondere auf die Wahl des Chatbot-Frameworks und die Formalisierung der Regeln gelegt. Anschließend wird der Prototyp evaluiert und die Ergebnisse der Evaluation detailliert diskutiert. Des Weiteren werden Herausforderungen bei der Konzeption und Realisierung einer solchen Chatbot-Anwendung separat herausgearbeitet. Abschließend werden mögliche Erweiterungen erörtert und eine Zusammenfassung der Arbeit gegeben.
13.09.20;28.02.22;2020;intern;Bachelor;DE;Vergleich von ISO 27001 mit IT Grundschutz und ISIS 12 ;
14.09.20;14.03.21;2020;extern;Bachelor;DE;Evaluation von skalierbaren Technologien für Build-Infrastrukturen in großen IT-Unternehmen und Konzeptionierung der Umsetzung am Fallbeispiel der DATEV eG;Aufgrund des schnellen Wachstums und somit auch steigender Mitarbeiterzahl vieler Unternehmen der Softwareentwicklung benötigen diese eine Build-Infrastruktur, die dynamisch auf die steigende Last reagieren kann. Da die Auslieferung der Software von der Build-Infrastruktur abhängig ist, stellt dies einen essenziellen Aspekt der Wertschöpfungskette jedes Softwareentwicklungsunternehmen dar.<br><br>Oft ist eine Build-Infrastruktur mit statischen Kapazitäten vorhanden, die unflexibel bezüglich Strukturänderungen und steigender Nutzerzahl ist. Im Kontext der Bachelorarbeit wird eine Infrastruktur mit ca. 1000 Nutzern und 5000 täglichen Builds betrachtet. Bei steigender Nutzerzahl ist manueller Personaleinsatz notwendig.<br><br>Ziel der Arbeit ist passende architektonische Prinzipien zu ermitteln und eine Lösung zu gestalten, wie am Markt verfügbare Buildtechnologien zu einer flexiblen, dynamischen Infrastruktur verbaut werden können, die sowohl hinsichtlich Last als auch geänderter Anforderungen flexibel ist.<br><br>Das Ergebnis wird ein Kriterienkatalog mit praxisnahem Anwendungsbeispiel sein, in dem sich alle wichtigen Aspekte und Eigenschaften hinsichtlich der oben genannten Zielsetzung der verschiedenen Technologien befinden.<br>Die ermittelten Prinzipien werden mittels Gestaltung eines Konzepts praxisnah am Fallbeispiel des Unternehmens DATEV eG dargestellt. Die Konzeptionierung der Umsetzung dient zur späteren Validierung im realen Umfeld.
14.09.20;14.02.21;2020;extern;Bachelor;DE;Konzeption und prototypische Anbindung eins cloudbasierten JavaScript Monitoring Tools;Die steigende Anzahl von JavaScript Anwendungen und die derzeit fehlenden Möglichkeiten echtzeitnah und ressourcenschonend bei der Sopra Financial Technogoly (SFT) Performanz und Fehler zu erfassen, ist der Ausgangspunkt für diese Arbeit. Durch eine nutzerorientierte Anforderungsanalyse wurde für die Firma wichtige Kriterien an ein mögliches Error Monitoring Tool eruiert. Mit Hilfe einer Nutzwertanalyse wird ein geeignetes Produkt ausgewählt. Dieses wird mit Hilfe einer minimalen Javascript-Anwendung für den Einsatz in der Sopra Financial Technogoly (SFT) erprobt.
14.09.20;14.02.21;2020;intern;Bachelor;DE;Einflüsse der Digitalisierung in der Pathologie auf die Wirtschaftlichkeit und die Arbeitsabläufe im Labor<br>;Aus Unternehmenssicht einer Pathologie ist es das Ziel, ihre Kunden, die einsendenden Ärzte, bestmöglich mit zuverlässigen Befunden zu versorgen. Als Herausforderung dabei bestehen nicht nur sinkende Laborbudgets und steigender Kostendruck, sondern auch ein zunehmender Fachkräftemangel. Verbesserungen erwarten Laborleiter und Geschäftsführer hier mit Hilfe der Digitalisierung durch die Reduktion manueller Tätigkeiten. In der Arbeit sollen die prozessualen, personellen und wirtschaftlichen Einflüsse der wachsenden Digitalisierung auf das pathologische Labor sowie die Befunderstellung dargestellt und kritisch betrachtet werden. Zudem sollen Lösungsansätze für das Problem des Fachkräftemangels aufgezeigt werden. Darüber hinaus erfolgt eine wirtschaftliche Gegenüberstellung der Investitionen in Bezug auf die Digitalisierung. Informationen aus der Praxis werden durch Interviews mit Laborberatern und Pathologen erhoben.<br>
21.09.20;21.02.21;2020;intern;Bachelor;DE;Konzeption, Design und Entwicklung einer nativen iOS App zur Untersuchung von responsive Design und Internationalisierung;Zur Untersuchung von responsive Design und Internationalisierung wurden für diese Arbeit drei native iOS Apps erstellt. Sie wurden mit dem UIKit Framework, dem Storyboard des Interface Builders von Xcode und dem seit September 2020 neu eingeführten SwiftUI Framework erstellt. Da sich jede dieser drei Varianten bei der Erstellung einer App unterscheidet wird zuerst auf die Grundlagen eingegangen. Responsive Design wird auch bei nativen Apps benötigt, da sich die Bildschirmauflösungen der einzelnen Modelle unterscheiden. Deshalb wird das Auto Layout, Adaptive Layout und das neue SwiftUI Layout System erklärt und miteinander verglichen. In Zusammenhang mit dem responsive Design steht die Internationalisierung einer App. Es wird beschrieben, wie diese unter iOS funktioniert und welche Vor- und Nachteile sich für die jeweiligen Varianten ergeben. 
21.09.20;26.01.21;2020;extern;Bachelor;DE;Konzeption und prototypische Implementierung eines Tools zur Kennzahlenvisualisierung im Serviceprozess bei der Dematic GmbH ;Dematic ist einer der führenden Intralogistik-Innovatoren, der automatisierte Lösungen für Fertigungs-, Lager- und Vertriebsumgebungen entwickelt, baut und betreut. Die Realisierung von Lagersystemen für Kunden beinhaltet vertraglich vereinbarte Service- und Supportdienstleistungen zur Wartung und Betreuung der Lagerverwaltungssoftware. Das Ziel der Arbeit ist, ein Tool zur Darstellung von Kennzahlen eines entsprechenden Serviceprozesses auszuwählen. Mit der Visualisierung von Kennzahlen können die richtigen Informationen in der richtigen Qualität den richtigen Adressaten zur richtigen Zeit zur Verfügung gestellt werden. <br>Mittels einer Kosten-Nutzen-Analyse sowie einer quantitativen Befragung der späteren Softwareanwender wird ein geeignetes Software-Tool zur nutzerfreundlichen Visualisierung von Ticketdaten ausgewählt. Die Untersuchung des Serviceprozesses folgt einem systemtheoretischen Lösungsansatz zur Ermittlung von wesentlichen Komponenten eines Systems und stellt als Ergebnis ein Kennzahlensystem für die Serviceleistungen des SAP Support-Bereichs dar. Mit dem Software-Tool werden die ermittelten Kennzahlen visualisiert und automatisiert bereitgestellt. 
21.09.20;21.05.21;2020;intern;Master;DE;Datenanalyse im Sport - Eine Untersuchung zur Übertragung von existierenden Datenanalyseprozessen von einer Sportart zur anderen;Der Sport ist ein wichtiger Bestandteil im Alltag der Menschen, wenige Wissen dass die Wirtschaft auch eine immanente Rolle in der Sportbranche spielt. Im Zuge der fortschreitenden Digitalisierung sind Daten das Rohstoff für den langfristigen Erfolg geworden und an dieser Stelle hilft die Datenanalyse Unternehmen um strategische Entscheidung zu treffen. Demnach verwenden Sportarten die Datenanalyse, um gewinnbringende und umfangreiche Informationen von Spielen und Spielern zu erhalten und zu verarbeiten. Der Erfolg durch die Datenanalyse in den Sportarten, baut auf den individuellen Ansätzen und Anpassungen der entwickelten Methoden auf. Die vorliegende Arbeit durchleuchtet die Konzepte der Datenanalyse in den verschiedenen Sportarten und prüft das Potenzial der Übertragbarkeit von innovativen Datenanalysekonzepten zwischen den unterschiedlichen Sportarten. 
22.09.20;19.02.21;2020;extern;Bachelor;DE;Konzeptionierung einer agilen Softwareentwicklung im IT-Systemhaus der Bundesagentur für Arbeit;Die vorliegende Bachelorarbeit, die in Kooperation mit dem IT-Systemhaus der Bundesagentur für Arbeit geschrieben wurde, beschreibt Konzepte für die Softwareentwicklung und das Anforderungsmanagement im Servicebereich BAS1. Die Konzepte versuchen, Lösungsansätze für die Herausforderungen des Servicebereichs aufzuzeigen. Das konzipierte Modell für eine agile Softwareentwicklung mit interdisziplinären Teams und einer testgetriebenen Entwicklung basiert auf der Methode Scrum und wurde an die Prozesse und Vorgaben des Servicebereichs angepasst. Gleichzeitig wird das entwickelte Konzept für das Anforderungsmanagement in den Softwareentwicklungsprozess integriert. Hiermit wird das Anforderungsmanagement neu ausgerichtet, durch ein teamübergreifendes, virtuelles Team durchgeführt und somit von den Teams losgelöst. Obwohl die Konzepte individualisiert sind, zeigen sie, wie eine agile Softwareentwicklung mit interdisziplinären Entwicklerteams und einem cross-funktionalen Anforderungsmanagement in IT-Abteilungen eingesetzt werden kann und können daher als Vorlage für andere Abteilungen dienen.
25.09.20;25.02.21;2020;extern;Bachelor;DE;Analyse und Visualisierung der Datenqualität innerhalb eines Data Warehouse;Für Banken ist für das Treffen von korrekten, finanzspezifischen Entscheidungen insbesondere eine hohe Datenqualität erforderlich. Diese Arbeit zeigt, dass Datenqualität mehr als nur korrekte Daten bedeutet. Zur Analyse von Datenqualität existieren aktuell wenige praktische Verfahren, die ohne manuellen Aufwand angewendet werden können. Anhand einer Stakeholder-Analyse werden drei zentrale Probleme eines Finanzdienstleisters skizziert und Methoden zur Analyse vorgeschlagen. Hierfür werden beispielhaft die Daten des Risikoscorings verwendet und anhand der Methoden untersucht. Basierend auf einer entsprechenden Evaluation erweisen sich diese Verfahren für den Finanzdienstleister als nützlich und geben erste Einblicke in die Datenqualität. Ein in der Arbeit evaluiertes Programm und dessen Visualisierungen zeigen praktisch umgesetzte Verfahren zur Analyse der Datenqualität.
28.09.20;28.02.21;2020;extern;Bachelor;DE;Konzeptionierung und Implementierung einer Performance Analytics Plattform für Managed Services bei einem IT-Dienstleister.;Der Titel dieser Arbeit lässt im Grunde schon das erahnen, was im Fortlauf durchleuchtet und bewertet wird: Wie lässt sich eine Performance Analytics Plattform für Managed Services bei einem IT-Dienstleister konzeptionieren und implementieren?<br>Die Theorie die sich in der umfangreichen Literatur ergründet, bietet einem Unternehmen zahllose Möglichkeiten sein IT-Servicemanagement zu strukturieren. Viele Rahmenwerke beschreiben mithilfe von generischen Modellen die Struktur, welche jedoch auf die Bedürfnisse und Anforderungen des Unternehmens angepasst werden müssen. Anhang der Struktur des IT-Servicemanagements und den Zielen der Organisation können Kennzahlen definiert werden, um den Betrieb steuern und die Unternehmensziele erreichen zu können.<br>Das Ziel ist es letztendlich ein erstes System aus aussagekräftigen Kennzahlen zu entwickeln und zu implementieren, um die Qualität der Services und die Performance der erbrachten Dienstleistung bei einem skalierbaren Wachstum sicherzustellen.<br>
29.09.20;28.01.21;2020;extern;Bachelor;DE;Konzeption und prototypische Realisierung einer Softwarekomponente zur Direktkommunikation von Pick-by-Light-Komponenten mit einem SAP-System;Für Ein- und Auslagerungen von Waren benötigen Unternehmen effiziente Lösungen, um im Wettbewerb bestehen zu können. Einer dieser Lösungsansätze ist die Dematic Pick-By-Light Komponente zur beleglosen Kommissionierung. Auf alte Systemhierarchien begründet ist die Komponente nicht direkt mit SAP EWM verbunden, sondern über das Zwischensystem Dematic SubDriver, welches in diesem Fall als vermittelnder Server fungiert. Aktuelle Änderungen an der Pick-By-Light Komponente ermöglichen deren Konfiguration als Server, weswegen die Funktion des SubDrivers nicht mehr benötigt wird. Gegenstand der hier vorgestellten Arbeit ist die Konzeption und prototypische Implementierung einer Pick-By-Light Komponente zur direkten Kommunikation mit dem SAP-EWM System.
29.09.20;26.02.21;2020;intern;Bachelor;DE;Digitale Transformation im Einkauf: Positionsbestimmung und Weiterentwicklung anhand von Reifegradmodellen;
29.09.20;17.05.21;2020;intern;Master;DE;Analyse der Auswirkungen der Corona-Pandemie auf E-Government;Die vorliegende Masterarbeit steht im Kontext zur Corona-Pandemie und betrachtet hierbei das E-Government. Die Arbeit beschäftigt sich konkret mit der Forschungsfrage nach den Auswirkungen der Corona-Pandemie auf das E-Government, welche aufgrund des Umfangs in fünf Teilbereiche untergliedert ist. Für die Beantwortung der Forschungsfrage werden drei Methoden zurate gezogen. Diese sind neben der Literaturrecherche ein Experteninterview sowie eine Umfrage, die im Rahmen der Arbeit durchgeführt wurden.<br>Zentrale Ergebnisse der Arbeit sind neue Online-Services, eine gesteigerte Nutzung digitaler Angebote wie auch eine Weiterentwicklung des Interaktionsgrades derartiger Services. Die Bedeutung digitaler Angebote im öffentlichen Sektor ist durch Kontaktbeschränkungen, die pandemische Lage und geschlossene Dienststellen deutlich gewachsen. In vielen Bereichen des E-Governments hat die Corona-Pandemie so zu einer Express-Digitalisierung geführt, die es ohne die Pandemie in dieser Form nicht gegeben hätte. Dennoch führen föderale Strukturen sowie regulatorische Rahmenbedingungen dazu, dass der Stand des E-Governments auch weiterhin durchaus unterschiedlich sein kann. <br>Die meisten der erhobenen Auswirkungen haben über die Corona-Pandemie hinaus Einfluss auf das E-Government. Damit kann die Corona-Pandemie als neuer Schub für eine beschleunigte Digitalisierung im öffentlichen Sektor dienen und das E-Government in Deutschland weiter vorantreiben.
01.10.20;28.03.21;2021;extern;Bachelor;DE;Integration und Evaluierung eines Werkzeugs zur automatischen Klassifikation von Textinhalten in das Redaktionssystem SCHEMA ST4;Das Ziel dieser Arbeit war es, Plusmeta, ein Tool zur automatischen Klassifikation von<br>Textinhalten in das Redaktionssystem ST4 zu integrieren. Es wird zuerst ein Konzept<br>erstellt, um Plusmeta in ST4 zu integrieren. Dieses Konzept wird anschließend<br>umgesetzt.<br>Nachfolgend werden in Plusmeta mithilfe von Daten aus ST4 verschiedene KIModelle<br>trainiert. Hierbei werden Klassen unterschiedlicher Kategorien verwendet,<br>um nachfolgend zu evaluieren, inwiefern die Qualität der Klassifikationsergebnisse sich<br>unterscheidet. Hierfür werden mithilfe von Stichproben die Klassifikationsergebnisse<br>geprüft und grafisch dargestellt.<br>Abschließend werden Probleme identifiziert, die die Arbeit mit Plusmeta entweder<br>zeitaufwändiger machen oder schlechtere Ergebnisse hervorrufen. Für diese Probleme<br>werden Lösungsvorschläge unterbreitet.
01.10.20;01.03.21;2021;extern;Bachelor;DE;Simulation einer HDR-Rohdaten-Kamera für Closed-Loop-HiL-Anwendungen im automotive Bereich ;Diese Bachelorarbeit thematisiert die Analyse und Realisierung einer Bild-Encodier-Funktionalität für Closed-Loop-HiL-Systeme in ROS 2 (Robot Operating System). Ziel des Softwareentwicklungsprojekts ist es, synthetische High Dynamic Range (HDR) Farbbilder in sensorspezifische Rohdatenformate zu konvertieren und diese Daten an ein automotive Steuergerät zu übertragen. Die Erzeugung der Rohbilddaten aus Farbbildern wird hierbei von Grund auf neu implementiert, da gängige Bildverarbeitungsframeworks ihren Fokus auf der Bilddekodierung von Rohbilddaten in Farbbildern gerichtet haben. <br><br>Besonders thematisiert wird die Analyse und Implementierung des Bayering der HDR-Farbbilder in RGGB-Bilddaten, die Farbkorrektur und die Erzeugung sensorspezifischer HDR-Formate. Zur Anpassung der Rohdatenformate erfolgt die Realisierung dieser Bildvorverarbeitungsschritte generisch und erweiterbar.<br>
01.10.20;26.02.21;2021;intern;Bachelor;DE;Integration von Wissensmanagement in Content Delivery Systeme am Beispiel des SCHEMA CDS;Ein Wissensportal stellt in einem Unternehmen eine Form des<br>Wissensmanagements dar, da Informationen gesammelt und verteilt werden<br>können. In der Content-Delivery liegt der Fokus auf dem Sammeln und<br>Verteilen von Informationen, speziell im Kontext der technischen<br>Dokumentation.<br><br>Diese Arbeit untersucht, wie ein Wissensportal in ein<br>Content-Delivery-System am Beispiel des SCHEMA CDS integriert werden<br>kann. Dabei werden die grundsätzlichen Ansätze der Content-Delivery und<br>eines Wissensportals aufgezeigt und miteinander verglichen.<br><br>Daraus werden die Anforderungen für die Integration definiert und eine<br>prototypische Anwendung konzipiert. Die Implementierung dieser Anwendung<br>wird schrittweise beschrieben, wobei auf die Wahl der Technologien und<br>Erwägungen bei der Architektur und Umsetzung des Programms eingegangen<br>wird. Abschließend wird die Implementierung mithilfe eines<br>Experteninterviews mit bestehenden Formen des Wissensmanagements in der Quanons Content Solutions GmbH verglichen.
01.10.20;01.03.21;2021;extern;Bachelor;DE;Skalierung serverseitiger Module eines CMS mit Aktoren und Microservices;ST4 ist ein Enterprise Content-Management-System, das auf Technische Dokumentation ausgerichtet ist.<br>Die Anzahl der Nutzer, die auf einer ST4 Installation arbeiten, steigt.<br>Dadurch wird der Server zunehmend stark belastet.<br>Um bei Kunden mit vielen Redakteuren angemessene Performance zu erreichen, gibt es momentan nur die Möglichkeit der vertikalen Skalierung.<br>Um den steigenden Anforderungen gerecht zu werden, benötigt ST4 die Möglichkeit horizontal zu skalieren.<br>Bisher wurde für serverseitige Operationen eine Architektur basierend auf dem Aktormodell verwendet.<br>Durch Implementationsdetails ist es nicht möglich mit dem verwendeten Aktorsystem horizontal zu skalieren.<br>Um eine horizontale Skalierung trotzdem zu ermöglichen, wird heutzutage häufig eine Microservice Architektur verwendet.<br>Ob diese Architektur sinnvoll oder überhaupt umsetzbar in ST4 ist, soll anhand eines Moduls analysiert werden.<br>Für diese Analyse wurde das Übersetzungsmodul gewählt.<br><br>Es muss zuerst ermittelt werden, welche Teile des Moduls als Microservice umgesetzt werden können.<br>Anschließend muss die Schnittstelle zwischen dem Microservice und der vorhandenen Architektur untersucht werden.<br>Mit den hieraus gesammelten Erkenntnissen soll dann ein Proof-of-Concept erstellt werden, um möglicherweise versteckte Schwierigkeiten bei der Entwicklung zu erkennen.<br>Anhand dieser beispielhaften Implementierung können dann die tatsächlichen Vor- und Nachteile gegenüber der Aktor-basierten Alternative festgestellt werden.
01.10.20;21.01.21;2021;extern;Bachelor;DE;Konzeption und Entwicklung eines Tools zur Validierung der Schnittstellenkommunikation zwischen ERP-Systemen und dem internen Warehouse Management System im Entwicklungsprozess bei der Dematic GmbH<br><br>;Die Dematic GmbH ist einer der führenden Anbieter für automatisierte Intralogistik.<br>Die Tests für die Schnittstelle zwischen dem internen Warehouse Management System DiQ und den externen ERP-Kundensystemen werden aktuell manuell für jedes Projekt angelegt und durchgeführt. Teile der Schnittstelle können ohne einen Kommunikationspartner gar nicht getestet werden. <br><br>In dieser Bachelorarbeit wird ein Problemlösungskonzept für ein Testsystem entwickelt. Anhand dessen wird ein Prototyp des Tools implementiert, der bereits erste Testfunktionalitäten abdeckt. <br><br>Zudem wird die Frage geklärt, ob für alle kommenden Projekte in der Dematic ein universales Test-Tool genutzt werden kann, das den Entwicklern ein effizientes Testen der Schnittstelle ermöglicht.<br>
01.10.20;01.04.21;2021;intern;Bachelor;DE;Genauigkeit von Verschriftungen - Vergleich zwischen automatischer, Laien und professioneller Verschriftung;Transkription ist die Übertragung von einem gesprochenen Text in Schrift. Dabei geht es jedoch nicht um die sinngemäße Verschriftung, sondern darum, dass jedes Wort exakt niedergeschrieben wird. Fehler, die bei der Transkription passieren, werden in Word Error Rate (WER) gemessen. Dies ist ein prozentualer Wert, welcher angibt, wie viele Wörter in dem transkribierten Text falsch sind. Fehler entstehen zum Beispiel durch ungenaues Zuhören eines Laien oder durch eine Maschine, welche das zu übertragene Wort nicht kennt.<br>Es werden zwei Korpora von Sprachaufnahmen untersucht. Für diese wurden jeweils menschliche (professionelle und Laien) und automatische Verschriftungen angefertigt. In der Bachelorarbeit soll untersucht werden, wie weit diese voneinander abweichen und ob bestimmte Wörter oder Redewendungen besonders gut oder schlecht erkannt werden.
01.10.20;01.03.21;2021;extern;Bachelor;DE;"Analyse, Konzeption und Implementierung eines barrierefreien Teilbereichs der ""Banking to go"" App für Android mit Fokus auf der Darstellung von Aktien-Charts bei der ING";In der Arbeit wird untersucht, wie der Investieren-Bereich der Banking-to-go App der ING<br>für Android barrierefrei gestaltet werden kann. Dazu wird erläutert, wie Barrierefreiheit<br>durch das Betriebssystem Android ermöglicht wird und an welchen Stellen Entwickler und<br>Entwicklerinnen eigene Erweiterungen schreiben können. Anhand einer Übertragung der<br>Web Content Accessibility Guidelines auf mobile Anwendungen wird analysiert, welche<br>Lücken es in der aktuellen Implementierung des Investieren-Bereichs gibt. Ein besonderer<br>Fokus liegt hierbei auf den Aktien-Charts: Es werden Anforderungen der Nutzer und Nutzerinnen an den Chart festgelegt und recherchiert, welche bestehenden Lösungen existieren.<br>Anschließend werden drei Konzepte (Textdarstellung, Sonification und Erkundungsseite)<br>erstellt, mit denen die vielen Informationen des Charts barrierefrei zur Verfügung gestellt<br>werden können. Die Konzepte und eine Auswahl der bei Analyse gefundenen Lücken wird in<br>die Banking-to-go App implementiert. Die meisten Mängel sind dadurch entstanden, dass<br>die Android Accessibility APIs mit zu wenigen Informationen befüllt wurden. Anschließend<br>wird ein Test zur Bewertung der Chartkonzepte mit einem blinden Nutzer durchgeführt. Es<br>zeigt sich, dass die entwickelten Konzepte nützlich sind, es aber noch Bedarf für Verbesserungen gibt.
01.10.20;01.03.21;2021;intern;Bachelor;DE;"Spielen von ""Sonic the Hedgehog"" mit Reinforcement Learning";Ziel dieser Arbeit ist ein Vergleich drei verschiedener Reinforcement Learning Algorithmen anhand des Computerspiels Sonic the Hedgehog. Zunächst wurden hierfür die theoretischen Grundlagen des Reinforcement Learning, sowie der drei konkreten Algorithmen erläutert. Damit die Algorithmen im Kontext des Spiels analysiert werden können, wurde sowohl der Ablauf des Spiels als auch dessen spezifische Schwierigkeiten erörtert. Weiterhin wurde betrachtet, wie Reinforcement Learning bei Sonic the Hedgehog umgesetzt wurde. Damit die Leistung der drei Algorithmen verglichen werden konnte, wurde eine einheitliche Strategie zur Durchführung des Trainings festgelegt. Dabei wurde ebenfalls untersucht, ob und inwieweit das Training beschleunigt werden kann. Es stellte sich hierbei heraus, dass Training auf einer GPU im Vergleich zu einer CPU schneller war. Zum Trainieren wurden zwei ähnliche Level aus Sonic the Hedgehog verwendet, wobei das zweite Level zur Validierung der Ergebnisse des ersten Levels diente. Bei der Analyse der Trainingsdaten wurde ersichtlich, dass nur einer der drei Algorithmen beide Level innerhalb weniger Minuten Trainingszeit lösen konnte, während die anderen beiden Algorithmen das Ziel generell nicht erreichten. Einer der beiden Algorithmen zeigte während des Trainings jedoch eine stetige Verbesserung der Belohnungen. Im Gegensatz dazu pendelte sich der andere Algorithmus auf einen bestimmten Belohnungswert ein, welchen er nicht weiter verbessern konnte.
01.10.20;19.02.21;2021;extern;Bachelor;DE;Digitalisierung der Jahresabschlussprüfung am Beispiel von Journal Entry Testing mithilfe des Tools Analytics4Audit;Der Bereich der Jahresabschlussprüfung durchläuft auch bei der Wirtschaftsprüfungsgesellschaft Rödl & Partner den Prozess der Digitalisierung. Möglichst viele Prozesse und Prüfungshandlungen sollen dabei optimiert werden. Auch die Analyse des Buchungsjournals, das Journal Entry Testing, welches ein wesentlicher Bestandteil der Jahresabschlussprüfung ist, folgte einem ineffizienten Prozess. Dieser wurde mit der Entwicklung des Tools Analytics4Audit an die Herausforderungen und Potentiale durch die Digitalisierung angepasst.<br><br>Die Arbeit beschäftigt sich mit der Frage, ob und inwiefern die Anpassung des Prozesses mit Unterstützung des Tools Analytics4Audit einem bisherigen Vorgehen überlegen ist. Um die Unterschiede der Vorgehen herauszuarbeiten, wurden beide Möglichkeiten genauer beschrieben und anhand wesentlicher Vergleichsaspekte untersucht.<br><br>Aus der Arbeit ergab sich, dass eine Verbesserung der internen Prozesse durch Analytics4Audit möglich ist.
01.10.20;14.03.21;2021;intern;Master;DE;Künstliche Intelligenz in der digitalen Forensik - Stand der Forschung, praktische Anwendungen und Weiterentwicklungen;
01.10.20;19.05.21;2021;extern;Master;DE;Lokalisierung Smarter Zähler;Zählerauslesung von Strom-, Gas- und Wasserzählern sind ein kostspieliger Faktor für den Betrieb eines Versorgungsnetzes. Die Firma Diehl Metering hat innovative Funknetze entwickelt, welche diesen Prozess vollständig automatisieren. Beim Betrieb eines solchen Zählernetzwerks fallen große Mengen an Daten an. Im Rahmen eines Innovationsprojektes soll erörtert werden, ob einzelne Zähler mithilfe dieser Daten geortet werden können. Es soll ein Modell beruhend auf topografischen Eigenschaften zwischen Sender und Empfänger, entwickelt werden. Die topografischen Eigenschaften werden dem Modell in Form von Satellitenbildern zugeführt. Mithilfe eines Convolutional Neural Networks wird eine Funktion approximiert, welche die Korridore auf dem Pfadverlust der Verbindung abbildet. Es wird gezeigt, dass Satellitenbilder Informationen über die Ausbreitungsbedienungen enthalten. Dadurch kann ein Modell erzeugt werden, welches den Pfadverlust zwischen Sender und Empfänger mit einer Abweichung von 5,18 % ermittelt. Diese Arbeit knüpft an ähnliche Vorarbeiten an, und führt die Konzepte hinsichtlich der Eingabedaten weiter. Maßgeblich wird gezeigt, wie der Pfadverlust einer Funkverbindung mit rein topografischen Merkmalen modelliert werden kann. Einerseits wird ein Algorithmus zur Extraktion von Kartendaten beigetragen, andererseits wird aufgezeigt, wie mithilfe dieser Daten ein DL-basiertes Modell für den Pfadverlust erlernt werden kann.
02.10.20;31.07.21;2021;extern;Master;DE;Prototyp eines intelligenten Informationsfilter mittels visueller Bauteilerkennung auf mobilen Endgeräten;Die vorliegende Arbeit beschäftigt sich mit einer intelligenten und visuellen Suche nach 3D-Modellen aus 2D-Bildern. Bisherige Lösungen bieten Rekonstruktionen von 3D-Modellen aus Bildern an, aber keine Suche in weiteren 3D-Modellen. Außerdem sind diese nicht für mobile Endgeräte entwickelt. Das Ziel dieser Arbeit ist ein neuronales Netz speziell für mobile Endgeräte zu erstellen, welches 3D-Modelle aus 2D-Bildern generiert und diese anschließend mit einem anderen Set aus 3D-Modellen abgleicht, um das ähnlichste zu finden.<br><br>Nach Abschluss der Arbeit ist eine Suche entstanden, bei welcher nach ungesehenen 3D-Modellen gesucht werden kann, ohne dass das neuronale Netz neu trainiert werden muss. Außerdem ist die Suche einfach für den Endbenutzer anwendbar und auf mobilen Endgeräten ausführbar, um diesem Zeit bei der Suche von tausenden Dokumenten zu ersparen. 
02.10.20;02.03.21;2021;extern;Bachelor;DE;Untersuchung einer Korrelation von Steuerfachbegriffen und betriebswirtschaftlichen Dokumenten durch maschinellem Lernen;Das Ziel dieser Arbeit ist es zu bestimmen, welche natürlichsprachigen Algorithmen<br>man für ein textgetriebenes Empfehlungssystem nutzen kann. Das System soll hierbei<br>anhand der Suchanfrage und den ersten zurückgelieferten Texten Empfehlungen für<br>neue, auch interessante Dokumente machen. Dazu wird zuerst die Forschungsfrage gestellt, welche textbasierten Algorithmen für ein Empfehlungssystem infrage kommen<br>und als zweites, wie man die empfohlenen Dokumente aufgrund einer Ähnlichkeitsanalyse in eine Rangordnung bringen kann.<br><br>Um die Forschungsfrage zu beantworten, wurden verschiedene Verfahren aus dem Information Retrieval und dem maschinellen Lernen hergenommen, um Schlüsselwörter<br>aus den zuerst zurückgelieferten Texten zu extrahieren. Mit word2vec, T F -IDF und<br>BERT sollen die Schlüsselwörter gefunden werden. Mit diesen Schlüsselwörtern werden wieder neue Texte gefunden. Durch eine Ähnlichkeitsanalyse sollen anschließend<br>die neuen Texte in eine Ordnung zu dem erstgefundenen Dokument gebracht werden.<br>Hierfür wird doc2vec verwendet.<br><br>Eine qualitative Studie zeigte, dass word2vec und T F -IDF die besseren Dokumente<br>durch die Schlüsselwortextraktion findet. Mit BERT ist das Empfehlungssystem weniger erfolgreich. Zusätzlich hat sich gezeigt, dass durch den Einsatz von doc2vec die<br>weiteren Dokumente in eine brauchbare Rangordnung gebracht werden können.
03.10.20;01.06.21;2021;intern;Master;DE;Entwicklung eines Verfahrens zur Crawler-basierten Optimierung von Filterlisten zur Blockierung von Cookie-Hinweisen;Das Ziel der Arbeit ist die Beantwortung der Fragestellung, wie die Qualität von Filterlisten für Werbe- und Inhaltsblocker zur Blockierung von Cookie-Hinweisen unter Verwendung eines Crawler-basierten Verfahrens optimiert werden kann. Hierzu sind die Konzeption und Implementierung sowie die Evaluation des Verfahrens durchgeführt worden.<br><br>Zunächst sind hierzu verwandte Arbeiten betrachtet und Vorüberlegungen zur Generierung von Domainlisten und der Erkennung von angewendeten Filterregeln sowie Cookie-Hinweisen getätigt worden. Auf dieser Basis sind daraufhin funktionale und nicht-funktionale Anforderungen an das Verfahren definiert worden. Im Rahmen der Konzeption ist daraufhin die konkrete Vorgehensweise des Crawler-basieren Verfahrens definiert und der technische Entwurf des Verfahrens durchgeführt worden. Nach der Konzeption ist durch die Implementierung des Verfahrens dessen praktische Realisierbarkeit aufgezeigt und die Grundlage für die Evaluation gelegt worden.<br><br>Durch die Evaluation ist bei der Verifikation die vollständige Erfüllung der definierten Anforderungen festgestellt worden. Mittels der Validierung sind beachtenswerte Ergebnisse belegt worden. Mithilfe einer repräsentativen Stichprobe ist eine Steigerung der Zahl der Webseiten, auf welchen Cookie-Hinweise erfolgreich entfernt worden sind, von 79,1 % auf 85,7 % nachgewiesen worden. Zudem konnte eine Reduktion der Zahl der notwendigen Filterregeln um 81,9 % festgestellt werden.
05.10.20;05.03.21;2021;extern;Bachelor;DE;Erweiterung von DATEV SmartLogin zum WebAuthN Medium;Das Ziel dieser Arbeit ist es die DATEV SmartLogin App zum WebAuthN Medium zu erweitern, da die DATEV zukünftig mehr die Standards der Industrie setzt. Die Frage, ob eine Implementierung des FIDO2 Standards für die Authentifizierung von Daten der Vertraulichkeitsklasse 3 dienen kann, wird mittels einer Gegenüberstellung mit den bestehenden DATEV Anmeldeverfahren untersucht.<br>Um die Frage zu beantworten, wurde die FIDO2 Schnittstelle untersucht und nativ in der App implementiert. Die Implementierung und weitere Anpassungen wurden dem SmartLogin-Team vorgestellt und mit ihnen diskutiert.<br>Das Ergebnis der Implementierung und der Diskussion zeigte, dass der FIDO2 Standard geringfügig angepasst werden muss um eine Tauglichkeit zu gewährleisten. Diese Anpassungen wurden bereits teilweise durchgeführt, können jedoch erst mit einem neuen Identitätsmanagement System der DATEV komplett umgesetzt werden.<br>Die Arbeit zeigt, dass die DATEV SmartLogin App zukünftig auch als WebAuthN Medium genutzt werden kann. Auf dieser Grundlage kann das neue Identitätsmanagement System bereits für die Nutzung angepasst werden, um eine schnelle Einführung zu garantieren.
06.10.20;17.03.21;2021;intern;Master;DE;Optimierung bei der Wahl der Standortverteilung einer logistischen Supply Chain, mit Hilfe eines Ameisenalgorithmus;
07.10.20;07.03.21;2021;extern;Bachelor;DE;Automatisierte Erzeugung von Headerdateien für Embedded Automotive Systeme mit AUTOSAR;Konzeptentwurf und Implementierung eines Codegenerators für die Erzeugung von Komponenten-<br>Headern in der Programmiersprache C für eine an AUTOSAR angelehnte Architektur<br>und Interfacedefinition. Die generierten Header sollen die abgekapselte Deklaration von AUTOSAR<br>Client/Server sowie Sender/Receiver Interfaces ermöglichen, die das bisherige Verfahren<br>nicht unterstützt. Weiterhin sollen UML-Diagramme basierend auf dem Architekturmodell generiert<br>werden, die im nachgelagerten ASPICE-Prozess zum Software Detailed Design genutzt<br>werden. Die Lösung soll anhand eines aktiven Produktentwicklungsprojektes evaluiert werden.<br>Dabei ist insbesondere die Konformität zu MISRA-C (2012) sicherzustellen. Aktuell wird von<br>Microsoft Excel VBA-Macros (schlecht erweiterbar) ein zentrales Header-File mit RTE Interface<br>Funktionen generiert. Diese Vorgehensweise ist jedoch nicht kompatibel mit Full-AUTOSAR<br>Projekten, da diese komponentenweise erzeugte RTE-Header erfordern. Es wird aktuell eine Anwendung<br>(Windows Forms, C#) implementiert, die die Verwaltung der RTE-Header erleichtern<br>soll. Als neues Modul soll ihm Rahmen dieser Bachelorarbeit die automatisierte Generierung von<br>komponentenweisen RTE-Headern hinzugefügt werden. Weiterhin wird während des Entwicklungsprozesses<br>Git (hier: Bitbucket) mit CI/CD eingesetzt.
08.10.20;08.03.21;2021;extern;Bachelor;DE;Automatische Klassifikation von virus-, bakterien- und Covid-19 induzierten Lungenentzündungen auf Basis von Röntgenbildern;An Lüngenentzündungen sterben laut WHO jährlich etwa 2.5 Millionen Menschen. Wie gefährlich Lungenentzündungen sind, zeigte sich auch seit Anfang 2020, als die Covid-19 Pandemie ihren Lauf nahm und bis heute mehr als zwei Millionen Tote verursachte. Die Behandlung von Lungenentzündungen ist erfolgsversprechender, je früher sie diagnostiziert wird, hierbei kann ein automatisches Verfahren, das Röntgenbilder der Lunge mit Hilfe von Machine Learning klassifiziert, helfen, diese Diagnose schneller und einfacher bereitzustellen. Im ersten Teil der Arbeit wird auf Basis von Röntgenbildern ein Klassifikator trainiert und evaluiert, der zwischen nicht infizierten, bakteriell- und viral- induzierten Lungenentzündungen unterscheiden kann. Im zweiten Teil der Arbeit wird der Klassifikator auf einem zweiten Datensatz getestet. Dieser enthält nicht infizierte, infizierte und durch Covid-19-induzierte Lungenentzündungen. Hierbei wird überprüft, inwieweit der Ansatzeines Machine Learning basierten Klassifikators auf ähnliche, aber nicht genau gleiche, Pro-bleme möglich ist. Im letzten Teil der Arbeit wird geklärt, inwieweit der Transfer-Learning Ansatz für ein Problem dieser Art verwendet werden kann. Dazu wird auf Basis des im ersten Teil der Arbeit trainierten Klassifikators ein für den zweiten Datensatz verwendbarer Klassifikator trainiert. Weitere mittels Transfer-Learning trainierte Klassifikatoren werden außerdem auf Basis der als ImageNet bekannten CNN trainiert.
09.10.20;09.03.21;2021;extern;Bachelor;DE;Verfahren zur ganzheitlichen Offline-Fähigkeit von Single Page Applications;Das Ziel dieser Arbeit ist es, durch Integration eines Service-Workers Verfahren zur Umsetzung der Offlinefähigkeit für eine Webanwendung zu untersuchen und in einem exemplarischen Projekt zu verproben. Dabei werden grundlegende Vorgehensweisen anhand der Patterns Offline-First und Optimistic-UI aufgezeigt. Die daraus resultierende Notwendigkeit der lokalen Datenhaltung wird zunächst im Thema Caching aufgegriffen. Anschließend erfolgte eine Evaluierung weiterer Datenspeicher zum Persistieren und Modifizieren dynamischer Anwendungsdaten, um die offline Bedienbarkeit zu gewährleisten. Den Abschluss des Theorieteils bildet die Synchronisation vorgenommener Änderungen mit dem Server gemäß der Methode Request-Queuing.<br><br>Die Ergebnisse der theoretischen und praktischen Untersuchung zeigen, dass mit der Umsetzung von Offlinefähigkeit in einer Webanwendung, durch Integration eines Service-Workers in Kombination mit den vorgestellten Speichertechnologien, die Verwendbarkeit und Benutzerfreundlichkeit progressiv verbessert werden kann. Das Ziel der Implementierung einer ganzheitlich offlinefähigen Webanwendung wurde für das Projekt erreicht, allerdings zeigten sich mögliche Probleme bei komplexeren Webanwendungen, beispielsweise im Hinblick auf die Sicherheit. Dennoch empfiehlt sich die frühzeitige Orientierung an Offline-First im Entwicklungsprozess, da selbst eine teilweise Umsetzung der Prinzipien zahlreiche Vorteile, lediglich in geringerem Maße, mit sich bringt.
11.10.20;11.03.21;2021;extern;Bachelor;DE;Visualisierung der Corona-Verbreitung in Europa mit Data-Science- und 3D-Verfahren;Die weltweit permanent wachsende Menge an Daten stellt Analysten und Interessierte im Hinblick auf Datenverständnis und Datentransparenz vor immer größere Herausforderungen. Aus diesem Grund müssen zwangsläufig neue Verfahren entwickelt werden, durch die den großen Datenmengen mit möglichst wenig Aufwand enthaltene Informationen entzogen werden können. Ein Beispiel, welches eine solche Datenmenge liefert, ist die Corona-Pandemie, die Deutschland, Europa und die ganze Welt seit über einem Jahr beschäftigt. Auch wenn es viele Quellen gibt, die Daten und Visualisierungen der Pandemie zur Verfügung stellen, so sind diese nicht immer einfach verständlich. Zumeist können außerdem nicht alle Informationen aufgrund der gewählten Darstellungsform entnommen werden. Um alle Informationen einsehen zu können, muss auf die Datenquelle zurückgegriffen werden. Diese besteht meist aus unübersichtlichen und umfangreichen Datentabellen. Die enthaltenen Informationen, wie Trends und Zusammenhänge, können aus diesen Tabellen ebenfalls nur schwer auf einen Blick entzogen werden. Die vorliegende Bachelorarbeit zeigt, wie am Beispiel der Corona-Pandemieverbreitung in Europa ein dreidimensionales und hochauflösendes Visualisierungsverfahren entwickelt wird. Mithilfe von Python und Blender soll dem Anwender die Möglichkeit gegeben werden, Daten zu importieren, sie zu verarbeiten und anschließend eine Grafik zu generieren, die eine übersichtliche und einfach verständliche Visualisierungsform liefert.
11.10.20;11.03.21;2021;intern;Bachelor;DE;Interpolation von Panoramen;"Grundlage <br>Bewegungen zwischen Rundumsichten, z.B. der ""Wuusch"" in Google-Streetview, sind oft nur ungenau interpoliert. Bibliotheken wie OpenCV enthalten Funktionen, um charakteristische Punkte zu erzeugen und zuzuordnen. Mittels dieser Merkmale soll anschließend ein optischer Fluss zwischen zwei Bildern erzeugt werden, welcher die Interpolation von Zwischenbildern ermöglicht. Es erscheint naheliegend, diesen Ansatz auf 2 oder 3 Dimensionen zu erweitern, so dass man zwischen 3 Punkten in der Fläche oder 4 Punkten im Raum interpolieren kann. <br> <br>Aufgabe <br>Der Ansatz wird in C++ mit der OpenCV-Bibliothek implementiert. Dann sollen mit einer vorhandenen 360°-Kamera Panoramen an 2 oder 3 Punkten in einem Raum, z.B. einem Hörsaal, aufgenommen werden. Mithilfe der Implementierung sollen zwischen diesen Punkten interpolierte Bilder errechnet werden. Als zukünftige Erweiterung soll der errechnete optische Fluss in Kombination mit der Computergrafik einen virtuellen Rundgang ermöglichen. Man soll sich virtuell zwischen den Punkten bewegen und umschauen können. <br>"
12.10.20;12.03.21;2021;extern;Bachelor;DE;Automatisiertes Deployment von Webanwendungen in eine OpenShift Cloud-Computing-Plattform <br>bei der NÜRNBERGER Versicherung<br>;In der Softwareentwicklung spielt die Qualitätssicherung eine wichtige Rolle. Um die Qualität eigenentwickelter Software, die der Auftragsabwicklung von Versicherungspolicen dient, zu erhöhen, hat sich die NÜRNBERGER Versicherung dazu entschieden, nur noch automatisierte Deployments zu erlauben. Dies gelingt mithilfe einer für die Software Jenkins entwickelten Continuous Delivery Pipeline.<br><br>Das Ziel der vorliegenden Bachelorarbeit ist es, die vorhandene Pipeline so zu erweitern, dass ein automatisiertes Deployment in ein Kubernetes Cluster ermöglicht wird. Um dieses Ziel zu erreichen, muss ein Konzept erstellt werden, das sicher stellt, das innerhalb des Clusters ein Container-Image erzeugt und auf Sicherheitslücken geprüft werden kann. Abschließend soll das resultierende Container-Image automatisiert in ein Kubernetes Cluster deployed werden können.<br><br>Der Vergleich verschiedener Werkzeuge für die Image-Erstellung hat gezeigt, dass für die NÜRNBERGER Versicherung die Software Kaniko am besten geeignet ist. Neben dem Werkzeug für die Image-Erstellung wurden auch drei Werkzeuge für das Scannen von Container-Images untersucht. Dabei hat sich heraus gestellt, dass Anchore für den Automatisierungs-Prozess verwendet werden soll. Das automatisierte Deployment erfolgt über ein vom Entwickler erstelltes Helm-Chart. Helm dient dabei als Paket-Manager und Deployment-Werkzeug für Kubernetes. <br>
12.10.20;12.03.21;2021;extern;Bachelor;DE;Konzeption und Einsatz von Wake on LAN im<br>Systemmanagement eines mittelständigen Unternehmens;"Die Bachelorarbeit soll sich mit der Technologie Wake on LAN beschäftigen. Sie soll eine Betrachtung der Technologie im Allgemeinen beinhalten, auch mit entsprechenden Vor- und Nachteilen in Bezug auf die Nutzung innerhalb eines Unternehmens. Anschließend soll eine Umsetzungsanalyse der Technologie in Kombination mit den bereits eingesetzten Technologien, wie beispielsweise 802.1.x stattfinden. Dies soll in einem ""inkrementellen"" Nachbau der Unternehmensinfrastruktur geschehen, um auch Aussagen über eventuell vorhandene Grenzen treffen zu können. Diese können sich z.B. aus der komplexen Netzwerkinfrastruktur ergeben, weshalb diese Herangehensweise gewählt wird. Sofern die entsprechenden Ergebnisse für eine Einführung der Technologie sprechen, soll darauf aufbauend in einem bestimmten Unternehmensbereich eine Beispielumsetzung durchgeführt werden. Auch sollen eventuell weitere Umsetzungsalternativen beleuchtet werden und diese gegeneinander abgewägt werden. Die Integration in bereits vorhandene Prozesse, in erster Linie mit dem Fokus auf das Patchmanagement, des Unternehmens soll außerdem betrachtet werden. Für die einzelnen Alternativen sollen Tests durchgeführt werden, um Aussagen über die Performanz und ihre Zuverlässigkeit treffen zu können.<br><br> "
12.10.20;10.03.21;2021;extern;Bachelor;DE;Entwicklung und Ergebnis eines Kriterienkatalogs für den Einsatz von Low Code in Projekten.;Das Ziel in der vorliegenden Bachelorarbeit ist die theoretischen Konzepte des Low Code Ansatzes zu erforschen. Diese Grundlagen dienen dafür, einen Kriterien-Katalog zur Überprüfung der Praxistauglichkeit von Low Code aufzustellen. Der Katalog deckt hauptsächlich die Kriterien der aspektorientierten Prozessmodellierung ab. Für die Evaluation wurde eine prozessbasierte Webanwendung mit Low Code Tools entwickelt. Zur Auswertung wurden zwei Low Code Plattformen, Bonitasoft und die Canvas Apps von Microsoft, miteinander verglichen. Es stellt sich heraus, dass beide Plattformen geeignet zum Entwickeln für prozessbasierten Anwendungen sind. Bonitasoft eignet sich eher für technische Entwickler während Canvas Apps mehr den Citizen Developern zusagt.
13.10.20;06.03.21;2021;extern;Bachelor;DE;Konzeption und Umsetzung einer Datenintegration zwischen einem<br>touristischen Reservierungssystem und der CRM-Lösung Salesforce für den<br>Austausch von Kunden- und Reiseauftragsdaten.;In der Bachelorarbeit wird die Datenübertragung von Salesforce genauer betrachtet. <br>Die Schnittstellen für die Datenübertragung werden analysiert und bewertet. Es wird <br>ein Prototyp für den Datenaustausch zwischen Salesforce und Pacific implementiert.
14.10.20;25.02.21;2021;extern;Bachelor;DE;Entwicklung einer Softwarelösung mit grafischer Bedienoberfläche zur Parametrierung von Steuergeräten anhand deren Binärcode;Kurzdarstellung<br>Bei der Softwareentwicklung von Steuergeräten im Automobilbereich ist es notwendig im Rahmen<br>von Softwaretests Anpassungen an den Initialwerten von Parametern vorzunehmen. Die<br>Werte dieser Parameter befinden sich zur Laufzeit im RAM und können während der Softwaretests<br>manipuliert, aber nicht abgespeichert werden. Eigentlich könnten die resultierenden<br>Werte der Softwaretests den jeweiligen Variablen im Quellcode neu zugewiesen werden. Allerdings<br>ergeben sich dabei zwei Schwierigkeiten. Es soll dem Kunden ermöglicht werden selbstständig<br>Parametrierungen der Steuergeräte vorzunehmen. Der Quellcode unterliegt jedoch der<br>Geheimhaltung und kann deshalb nicht ausgeliefert werden. Außerdem würde ein erneutes Kompilieren<br>einen erneuten Softwarequalifizierungsprozess erfordern, welcher einen großen Aufwand<br>mit sich bringt. Um Anpassungen an den Parametern effektiv zu gestalten soll im Rahmen dieser<br>Bachelorarbeit eine Lösung erarbeitet werden, um mithilfe einer grafischen Bedienoberfläche<br>eine Möglichkeit zu erschaffen, die geänderten Parameterwerte direkt in die Hex-Dateien der<br>Software zu übernehmen. Dabei muss eine Lösung gefunden werden, die Speicheradressen der<br>Parameter herauszufinden. Sind die Stellen der Parameterwerte in der Hex-Datei lokalisiert, soll<br>es anschließend möglich sein, diese zu verändern. Sowohl jede Zeile als auch die gesamte Hex-<br>Datei sind mit einer Prüfsumme versehen, welche schließlich noch angepasst werden müssen.<br>
14.10.20;11.03.21;2021;extern;Bachelor;DE;Untersuchung und Konzeption der Softwaresysteme Ansible und Terraform für die Provisionierung virtueller Maschinen;DATEV betreibt ein Projekt zum Aufbau eines Cloud-Rechenzentrums. Um die Self-Service-Charakteristik einer Cloud zu erfüllen, wird ein Softwaresystem für die automa-tische Provisionierung virtueller Maschinen benötigt. Es ist jedoch nicht klar, welches Softwaresystem am besten zu diesem Anwendungsfall passt, weswegen im Rahmen dieser Arbeit eine Evaluierung der Softwaresysteme Ansible und Terraform durchge-führt wird. Außerdem wird auf Basis der Ergebnisse der Evaluierung ein Konzept für die Provisionierung virtueller Maschinen erarbeitet.<br>Für die Evaluierung der beiden Softwaresysteme werden anfangs durch eine struktu-rierte Literaturrecherche in der Wissenschaft bekannte Kriterien zur Auswahl eines Softwaresystems identifiziert. Anschließend werden die gefundenen Kriterien durch eine Onlinebefragung der Projektteilnehmer für die Provisionierung virtueller Maschinen validiert sowie priorisiert. Die Ergebnisse der Befragung dienen als Grundlage für die Evaluierung der Softwaresysteme.<br>Die Evaluierung zeigt, dass Terraform für den Einsatzzweck bei DATEV besser geeig-net ist. Eine vollautomatische Provisionierung ist jedoch nicht allein durch Terraform realisierbar. Ansible bietet Funktionalitäten, um die nicht automatisierbaren Vorgänge von Terraform zu ergänzen. Daher ist ein Konzept erarbeitet worden, das eine Kombi-nation beider Technologien verwendet.<br>
15.10.20;15.03.21;2021;intern;Bachelor;DE;Untersuchung maschineller Lernverfahren zur Übersetzung natürlicher Sprache in SQL;Viele Unternehmen nutzen Datenbanken um jegliche Art von Informationen zu speichern. Das Problem dabei ist jedoch, dass die Abfrage dieser Daten komplex sein kann. Es ist schlichtweg nicht immer möglich mit den zur Verfügung gestellten Suchfunktionen alle Bedingungen zu übergeben.<br><br>Mithilfe von künstlicher Intelligenz können Computer die Anliegen von Nutzern besser verstehen, da sie in der Lage sind natürliche Sprache zu interpretieren. Ein Beispiel hierfür ist der Google Assistent. Dieser kann viele allgemeine Wissensfragen beantworten. Um diese Fähigkeiten auch auf unternehmensspezifische Daten zu übertragen gibt es neuronale Netze, welche natürliche Sprache in Datenbankbefehle übersetzen.<br><br>Der Zweck dieser Übersetzungen ist es, dass ein Endanwender nun ohne spezielles Fachwissen einer Datenbanksprache komplexe Datenbankabfragen vollziehen kann. Damit werden Zeit und Kosten für einen Programmierer gespart und Unternehmen können somit effizienter arbeiten.<br><br>In dieser Arbeit wird untersucht, welche Methoden es gibt, um natürliche Sprache in Datenbankbefehle umzuwandeln, sowie eine prototypische Implementierung einer Weboberfläche basierend auf einem Open-Source neuronalen Netzwerk zu erstellen. Zuletzt wird das neuronale Netzwerk auf Klausuren des Faches Datenbanken angewandt und die Ergebnisse dessen erläutert.
15.10.20;15.03.21;2021;extern;Bachelor;DE;Wissenstransfer in Softwareentwicklungsteams - eine praxisbezogene Analyse bei DATEV eG;Diese Arbeit umfasst die Ausarbeitung einer effektiven Vorgehensweise für den Wissenstransfer in Softwareentwicklungsteams um Lösungen zu finden, welche den Prozess des Wissenstransfers im Team nachhaltig verbessern können. Im ersten Teil der Arbeit werden die theoretischen Grundlagen des Wissenstransfers beleuchtet, wobei eine Brücke zwischen dem theoretischen Wissenstransfer und der Anwendung in einem IT-basiertem Unternehmen geschlagen wird. Danach folgt eine Ist-Analyse, in der vorwiegend durch Mitarbeiterinterviews herausgefunden wird, wie der Wissenstransfer in Softwareentwicklungsteams aktuell im Unternehmen durchgeführt wird. Aus dieser Ist-Analyse werden Schwachstellen abgeleitet, die kategorisiert und priorisiert werden. Für die optimierbarsten Schwachstellen werden darauffolgend Anforderungen an deren Lösungen definiert. Die vielversprechendsten und umsetzbarsten erarbeiteten Lösungen werden am Ende umgesetzt und evaluiert.
15.10.20;14.03.21;2021;intern;Bachelor;DE;DeepFake-Videos: Stand der Technik und praktische Evaluation;DeepFake-Videos können durch gezieltes Streuen von Falschinformationen zu einer Gefahr für die Demokratie werden. Deshalb ist es notwendig herauszufinden, welche Möglichkeiten der aktuelle Stand der Technik bietet und wie überzeugend die generierten Videos sind.<br><br>Für die Untersuchungen wurden die Frameworks DeepFaceLab und First Order Model for Image Animation verwendet. Hierbei wurde untersucht, welche Ausgangsdaten für das Training des künstlichen neuronalen Netzwerkes und dem Erstellen der DeepFake-Videos für die beiden ausgewählten Verfahren benötigt werden. Die Ergebnisse aus den Experimenten wurden anschließend auf Qualität und Überzeugungsfähigkeit untersucht. Hierfür wurde zusätzlich eine Umfrage durchgeführt. Es zeigte sich, dass mit dem Framework First Order Model for Image Animation einfache überzeugende DeepFake-Videos generiert werden können. Allerdings war es hiermit nur möglich die Person von den Schultern aufwärts darzustellen. Die erzeugten Videos mit DeepFaceLab waren weniger überzeugend. Dieses DeepFake-Video wurde deshalb von fast allen Befragten als Fälschung erkannt. Wie allerdings aus den Experimenten hervorgeht, bietet DeepFaceLab im Vergleich zum anderen Framework mehr Optionen. Aus diesem Grund besteht mit dem DeepFaceLab Framework die Möglichkeit, dass mit geändertem Ausgangsmaterial und anderen Einstellungen ebenfalls ein überzeugendes DeepFake-Video erzeugt werden kann.
16.10.20;29.01.21;2021;extern;Bachelor;DE;Information Extraction aus Suchanfragen bei<br>der DATEV;Die vorliegende Arbeit beschäftigt sich mit einer Möglichkeit, Suchmaschinen in<br>Unternehmen wie der Datev zu verbessern. Dabei wird gezielt versucht, komplexe Suchanfragen<br>beantwortbar zu machen. Vor allem für die Beantwortung von komplexen<br>Suchanfragen werden meistens viele Informationen aus verschiedenen Quellen benötigt. Ein<br>Problem dabei ist, dass die bestehenden Suchmaschinen nicht auf die benötigten<br>Informationen zugreifen können. Darüber hinaus fehlt den Unternehmen die Möglichkeit,<br>das Verhalten von Suchmaschinen aktiv zu beeinflussen. Demnach ergibt sich die<br>Forschungsfrage, wie die Trefferqualität einer Suchmaschine mit Information Extraction (IE) bei<br>der Datev verbessert werden kann. Mithilfe von IE aus den Suchanfragen<br>und zusätzlichen Daten, Informationen und Wissen sollen neue Antwortmöglichkeiten<br>ermöglicht werden.<br><br>Aufbauend auf den Grundlagen der Suchmaschinen wird die Methodik vorgestellt, welche<br>für die Implementation des Prototyps benötigt wird. Dabei wird hauptsächlich das<br>Forschungsgebiet Natural Language Processing (NLP) betrachtet. NLP hilft einer Maschine<br>die Suchanfragen zu verstehen und zu bearbeiten. Im Anschluss an die Implementation wird<br>eine Evaluation in Form einer Primäranalyse durchgeführt. Dabei wird der Prototyp<br>systematisch analysiert und evaluiert. Ebenso werden auch die Grenzen und die Trefferqualität<br>des Prototyps bewertet. Abschließend werden alle notwendigen weiteren Schritte<br>für eine produktive Version des Prototyps zusammengefasst.
18.10.20;18.03.21;2021;intern;Bachelor;DE;Kamerabasierte Visualisierung von 3D-gedruckten Objekten;Durch die gute Verfügbarkeit von 3D-Druckern im Hobbybereich und auch der Industrie erfreut sich der 3D-Druck immer größer werdender Beliebtheit. Erhebliche  Probleme bestehen jedoch noch in der Qualitätskontrolle gedruckter Objekte. Daher ist es notwendig, Methoden zur Fehlererkennung und Nachvollziehbarkeit eines Druckes einzusetzen.<br><br>Das Ziel dieser Arbeit ist, die Qualitätskontrolle im 3D-Druck zu vereinfachen. Dazu wird eine gesamtheitliche Visualisierungsanwendung konzipiert und als Prototyp umgesetzt.<br><br>Eingehend werden die Anforderungen an eine breit einsetzbare Anwendung erörtert. Dabei liegt besonderes Augenmerk in der nahtlosen Integration in bestehende Druckprozesse. Die für das Gesamtsystem gewählte Mircoservice-Architektur, ermöglicht eine Vielzahl verschiedener Einsatzszenarien und deckt den kompletten Visualisierungsprozess des Druckes ab. Begonnen wird mit der Aufnahme von Schichtbildern eines 3D-Druckes. Anschließenden erfolgt die Datenanalyse und Reproduktion des gedruckten Objektes. Dem Anwender wird eine App zur Verfügung gestellt, mit der die einzelnen Komponenten der Anwendung steuerbar sind.<br><br>Weiterführende Forschung im Bereich der Analyse von Schichtbildern, könnte auf das Potential einer vollautomatischen Bewertung von Fehlern in gedruckten Objekten auf Basis der geschaffenen Datengrundlage ausgerichtet sein.
19.10.20;08.04.21;2021;extern;Bachelor;DE;Konzept für die künftige IT-Unterstützung von Mitarbeitern im mobilen Einsatz;Am Anfang des Jahres 2020 ist eine weltweite Coronapandemie ausgebrochen. Die Arbeitgeber wurden von der Bundesregierung darin bestätigt, ihren Mitarbeitern das Arbeiten von zu Hause zu ermöglichen, da in engen Büroräumen die Ansteckungsgefahr stark erhöht ist. <br>Das Ziel dieser Abschlussarbeit ist es, die derzeit verwendete Softwareausstattung eines mittelständischen Unternehmens zu erläutern und neue Alternativen zu erarbeiten. Diese Arbeit kann dazu verwendet werden, Entscheidungen der Führungskräfte über Anpassungen der Ausstattung für den mobilen Einsatz zu erleichtern.<br>Für ein aussagekräftiges Ergebnis wurde eine Mitarbeiterumfrage durchgeführt. Hierbei wurden 300 zufällig ausgewählte Mitarbeiter über die derzeitig verwendete Software befragt. Die Umfrage lies auch Raum für eigene Anregungen und Verbesserungsvorschläge der Teilnehmer. <br>Die Ergebnisse zeigten, dass die Kommunikation über Microsoft Teams  stark verbreitet ist. Durch eine Kopplung dieser Software mit der Telefonanlage OpenScape Voice könnten externe Gespräche mit z.B. Kunden oder Lieferanten ebenso über Teams abgewickelt werden. In der Arbeit wurden verschiedene Alternativen der Umsetzung erörtert.<br>Als zusätzliche Software wurde das Produkt Miro vorgestellt. Diese Software ist ein Online-Whiteboard, welches beispielsweise für Projektarbeit genutzt werden kann. 
26.10.20;15.04.21;2021;intern;Bachelor;DE;Konzipierung und Implementierung eines Smarthomeplaners ;Die vorliegende Arbeit beschäftigt sich mit der Konzipierung eines Smarthomeplaners, der das Thema Sicherheit und Datenschutz in Smart Home Geräten während der Konfigurationsphase eines Smarthomes verbinden soll. Um das Konzept zu erstellen, wurden einige Smarthomeplaner näher betrachtet und eine kurze Recherche durchgeführt, die zu einigen ausgewählten Smarthome Geräten Sicherheitslücken sowie Datenschutzinformationen zusammenfasst und damit die Problematik zeigt, dass Smarthome Geräte oft Sicherheitslücken besitzen, die teilweise auch lange Zeit nicht behoben werden. Das Konzept wurde anschließend in Form eines Prototyps implementiert, der das Django-Webframeworks in Kombination mit dem Frontend Framework Vue.js sowie der Javascript HTML5 canvas Bibliothek fabric.js nutzt. Anschließend wurde eine Nutzer-Evaluation durchgeführt, um zu überprüfen, wie der Smarthomeplaner von Benutzern bewertet wird. Das Ergebnis der Nutzer-Evaluation hat dabei einen ersten Einblick geben können, dass der Smarthomeplaner insgesamt als Benutzerfreundlich angesehen werden kann und die zusätzlichen sicherheitsrelevanten Funktionen des Smarthomeplaner von den Benutzern positiv aufgenommen wurden.<br>
26.10.20;17.03.21;2021;extern;Bachelor;DE;Service Design und Service Transition gemäß ITIL - Konzeption eines Self-Service-Portals unter dem Aspekt der Performanceoptimierung ;Durch den Wandel der Digitalisierung verändert sich die Nachfrage und die Anforderungen an die IT innerhalb der Unternehmen. Die Betriebsabläufe und Dokumente werden teilweise lückenhaft digitalisiert. Um die Nachfrage und die Anforderungen für den fortlaufenden Betrieb an die IT sicher stellen zu können, müssen die internen IT-Serviceleistungen strukturiert und gebündelt für die internen Anwender zur Verfügung stehen. In der NÜRNBERGER Versicherung sollen die internen IT-Serviceleistungen in einem Self-Service-Portal verwaltet werden, diese sind bereits in einem hierfür entwickelten IT-Servicekatalog für den Anwender abgebildet. Das Self-Service-Portal soll die einheitliche Anfrage bzw. Beantragung ermöglichen. Hierfür musste eine Analyse des IST-Zustandes durchgeführt werden und ein Konzept für die umzusetzenden IT-Serviceleistungen erarbeitet werden.  Um den IST-Zustand des bestehenden IT-Servicekatalogs zu ermitteln, wurde der Entwicklungsstand durch einen Schemavergleich mit einem Reifegradmodell ermittelt und die Bestell- bzw. Beantragungsarten der IT-Serviceleistungen betrachtet. Mit Hilfe einer empirischen Untersuchung wird ein Konzept erarbeitet, bei dem das in der IT genutzte System OMNITRACKER betrachtet wird. Anschließend wird eine Machbarkeitsanalyse durchgeführt und die Umsetzungsreihenfolge festgelegt. Hierfür werden in Interviews die IT-Serviceketalogverantwortlichen und die für das System OMNITRACKER zuständigen Mitarbeiter befragt. ...
26.10.20;25.06.21;2021;extern;Master;DE;Entwurf und prototypische Realisierung einer containerbasierten Pipeline zur Entwicklung und Bereitstellung von Machine-Learning-Projekten;Maschinelles Lernen (ML) gewinnt in den Unternehmen immer mehr an Relevanz. Über den Verlauf eines ML-Projekts kann die Anzahl an beteiligten Personen zunehmen. Sofern kein einheitlicher Entwicklungs- und Bereitstellungsprozess etabliert ist, können unterschiedliche Versionsstände, ein uneinheitlicher Umgang mit Daten, verschiedene Technologieversionen und fehlende Reproduzierbarkeit die Folgen sein. Mit Machine Learning Operations (MLOps) sollen diese Herausforderungen angegangen werden, indem Praktiken aus DevOps auf die ML-Entwicklung und Bereitstellung übertragen werden. Durch das Etablieren von Pipelines kann die Automatisierung, Reproduzierbarkeit sowie Standardisierung der Abläufe erfolgen. Die Entwicklung von Pipelines kann jedoch komplex sein. Daher werden in dieser Arbeit auf Basis von identifizierten Anforderungen, Pipeline-Referenzmodelle bereitgestellt, die als Vorlagen für die Erstellung eigener Pipelines fungieren sollen. Elementarer Bestandteil der Referenzmodelle ist die Containertechnologie, mit der unter anderem ein einheitlicher Umgang mit den Arbeitsschritten und eine Modularisierung der Pipeline erreicht wird. Weiterhin wird untersucht, wie eine ML-Entwicklung mit der bestehenden Softwareentwicklung vereinbart werden kann, um ML-Modelle in kundennahe Anwendungen integrieren zu können. Durch eine abschließende prototypische Realisierung wird die Plausibilität der entworfenen Referenzmodelle sichergestellt.
28.10.20;02.02.21;2021;extern;Bachelor;DE;Konzeption einer Cloud Strategie in einem Pharmazeutischen Unternehmen: Technologieentscheidung und Providerauswahl;
29.10.20;14.03.21;2021;extern;Bachelor;DE;Konzeption und Implementierung von Metriken zur Auswertung von IT-Infrastrukturdaten;Im Rahmen eines internen Projektes der DATEV eG ergab sich die Anforderung, IT-Infrastrukturdaten aus einer Configuration Management Datenbank zu analysieren. Diese Datenbank wird in regelmäßigen Abständen mit Daten aus zahlreichen aktiven Systemen befüllt. Das geschieht, indem die Infrastruktur mit verschiedenen Discovery Mechanismen ausgelesen wird. Durch die hochdynamische und heterogene Natur der Datenquellen ist es eine große Herausforderung, die Integrität der Daten zu gewährleisten. Mittels der Vernetzung dieser Daten entstehen Metainformationen, die nur schwer mit den vorhandenen Mitteln visualisierbar und nur mit Fachwissen interpretierbar sind. <br><br>Ziel der Bachelorarbeit ist es, Metriken zu finden, die diese Infrastrukturdaten auswerten und klassifizieren. Zusätzlich ist eine passende Visualisierung dieser Metriken gefordert. Schwerpunkt der Arbeit wird es sein, die Relevanz der Daten zu analysieren, Klassifizierungen einzuführen und vorzunehmen sowie Aussagen über die Vollständigkeit der Daten zu treffen. Die Metriken sollen dabei helfen, einen Überblick der Zusammenhänge unterschiedlicher Daten zu erlangen, welche auf den ersten Blick nicht erkennbar sind. <br><br>Dazu wird im Rahmen dieser Bachelorarbeit ein Tool zur Auswertung der genannten Daten entwickelt. Durch das Tool sollen Visualisierungen möglich sein, mit denen auf einen Blick eine Übersicht über die Zusammenhänge und Menge der Daten generiert werden kann.<br>
01.11.20;04.05.21;2021;extern;Master;DE;Analyse und Optimierung der Einrichtung produktiver Laufzeitumgebungen im Unternehmensumfeld<br>;Das Aufsetzen kundenseitiger Produktivumgebungen ist in der Praxis zeitintensiv und führt dazu, dass Entwickler sich nicht auf die Implementierung von Systemfunktionalitäten konzentrieren können. Im Bereich der Intralogistik speziell als Dienstleister für Intralogistik-Software ist die Anzahl von verschiedenen Kunden groß, was ein regelmäßiges Aufsetzen der Produktivumgebung beim jeweiligen Kunden zur Folge hat. Durch die Optimierung dieser Konfiguration können Zeit und Kosten gespart werden. Zusätzlich werden durch entsprechende Verbesserungen menschliche Fehler bei der Konfiguration minimiert und der Aufwand des Entwicklers für die Einrichtung verringert. Die Masterarbeit behandelt die Untersuchung der aktuellen Vorgehensweise für das Aufsetzen der produktiven Laufzeitumgebungen. Anschließend sollen Schwachstellen identifiziert und priorisiert werden. Zur Behebung der dringlichsten Schwachstellen wird eine Anwendung zur automatischen Paketierung und Installation von Produktivumgebungen konzipiert und umgesetzt. In einer durchgeführten quantitativen Studie wird die entwickelte Anwendung auf dessen Funktionsfähigkeit in der Praxis geprüft. Die Ergebnisse zeigen, dass der zeitliche Aufwand für das Aufsetzen von produktiven Laufzeitumgebungen bei der Dematic GmbH um 94 % reduziert und das Fehlerrisiko verringert werden konnte.
01.11.20;01.04.21;2021;extern;Bachelor;DE;Anbindung der betrieblichen Infrastruktur an Cloud-Anwendungen am Beispiel von E-Mail und Workday HCM;Inhalt bzw. Ziel der Bachelorarbeit soll es im Allgemeinen sein, die verschiedenen Möglichkeiten der Anbindung von Email-Servern an Cloud-Software darzustellen. Als Praxisbeispiel wird hierfür in Kooperation mit der DATEV eine geeignete Möglichkeit gesucht, um einen DATEV Email-Server an die in 2019 eingeführte Cloudsoftware Workday anzubinden. Hierfür wird speziell eine Lösung gefordert, die in das bestehende Sicherheitskonzept der DATEV passt. Bei Workday handelt es sich um ein cloudbasiertes System, welches unter anderem zur Personalverwaltung innerhalb der DATEV eingesetzt wird. Durch die Verlagerung von externen auf interne Server soll es ermöglicht werden Bouncebacks zu erhalten sowie den E-Mails verschiedene Tags zuordnen zu können. Zu Beginn soll diese Umstellung für das Recruiting durchgeführt werden. 
01.11.20;01.04.21;2021;extern;Bachelor;DE;Anomalieerkennung mittels Autoencoder in cyber-physischen Produktionssystemen;Methoden und Anwendungen der künstlichen Intelligenz und des maschinellen Lernens  stellen eine aussichtsreiche Möglichkeit zur Beherrschung der wachsenden Komplexität automatisierter technischer Systeme in der produzierenden Industrie dar. Anwendungsfälle umfassen dabei die modellbasierte Optimierung, Überwachung und technische Diagnose. Insbesondere der Schritt der Modellbildung kann durch maschinelle Lernverfahren unterstützt werden.<br><br>In der vorliegenden Abschlussarbeit wird die Eignung von Autoencodern am Beispiel von drei disjunkten industriellen Anwendungsfällen in diesem Kontext bewertet. <br>Einen Schwerpunkt stellt dabei die Erkennung von Anomalien im Betrieb von Produktionsanlagen unter Zuhilfenahme von Autoencodern dar.<br><br>Die Datengrundlage umfasst hierbei diskrete binäre Steuerungssignale, kontinuierliche Prozessvariablen sowie deren Kombination. Für die Modellierung werden verschiedene Netz Topologien untersucht und verglichen.
01.11.20;01.04.21;2021;intern;Bachelor;DE;Untersuchung verschiedener Ansätze des Dynamic Topic Modeling zur Analyse thematischer Trends;In der vorliegenden Arbeit sollen die unterschiedlichen Ansätze des zeitabhängigen Topic Modellings evaluiert werden. Hierfür werden unterschiedliche theoretische Ansätze untersucht, mittels derer eine Grundlage für die Evaluation der öffentlich verfügbaren Programmiercodes zu zeitabhängigen Topic Models möglich ist. Für die Arbeit mit den unterschiedlichen Modellen werden zwei Datensätze verwendet. Der erste Datensatz der UN-Debatten von 1970 bis 2015 liegt in Englisch vor und umfasst 7.507 Dokumente mit Erscheinungsjahr. Der zweite Datensatz wurde im Laufe der Arbeit aus der Webseite des FOCUS Online Archivs zusammengestellt und umfasst insgesamt 134.614 Artikel in Deutsch von 1993 bis Januar 2021 mit dem entsprechenden Erscheinungsdatum des dazugehörigen Magazins. Um die Ergebnisse der Modellcodes auszuwerten, wurden zudem nach unterschiedlichen Visualisierungsmöglichkeiten gesucht. Hierbei wurde hauptsächlich auf gängige Visualisierungsformen des allgemeinen Topic Models zurückgegriffen und eine zeitliche Darstellung in Form eines Diagramms, in dem die unterschiedlichen Kernpunkte der jeweiligen Modelle visualisiert werden konnten. Zum Schluss der Arbeit wurden die Modelle und deren Programmiercodes auf Basis selbstgewählter Evaluationspunkte bewertet und ein Fazit zur Arbeit mit diesen Modellen gezogen.
01.11.20;01.04.21;2021;extern;Bachelor;DE;Supervoxel-Clustering zur Reduktion von Übersegmentierung in der Instanz-Segmentierung großvolumiger CT-Volumen;Mittels XXL-Computertomographie (XXL-CT) können großvolumige Datensätze von gescannten Objekten generiert und mittels nachfolgender Bildverarbeitung und Instanz-Segmentierung in ihre Teilobjekte zerlegt werden.<br>Unbekannte und unterschiedliche Eigenschaften, wie Form, Dichte, Material, oder Zusammensetzung dieser Entitäten, führen jedoch bei automatischen Segmentierungen nach aktuellem Stand der Technik, zum Beispiel mittels Deep Neural Networks, zu Übersegmentierungen.<br><br>Im Rahmen dieser Arbeit wird ein auf Affinity Propagation basierendes Clustering-Verfahren untersucht, welches diese Übersegmentierungen als Supervoxel interpretiert, und zu deren Reduktion innerhalb einer Bildverarbeitungs-Kette beitragen soll.<br>Unter Verwendung verschiedener Ähnlichkeitsmerkmale zur Clusterung konnte eine Reduktion der gegebenen Übersegmentierung bei nur geringer zusätzlicher Untersegmentierung erreicht werden.<br>
01.11.20;01.07.21;2021;intern;Master;EN;HMM-based Musical Improvisation;
01.11.20;14.03.21;2021;intern;Bachelor;DE;Konzeption und prototypische Umsetzung eines Freemium-Modells zur Monetarisierung einer App im Bildungsbereich;Im deutschen Schulalltag sind die Potentiale der Digitalisierung noch nicht ausreichend ausgeschöpft. In der vorliegenden Arbeit werden leistungsfähige Zukunftsmodelle der Notenapp dargestellt. Die Notenapp ermöglicht schon heute Schülern, ihre digitalen Kompetenzen, welche die Generation Z auszeichnet, im Schulalltag einzusetzen. Sie hilft diesen zu organisieren, den Überblick zu behalten und alles rund um Schule in der Hosentasche mit sich zu tragen. Die Arbeit gibt Anregungen für eine Monetarisierung der App, um sich das Potential der rückständigen Digitalisierung langfristig zu Nutzen zu machen. Ein Konzept für ein Freemium-Modell wird entwickelt. Dieses wird durch umfangreiche Nachforschung, einer Befragung und durch Analysen anderer Marktteilnehmer im Bildungsmarkt gestützt und entworfen. Dabei wird ein Anreiz zur Gestaltung einer Umfrage mit Ideen für mögliche Fragen, dem Aufbau und Ablauf, sowie zur Auswertung gegeben. Hierdurch werden wichtige Aspekte zur Auswahl möglicher Premium-Funktionen, der Preisgestaltung und den damit entstehenden Chancen und Risiken aufgezeigt. Anschließend wird das entwickelte Konzept voll funktionsfähig als Proof-of-Concept implementiert. Die Vorgehensweise und Learnings des Prozesses sind dabei auf andere Apps im Bildungssektor übertragbar. Abschließend wird es mit dem aktuell angewandten Werbemodell verglichen, um die Leistungsfähigkeit des Freemium-Modells zu verdeutlichen.
01.11.20;01.04.21;2021;intern;Bachelor;DE;Visuelle Emotionserkennung durch Deep Learning;"Meine Bachelorarbeit beschäftigt sich mit der Analysierung der in Videos vorhandenen Emotionen. Quellen des Inputs werden sowohl Video-Dateien, als auch Live-Kameras sein. Aus den Eingaben sollen in Echtzeit Gesichter extrahiert und zum vortrainierten Model übergeben werden. Das Model kennt 6 Emotionen als Ausgabe und erzielt eine Vorhersage, welche Emotion auf dem Gesicht ausgedrückt wird. Die Trainings/Test-Daten stammen aus 2 Datensätzen: ""CMU-Mosei Dataset"" und ""Kagle Dataset"". Um Gesichter zu extrahieren bzw. Gesichtspunkte zu finden wird OpenCV verwendet. Das Neuronale Netz wird in PyTorch gebaut. Es werden insgesamt 2 Modelle erstellt. Das eine bekommt die Eingabe mit Pixeldaten und das andere bekommt die Gesichtsmerkmale. Das komplette Projekt wird in Python und den dazugehörigen Bibliotheken/Frameworks Programmiert."
01.11.20;01.04.21;2021;intern;Bachelor;DE;Landessprachenerkennung mittels X-Vektoren und Meta-Klassifikation;
02.11.20;14.03.21;2021;extern;Bachelor;DE;Einführung einer Pipeline für Continous Integration und Continous Deployment in einer Kubernetes-Umgebung im Kontext der Zertifizierung als Medizinprodukt;Diese Bachelorarbeit beschäftigt sich mit dem Aufbau und der Einführung einer Pipeline<br>für Continuous Integration und Continuous Deployment für eine als Medizinprodukt zu zertifizierende<br>Software der Firma O.Meany Medical Data & Project Management GmbH. Es<br>wurde untersucht, inwieweit die Einführung der Pipeline den Entwicklungs-, Auslieferungsund<br>Genehmigungsprozess im Sinne der Zertifizierung unterstützt. Im Einzelnen wurde<br>auf die Zertifizierungsanforderungen eingegangen und welche Vorgaben hiervon für den<br>Entwicklungsablauf entstehen. Speziell wurde die Nachvollziehbarkeit der Softwareentstehung<br>von der Idee über die Implementierung bis zum Test und in diesem Zusammenhang<br>die Integration der CI/CD-Pipeline mit dem bestehenden Versionsverwaltungssystem (Bitbucket)<br>betrachtet. Als Technologie für die Pipeline wurden Kubernetes für die Container-<br>Orchestrierung und Rancher für das Cluster-Management ausgewählt. Mit diesen Tools<br>wurden Laufzeitumgebungen für die unterschiedlichen Entwicklungsstufen erstellt und betrieben.<br>Somit erwies sich die Pipeline, die die formale Beschreibung eines zusammenhängenden<br>Prozesses darstellt, als Unterstützung des sowohl für den Entwicklungsablauf als<br>auch für die angestrebte Zertifizierung.
02.11.20;19.06.21;2021;extern;Master;DE;Anomalieerkennung in industriellen Fertigungsprozessen durch den Einsatz von Autoencodern;Im industriellen Umfeld stellt die Aufzeichnung und Analyse von kontinuierlichen Sensordaten ein wichtiges Instrument dar, um die rechtzeitige Identifikation von Prozessanomalien sicherzustellen. Eine zunehmende Prozesskomplexität und die Erzeugung von großen Datenmengen erfordern den Einsatz von Analysemethoden, die ein Modell durch historische Sensordaten entwickeln und Prozessanomalien in einem frühen Stadium erkennen. Anomalien treten nur selten auf, sind oftmals nicht gekennzeichnet oder überhaupt nicht bekannt. Diese Arbeit setzt einen Autoencoder als künstliches neuronales Netz für die Anomalieerkennung in industriellen Fertigungsprozessen ein. Die Fähigkeit zur Anomalieerkennung wird anhand eines Spritzgieß- und Sägeprozesses demonstriert und mit konventionelleren Methoden verglichen. Für die Separierung zwischen normalen Fertigungszyklen und Prozessanomalien dient sowohl der Rekonstruktionsfehler als auch der latente Merkmalsraum des Autoencoders. Darauf aufbauend stellt diese Arbeit weiterhin ein interaktives Konzept vor, die einem Benutzer die Entwicklung eines Autoencoders durch eine grafische Benutzeroberfläche ermöglicht. Die Experimente zeigen für den Autoencoder vielversprechende Ergebnisse, indem lediglich eine einfache Architektur verwendet und geringe Vorverarbeitung vorgenommen wird. Trotz der geringen Datenmenge wird ein Großteil der Baseline-Methoden von den Autoencodern übertroffen, weshalb sich der Einsatz im industriellen Fertigungsumfeld empfiehlt.
04.11.20;01.04.21;2021;intern;Bachelor;DE;Anonymisierung von Sprechern in<br>Vorlesungsvideos;
04.11.20;04.04.21;2021;intern;Bachelor;DE;Einfluss der Covid-19 Pandemie auf das Wissensmanagement und die Geschäftsprozesse der Hoffmann Group in Nürnberg;Das Ziel dieser Bachelorarbeit ist es, die Geschäftsprozesse und den stattfindenden Wissenstransfer bei der Hoffmann Group in Nürnberg zu analysieren und daraus Ergebnisse für die zentrale Frage abzuleiten, welchen Einfluss die COVID-19 Pandemie auf das Unternehmen in diesen Bereichen hat. Der Wissenstransfer wird im operativen Geschäft mit den Methoden und Techniken des Wissensmanagements stringent untersucht, um daraus Erkenntnisse und Schwachstellen zu erarbeiten. Um das Ziel zu erreichen, werden Umfragen bei den Angestellten durchgeführt und Geschäftsvorfälle untersucht. Die durch COVID-19 standortspezifisch bedingten Änderungen, vor allem im Hinblick auf das Hygiene- und Arbeitskonzept, die der Standort in Nürnberg erfahren hat, sind in dieser Arbeit immanent. Opportun werden präventive Maßnahmen betrachtet, mit denen man Herausforderungen einer Pandemie im Voraus bewerkstelligen kann.
06.11.20;06.04.21;2021;extern;Bachelor;DE;Agilität außerhalb der Softwareentwicklung - Konzeption für die agile Transition der Abteilung IT-Infrastruktur Services (T233) der DATEV eG<br>;"Die Bachelorarbeit behandelte das Thema: ""Agilität außerhalb der Softwareentwicklung ? Konzeption für die agile Transition der Abteilung IT-Infrastruktur Services (T233) der DATEV eG"". Hierbei war folgende Forschungsfrage zu beantworten: ""Kann die Abteilung IT-Infrastruktur Services (T233), in eine agile Arbeitsweise transitiert werden?"" Im ersten Schritt war der aktuelle Wissenstands der Forschung zu erläutern. Außerdem wurde der aktuelle Einsatz von Agilität in der Wirtschaft präsentiert. Die Thematik dieser Arbeit wurde mit Hilfe der empirischen Forschung geprüft. Diese beinhaltete zwei quantitative, sowie zwei qualitative Befragungen. Die Umfragevarianten dienten zum einen für die Erfragung der Problemfelder einer agilen Transition und zum anderen der Erfragung der Lösungsmethoden für eine agile Transition. Zuzüglich wurde innerhalb der qualitativen Befragungen, bezogen auf die Lösungsmethoden eine Expertise erhoben. Die Prüfung, ob eine agile Transition möglich ist, wurde mit drei Hypothesen untermauert. Die erste Hypothese bezog sich auf das Wissen über Agilität, die zweite Hypothese bezog sich auf die Unterstützung von höheren Hierarchien und die dritte Hypothese fordert das Tätigkeitsfeld an sich heraus. Die Hypothese 1 wurde durch die gesamte empirische Forschung bestätigt. Die Hypothese 2 wurde durch die gesamte empirische Forschung widerlegt. Die dritte Hypothese wurde widerlegt. Demnach ist eine agile Transition von T233 möglich."
06.11.20;15.03.21;2021;extern;Bachelor;DE;Flexible Einlagerung mit Multishuttle: Konzeption und prototypische Umsetzung in SAP EWM;"Das Multishuttle von Dematic dient zur effizienten Einlagerung von Waren. Die Lagerplätze, die das Shuttle anfährt, sind dabei standardmäßig statisch festgelegt, d.h. die anzufahrenden Koordinaten sind festgelegt und unveränderbar. Seit geraumer Zeit gibt es die ""Flex"" Erweiterung für das Shuttle. Im Flex werden lediglich Bereiche definiert und die anzufahrende Koordinaten ergeben sich dynamisch auf Basis der Abmessungen der Ware und der Lagersituation.  <br>Diese Koordinaten müssen vom übergeordneten Warehouse-System übergeben werden. Das Warehouse-System ist also für die Berechnung eines optimalen Platzes in einem Lagerplatz zuständig. Hierfür muss eine Einlagerungsstrategie mit einer Vielzahl von Restriktionen ausgearbeitet und implementiert werden.<br>"
09.11.20;30.03.21;2021;extern;Bachelor;DE;Datenvisualisierung in Virtual Reality;Die Server der Rechenzentren der DATEV generieren während ihrer Laufzeit jeden Tag mehrere Terabytes an Logfiles, deren Daten zur Überwachung und Optimierung der Server analysiert werden. Gegenstand der Arbeit ist es, neue Herangehensweisen an diesen Prozess zu erforschen. Der Fokus liegt dabei auf der Datenvisualisierung über Virtual Reality und damit in Verbindung stehenden, intuitiven Herangehensweisen an die Analyse von Daten. Ziel der Arbeit ist es, neue Perspektiven für die generierten Daten zu erhalten und damit die Überwachung der Server effektiver zu gestalten. Zu Beginn der Arbeit wurden die Logfiles mittels Datenmanipulation in neue Strukturen modelliert, die visualisiert werden sollen. Als nächster schritt wurde eine Anwendung entwickelt, die diese Daten einliest und damit Datenvisualisierungen erstellt, deren einzelne Datenpunkte greif- und bewegbar sind. Weiterhin wurden Features implementiert, die die Filterung und Neuanordnung der Datenpunkte vereinfachen Übersicht im Angesicht vieler Daten zu schaffen. Nach Fertigstellung des Prototyps wurden an Testpersonen außerhalb des Fachgebiets der Datenanalyse Tests durchgeführt. Diese Tests sollten abprüfen, wie intuitiv Daten mit der Anwendung von Menschen analysiert werden können, die in diesem Feld nicht bewandert sind. Eine der Testpersonen hatte bereits Erfahrungen mit der Nutzung einer VR-Brille. Der entwickelte Prototyp stellt eine Basis dafür dar, Menschen beliebiger Fachrichtung Datenanalyse zu ermöglichen.
10.11.20;10.04.21;2021;intern;Bachelor;DE;Analyse und Design eines barrierefreien Interfaces mit Flutter, zur Unterstützung stark sehbeeinträchtigter Personen.;Das Ziel der vorliegenden Bachelorarbeit ist es, ein barrierefreies und plattformübergreifendes Interface für sehbeeinträchtigte Menschen zu analysieren, gestalten und zu entwickeln. Dieses Interface soll ebenfalls als Vorlage dienen, damit bei weiteren Entwicklungen die Barrierefreiheit von Applikationen ohne großen Aufwand gewährleistet werden kann. Der zu programmierende Lösungsvorschlag wird sich auf bereits aus der Forschung entstandene Erkenntnisse beziehen, außerdem wird auf diese Erkentnisse mittels einer iterativen Konzeption, begleitet durch einen Test, aufgebaut. Die Umsetzung der Applikation sowie die plattformübergreifende Entwicklung werden mit dem von Google bereitgestellten Framework Flutter unternommen. Dieses Framework wird auf Deployment, Besonderheiten, Funktionsweisen sowie im Bezug auf die barrierefreie Zielsetzung betrachtet. Des Weiteren werden gestengesteuerte Funktionalitäten für die Applikation konzeptioniert und implementiert. Die Oberfläche wird ebenfalls durch eine Sprachausgabe für sehbeeinträchtigte Nutzer zugänglich gemacht. Um das entwickelte Interface zu evaluieren, wird eine kleine Testgruppe von Sehbeeinträchtigten gebildet und auf den entstandenen Ergebnissen aufgebaut.
13.11.20;13.04.21;2021;extern;Bachelor;DE;Auswahl und Evaluierung von Verfahren zur Identifikation von Dubletten am Beispiel der Ersatzteilbereitstellung bei Siemens Mobility GmbH;Zur Erleichterung der Ersatzteilbereitstellung sucht die Siemens Mobility GmbH nach einer Möglichkeit Materialien automatisiert als Ersatzteile zu klassifizieren. Hierfür sollen noch nicht klassifizierte Materialien mit ähnlichen und schon klassifizierten Materialien abgeglichen werden und ab einem gewissen Ähnlichkeitsgrad die Ersatzteilklassifizierung vererbt bekommen. Dafür sollen Verfahren der Dublettenerkennung verwendet werden, die im Rahmen einer Datenbereinigung oder Datenintegration durchgeführt werden. Unter Dubletten versteht man alle Datensätze, die das gleiche Realweltobjekt repräsentieren. Große Schwierigkeiten bei der Erkennung von Duplikaten sind Nicht-Eindeutigkeiten von Identifikationsnummern und inkonsistente Attributwerte beziehungsweise Darstellungen. Da ähnliche Materialien die gleiche Problematik mit eventuell höheren Abweichungen aufweisen, können sie als Duplikate angesehen werden. Eine weitere Schwierigkeit ist die Menge der abzugleichenden Datensätze. Wenn jeder Datensatz mit jedem anderen abgeglichen wird, folgt dies zum einen zu vielen unnötigen Vergleichen und zum anderen zu hohen Laufzeiten, die bei entsprechend hohen Datensatzmengen wirtschaftlich nicht sinnvoll sind. Als solches werden Ähnlichkeitsmaße und Klassifikationsansätze zur Erkennung von Duplikaten und Blocking-Algorithmen zur Adressierung der hohen Laufzeit untersucht und zur Eignung der Problemstellung der Siemens Mobility GmbH evaluiert.
15.11.20;15.04.21;2021;extern;Bachelor;DE;Konzeption und prototypische Entwicklung eines integrativen Testframeworks für ein Warehouse Execution System; 
15.11.20;15.04.21;2021;intern;Bachelor;DE;Voice Cloning: Stand der Technik und praktische Evaluation;
15.11.20;15.04.21;2021;intern;Bachelor;DE;Konzeption und Implementierung einer Web-Applikation für die<br>interaktive Filterung und Visualisierung textueller Daten;Diese Bachelorarbeit befasst sich mit CASOVIS, einer Web-Anwendung und Teilprojekt von<br>CASoTex zur Visualisierung von textuellen Daten. Die Web-Anwendung bietet in ihrer ersten Version nur die Möglichkeit der Generierung von einfachen Linien-,  Balkendiagrammen und Wordclouds. Mit den bisherigen Funktion können bisher nur allgemeingültige Erkenntnisse<br>über die Daten gezogen werden.  Das Ziel dieser Bachelorarbeit ist die Konzeption und Weiterentwicklung von CASOVIS.<br><br>Um detaillierte Informationen über die Daten in Erfahrung bringen zu können, sollen<br>weitere geeignete Visualisierungsfunktionen implementiert werden sowie eine Freitext-Suche<br>und Filterung integriert werden. Außerdem soll die Möglichkeit geschaffen werden dynmisch Topic Modelle zu erstellen. Für den Betrieb der Anwendung wird in dieser Bachelorarbeit noch eine moderne Identity-and-Access-Managementlösung implementiert. 
15.11.20;15.04.21;2021;extern;Bachelor;DE;Entwicklung einer Webanwendung, die mit Hilfe von modernen Technologien einen internen Prozess im Umfeld der Gehaltsberatung automatisiert.;Ein Mal pro Nacht werden innerhalb der DATEV in einem Batch-Lauf alle Berater- und Mandantenüberträge des Vortages verarbeitet und die Informationen dazu an das Rechenzentrum gesendet. Durch technische Probleme entstehen dabei aber oft fehlgeschlagene Überträge. Diese sollen im Umfeld der Gehaltsberatung in einer Oberfläche aufgelistet und manuell nachbearbeitet werden können. In diesem Projekt ist eine Webanwendung mit einer dazugehörigen Schnittstellenbeschreibung entwickelt worden, welche die manuelle Nachbereitung dieser fehlgeschlagenen Überträge und Löschungen automatisiert. Die Oberfläche wurde mit dem Framework Angular umgesetzt und wird später im internen Produktivbetrieb Cloud Foundry laufen.
16.11.20;09.07.21;2021;extern;Master;DE;Aufbau einer automatisierten Workflowlandschaft für das IKS eines Finanzdienstleisters auf Basis der TIM Solutions Process Engine;Ein effizientes und wirksames IKS wird zur Steuerung von Unternehmensrisiken für Banken und Fintechs zunehmend wichtiger. Zurückzuführen ist dieser Aspekt vor allem auf die komplexer werdende Geschäftswelt, die regelmäßige Anpassung von Gesetzen und die voranschreitende Digitalisierung der Bankenbranche. Ein Ziel der vorliegenden Arbeit ist es deshalb zu untersuchen, wie sich IKS- und respektive Risikomanagementprozesse mithilfe der TIM Solutions Process Engine digitalisieren und automatisieren lassen. Ebenso gilt es zu beantworten, inwiefern sich die aufgebaute Workflowlandschaft als Service am Bankenmarkt vertreiben lässt.Zur Beantwortung der Fragestellungen wurden die IKS- und Risikomanagementprozesse der Sopra Financial Technology als Kooperationsunternehmen analysiert und transformiert. Außerdem wurde eine Umfrage mit weiteren Finanzinstituten durchgeführt, um deren Ausgestaltung von (IKS-)Prozessen und die dabei verwendeten IT-Systeme zu erfassen.Die Analyse zeigt, dass die beiden betrachteten Prozesskategorien stark von manuellen Aktivitäten geprägt sind und Automatisierungstechnologien kaum zum Einsatz kommen. Resultierend daraus, ergeben sich durch den Aufbau einer digitalen Workflowlandschaft Effizienzsteigerungen und eine Minderung der Prozesskosten. <br>Hervorzuheben ist, dass die Implementierung auf einer Low-Code-Entwicklung basiert. Diese eignet sich somit für einen leicht anpassbaren (Consulting-)Service, welcher durch weitere Marktstudien ausgebaut werden kann.
17.11.20;17.04.21;2021;intern;Bachelor;EN;Topic Segmentation and Visualization for Video Lectures;"The following bachelor thesis describes the process of extracting Topics from lectures, applying periods to them, and afterward visualizing the result on a website.<br>Subjects of the lectures are ""Interventional Medical Image Processing"" and ""Pattern Analysis"", both held by Prof. Dr.-Ing. Joachim Hornegger.<br>First, the transcripts are preprocessed and then each word gets converted into a token. <br>Combining these into multiple vectors results in a matrix that represents the documents and their including words.<br>Algorithms for Topic Modelling, like Latent Semantic Analysis, calculate the topics of this matrix.<br>New documents can be transformed into this topic space, returning the topic distribution of it.<br>This process is now applied to different timestamps of the lecture.<br>Finally, the distribution is visualized on a web app, using the JavaScript library ChartJs.<br>Additionally, this method is compared against another Algorithm called ""TopicTiling"".<br>To evaluate the techniques, the keywords will be compared against a list of topics, which was created by humans.<br>Additionally, the algorithms will be applied to biology courses for testing.<br>The outlook describes the integration of this project into the media-sharing platform. "
23.11.20;21.04.21;2021;extern;Bachelor;DE;Neukonzeption eines Monitoring-Tools für den Einzelhandel auf der Basis von Microsoft 365 Business Central;In dieser Bachelorarbeit wird der Einfluss der Cloud-Technologien auf die Weiterentwicklung<br>der ERP-Lösung von Microsoft untersucht. Die kundenspezifischen<br>Geschäftsprozessanpassungen, die für klein- und mittelständische Unternehmen<br>von Bedeutung sind, werden im Zuge dieser Transformation auf eine andere Weise<br>vom Dienstleister entwickelt und bereitgestellt.<br><br>Die folgenden Forschungsfragen sind zu beantworten:<br><br>1. Wie sehen die neuen Prozesse für die Bereitstellung der kundenspezifischen<br>Anpassungen für die Cloud-Lösung aus und wie können sie effektiv und effizient<br>gestaltet werden?<br><br>2. Wo geht der Trend im Einzelhandel hin und welche Funktionalitäten werden<br>im Einzelhandel gebraucht?<br><br>In der Abschlussarbeit wird gezeigt, dass das Bereitstellungsmodell Software-as-a-<br>Service in der ERP-Welt an Bedeutung zunimmt. Prozesse und neue Denkweisen<br>müssen vom Dienstleister in den Unternehmensalltag integriert werden. Flexibilität,<br>schnelle Anpassungsfähigkeit und der interne Wissensaustausch sind gefordert,<br>um den Bereitstellungs- und Verwaltungsprozess zu standardisieren und wenn<br>möglich zu automatisieren.
27.11.20;27.04.21;2021;extern;Bachelor;DE;Untersuchung von Decentralized Identifiern, deren Auswirkung auf den Datenschutz sowie ihre Anwendung in einem Prototyp eines digitalen Geldbeutels;Klassische Authentifizierungsverfahren wie z.B. Single Sign-On, speichern Daten des Benutzers, beispielsweise den Benutzername und das Passwort, in der Regel auf firmeninternen Servern ab. Dieses Konzept entzieht dem eigentlichen Dateninhaber allerdings die volle Kontrolle über seine Daten. Beispielsweise wären mit einem Hackerangriff die Daten gefährdet oder sogar weitere Daten des Users mit einem Löschen der Webseite nicht mehr verfügbar. Im Rahmen dieser Bachelorarbeit wird ein dezentralisiertes Verfahren vorgestellt, das keine Speicherung von Identitätsdaten, z.B. für eine Anmeldung, beim Webseitenbetreiber benötigt. Des Weiteren wird eine Möglichkeit vorgestellt, wie physikalische Identitätsnachweise, wie z.B. ein Personalausweis, durch ein digitales Pendant ersetzen werden können. Darauf aufbauend werden Strategien vorgestellt, die es gestatten den Informationsaustausch mit Dritten auf ein Minimum zu beschränken und so nur ausgewählte Daten zu teilen. Durch eine lokale Speicherung dieser Identitätsnachweise in einem digitalen Wallet, kann der Benutzer künftig selber entscheiden was und wieviel von seiner Identität preisgegeben werden kann. <br>
30.11.20;30.04.21;2021;intern;Bachelor;DE;Konzeption einer Entity Linking-Pipeline zur Disambiguierung von Unternehmensentitäten in unstrukturierten Texten;Die Disambiguierung von Unternehmensentitäten ist durch den bisherigen Entity Linking-Ansatz<br>stark limitiert. Das zugrundeliegende Wissen kann außerdem nur schwer erweitert werden und<br>ist auf spezifische Datenbanken beschränkt. Das Ziel der vorliegenden Arbeit ist daher, die<br>Disambiguierung von Unternehmensentitäten in unstrukturierten Texten zu verbessern. Dazu<br>werden insgesamt drei Forschungsfragen gestellt, die sich mit der Erweiterbarkeit der Wissensba-<br>sis, der zuverlässigen Erkennung von ungesehenen Entitäten und dem Vergleich verschiedenener<br>Entity Linking-Ansätze beschäftigen. <br><br>Um diese Forschungsfragen zu beantworten, wurde ein Prototyp für eine NEL-Pipeline erarbeitet. Zuerst wurde eine Wissensdatenbank konstruiert und mit Entitäten aus Textdaten befüllt. Daraufhin wurden verschiedene Entity Linking-Ansätze aus der Literatur gegenübergestellt und bewertet. Auf Basis dieser Bewertung wurden geeignete Verfahren ausgewählt, exemplarisch implementiert und schließlich auf den annotierten Textdaten evaluiert. Damit eine umfangreiche Ergebniseinschätzung möglich ist, wurde zusätzlich ein Vergleich mit der vorherigen Lösung und einem kommerziellen Tool gezogen. <br><br>Die Ergebnisse der Evaluation zeigten, dass die Disambiguierung durch die Verwendung der konzipierten Wissensdatenbank erheblich verbessert werden konnte. Auch der anschließende Vergleich mit anderen Tools offenbarte eine deutliche Steigerung der Erkennungsrate.
30.11.20;30.04.21;2021;extern;Bachelor;DE;Prozessverbesserung durch Methoden des maschinellen Lernens am Beispiel der Kategorisierung von Artikeln im E-Commerce;Die Integration von Machine-Learning-Anwendungen in bestehende Arbeitsabläufe gestaltet sich häufig schwierig. Um einen Anstoß für die Lösung dieses Problems zu geben, wurde in dieser Arbeit eine Kombination von Methoden des Prozessmanagements und des Machine Learning Engineerings auf ein Fallbeispiel aus der betrieblichen Praxis angewendet. Dabei handelte es sich, um die Kategorisierung von Artikeln im Artikelpflegeprozess eines Onlineshops aus dem Einzelhandel. Ausgehend von einer konkreten Problemstellung wurde festgestellt, wie eine Machine-Learning Anwendung zur Kategorisierung von Artikeln den bestehenden Arbeitsablauf verbessern könnte, wie sie in ihn integriert werden könnte und wie ihr Erfolg gemessen werden könnte. Des Weiteren wurde für das dabei entwickelte Verbesserungskonzept ein Proof of Concept über die Entwicklung relevanter Softwarekomponenten erbracht.
30.11.20;30.04.21;2021;intern;Bachelor;DE;Semi-automatische Erstellung von Wissensdatenbanken für Question-Answering-Systeme;Ziel dieser Arbeit ist es, einen Prozess für die schrittweise Erweiterung der Wissensdatenbank von Chatbots zu entwerfen. Der Fokus liegt dabei auf unstrukturierten Daten, wie beispielsweise Textdokumenten oder E-Mails. Es liegt ein großer Bestand an E-Mail-Protokollen vor, welcher im Rahmen dieser Arbeit aufbereitet und als Datenbasis für den Prozess verwendet wird. Weiterhin wird dieser Prozess in Form einer Webanwendung prototypisch implementiert.
01.12.20;29.07.21;2021;intern;Master;DE;Framework für die Simulation kooperierender verteilter Prozesse;Im Rahmen von Lehre und Forschung werden kooperierende verteilte Prozesse betrachtet. Hierfür ist ein Framework notwendig, das bei der Untersuchung der Interaktionen dieser Prozesse unterstützt.<br><br>Dieses Framework soll ermöglichen, beliebig komplexe Szenarien durch Komposition von Bausteinen wie Nachrichten, Prozessen und Kanälen zu modellieren. Um das Verhalten des modellierten Systems nachvollziehen zu können, soll es sich in geeigneter Weise verfolgen lassen. Da das Framework von Professoren, Studierenden und weiteren Personen auf verschiedenen Systemen eingesetzt wird, soll es plattformübergreifend implementiert werden.<br><br>In dieser Arbeit wird ein solches Framework konzipiert und in Java implementiert. Es werden dabei mit diesem einige Szenarien aus der Lehre modelliert.
01.12.20;01.05.21;2021;intern;Bachelor;DE;Entwicklung eines Konzepts zur kontinuierlichen Verbesserung der Usability einer Online-Beratungssoftware;Eine effektive, effiziente und zufriedenstellende Nutzung von Softwareprodukten bedarf einer guten Usability. Diese Bachelorarbeit befasst sich mit der Identifikation und Beseitigung von Usability-Schwachstellen in der Berater-Nutzeroberfläche der Online-Beratungssoftware des Instituts für E-Beratung. In einem ersten Schritt werden in Anlehnung an die Vorgehensmethodik des Usability Engineering sowohl der Ist-Zustand der Software analysiert als auch ihre Schwachstellen mittels UX-Tagebuchstudie und standardisiertem Fragebogen identifiziert. Anschließend wird ein Usability-Konzept entwickelt, welches Handlungsempfehlungen zum Beheben der aufgedeckten Schwachstellen beinhaltet. Zudem wird eine Guideline erarbeitet, die auf wichtige, zu beachtende Aspekte der Gebrauchstauglichkeit hinsichtlich zukünftiger Erweiterungen der Software aufmerksam macht. Durch die kontinuierliche Umsetzung dieser Handlungsempfehlungen soll die Zufriedenheit der Nutzer*innen dieser Software gesteigert werden. 
01.12.20;14.03.21;2021;intern;Bachelor;DE;Konzeption und protypische Implementierung einer Suchmaschine für Stellenangebote der Hochschuljobbörse;Ziel dieser Arbeit ist die Entwicklung einer Suchfunktion für die Plattformen der Hochschuljobbörse.<br>Mit einer vorher ausgewählten Software soll ein Index über bestehende und neue Inserate erstellt werden, der sowohl vorher festgelegte Parameter als auch den Inhalt des Inseratstextes beinhaltet.<br>Dieser Index wird für eine Freitextsuche verwendet, die an die bekannten Suchmaschinen angelehnt ist. Weiterhin können über diesen Suchvorschläge generiert werden.<br>Interessierten soll diese Suche auch über die angegebenen Parameter hinaus passende Vorschläge liefern können, für Inserierende können die Daten aus Index und bestehenden Suchanfragen Informationen über die Interessen der jeweiligen Zielgruppe liefern.<br>
07.12.20;07.05.21;2021;extern;Bachelor;DE;Konzeption und Implementierung einer Komponente zur benutzerfreundlichen Visualisierung von Veränderungen in Datenstrukturen.;
11.12.20;11.08.21;2021;intern;Master;DE;Sicherheit im E-Mail-Verkehr;E-Mails sind ein verbreitetes Kommunikationsmittel. Mit ihnen werden auch schützenswerte Daten über das Internet versendet, weshalb die Kommunikation sicher sein muss. Diese Arbeit gibt einen Einblick in die Funktionsweise des E-Mail-Verkehrs und stellt etablierte sowie aktuelle Standards vor, um die Sicherheit zu erhöhen. Hierbei liegt der Fokus auf der Transportverschlüsselung, bei welcher unter anderem die Standards MTA-STS und SMTP via DANE analysiert werden. Weiterhin wird untersucht, wie aus Sicht eines Absenders sichergestellt werden kann, dass eine E-Mail transportverschlüsselt übertragen wird. Hierzu wird ein Konzept entwickelt, implementiert und getestet. Dadurch kann beim Versenden einer E-Mail angegeben werden, dass diese vom eigenen E-Mail-Server ausschließlich transportverschlüsselt übertragen werden darf. Es zeigt sich, dass E-Mails vor Angriffen geschützt übermittelt werden können, wenn Absender und Empfänger aktuelle Standards verwenden. Deshalb müssen Betreibende von E-Mail-Servern verfügbare Technologien wie DNSSEC und SMTP via DANE nutzen, um die Sicherheit im E-Mail-Verkehr zu erhöhen. Bis dahin bietet sich die Überprüfung des empfangenden E-Mail-Servers an. Hierfür kann die in dieser Arbeit implementierte Erweiterung verwendet werden.
17.12.20;14.03.21;2021;intern;Bachelor;DE;Einfluss von Transkriptionen auf die Leistungsfähigkeit von Methoden des maschinellen Lernens am Beispiel USOMS;Der Geisteszustand (SOM) eines Menschen kann sich durch Emotionen verändern. Die geistige Gesundheit wird von der gewohnheitsmäßigen Anpassung oder Fehlanpassung des SOM beeinflusst. In der Studie von Rathner et al. konnte gezeigt werden, dass der SOM durch persönliche Erzählungen (Narrative) beeinflusst werden kann und SOM sowie Sentiment (positiv, negativ) können durch die Analyse des Wortgebrauches vorhergesagt werden. Für ihre Analyse zogen sie den USoM Datensatz heran, der studentische Verschriftungen von persönlichen Narrativen enthält. Es ist wenig bekannt darüber, welchen Einfluss die Art und Genauigkeit von Verschriftung auf die Ergebnisse dieser Art von Analysen hat. Für diese Studie wird eine Version des Ulm State-of-Mind Datensatzes verwendet, die um weitere Verschriftungsarten, studentisch, von einem professionellen Transkriptionsservice (wortgetreu) und durch ein kommerzielles state-of-the-art Spracherkennungssystem, ergänzt wurde. Die vorgestellte Studie soll aufzeigen, inwiefern die Art der Transkription Auswirkungen auf die Genauigkeit und Aussagekraft des Ergebnisses von maschinellen Lernverfahren hat. Außerdem kann ein Beitrag dazu geleistet werden, die Frage zu beantworten, ob automatische Spracherkennung gut genug funktioniert, um in einem voll automatisierten System, vergleichbare Ergebnisse liefern zu können. Dafür wird experimentell der Einfluss der unterschiedlichen Verschriftungsarten auf die Leistungsfähigkeit von Klassifikatoren untersucht.
13.01.21;13.06.21;2021;intern;Bachelor;DE;Analyse temporaler Word-Embedding-Verfahren zur Feststellung von Bedeutungsveränderungen;Die Analyse temporaler semantischer Verschiebungen von Wörtern in natürlichsprachlichen Texten wird in der Wissenschaft immer populärer. Hierfür gibt es mittlerweile viele unter-schiedliche maschinelle Lernverfahren, durch die eine temporale semantische Verschiebung von Wörtern festgestellt werden können. <br>Aus diesem Grund werden in dieser Arbeit die verschiedenen temporalen Word-Embedding-Verfahren, die aktuell häufig in der Literatur verwendet werden, identifiziert. Auf Basis einer Entscheidungstabelle wurden die zwei Verfahren CADE und HistWords ausgewählt, um genauer betrachtet zu werden. Die Verfahren wurden implementiert und auf Basis der Plenarprotokolle von der 1 ? 18 Wahlperiode des deutschen Bundestages trainiert und ausgewertet. Dabei war das CADE Verfahren im Gegensatz zum HistWords Verfahren über-sichtlicher und einfacher zu trainieren. Zudem waren die Ergebnisse bei der Auswertung von CADE aussagekräftiger als die Ergebnisse von HistWords. Dies zeigt, dass das Verfahren CADE für die Analyse von temporalen semantischen Verschiebungen der Wörtern aus den Plenarprotokollen des deutschen Bundestages besser geeignet war als das Verfahren HistWords.<br>
18.01.21;18.06.21;2021;extern;Bachelor;DE;Konzipierung und prototypische Umsetzung einer digitalen IT-Sicherheitsschulung nach IT-Grundschutz<br>;Ziel dieser Arbeit ist es, für das Unternehmen CodeCamp:N GmbH eine digitale IT-Sicherheitsschulung zu konzipieren, von der ein Teil als Prototyp umgesetzt werden soll, um diesen mittels eines Usability-Tests Mitarbeitenden vorzustellen. Es soll darauf geachtet werden, dass die Schulungsinhalte so individuell wie möglich an die einzelnen Mitarbeitenden angepasst werden können.<br>Dafür wurden Anforderungen definiert, die sich aus den Vorgaben des IT-Grundschutz-Kompendiums des Bundesamts für Sicherheit in der Informationstechnik und des Unternehmens zusammensetzen. Es wurden verschiedene Darstellungsformen für die Schulung verglichen. Die Verwendung einer Lernplattform in Verbindung mit Gamificationelementen schnitt am besten ab. Aus dem Bereich der Gamification wurden Abzeichen, ein Highscore-System und eine Fortschrittsanzeige übernommen, um die Motivation der Schulungsteilnehmer zu erhöhen. Anhand Kriterien wie Abteilung, Beschäftigungsart und Position werden die Schulungsinhalte durch das System an den Teilnehmer angepasst. Der Prototyp wurde in Adobe XD als Clickdummy realisiert. In einem Usability-Test wurden sechs Mitarbeitenden des Unternehmens Aufgaben und Fragen zu diesem Prototyp gestellt. Die Ergebnisse dieses Tests zeigen, dass das Konzept bei den Probanden Zuspruch fand. Einige wenige kritische Probleme, die sich bei dem Test ergaben, wurden im Rahmen dieser Arbeit behoben. 
21.01.21;21.09.21;2021;extern;Master;DE;Customer Lifetime Value Prediction -  Evaluierung geeigneter CLV-Prognose-Methoden im Gesundheitswesen<br>;Diese Masterarbeit untersucht in Kooperation mit Danone Specialized Nutrition D-A-CH unterschiedliche Customer Lifetime Value (CLV) Prognosemethoden, die für den Einsatz im Gesundheitswesen geeignet sind. Das Ziel ist es, geeignete Verfahren zu finden, mit denen der CLV eines Kunden prognostiziert werden kann. Zu diesem Zweck werden mehrere, konkurrierende Ansätze vorgestellt, implementiert und evaluiert. Eine grundlegende Unterscheidung besteht bei der Prognose für Bestandskunden und bei der Prognose für potenzielle Neukunden. Die Prognose des CLV von Bestandskunden wird mittels probabilistischer Modelle erstellt. Mittels baumbasierter Ensemble-Learning-Techniken wird versucht Aussagen über den voraussichtlichen CLV von potenziellen Neukunden zu treffen. Alle Voraussagen werden sowohl auf individueller als auch auf kollektiver Ebene erstellt. Im Zuge der Evaluierung wird herausgestellt, welche Modelle die besten Ergebnisse generieren. Dabei werden die modellspezifischen Vorteile, aber auch deren Grenzen aufgezeigt. 
25.01.21;23.07.21;2021;extern;Bachelor;DE;Konzeption und Realisierung eines automatisierten und standardisierten Prozesses zur Beantragung, Einrichtung und Kontrolle von Administrationsrechten<br>;Die Firma MR Datentechnik Vertriebs- und Service GmbH ist ein mittelständisches Unternehmen für IT-Systeme und -Lösungen, das nach verschiedenen, international gültigen Normen der Internationalen Organisation für Standardisierung arbeitet. Bei einer Zertifizierungsprüfung wurde, die von der Firma umgesetzte ISO 27001 Norm unter anderem am Prozess zur Beantragung und Einrichtung von Administrationsrechten überprüft. Dabei kamen allgemeine Schwachstellen des aktuellen Prozesses zum Vorschein. Außerdem ergaben sich Differenzen zu der von der ISO vorgeschlagenen Umsetzungsstrategie, mit der ein international gültiger Standard eingehalten werden kann. Des Weiteren wurde von Prozess-beteiligten die manuelle und wenig technisch gestützte Abwicklung des Prozesses kritisch bewertet.<br>Ziel dieser Arbeit ist es, die Schwachstellen des Prozesses umfassend zu analysieren und daraus Anforderungen an ein Sollkonzept abzuleiten. Auf Basis dessen soll eine Neuentwicklung und Automatisierung, sowie eine Implementierung und Inbetriebnahme des Prozesses realisiert werden. Zu diesem Zweck erfolgt eine Befragung der Prozessbeteiligten hinsichtlich bereits bekannter Schwächen und Anforderungen sowie die Analyse und Auswertung bereits vorhandener Dokumente, die Aufschlüsse über den Prozess geben. Das Ergebnis dieser Arbeit zeigt den Nutzen, welcher sich für das Unternehmen mit der Neuentwicklung ergibt. 
01.02.21;15.09.21;2021;intern;Master;DE;Erforschung und prototypische Entwicklung eines multimodalen Machine-Learning-Systems zur Erfolgsbewertung eingehender Kundenanfragen;In der schnelllebigen Automobilindustrie entscheiden oftmals wenige Tage über den Erhalt eines Kundenauftrags. Ein Auftrag impliziert eine vorhergegangene Anfrage eines Kunden. Insbesondere für mittelständische Unternehmen kann die Menge an Anfragen und deren Verarbeitung eine Herausforderung darstellen. Eine Machine Learning gestützte Klassifikation eingehender Anfragen, könnte zu einer effizienteren Nutzung der Bearbeitungszeit und zu einer höheren Gewinnquote führen.<br><br>Im Rahmen dieser Arbeit wurden daher in Zusammenarbeit mit der Dr. Schneider Unternehmensgruppe verschiedene Ansätze für die Klassifikation von eingehenden Kundenanfragen konzipiert, implementiert und evaluiert.<br>Dabei sollte untersucht werden, inwiefern, basierend auf den Anfragedokumenten, eine Aussage über den Gewinn oder Verlust einer Anfrage getroffen werden kann. Des Weiteren wurde evaluiert, in welchem Ausmaß der Einsatz von multimodalen Features zu einer Verbesserung der Ergebnisse beiträgt.<br><br>Eine generische Aussage durch die Verwendung von multimodalen Features konnte in dieser Arbeit nicht getroffen werden. Mit einer Accuracy von 85 % erzielte ein, auf einem feingetunten BERT Modell basierter Ansatz, die besten Ergebnisse. Obwohl eine schwierige Datengrundlage vorliegt, zeigt sich, dass eine Aussage über den Erfolg einer Anfrage getroffen werden kann. Damit liefern die Erkenntnisse dieser Arbeit fortan einen entscheidenden Vorteil in der Bearbeitung von eingehenden Anfragen. 
07.02.21;07.07.21;2021;extern;Bachelor;DE;Regelung der Nachrichtenaustauschrate zur Überlastvermeidung in verteilten Systemen;Ziel dieser Bachelorarbeit ist es, ein Konzept zur automatisierten Anpassung der Verarbeitungsgeschwindigkeit von Anwendung abhängig von der Fehlerrate zu entwickeln.<br>Dieses wird prototypisch in eine bestehende Anwendung der Kooperationsfirma Sopra Financial Technology GmbH implementiert.<br>Dies ist nötig, da bei anhaltendem Fehlerzustand einer Anwendung die Menge an Fehlermeldungen dazu führen kann, dass die Log-Partition des Anwendungsservers vollständig belegt ist.<br>Dadurch werden die Anwendungen, die auf dem Anwendungsserver laufen, blockiert und fallen aus. <br><br>In dieser Arbeit werden zunächst die für die prototypische Umsetzung ausgewählte Anwendung, sowie das bestehende Problem analysiert.<br>Anschließend wird auf Basis der gewonnenen Informationen ein Konzept zur automatisierten Drosselung der Verarbeitungsgeschwindigkeit erarbeitet.<br>Wichtig ist hierbei, dass die Verarbeitungsgeschwindigkeit bei steigender Fehlerrate reduziert, aber mit fallender Fehlerrate auch wieder erhöht wird.<br>Zusätzlich muss erarbeitet werden, wie hoch das Maß der Drosselung abhängig von der Fehlerrate sein muss.<br>Das entwickelte Konzept wird dann prototypisch implementiert und abschließend getestet.
08.02.21;03.09.21;2021;intern;Master;DE;Unterstützung der Bildbearbeitung durch Neuronale Netze;
01.03.21;31.08.21;2021;intern;Master;EN;Whispered and Alaryngeal Speech Conversion Using Variational Autoencoders and Generative Adversarial Networks;Bei klinischen Eingriffen, die beispielsweise auf Grund von Kehlkopfkrebs notwendig werden, sind Personen mit dauerhaften Einschränkungen bei der Sprachkommunikation konfrontiert. <br>Die Sprache ohne Kehlkopf weist ähnliche Eigenschaften zu geflüsterter Sprache auf. <br>Hauptsächlich auf Grund der fehlenden Grundfrequenz ist die Sprachqualität oftmals stark eingeschränkt und wird als weniger natürlich und ausdrucksstark empfunden. <br>Diese Eigenschaften können für Kehlkopfkrebspatienten viele Alltagssituationen erschweren und verringern letztlich die Lebensqualität. <br><br>Diese Arbeit stellt aktuelle, auf Techniken des maschinellen Lernens basierende Ansätze, gegenüber und vergleicht deren Effektivität im Bezug auf die Fähigkeit zur Rekonstruktion natürlichsprachlicher Eigenschaften. Ziel ist die erfolgreiche Transformation von geflüsterter und tracheoösophagealer Sprache. <br><br>Die verwendeten Ansätze umfassen VAEs und GANs, die in der Regel nicht zur Transformation von Sprache ausgelegt sind und deshalb hinsichtlich ihrer Kostenfunktion und anderen Modellelementen modifiziert werden müssen. <br><br>Im Rahmen der Arbeit wird gezeigt, dass VAE und GAN Modelle geeignet sind, sowohl geflüsterte Äußerungen, als auch mit tracheoösophagealen Ersatzstimmen gesprochene Äußerungen zu verbessern. <br>Basierend auf verschiedenen qualitativen Metriken liefert ein modifiziertes MelGAN Modell die besten Ergebnisse. 
01.03.21;01.08.21;2021;intern;Bachelor;DE;Digitale Signaturen: Theoretischer Hintergrund und Evaluierung am Beispiel der Technischen Hochschule Nürnberg;Die TH Nürnberg hat sich zum Ziel gesetzt, die hochschulinternen Abläufe zu digitalisieren.<br>Viele Verwaltungsabläufe werden aktuell auf Basis von Papierdokumenten mit handschriftlichen Unterschriften abgewickelt.<br>Um die Abläufe aufwandseffizient digital abbilden zu können, sollen mit der vorliegenden Arbeit die Möglichkeiten digitaler Unterschriften untersucht werden.<br>Dabei wird zunächst aufgezeigt, welche Möglichkeiten es grundsätzlich für digitale Unterschriften gibt und für welche Anwendungsszenarien diese geeignet sind.<br>Anschließend werden die betrachteten Aspekte in einer Matrix zusammengefasst und so eine Einordnung von Signatursystemen nach ausgewählten Kriterien vorgenommen. <br>Der Vergleich der Signatursysteme zeigt, dass mit digitalen Signaturen in Standardbürosoftware das beste Kosten-Nutzen-Verhältnis für die Hochschule erzielt werden kann.<br>Eine anschließende Gegenüberstellung der Signaturfunktionen in Adobe Acrobat und Microsoft Office macht deutlich, dass Ersteres für den praktischen Einsatz besser geeignet ist.<br>Ausgehend von den gewonnenen Erkenntnissen wird beispielhaft der Eingangsrechnungsprozess neu konzipiert und anschließend mit Experteninterviews evaluiert.<br>Die Interviews bestätigen, dass die konzipierte Lösung zu schnellen Mehrwerten mit moderatem Aufwand führt. <br>Für die langfristige Entwicklung wird eine höhere Automatisierung der Abläufe angestrebt, weswegen digitale Signaturen im vorliegenden Kontext als Brückentechnologie eingeordnet werden können.
01.03.21;01.08.21;2021;extern;Bachelor;DE;Betrachtung aktueller Chancen von Progressive Web Apps im Gegensatz zu Native Apps;In der vorliegenden Bachelorarbeit wird untersucht, ob und welche Vor- und Nachteile das Entwickeln einer Progressive Web App (PWA) - eine Webanwendung, die Funktionalitäten wie Offlinebetrieb und Installation unterstützt - im Gegensatz zu einer Native App bieten. <br>Ferner soll damit die Frage beantwortet werden, ob sie diese ersetzen kann, um die Chancen von PWAs zu beurteilen.<br>Um eine Grundlage für den Vergleich zu schaffen, findet hierbei eine plattformunabhängige Entwicklung der Native App statt.<br>Für den Vergleich wurde auf Basis eines Kriterienkatalogs, bestehend aus Funktionalität, Kompatibilität mit verschiedenen Betriebssystemen und Entwicklungsaufwand, jeweils eine App entwickelt.<br>Diese stellt die aktuellen COVID-19 Fallzahlen dar und unterstützt neben der Installation und dem Offlinebetrieb die Funktionen Standortzugriff, Kontaktzugriff und Benachrichtigungen.<br>Die implementierten Funktionalitäten verdeutlichen, dass PWAs durch moderne Webschnittstellen an Potential gewinnen.<br>Vorteile sind dabei die Unabhängigkeit von der Installation der Anwendung und der geringere Entwicklungsaufwand.<br>Jedoch ist eine entscheidende Schwachstelle von PWAs die fehlende Unterstützung einiger Funktionalitäten auf iOS Geräten.<br>Zusammenfassend zeigt das Ergebnis, dass PWAs nur bis zu einem gewissen Grad in der Lage sind, nativen Anwendungen zu ersetzen.<br>Deshalb muss die Entscheidung für die Entwicklung einer PWA zudem abhängig von den Anforderungen des Anwendungsfalls betrachtet werden.
01.03.21;12.08.21;2021;extern;Master;DE;Entwicklung einer Android App als Erweiterung eines Android TV Players für die Optimierung der User Experience im Bereich des OTT Streaming Service;Smart-TVs entwickeln sich im Gegensatz zu Smartphones in eine andere technologische Richtung. Dadurch verfügen Smart-TVs nicht über die gleichen Funktionalitäten wie Smartphones. Um dem entgegenzuwirken, wird in dieser Arbeit eine Smartphone-App erstellt. Diese sammelt Informationen und stellt sie dem Smart-TV zur Verfügung. Anhand der Auswertung der Daten erfolgt eine Anpassung des Media Playbacks auf dem Smart-TV. Mithilfe einer Umfrage, einem Konzept, der prototypischen Implementierung und einigen Experimenten wird die Arbeit umgesetzt. Die durchgeführten Experimente zeigen, dass eine Verbesserung der User Experience während des Konsums von Streaming-Inhalten durch eine solche App erzielt werden kann.
08.03.21;08.08.21;2021;intern;Bachelor;DE;Spielerische Gestaltungselemente von Social Scoring Systemen in China;Da China aufgrund des technologischen Fortschrittes weltweit an Bedeutung gewinnt, wird China neben der Aussicht, technologisch führend zu sein, generell ein Vorbild in der Gestaltung sozio-technischer Systeme. Damit einhergehend sind vor allem Social-Scoring-Systeme interessant, die China unter anderem zur Verhaltenskontrolle im großen Ausmaß betreibt. Zwar sind Scoringsysteme nicht neu, ihre Untersuchung erfolgt jedoch meist nur unter bestimmen Gesichtspunkten wie dem Datenschutz oder -überwachung. Dazu kommt, dass spielerische Mechaniken, die solchen Systemen zugrunde liegen, nicht ausreichend genug betrachtet und somit beispielsweise auf eine einfache Punktevergabe reduziert werden. In diesem Zusammenhang wird in dieser Arbeit eine detaillierte Untersuchung des Einsatzes von spielerischen Gestaltungselementen auf der Systemebene dieser Scoringsysteme vorgenommen.
10.03.21;10.08.21;2021;extern;Bachelor;DE;Erstellung einer Handlungsempfehlung zur Flexibilisierung agiler Teams im Entwicklungsbereich der DATEV e.G.;Das visionäre Ziel ist, dass durch optimal aufgestellte Teams und passend geschnittene Arbeitspakte jedes Team jedes Thema bearbeiten kann, und so wichtige Kundenbedürfnisse und strategische Technologie-Entscheidungen möglichst schnell umgesetzt werden können. So kann auch schnell auf Veränderungen am Markt, an die Anforderungen an das Produkt und auf Änderungen in der Organisation reagiert werden, was zu besserer Leistung und höherer Konkurrenzfähigkeit führt. Ziel dieser Arbeit ist es eine Handlungsempfehlung zu erstellen, die beschreibt, wie der Prozess der Zusammenarbeit aussieht, wie Arbeitspakete am besten geschnitten werden müssen und wie man das Mindset der Teams dahingehend verändert, dass sie Arbeitspakete abgeben bzw. annehmen. Gerade die Angst vor Fehlern, Veränderung und Transparenz, sowie die Abgabe der Code Ownership stehen hier im Vordergrund. Ausgehend von dieser Handlungsempfehlung sollen flexible Teams so arbeiten, dass sie möglichst viele team-fremde Themen übernehmen können.
11.03.21;13.12.21;2021;intern;Master;DE;Agiles Requirements Engineering in verteilten Softwareentwicklungsteams;"Die Masterarbeit ist im Kontext des Agile Requirements Engineerings in Kombination mit verteilten Teams angesiedelt. Das verteilte agile Arbeiten in Softwareunternehmen in Deutschland hat unter anderem durch die COVID-Pandemie viel Aufmerksamkeit erhalten und Handlung seitens der Unternehmen erzwungen. Durch die mangelnde Erfahrung und die plötzliche Notwendigkeit standen die Organisationen vor der Herausforderung, Mitarbeiter auf Distanz zu organisieren und die Zusammenarbeit zwischen ihnen und den Kunden stabil zu halten. Weiter wussten die Unternehmen nicht, wie sie den Requirements Engineering Prozess für verteilte Teams gestalten sollten. Um Anforderungen von Kunden richtig und vor allem vollständig zu erheben, ist eine effiziente Kommunikation und Zusammenarbeit erforderlich. In dieser Masterarbeit wird daher aufgezeigt, wie verteilte Teams ihren agilen Requirements Engineering Prozess gestalten können. Das wird mit Hilfe von theoretischen Quellen und mit Befragungen von Unternehmen herausgefunden. In der Literatur wird die folgende Frage gestellt: ""Braucht die globale Softwareentwicklung einen anderen Requirements Engineering Prozess?"". Die Antwort dazu lautet auf Basis der beschriebenen Überblicke aus Literatur und Praxis, sowie den Erkenntnissen und Beobachtungen aus den Interviews eindeutig ja. Zentrale Erkenntnisse der Arbeit sind die mangelnde Qualität von User Stories und die Wichtigkeit einer zentralen, einfach zugänglichen, transparenten Dokumentation."
15.03.21;14.08.21;2021;intern;Bachelor;DE;Einsatz von Qualitätsmanagement-Methoden zur<br>Sicherstellung der Lieferantenqualität zur<br>Generierung zuverlässiger Trainings- und<br>Testdaten für maschinelle Lernverfahren;In dieser Arbeit wurde die Anwendung von bekannten und praxisorientierten Stichprobenprüfungen am Projekt EMPAMOS zur Generierung von zuverlässigen Trainings- und Testdaten behandelt. Für die Sicherstellung eines qualitativ hochwertigen Datensatzes wurden verschiedene Stichprobenprüfungen anhand qualitativer Merkmale, sowie kontinuierliche Stichprobensysteme recherchiert und schließlich mit einer an das Forschungsprojekt angepasste Simulation simuliert. <br><br>Zu Beginn der Arbeit wurde ein deutliches Ergebnis erwartet, welches die Vorteile der Anwendung einer Stichprobenkontrolle bestätigt und eine zeitliche Einsparung bei der Kontrolle der eingegebenen Daten liefert. Diese Erwartung wurde zu Beginn der Simulation nicht erfüllt, da bei der immer gleichbleibenden Wahrscheinlichkeit und der schwankenden Wahrscheinlichkeit keine für das Projekt erfolgreichen Ergebnisse erzielt werden konnten. Durch eine weitere Anpassung der Eingabewahrscheinlichkeit an die Praxis konnten schließlich mit der immer besser werdenden Wahrscheinlichkeit erfolgreiche Ergebnisse erzielt werden. Dementsprechend kommt es bei dem Nutzen der behandelten Stichprobensysteme darauf an, wie die Fehlerwahrscheinlichkeitskurve der einzugebenden Daten gesetzt wird. Da es sich bei der immer besser werdenden Wahrscheinlichkeit um realitätsnähere Eingaben handelt, kann durch die Arbeit durchaus bestätigt werden, dass der Einsatz von Stichprobensystemen einen qualitativ hochwertigeren Datensatz gewährleisten kann.
15.03.21;12.08.21;2021;extern;Bachelor;DE;Cloud-Transformation: Entwicklung von Geschäftsmodellen bei DATEV;In dieser Bachelorarbeit wird der Produktportfoliowandel hin zu cloudbasierten Anwendungen sowie die damit fördernde Entwicklung von Geschäftsmodellen bei der DATEV eG untersucht. Außerdem soll diese Arbeit anhand einer qualitativen Analyse die Chancen und Herausforderungen bei der Nutzung der Public- als auch der DATEV-Cloud aufzeigen. <br>Die folgenden Forschungsfragen sind zu beantworten: <br>1) Wie behauptet sich das DATEV-Rechenzentrum gegenüber Public-Cloud-Anbietern?<br>2) Wie wird sich das bestehende Geschäftsmodell der DATEV eG im Zuge der Cloud-Transformation entwickeln?<br>In dieser Abschlussarbeit wird gezeigt, dass ständig wandelnde Marktgegebenheiten eine dynamische Geschäftsmodellanpassung erfordern. Anlass dafür ist die Sicherung einer Konkurrenzfähigkeit und eines zukünftigen Unternehmenserfolges. 
15.03.21;17.08.21;2021;intern;Master;DE;Künstliche Intelligenz im Rechnungseingangsprozess: Bewertung von Einsatzpotenzialen und Grenzen<br>;Die Forschungsfrage dieser Thesis war, welche Einsatzpotenziale und Grenzen sich bei einer KI-Implementierung im Rechnungseingangsprozess (REP) ergeben werden und wie diese Implementierung aussehen soll. Aus dieser Forschungsfrage ergaben sich zwei Ziele. Das erste Ziel war die Bewertung von Einsatzpotenzialen und Grenzen der KI im REP, während das zweite Ziel die Darstellung und Erläuterung der konzeptionellen Integration der KI im REP war. Beantwortet wurde die Forschungsfrage mithilfe einer Nutzwertanalyse und Leitfadeninterviews. Die Auswertung der Ergebnisse ergab, dass die Automatisierung und die Zeiteffizienz die größten Potenziale der KI im REP sind. Auf der anderen Seite sind die Datenverfügbarkeit und -qualität sowie der hohe Implementierungsaufwand die größten Grenzen der KI im REP. Außerdem konnte anhand der Aussagen aus den Leitfadeninterviews eine konzeptionelle Integration der KI im Rechnungseingangsprozess zusammengestellt werden. Diese offenbarte einerseits, dass KI am sinnvollsten bei der Erfassung der Rechnungsdaten sowie bei diversen Prüfungen im REP ist und in diesen Bereichen den größten Nutzwert hat. Anderseits waren der Rechnungseingang und die Archivierung von Rechnungen die Bereiche im Rechnungseingangsprozess mit dem geringsten Nutzwert der KI. Die Ergebnisse dieser Arbeit sollen als Grundlage für die Entscheidungsfindung zur Einführung oder Modernisierung eines Rechnungseingangsprozesses mit künstlicher Intelligenz verwendet werden. 
15.03.21;26.07.21;2021;extern;Bachelor;DE;Entwicklung eines Konzepts zur Messung von IT-Security Awareness - Wie kann man Sicherheitsbewusstsein messen?;Attacken im digitalen Raum haben sich zu einem bedeutenden Wirtschaftssektor für Kriminelle entwickelt. In den meisten Fällen stellt der Faktor Mensch das größte Risiko dar. Es ist unerlässlich, dass sich Internetnutzer über mögliche Risiken im digitalen Raum bewusst sind.<br> <br>Ziel der Abschlussarbeit ist die Messung des IT-Sicherheitsbewusstseins der Mitarbeiter im Unternehmen. Als geeignete Methode wurde ein fingierter Phishing-Angriff auf das Unternehmen durchgeführt. Strenge Einschränkungen wurden beachtet, um Datenschutz, Gesetzen und der Unternehmenskultur gerecht zu werden.<br><br>Der Angriff war erfolgreich und lieferte einige Zugangsdaten zu einem unternehmensinternen Dienst. Dennoch reagierten viele Mitarbeiter umgehend, sodass die Attacke schnell aufflog. Es konnte daher ein insgesamt sehr wünschenswertes Bild des IT-Sicherheitsbewusstseins gewonnen werden. Dennoch wird dem Unternehmen empfohlen weitere Maßnahmen zur Steigerung der Awareness und Systemsicherheit zu ergreifen. <br><br>Ein Test-Angriff erwies sich als gute Möglichkeit, die tatsächlichen Reaktionen der Zielgruppe auf Bedrohungen zu erfassen. Dennoch sollte dieses Mittel mit Befragungen kombiniert werden, um mehr über die Hintergründe von Handlungen der Mitarbeiter zu erfahren.
19.03.21;03.08.21;2021;intern;Bachelor;DE;Auswirkungen der Coronapandemie auf die Nutzung von Omnichannel-Strategien am Beispiel des amerikanischen Einzelhandels;Das Ziel der vorliegenden Bachelorarbeit ist es, die Auswirkungen der Coronapandemie auf die Nutzung von Omnichannel-Strategien am Beispiel des amerikanischen Einzelhandels zu analysieren und einen theoretischen Strategieleitfaden zur Einführung einer Omnichannel-Strategie am Beispiel eines stationären Einzelhändlers zu erstellen.<br><br>Zur Ermittlung der veränderten Nutzung von Omnichannel-Strategien wurden mehrere Umfragen ausgewertet. Die Analyse betrachtet sowohl die Kunden als auch die Unternehmensseite.<br>Um den Strategieleitfaden zu erstellen, sind theoretische Strategiepapiere genutzt und mit entsprechenden Zusatzinformationen angereichert worden, um den nötigen Tiefgang zu erzeugen. Evaluiert wurde der Leitfaden mit dem 8C Modell von Roland Berger. <br><br>Die Untersuchung zu den Auswirkungen der Coronapandemie auf die Nutzung von Omnichannel-Strategien zeigen, dass sowohl auf Kunden- als auch auf Unternehmensseite die Nutzung beziehungsweise Bereitstellung von Omnichannel-Strategien gestiegen ist. Außerdem kann sich die Hälfte der befragten Konsumenten vorstellen, diese auch nach der Pandemie weiterzunutzen. Ebenfalls planen mehrere Unternehmen in Zukunft Omnichannel-Strategien bereitzustellen. Ein abschließendes Fazit lässt sich wegen der weiterhin andauernden Pandemie allerdings noch nicht bilden.<br>Der Strategieleitfaden ist erfolgreich erstellt worden, schnitt in der Evaluation auf Vollständigkeit allerdings nur mittelmäßig ab. 
19.03.21;19.08.21;2021;extern;Bachelor;DE;Analyse, Integration und Evaluierung von geometrischen Bin Packing Verfahren zur Optimierung des Drucks von Faltschachteln in der Verpackungsindustrie;Durch die Nutzung eines effizienten, zweidimensionalen Bin Packing Verfahrens kann der Materialverbrauch in vielen Bereichen der Industrie verringert werden.<br>Das Ziel dieser Bachelorarbeit ist es, ein zweidimensionales Bin Packing Problem aus der Verpackungsindustrie zu optimieren. Um dies zu erreichen, wird das vorliegende Problem eingeordnet und die relevanten Aspekte der Platzierungsstrategien und der Überlappungserkennungen untersucht, um passende Ansätze für den Einsatz in einem Firmenprojekt zu finden. Anhand der vorhandenen Literatur auf diesem Gebiet wird sich für eine Constraint basierte Lösung entschieden, welche die optimale Anordnung von Faltschachteln garantiert. Um Überlappungen der Faltschachteln zu vermeiden, wird ein No-Fit Algorithmus aus der Literatur und die eigens entwickelte Abwandlung einer bekannten Methode angewendet. Die Implementierung dieser Verfahren wird anschließend durch eine Evaluation, vorwiegend mit Bezug auf den Faktor der Berechnungsdauer, überprüft. Es lässt sich zeigen, dass durch die neue Strategie eine Verbesserung der Anordnung der Polygone entsteht. Die Ergebnisse machen deutlich, dass die Grenzen des Verfahrens bei einer hohen Anzahl an möglichen Platzierungspunkten der Faltschachteln liegen. Werden die Platzierungspunkte begrenzt, eignet sich vor allem der eigens entwickelte Algorithmus für die Erkennung von Überlappungen. 
22.03.21;20.08.21;2021;intern;Bachelor;DE;Detektion von Konversationsmustern in psycho-sozialen Online-Foren mittels maschineller Lernverfahren;Öffentliche psycho-soziale Online-Beratungsforen bieten Menschen mit unterschiedlichen Problemen eine kostenlose Plattform an, um Ratschläge und Hilfe zu erlangen. Gleichzeitig stellen diese Foren eine Datengrundlage an Beratungsgesprächen dar, wodurch mithilfe von Analysen Kenntnisse über die Beratung erzeugt werden können. Die Analyse der Beratungsgespräche ist jedoch sehr zeitintensiv, weshalb die Nutzung von maschineller Lernverfahren für die automatisierte Analyse der Beratungsgespräche eine Alternative darstellt. <br><br>Aus diesem Grund befasst sich diese Arbeit mit der Analyse von Online-Beratung mithilfe von maschineller Lernverfahren, um Eigenschaften der Online-Beratung zu identifizieren, welche für die Gestaltung einer effektiveren Beratung genutzt werden können. Durch Nutzung der Vorarbeiten des CaSoTex-Projekts und der Erstellung eines eigenen Modells zur Erkennung der Emotionen in Beratungsgesprächen konnten die Threads der Foren in einer mathematischen Form dargestellt werden. Diese vektorisierte Form der Threads wurde genutzt, um diese genauer hinsichtlich des Beratungserfolg zu analysieren. Bei der Analyse konnten jedoch keine Eigenschaften, welche den Beratungserfolg charakterisieren, identifiziert werden. Ein Grund für dieses Ergebnis ist, dass die Beratung in den Threads schwer nachvollzogen werden kann. Nichtsdestotrotz konnten in dieser Arbeit einige Verbesserungsansätze identifiziert werden, welche als Grundlage für weitere Analysen fungieren können.
22.03.21;21.07.21;2021;intern;Bachelor;DE;Barrierefreie Informations- und Kontrolleinheit für autarke Lebensräume am Beispiel Wohnmobil und Caravan;Wohnmobile und Caravans sind für viele Besitzer eine Art Zweitwohnsitz. Ein zentrales, digitales, für jede Person nachrüstbares Informations- und Kontrollsystem, welches die große Anzahl an unterschiedlichen Sensoren und Aktoren innerhalb eines Wohnmobils auf einer übergeordneten Abstraktionsebene zusammenführt, eine barrierefreie und aus der Ferne kontrollierbare Bedienung ermöglicht und die Informationsqualität deutlich erhöht, ähnlich eines Smart-Home-Systems, existiert allerdings auf dem Zubehörmarkt nicht.<br>Viele Umgebungsvariablen, die für ein Wohnmobil gelten, sind auch in anderen Lebensräumen, wie Tiny Häuser, Hausboote, Forschungsstationen oder Gartenhäuser, in denen Autarkie teilweise oder ganz gewünscht ist, zu finden. Daher ist der Einsatzbereich einer barrierefreien Informations- und Kontrolleinheit nicht nur auf Camper beschränkt. Die theoretische und praktisch durchgeführte Umsetzung einer solchen Informations- und Kontrolleinheit wird in dieser Arbeit beschrieben. Es ist gelungen, Steuerung und Rückmeldung eines Campers in einem einzigen Gerät zu vereinen, diese barrierefrei und intuitiv bedienbar zu gestalten und auf andere autarke Lebensräume übertragbar zu machen. Durch die interne Kommunikation der verschiedenen Sensoren und Aktoren wird eine Automation eines gesamten autarken Lebensraumes ermöglicht. <br>
22.03.21;06.08.21;2021;extern;Bachelor;DE;Konzeption und prototypische Implementierung eines Controllingsystems für ein Software-Entwicklungs-Unternehmen;Das Ziel der Bachelorarbeit war es, die einzelnen Konzeptionen mithilfe grafischer Dashboards, ergänzender Kennzahlen und Benchmarking passend in die vorhergesehene Rechtestruktur des neuen Controllingsystems einzubinden. Nach der prototypischen Implementierung und Anwendung der Ergebnisse lässt sich die Forschungsfrage folgendermaßen beantworten: Die einzelnen Bereiche des Controllingsystems können durch das Zusammenspiel der Systeme des Microsoft Reporting Services 2019 und den Einsatz des hauseigenen org.manager zielführend implementiert werden. Mithilfe der Darstellungsmöglichkeiten und der vorhandenen Integration in die Organisationsstrukturen, kann der org.manager einzelne Dashboards individuell und effizient gestalten. Durch die Fachexpertise der Mitarbeiter ist Ingentis unabhängig von anderen Systemen und kann individuelle Anpassungen vornehmen. Die einzelnen Kennzahlen der Dashboards im org.manager sind mit den paginierten Berichten des Microsoft Reporting Services 2019 verbunden und können bei Bedarf auf tieferes Controlling aufgerufen werden. Durch die Mitarbeiterbefragung von Great Place To Work erhält Ingentis Marktdurchschnittswerte. Der Vergleich der Werte sowie die bereits ermittelten Benchmark-Zahlen liefern das angestrebte Feedback.<br><br>Schlussfolgernd lässt sich sagen, dass durch das Zusammenspiel der einzelnen Systemkomponenten langfristig ein optimaler Nutzen erzielt werden kann.
23.03.21;23.08.21;2021;extern;Bachelor;DE;Entwicklung von Maßnahmen zur Verbesserung der ökologischen Nachhaltigkeit der IT-Infrastruktur der<br>Senacor Technologies AG<br>;Da die Senacor Technologies AG erkannt hat, dass eine reine Reduktion auf ökonomische Unternehmensziele nicht mehr zeitgemäß ist und perspektivisch Wettbewerbsnachteile hervorbringen kann, wurden Maßnahmen eingeleitet, um die Unternehmensziele auf Nachhaltigkeitsdimensionen abseits der ökonomischen, also außerdem auf die soziale und ökologische Dimension zu erweitern. Um dies zu erreichen, müssen alle Bestandteile des Unternehmens begutachtet werden. Dazu gehört unter anderem auch die Gestaltung einer ökologisch nachhaltigen IT-Infrastruktur. In dieser Arbeit wurden mithilfe literarischer Quellen hinsichtlich der Green-IT-Thematik, Experteninterviews und betrieblichen Beobachtungen Maßnahmen entwickelt, wie die ökologische Nachhaltigkeit der IT-Infrastruktur der Senacor Technologies AG verbessert werden kann. Dafür wurden die verschiedenen Teilbereiche einer IT-Infrastruktur betrachtet und Ansatzpunkte ermittelt, wie diese hinsichtlich der Ökologie nachhaltiger gemacht werden können. Die Ansatzpunkte waren hierbei sowohl ökologisch nachhaltige Prozesse, worunter unter anderem die Reduktion des Materialverbrauchs innerhalb der Prozesse oder die grüne Softwareentwicklung fallen als auch ökologisch nachhaltige Hardware, also der rücksichtsvolle Umgang mit IT-Hardware entlang des gesamten Lebenszyklus oder der Aufbau einer effizienten Serverinfrastruktur.
23.03.21;20.10.21;2021;extern;Master;DE;"Erweiterung des Elektrobit ""Voice Assistant Broker"" um einen weiteren Sprachassistenten (RASA)";In dieser Masterarbeit wurde der generische Elektrobit Voice Assistant Broker um einen weiteren Sprachassistenten erweitert, welcher auf Rasa Open Source basiert. Dazu erfolgte die Entwicklung eines Adapters, welcher eine prototypische Benutzerschnittstelle mit dem Assistenten Rasa verbindet und dadurch als Sprachassistent verwendet werden kann. Rasa Open Source besitzt dabei Fähigkeiten zum natürlichen Sprachverständnis (Natural Language Understanding) und Dialogmanagement. Da Rasa keine Spracheingaben unterstützt, sondern textbasiert arbeitet, wurde zusätzlich Sensory TrulyNatural als Speech-to-Text und Coqui als Text-to-Speech Engine verwendet, um eine volle Sprachfunktionalität des Assistenten zu gewährleisten. Abschließend erfolgte ein Vergleich zwischen dem Sprachassistenten mit Rasa und dem vorher bereits implementierten ontologie-basierten Ansatz von Elektrobit. Hierbei wurde auch eine kurze Benutzerstudie mit fünf Teilnehmern zur Evaluation des mit Rasa implementierten Sprachassistenten durchgeführt.
24.03.21;24.08.21;2021;intern;Bachelor;DE;Phantom Malware: Implementierung und Analyse am Beispiel von Ransomware;In dieser Arbeit wird das Konzept der Phantom Malware am Beispiel einer Implementierung als Ransomware analysiert. Zu Beginn werden die theoretischen Grundlagen in Bezug zum Konzept der Phantom Malware und Malware im Allgemeinen vermittelt. Anschließend wird ein Konzept für die Implementierung in C++ mit Windows als Zielbetriebssystem ausgearbeitet. Dabei erschließt sich, dass zusätzlich eine Debug Variante der Malware implementiert werden muss. Außerdem wird ein in Node.js und Express.js zu implementierender C&C Server konzipiert. Als Methode zum Kommunizieren mit dem C&C Server wird die PowerShell von Windows genutzt. Es stellt sich heraus, dass gegenüber dem originalen Konzept der Phantom Malware, durch das Nutzen des Clipboards, die Performanz verbessert werden kann. Diese Steigerung der Performanz wird durch Tests belegt, wobei auch die Probleme des Phantom Malware Konzepts aufgezeigt werden. Die umgesetzte Implementierung der Phantom Ransomware, des Entschlüsselungsprogramms und des C&C Servers wird zudem an Codebeispielen beschrieben. Die vorliegende Phantom Ransomware Implementierung soll für Forschungszwecke genutzt werden und ist somit nicht schadhaft. Es wird des Weiteren erörtert, dass Phantom Malware eine realistische Angriffsmethode für Cyberkriminelle ist, da es durch Antiviren-Software unerkannt bleibt.
26.03.21;26.11.21;2021;extern;Master;DE;Integration von Usability und User Experience in einem Model Driven Architecture Ansatz im Kontext der modellbasierten Produktentstehung;In fasst allen Lebenslagen haben wir es mit einer wachsenden Verunsicherung zu tun. Dahinter verbirgt sich auch die Agilität. Diese basiert auf dem agilen Manifest welches wiederum auf der Entwicklung von Software, als etwas was Computer verstehen können, basiert. Agilität fokussiert jedoch auf den Menschen der die Software nutzt und entwickelt. Ein weiteres wichtiges Element sind Modelle. Diese können Veränderung, Komplexität und Mehrdeutigkeit abbilden und helfen den Menschen dabei Dinge zu verstehen. Durch höhere Formalisierung werden Modelle auch von Computern verstanden. <br>Software und Modelle ähneln sich auf gewisse Weise, denn beide werden von Menschen entwickelt und benutzt als auch von Computern verstanden. <br>Daher kann der Gedanke verfolgt werden, dem Menschen ein Modell von dessen Use Case entwickeln zu lassen und durch den Computer, sprich einer logischen und funktionalen Ablaufreihenfolge an Regeln, einen Softwarecode zu generieren. Dieses Konzept wird durch MDA verfolgt. Dabei fehlt allerdings die Komponente der User Experience, der ästhetisch ansprechenden Form der Software. Das erarbeitete Konzept erlaubt es den Nutzenden ein passendes Darstellungskonzept zu erstellen oder gar dieses automatisiert vorgeschlagen zu bekommen.
26.03.21;26.11.21;2021;extern;Master;DE;Fallstudie: Echtzeit-Monitoring von Herstellungsprozessen in der Industrie 4.0 ;
29.03.21;29.08.21;2021;extern;Bachelor;DE;Evaluation von ecl@ss zur semantischen Beschreibung von Mittelspannungsumrichtern;Nachdem alle Problematiken betrachtet wurden, lässt sich die Forschungsfrage<br>folgendermaßen beantworten: Der ECLASS-Standard stellt für die Beschreibung eines<br>Mittelspannungsumrichters eine Vielzahl von Elementen zur Verfügung. Grundlegende<br>Merkmale oder Angaben lassen sich mit Hilfe der Klassifikationsklasse definieren. Bei<br>Betrachtung aller Verfügbaren Elemente, kann ein Großteil der Merkmale und Werte<br>eindeutig definiert werden. Es sind aktuell jedoch noch nicht alle Informationen eines<br>Umrichters mit der vorhandenen ECLASS-Struktur abzubilden. Dies liegt daran, dass die<br>benötigten Merkmale und Werte nicht in dem vorhandenen ECLASS-Vokabular existieren.<br>Für diese Daten wurden jedoch Konzepte, in Form von Lösungsvorschlägen erarbeitet.<br>Schlussfolgernd lässt sich sagen, dass die Beschreibung eines Mittelspannungsumrichters<br>mit ECLASS durch die Umsetzung des erarbeiteten Lösungsvorschlags möglich ist. 
29.03.21;29.08.21;2021;extern;Bachelor;DE;Konzeption und Realisierung einer Plattform zum Ausgleich von Unter- und Überbeständen für ein Webportal des pharmazeutischen Einzelhandels;Für die Firma Endobit Software Solutions (kurz: Endobit) soll eine innovative Plattform zum Austausch von Artikel- und Bestandsinformationen zwischen Apotheken entwickelt werden. Endobit entwickelt bereits ein Portal für Apotheken, welches unter anderem die Verwaltung von Personaldaten sowie die Kommunikation apothekenintern und auch apothekenübergreifend ermöglicht. Verschiedene Ursachen führen in den vergangenen Jahren zu einer Zunahme von Arzneimittelknappheit. Die Softwarelösung soll deshalb um eine Komponente erweitert werden, mit der Über- und Unterbestände bei einzelnen Artikeln (gekennzeichnet über die PZN-Pharmazentralnummer bzw. die EAN-European Article Number) zwischen Apotheken und ihren Filialen ausgeglichen werden können. Die neue Applikation soll im Rahmen der Arbeit als Webanwendung prototypisch realisiert werden.
31.03.21;31.08.21;2021;extern;Bachelor;DE;Vergleich von GraphQL und REST - Evaluation einer möglichen<br>Performancesteigerung durch den gezielten Einsatz der beiden Ansätze;Der Architekturstil REST hat sich für die Umsetzung von Webschnittstellen weitestgehend durchgesetzt.<br>Mit GraphQL veröffentlichte Facebook 2015 eine Alternative hierzu.<br>GraphQL soll vor allem die übertragene Datenmenge durch spezifische Anfragen reduzieren und Webservices somit performanter machen.<br><br>In der vorliegenden Arbeit wird REST und GraphQL verglichen. Darüber hinaus wird dargestellt, wie eine vorhandene REST Schnittstelle durch GraphQL im Zuge eines Umbaus verbessert werden kann und wann ein solcher Umbau sinnvoll ist.<br><br>Anhand einiger Kriterien und mithilfe einer Beispielanwendung, welche sowohl REST als auch GraphQL implementiert, werden die beiden Stile verglichen.<br>Anschließend wird aufbauend auf drei Praxisbeispielen erläutert, welche Möglichkeiten bestehen, eine vorhandene REST Schnittstelle durch GraphQL zu verbessern.<br>Auf Basis dessen wird ein solcher Umbau an einem Projekt des betreuenden Unternehmens vollzogen und zuletzt evaluiert, welche Resultate dadurch erzielt wurden.<br><br>Die Arbeit zeigt, dass GraphQL vor allem für mobile Anwendungen Vorteile mit sich bringt, da diese oft mit beschränkter Bandbreite und beschränktem Datenvolumen funktionieren müssen.<br>Dementsprechend bietet sich ein Umbau einer REST Schnittstelle besonders dann an, wenn die Anwendung einen mobile Client besitzt.<br>Die übertragene Datenmenge lässt sich einerseits mit GraphQL in jedem Fall senken, andererseits wird bei guter Netzwerkgeschwindigkeit kein signifikanter Performancegewinn erzielt.
31.03.21;31.08.21;2021;intern;Bachelor;DE;Eine sentimentbasierte Analyse meinungsabhängiger Verknüpfungstendenzen im Twitter-Netzwerk im Kontext der politischen Maßnahmen zur Eindämmung der Corona-Pandemie in Deutschland;Durch den Ausbruch des SARS-CoV-2 Virus im Frühjahr 2020 in Deutschland wurden durch die Bundesregierung verschiedene Maßnahmen zur Pandemiebekämpfung beschlossen. Da sowohl der Virus an sich, als auch die Maßnahmen nicht von jedem Bürger gleichermaßen als existent und notwendig erachtet werden, gibt es auch Personen, welche offizielle Informationen nicht anerkennen. Stattdessen, werden durch diese Personengruppe falsche Informationen und Verschwörungstheorien auf sozialen Plattformen wie beispielsweise Twitter oder Facebook verbreitet.<br>Mit dieser Arbeit sollen Aussagen über die Verknüpfung verschwörerischer Benutzer getroffen und den Verknüpfungen neutraler oder positiv zu den Maßnahmen eingestellten Personen gegenübergestellt werden. Ferner wird untersucht, inwieweit die unterschiedlichen Personengruppen sich untereinander vermischen oder unter Ihres gleichen vernetzen.<br>Um zunächst eine Datengrundlage zu bilden, werden Twitternachrichten via Web-Scrapping erfasst und aufbereitet. Auf dieser Grundlage wird dann ein neutrales Sentimentlexikon so erweitert, dass es in den Corona-Kontext verwendet werden kann. Nach Anpassung der Tweets und des Sentiments, wird schließlich die Sentimentanalyse durchgeführt. Abschließend werden die daraus gewonnenen Informationen ausgewertet und analysiert.<br>
01.04.21;30.09.21;2021;intern;Bachelor;DE;Entwicklung und Adoption der Kryptowährung Bitcoin in finanziellen Krisenzeiten;In dieser Bachelorarbeit wird die Entwicklung und Adoption von Bitcoin in finanziellen Krisenzeiten am Beispiel der COVID-19-Pandemie seit März 2020 erläutert. Dabei wird exemplarisch auf wichtige Geschehnisse eingegangen, da die schnelle Entwicklung und die Vielzahl der Ereignisse den Umfang der Arbeit überschreiten würde. Es wird der Zusammenhang zwischen ökonomischen, ökologischen und regulatorischen Ereignissen den Bitcoin betreffend aufgezeigt, die u.a. ihren Ursprung in der Finanzkrise 2008 haben und in der COVID-19-Pandemie verstärkt Einfluss auf die Weltwirtschaft genommen haben.<br><br>Das Bitcoin-Netzwerk wurde an der interdisziplinären Schnittstelle von Ökonomie, Kryptographie und Informatik geschaffen. Um den Bitcoin zu verstehen, ist somit ein Verständnis dieser drei Teilbereiche vonnöten. Aus diesem Grund führt die Bachelorarbeit in den Kapiteln Bitcoin Konzeption und monetär-theoretische Überlegungen zu Bitcoin die Grundlagen ein.  Daran schließt sich das Kapitel Entwicklung und Adoption von Bitcoin, das den Bitcoin zuerst unter ökonomischen Aspekten analysiert. Hierbei spielen die Entstehung und Funktion von Geld, die Maßnahmen der Notenbanken in Krisenzeiten und die Möglichkeit Bitcoin als Vermögenswert zu nutzen, eine tragende Rolle. Im weiteren Verlauf werden ökologische und regulatorische Aspekte betrachtet. Bitcoin wird im Hinblick auf den Energieverbrauch und Regulierungsmaßnahmen untersucht. Ein abschließendes Fazit fasst die Ergebnisse der Arbeit zusammen.
01.04.21;01.12.21;2021;extern;Master;DE;Entwicklung eines prototypischen Knowledge Graphen zur Ermöglichung des automatisierten Wissenszugriffs durch Softwarelösungen der DATEV eG;"Damit die Kunden der DATEV eG im Rahmen ihrer Prozesse für deren Mandanten relevantes Wissen einholen können, werden Informationen aus verschiedenen Quellen benötigt, wobei diese Informationen in verschiedenen Formaten vorliegen können. Die Informationssuche gestaltet sich für den Kunden damit aufwändig. Anstelle ""Anwender sucht Wissen"" soll zukünftig deshalb ""Wissen findet Anwender"" als neuer Prozess etabliert werden. Ein möglicher technischer Lösungsansatz, der zur Verwirklichung der Vision beitragen kann, ist die Verwendung eines Knowledge Graphen auf Basis von Semantic Web Technologien. In der vorliegenden Arbeit wird überprüft, ob dieser Ansatz unter Einbezug strukturierter Daten für DATEV geeignet ist. Dazu wird eine Definition des Begriffes ""Knowledge Graph"" erarbeitet und ein Vorgehensmodell für die Umsetzung eines Knowledge Graphen entwickelt. Unter Verwendung dieses Modells wird zudem ein prototypischer Knowledge Graph für einen bestimmten Anwendungsfall innerhalb eines Kundenprozesses auf Basis strukturierter Daten umgesetzt und evaluiert."
01.04.21;01.12.21;2021;intern;Master;DE;Untersuchung von Methoden zur lexikalischen und semantischen Vereinfachung deutschsprachiger Texte mittels statistischer Sprachmodelle;"Im Rahmen des ""Civic Innovation Platform"" (CIP) Projektes der Denkfabrik Digitale Arbeitsgesellschaft im Bundesministerium für Arbeit und Soziales wurde das Projekt ""Unkafka - Behördliche Schreiben einfach und verständlich"" eingereicht. Unkafka konzentriert sich darauf, Kommunikation unter Einsatz eines Textvereinfachungssystems zu verbessern.<br>Ziel ist, in Vorbereitung des Unkafka-Projektes Fragestellungen zur automatisierten Vereinfachung deutscher Texte zu klären. Es werden folgende Fragen behandelt:<br><br>- Sind vortrainierte Sprachmodelle geeignet, deutsche Texte in einer Qualität zu Vereinfachen, die menschlicher Adaption genügt?<br>- Wie kann die Komplexität von Texten auf der Ebene von Dokumenten, Satzgefügen, (Teil)Sätzen oder Worten quantifiziert werden?<br>- Welche Verfahren sind geeignet, die Performanz von Sprachmodellen bezüglich Vereinfachung zu beurteilen?<br><br>Neben einer generellen Verfahrensstudie wird eine lexikalische Textvereinfachungspipeline implementiert und die vortrainierten Sprachmodelle BERT, GPT-2 und Fasttext als Vertreter bidirektional kontextueller, regressiv kontextueller und kontextfreier Sprachmodelle evaluiert. Es zeigt sich, dass eine Vereinfachung deutscher Texte auf lexikalischer Ebene mit allen getesteten Modellen prinzipiell möglich ist, wobei Kompositwörter als grammatikalische Besonderheit der deutschen Sprache Synonymfindung und semantische Kohärenz der vereinfachten Texte beeinträchtigen und besonderer Beachtung bedürfen."
01.04.21;01.09.21;2021;extern;Bachelor;DE;Automatisierung der Wärmezählerauswahl der Firma Landis+Gyr bei einer Ausschreibung;Das Ziel dieser Arbeit besteht darin, einen Konfigurator zu entwickeln, welcher es ermöglicht automatisch einen Ausschreibungstext für einen Wärmezähler der Firma Landis+Gyr zu generieren. Dafür wurde der Arbeitsablauf eines Planers beim Konfigurieren des Wärmezählers und Erstellen einer Ausschreibung genauer untersucht. Daraufhin wurde eine Webanwendung entwickelt, mit der es möglich ist, die Umwelt zu schonen. Da der Arbeitsschritt, den Ausschreibungstext zu schreiben, mit der Fertigstellung des automatisierenden Konfigurators komplett entfällt, wurde zusätzlich eine signifikante Zeitersparnis erzielt.<br><br> 
01.04.21;31.01.22;2021;intern;Bachelor;DE;Diarization und Overlap Detection für Arzt-Patienten-Gespräche;Diese Arbeit beschäftigt sich mit Speaker Diarization. Sie hat zum Ziel ein Diarization<br>System vorzubereiten, das potenziell mit Arzt-Patienten-Gespräche zurechtkommen könnte.<br>Dazu wird vorausgesetzt, dass das System dazu in der Lage ist, mit Speech Overlap und<br>einer flexiblen Anzahl an Sprechenden umzugehen. Weiter ist der AMI Korpus zum Testen<br>und eval2000 Korpus zum Evaluieren vorgegeben. Für die Auswahl eines Systems werden<br>die besten drei Systeme auf Track 2 der DIHARD Challenge III und ein Subsystem auf<br>Qualitätsmerkmale wie beispielsweise DER, Komplexität oder Echtzeitfähigkeit analysiert.<br>Das Subsystem Self-Attentive (SA) End-to-end Neural Network-based speaker diarization<br>model (EEND) mit Encoder-Decoder-Attractor (EDA) wird als Testsystem genutzt (https:<br>//github.com/hitachi-speech/EEND). Als Baseline dient ein Kaldi Standard Rezept für<br>den AMI-Korpus mit Overlap Detection (kaldi/egs/ami/s5c). Letzteres implementiert ein<br>Diarization System mit folgender Pipeline: Genutzt werden MFCC, Oracle SAD, X-Vektor<br>Exktraktion mit vortrainiertem DNN, PLDA, Spectral Clustering und abschließend wird<br>ein TDNN LSTM für Overlap Detection trainiert. Die bestehenden Diarization Systeme<br>werden auf die vorgegebenen Datensets angepasst. Das Ergebnis auf dem eval2000 Set für die<br>Baseline ergibt 84,9 % DER, für das Testsystem 100 % DER. Es wurden Hypothesen zum<br>schlechten Abschneiden beider Systeme aufgestellt, allerdings konnte keine abschließende<br>Erklärung gefunden werden.
01.04.21;01.12.21;2021;intern;Master;EN;Real-time sequence-to-sequence neural networks as an artificial musical duo partner;
02.04.21;01.09.21;2021;intern;Bachelor;DE;Analyse von Bewerbungen mittels Text Mining zur Vorsortierung geeigneter <br>Bewerber<br>;Personalabteilungen von Unternehmen erhalten bei Ausschreibung einer Stelle oftmals mehrere hunderte Bewerbungen, deren Sichtung und Zusammentragen viel Zeit in Anspruch nimmt. Die richtige Person für einen Job zu finden ist weiterhin eine schwierige Aufgabe für Unternehmen.<br>Moderne Datenverarbeitungsverfahren können dabei helfen, diese Bewerbungen vorab hinsichtlich ihrer Eignung zu beurteilen, um eine Vorsortierung vorzunehmen. <br><br>Somit sind die folgenden zentralen Forschungsfragen zu beantworten:<br><br>Ist es möglich, ein Verfahren bzw. System zu entwickeln, welches Bewerbungstexte in Bezug auf eine Stellenausschreibung vorsortiert? Ist im Rahmen dessen die Erzeugung einer Trefferliste mit geeigneten Kandidaten möglich?<br>Besteht die Möglichkeit für das Ersetzen oder Ergänzen von bereits bestehenden Bewerbermanagementsystemen, um den Bewerbungsprozess automatisiert durchzuführen und manuelle Arbeiten zu minimieren?<br><br>Dafür wird ein Verfahren entwickelt, um Bewerbungen mit Stellenausschreibungen zu vergleichen. Dieses bildet Vektoren von in den Bewerbungen enthaltenen Wörtern, gewichtet diese und untersucht so die Ähnlichkeiten zwischen den Bewerbungen und den Stellenausschreibungen.<br><br>Das Verfahren zeigte, dass ähnliche Ergebnisse im Vergleich zum manuellen Bearbeiten der Bewerbungen erzielt werden konnte. Außerdem wird ersichtlich, dass das Verfahren sich nicht für das Ranking selbst eignet, sondern nur als Unterstützung zur Vorsortierung.<br><br>
06.04.21;06.12.21;2021;extern;Master;DE;Entwicklung eines dezentralen WebRTC Videokonferenzdienstes;Die häufigsten Topologien nach denen Videokonferenzen aufgebaut werden sind die Mesh- und Stern-Topologie. In der Stern-Topologie senden die Teilnehmer ihre Videostreams an einen Server und dieser führt dann die Verteilung auf die anderen Teilnehmer durch. Deshalb erfordert die Stern-Topologie einen leistungsstarken Server, was mit hohen Kosten verbunden ist. In der Mesh-Topologie ist dies nicht der Fall, da jeder Teilnehmer direkt mit jedem anderen Teilnehmer verbunden wird. Aufgrund der Belastung durch die zahlreichen Verbindungen ist die Mesh-Topologie allerdings nicht für größere Videokonferenzen geeignet.<br><br>Im Rahmen dieser Arbeit wird ein Videokonferenzdienst entworfen, der die Vorteile der Mesh- und Stern-Topologie verbindet und damit ohne leistungsfähige Server größere Videokonferenzen ermöglicht.<br>Dies wird erreicht, indem die Videostreams von den leistungsstärksten Teilnehmern verteilt werden statt von einem Server.<br><br>Es werden die Konzepte vorgestellt wie die Leistungsfähigkeit einzelner Teilnehmer ermittelt wird, um so deren Eignung festzustellen. Außerdem wird ein Algorithmus vorgestellt, der die Verteilung im Netzwerk der Teilnehmer koordiniert.<br>Die im Anschluss durchgeführten Tests zeigen, dass die Leistungsfähigkeit der Teilnehmer zuverlässig bestimmt werden kann. Außerdem erreicht das System eine Verbesserung der Videoqualität. Die zeitliche Verzögerung, mit der die Gesprächspartner miteinander kommunizieren, nimmt hingegen zu.<br>
07.04.21;17.08.21;2021;intern;Bachelor;DE;Unterrepräsentierte Studierendengruppen in der digitalen Lehre.<br>Auswahl digitaler Lehr- und Lernmethoden zur Vermeidung individuell auftretender Probleme.;Im Fokus der Untersuchung steht die Vermeidung individuell auftretender Prob-leme Studierender aus unterrepräsentierten Studierendengruppen bei der digita-len Lehre. Auf Basis möglicher Herausforderungen betroffener Studierenden-gruppen wurde ein Konzept für die digitale Lehre erstellt und prototypisch umge-setzt. Das Ergebnis einer Untersuchung bestehender Literatur war, dass ein Konzept für die digitale Lehre den Fokus auf eine gezielte Kombination einzel-ner, ausgewählter Lehr-Lernmethoden legen sollte. Außerdem sollten Methoden unterschiedlicher Lerntheorien verwendet werden, um eine ökonomisch umsetz-bare, aber dennoch individuelle und tiefgreifende digitale Lehre anzubieten. Bei einer anschließenden Befragung der betroffenen Zielgruppe zeigte sich, dass sie sich im vorliegenden Konzept als Mitglied einer unterrepräsentierten Studieren-dengruppe mehr beachtet fühlen als in deren bisherigen Erfahrungen mit digita-ler Lehre im Studium. Auch die genauere Untersuchung der Herausforderungen und Bedürfnisse der befragen Studierenden im Umfeld der digitalen Lehre im Studium wies auf eine erfolgreiche Unterstützung der Studierender bezüglich einiger Probleme durch das Konzept hin. Es ließen sich jedoch auch Hinweise auf weitere Verbesserungsmöglichkeiten in Form von weiterhin bestehenden Bedürfnissen der befragten Studierenden erkennen.
09.04.21;09.09.21;2021;intern;Bachelor;DE;Konzeption und Implementierung eines Texteditors mit Autocomplete und Typeahead, zur schnellen Verschriftung von Sprachaufnahmen;"Im Rahmen dieser Bachelorarbeit soll eine Webanwendung in Form eines Texteditors konzipiert und unter Verwendung des Web-Frameworks ""Angular"" entwickelt werden. Dieser soll den Nutzer dabei unterstützen Sprachaufnahmen schneller zu verschriften. Dabei greift er auf eine gewünschte Audiodatei zu und ist in der Lage, diese abzuspielen. Die Unterstützung des Nutzers soll durch eine auf Basis des Jaro-Winkler-Algorithmus implementierte Autovervollständigung der Nutzereingabe sowie eines Typeahead erfolgen. Für diese Dienste wird eine Datei, die eine computergenerierte Verschriftung der zu verwendeten Sprachaufnahme enthält, als Datenquelle genutzt. Außerdem vergleicht der Texteditor die Verschriftung des Nutzers mit der computergenerierten und visualisiert die Gemeinsamkeiten und Unterschiede. Dieser Vergleich findet auf Basis des Needleman-Wunsch-Algorithmus statt. Im Verlauf dieser Arbeit werden die Schritte der Entwicklung des Texteditors beschrieben. Außerdem werden für die Realisierung der Anwendung interessante Algorithmen analysiert und Begründungen für die Wahl der soeben genannten Algorithmen geliefert.   "
09.04.21;09.09.21;2021;extern;Bachelor;DE;Prototypische Entwicklung eines Systems zur flexiblen Extraktion und Analyse unstrukturierter Daten in technischen Planungsdokumenten;Viele Industrieunternehmen entwickeln, produzieren und vertreiben Produkte an verschiedenen Standorten weltweit. In diesem internationalen Netzwerk bildet die Montageplanung das Bindeglied zwischen der Konstruktion und Montage. Die Aufgabe der Montageplanung besteht daher darin, Ressourcen kostenoptimal an neue Anforderungen anzupassen. Dafür müssen damit verbundene Änderungen finanziell bewertet werden. Montageplaner nutzen dafür ihr Wissen, sprechen mit Kollegen, holen Planungsdokumente bei Lieferanten oder von vergangenen Projekten ein. Probleme dieser Lösungen sind, dass eigenes Wissen oft nicht umfangreich vorhanden ist und erfahrene Kollegen nicht immer erreichbar sind. Werte von Lieferanten können schwer plausibilisiert werden und die Suche nach empirischen Planungsdokumenten ist sehr zeitaufwändig. Das Ergebnis ist eine ungenaue Einschätzung der finanziellen Aufwände der Anpassungen. Daher wird in diesem Ansatz eine prototypische Entwicklung eines Systems zur flexiblen Extraktion und Analyse unstrukturierter Daten in technischen Planungsdokumenten erarbeitet, um Planwerte zu generieren. Ein Planwert steht für den finanziellen Aufwand einer Anpassung. Der resultierende Prototyp bietet eine automatisierte Extraktion und Normalisierung der relevanten Daten aus Planungsdokumenten. Außerdem liefert er eine zentrale und zugängliche Datenquelle für die Kosteneinschätzung von Anpassungen und eine intuitive Benutzeroberfläche zur aufwandsarmen Datenanalyse und -suche.
12.04.21;12.09.21;2021;intern;Bachelor;DE;Optimierung der Intent-Erkennung eines Chatbots durch Evaluation verschiedener Sprachmodelle<br><br>;"Das Ziel der Arbeit ist es, Vorgehensweisen und Parameter im Chatbot-Framework Rasa zu optimieren, um eine Steigerung der Intent-Erkennung zu erreichen. Dazu werden Tests mit verschiedener Anzahl an Trainingsdaten zu einem Intent, sowie diverse Pipeline-Konfigurationen getestet. Anschließend werden die Ergebnisse verglichen, interpretiert und evaluiert. Als Basis soll der aus dem Projekt ""Digitale Assistenz"" der Technischen Hochschule Nürnberg entstandene Chatbot ""Zeobot"" dienen."
13.04.21;13.09.21;2021;extern;Bachelor;DE;Einsatz von Open-Source-Systemen für Business Intelligence - Analyse, Handlungsempfehlung und prototypische Implementierung für ein konkretes BI-Projekt;
13.04.21;13.09.21;2021;intern;Bachelor;DE;Konzeption und Implementierung eines interaktiven Dashboards zur Erforschung des Zusammenhangs zwischen Aktivitäten in einem E-Learning-Kurs und Leistungen in digitalen Prüfungen;Ziel dieser Arbeit ist die Konzeptionierung und Entwicklung eines Dashboards, das es erlaubt den Zusammenhang zwischen Beteiligung in E-Learning-Kursen und Ergebnissen in digitalen Prüfungen zu untersuchen. Dazu werden im zweiten Kapitel wichtige Grundlagen für das Verständnis dieser Arbeit behandelt, insbesondere die Beschaffenheit der Lernplattform Moodle, sowie die grundsätzlichen Eigenschaften von digitalen Dashboards. Darauf aufbauend wird im dritten Kapitel auf die Konzeption eines solchen Informationssystems eingegangen und neben der Wahl eines geeigneten Vorgehensmodells, auch die Durchführung einer Anforderungsanalyse, sowie die Erstellung des Projektplans näher beschrieben. Besonders die Details in der Designphase, wie Aufbau der Systemarchitektur, das Design der Weboberfläche und die Auswahl einer geeigneten Entwicklungsumgebung, werden hier verdeutlicht. Das vierte Kapitel beschreibt auf detaillierte Weise, wie das Konzept aus dem vorherigen Kapitel, in die Realität umgesetzt wird. Besonders wichtige Aspekte sind dabei die Verfahren zum Datentransfer zwischen Moodle-Kurs und Dashboard, sowie die Anzeige der einzelnen Dashboard Komponenten und deren Einbindung in eine Webseitenoberfläche. Auch die Methoden zur Erzeugung von Interaktivität zwischen Anwender und Programm sind hier beschrieben. 
13.04.21;13.09.21;2021;extern;Bachelor;DE;Entwicklung eines KI-basierten Algorithmus zur Erkennung von Fehlern unter Nutzung einer robotergestützten Bildaufnahme;Um die Qualität in Serienproduktionen zu gewährleisten, kommt eine automatisierte Sichtprüfung zum Einsatz. Problematisch dabei ist, dass die Prüfung aus einer Richtung stattfindet und nicht bekannt ist, ob alle relevanten Fehler erkannt werden können. Zu diesem Zweck existieren manuelle Machbarkeitsstudien, die jedoch mit Nachteilen behaftet sind. Das Ziel der Bachelorarbeit ist es, einen Algorithmus für eine robotergestützte Bildaufnahme und KI-gestützter Fehlererkennung zu entwickeln, um die Reproduzierbarkeit, die Bedienerunabhängigkeit und eine datengetriebene Auswertung zu gewährleisten. Der Konzeptentwurf wurde mit dem morphologischen Kasten erarbeitet. Dabei wurde ein Roboter- und Kameraprogramm entwickelt, welches ein Objekt in verschiedenen Posen ablichtet und zuordnet. Außerdem ein Vorgehen zur Präparation der Bilder, um sie durch die trainierte Auswertestufe bewerten zu können. Abschließend wurde eine Visualisierung entwickelt, welche die Werte der Abweichung darstellt. Die Erprobung des entwickelten Ansatzes zeigte, dass die Robustheit der Fehlererkennung gegen eine Änderung des Blickwinkels feststellbar ist. Anhand der Auswertung kann der Bereich abgelesen werden, der eine sichere Fehlererkennung garantiert. Der entwickelte Ansatz bietet die Möglichkeit zu einer automatisierten Machbarkeitsstudie. Jedoch besteht Potential zur Weiterentwicklung, um eine allgemeinere Aussagekraft über den Erkennungsbereich treffen oder mehrere Fehlermerkmale kombinieren zu können.
15.04.21;15.09.21;2021;extern;Bachelor;DE;"Entwurf und Umsetzung eines universellen ""Notification centre"" als Microservice ";Ziel der Bachelorarbeit war die Entwicklung eines Microservices, der empfange Information intelligent filtert und klassifiziert, sodass er diese dann in kleinere Teilinformation zerlegt. Die einzelnen Teilinformationen werden dann an jeweilige Nutzer bzw. Systeme verschickt werden, für die Sie auch relevant sind. Der Microservice funktioniert als kontextbezogenes und adressatengerechtes Benachrichtigungszentrum funktionieren, das universell einsetzbar ist.
15.04.21;13.12.21;2021;extern;Master;DE;Kombinatorische Optimierung mittels Reinforcement Learning am Beispiel des Behälterproblems;In dieser Arbeit wird eine Variation des Behälterproblems behandelt, welche die platzsparende Anordnung von beliebig-förmigen Elementen umfasst. Die Formen der anzuordnenden Elemente werden dabei über einen Verbund von zusammenhängenden Quadraten repräsentiert. Zur Lösung des Problems wurde ein Reinforcement-Learning-System im Stile von AlphaGo Zero entwickelt. Dieses nutzt zur Entscheidungsfindung einen Monte-Carlo Tree Search, der durch ein neuronales Netz geleitet wird. Die Trainingsdaten für das neuronale Netz werden durch Simulationen generiert, in denen zufällig erzeugte Probleme durch das realisierte System gelöst werden. Für das Training wird daher neben der Kenntnis der problemspezifischen Rahmenbedingungen kein menschliches Experten- und Domänenwissen benötigt. Bei der Lösung von verschiedenen Konfigurationen der untersuchten Problemstellung erzielte das System überwiegend Ergebnisse, die einer nahezu optimalen Anordnung entsprechen. Neben dem Finden einer Anordnung von beliebig-förmigen Elementen wurde das System auch auf eine Variation des Behälterproblems, welche die Anordnung von rechteckigen Objekten beinhaltet, angewandt. Im Rahmen dessen konnte es bessere Ergebnisse erzielen als aktuell eingesetzte heuristische Verfahren. Das System ist so konzeptioniert, dass es nach der Implementierung von problemspezifischen Dynamiken auf eine Vielzahl weiterer kombinatorischer Optimierungsprobleme anwendbar ist.
15.04.21;15.11.21;2021;intern;Bachelor;DE;Snapshotbasierte Versionierung für die iterative<br>hypothesengetriebene Entwicklung eines Business Model Canvas;
16.04.21;16.09.21;2021;extern;Bachelor;DE;Autorisierungstechnologien für Banken APIs am konkreten Beispiel FAPI;Trotz der immer höheren Sicherheits- und Skalierungsanforderungen von modernen WebApplikationen, insbesondere im Finanzenbereich, basiert ein Großteil der Anwendungen immernoch auf veralteten, unsicheren Techniken wie beispielsweise Screen Scraping [FAPIc].<br>Beim Screen Scraping gewähren die Nutzer von Fintech-Services einer Anwendung Zugang,<br>indem sie, üblicherweise, ihre bankenspezifischen Kennungsdaten der Applikation zur Verfügung stellen. Eine Möglichkeit, um diese Probleme zu mitigieren, stellt die Heranziehung<br>des OAuth 2.0 Framework dar, welches es ermöglicht auf Ressourcen zugreifen zu können,<br>ohne dass den Fintech-Services Nutzerdaten direkt übermittelt werden.<br>Ein neuer Ansatz, welcher auf OAuth 2.0 und OpenID Connect baut, und diese für das<br>sensitive Umfeld der Finanzwelt anpasst, ist die FAPI, kurz für Financial-grade Application<br>Programming Interface.<br>Das Ziel dieser Arbeit ist es, zunächst die theoretischen Grundlagen der unterschiedlichen<br>Technologien herauszuarbeiten und aufzubereiten. Anschließend soll das erarbeitete Wissen<br>genutzt werden, um herauszufinden ob sich die Anbindung von FAPI basierenden Applikationen für den Finanzsektor rentiert. Dazu wird folgende Forschungsfrage aufgestellt: Was<br>sind die Vor- und Nachteile, FAPI als primäre Technologie für das Bereitstellen von autorisierungsbezogenen Schnittstellen zu integrieren?<br>Um diese Frage beantworten zu können, wird ein prototypischer Autorisierungsserver entwickelt, der den Anforderungen von FAPI gen
16.04.21;16.12.21;2021;extern;Master;DE;Der Produktportfoliowandel von On-Premises- zu Cloud-Anwendungen: Bestandsaufnahme und Gestaltungsempfehlungen innerhalb der DATEV eG;Die zunehmende Bedeutung der Digitalisierung, Automatisierung und Kollaboration sowie die damit zusammenhängende Nutzung von Cloud-Computing verpflichtet Unternehmen, ihre bislang verfolgte Strategie stetig anzupassen. Daher hat sich die DATEV eG das Ziel einer Cloud-Only-Strategie gesetzt, um ihren Kunden die bisherigen On-Premises-Produkte als Cloud-Anwendungen zur Verfügung zu stellen.<br><br>Im Rahmen dieser Masterthesis wird der Portfoliowandel der DATEV eG näher beleuchtet, eine Bestandsaufnahme der aktuellen Umstellungsstrategien in verschiedenen Bereichen durchgeführt und auf Basis der gesammelten Informationen Gestaltungsempfehlungen vorgestellt. Zwar stellt die Online-Strategie ein Querschnittsthema im Unternehmen dar und leitet sich aus der Gesamtstrategie ab, dennoch ist die konkrete Umsetzung den einzelnen Bereichen überlassen. Die Bestandsaufnahme zeigt, dass sich die Workstreams unterschiedlich intensiv mit den zukünftigen Produkten auseinandergesetzt haben und verschiedene Voraussetzungen wie bspw. freie Kapazitäten für die Online-Entwicklung aufweisen. Generell werden jedoch die Greenfield-Strategie und der hybride Ansatz fokussiert.<br><br>Zusammenfassend stellt der Portfoliowandel die DATEV eG vor eine Herausforderung. Dennoch kann mittels Fokussierung auf einzelne Online-Anwendungen bzw. deren Zusammenspiel untereinander sowie unter Berücksichtigung der Kundenrückmeldungen ein von Anwendern akzeptiertes Cloud-Portfolio geschaffen werden.
17.04.21;17.09.21;2021;extern;Bachelor;DE;"Konzeption und prototypische Implementierung eines Dashboards zur kontrollierten Begleitung des Portfoliowandels im Rahmen der ""Cloud-only""-Strategie bei der DATEV eG";"Die neue strategische Ausrichtung der DATEV e.G. erfordert in den kommenden Jahren einen zunehmenden Abzug von Mitarbeitern aus der Weiterentwicklung und Wartung der OnPremise-Bestandsprodukte in die Neuentwicklung einer Cloud-Generation.<br><br>In dieser Arbeit wird ein prototypisches Dashboard entwickelt, welches durch die Darstellung von relevanten Metriken bei der Steuerung und Kontrolle dieser Ressourcenumschichtung unterstützt und den Verlauf des ""Gesundheitszustands"" der Produkte über den Verlauf des Portfoliowandels abbildet.<br><br>Für die Konzepterstellung werden Datenquellen untersucht, Metriken verschiedener Sichtweisen ermittelt und ein Konzept zur Integration dieser Daten erarbeitet. Anschließend wird der Entwurf anhand geeigneter Technologien implementiert und zuletzt anhand eines Benutzertests evaluiert.<br>"
19.04.21;17.09.21;2021;extern;Bachelor;DE;Untersuchung der nativen Schnittstellen zur Einbindung von C++ in<br>iOS, Android und NodeJs basierten Anwendungen;Diese Arbeit beschäftigt sich mit der Integration von C++ in Android-, iOS- und Node.js-Anwendungen.<br>Die Arbeit zeigt Anwendungsfälle auf, in welchen die Integration von C++ sinnvoll sein kann. Außerdem werden Konzepte vorgestellt, wie eine bestehende C++-Bibliothek auf der jeweiligen Plattform integriert werden kann. Mit diesen Konzepten wurde anschließend eine Beispielanwendung erstellt, welche im Laufe der Arbeit im Detail gezeigt wird.<br>Im Zuge dessen wurde ein Test durchgeführt, um zu erfahren wie der Aufruf von C++-Funktionen auf den jeweiligen Plattformen die Geschwindigkeit der Applikationen durch die Übergabe von Funktionsparametern zwischen C++ und der Plattform einschränken kann.<br>Zuletzt findet eine Zusammenfassung sowie eine Auswertung der Ergebnisse statt.
20.04.21;20.12.21;2021;extern;Master;DE;Event-basierte Auditierung von Softwareapplikationen über den gesamten Entwicklungsprozess;Ziel der Abschlussarbeit ist es relevante Fragestellungen über den Lebenszyklus einer Softwarekomponente zu identifizieren und diese anhand eines Prototyps zu beantworten. Dazu werden die Grundlagen erläutert, die für eine Event-basierte Auditierung notwendig sind, sowie auf den Ursprung der relevanten Events, die während der Entwicklung auftreten, eingegangen. Weiterhin wird die Technologie Apache Kafka erläutert, die die Events als Messages abspeichert und zentral zur Weiterverarbeitung bereitstellt. Dabei ist entscheidend, wie Events einer Softwarekomponenten zugeordnet werden können. Als praktische Umsetzung wird ein Prototyp entworfen, der einer Producer-Consumer Architektur folgt. Dieser wird die entstehenden Events erfassen, aufbereiten und an die Streaming Plattform Kafka senden (Producer), sowie anhand einer Fragestellung die relevanten Events von Kafka beziehen und auswerten, sodass die Fragestellung beantwortet werden kann (Consumer).
20.04.21;20.09.21;2021;extern;Bachelor;DE;Transformer-Technologien zur Analyse von Bewerberdaten;"With the continuous further development of machine learning methods, a growing area of application of artificial intelligence is opening up for companies. <br>Especially large enterprises have an increasing interest in the most advanced information technologies in this area to increase the efficiency and in the best case effectiveness of their processes. One process that is being mastered by an increasing number of large companies, with the support of Artificial Intelligence, is that of personnel selection. The creation of artificial intelligence that supports the process of personnel selection is associated with development effort and is only accessible in the internal corporate environment. Thus, there are only isolated projects in the public domain, which are general and do not suit to any specific company. The focus of this work is on the development of an artificial intelligence using BERT (Bidirectional Encoder Representations from Transformers) the state-of-the-art machine learning technique in natural language processing. This is to bring the company Dr. Schneider Unternehmensgruppe a time saving in the process of personnel selection, by the preselection of individual applicants, in each case into one of the categories: ""acceptance"" or ""rejection"" or by comparing the text similarity between resumes to a specific job posting.<br>For this purpose, four variants are developed, evaluated and compared in this thesis in order to finally determine the most suitable one.  "
21.04.21;21.09.21;2021;extern;Bachelor;DE;Evaluierung einer WEB IDE im Unternehmenseinsatz ;Die zugrunde liegende Arbeit beschäftigt sich mit der Evaluierung einer Web IDE im Unternehmenseinsatz. Im ersten Schritt wird die momentane Entwicklungsumgebung des Unternehmens beschrieben und die damit verbundenen Probleme aufgezeigt. Daraus abgeleitet folgt eine Anforderungsanalyse, in welcher die Anforderungen an eine zukünftige Web IDE definiert werden. In der Konzeptionsphase werden zuerst die lokale und die webbasierte IDE in Vergleich gesetzt. Anschließend werden anhand von definierten Kriterien zwei bestehende Web IDEs (Gitpod und Eclipse Che) verglichen und bewertet, um die präferierte Web IDE in der Realisierung einzurichten. Die Einrichtung einer Web IDE in der eigenen Infrastruktur (Selbst Hosten) erfordert ein Hostkonzept. Dafür wird Kubernetes als Grundlage einer Web IDE beschrieben und die Konzepte von Kubernetes erklärt. Eine Schnittstellendefinition mit einem allgemeinen Komponentendiagramm rundet das Hostkonzept ab. Zuletzt folgt die prototypische Realisierung der Web IDE. Diese handelt von der Einrichtung und Verwaltung eines Kubernetes Clusters in der Cloud und beschäftigt sich ebenso mit der Installation und Konfiguration der Web IDE auf einem Kubernetes Cluster. Schließlich wird die Web IDE anhand der Anforderungen aus der Anforderungsanalyse bewertet. Eine Zusammenfassung über die Thematik und ein Ausblick über eine mögliche Zukunft einer Web IDE vervollständigt die Bachelorarbeit.
23.04.21;23.12.21;2021;extern;Master;DE;Robotic Process Automation für die automatisierte Verwaltung von Serversystemen im Unternehmen;Diese Arbeit untersucht den Einsatz von Robotic Process Automation (RPA) für die automatisierte Verwaltung von Serversystemen in einem Unternehmen. Es werden Geschäftsprozesse, die von der Serverbeantragung bis zur -bereitstellung benötigt werden, identifiziert, untersucht und ggf. automatisiert. Für die Verwaltung der Automatisierungen wird eine Web-Anwendung entwickelt.<br><br>Nachdem in den Grundlagen die Begriffe Geschäftsprozess, Digitalisierung, Automatisierung und RPA erläutert und ein Einblick über verwendete Frameworks gegeben wird, folgt die Anforderungsanalyse und Implementation. Zuletzt werden die Ergebnisse beschrieben, diskutiert und ein Fazit gezogen.<br><br>Die Ergebnisse zeigen, dass nicht jeder Geschäftsprozess oder jeder Teilschritt eines Geschäftsprozesses ohne Anpassung automatisierbar ist. Es gibt technische, aber auch administrative Gründe, warum ein Geschäftsprozess nicht automatisiert werden kann. Zusätzlich zeigt sich, dass RPA insbesondere für Systeme, die kaum noch Aktualisierungen erhalten, sinnvoll sein kann. Für Systeme, die regelmäßig Änderungen erhalten, steigt der Wartungsaufwand, wenn RPA menschliches Verhalten imitiert, da mit der Aktualisierung oder Veränderung eines Systems ggf. auch eine Aktualisierung des RPA-Programmcodes einhergeht. Es müssen demnach für die Automatisierung von Geschäftsprozessen mittels RPA unterschiedliche Faktoren berücksichtigt werden, und so im Einzelfall entschieden werden, inwieweit ein (Teil-)Prozess automatisierbar ist.
26.04.21;26.09.21;2021;intern;Bachelor;DE;SWOT-Analyse zu unterschiedlichen Lehrformen in der Hochschullehre mithilfe von Literatur- und Datenanalysen.;Die Digitalisierung und der damit einhergehende technische Wandel beeinflussen zunehmend die Lehrformen an deutschen Hochschulen. Dieser Effekt wurde durch die Corona-Pandemie verstärkt. Die für diese Arbeit festgelegten Lehrformen, Präsenzveranstaltung, eLearning, Blended Learning, Inverted Classroom und Selbststudium, beeinflussen das Lern- und Studienverhalten. Es müssen langfristige Veränderungen herbeigeführt werden, um technischen sowie didaktischen Herausforderungen, gerecht zu werden.<br>Bisweilen existieren keine Studien oder Analysen über Stärken, Schwächen, Chancen und Risiken einzelner Lehrformen, welche einen Vergleich untereinander ziehen. <br>Das Ziel der Bachelorthesis ist es, eine SWOT-Analyse je Lehrform zu erstellen, um die folgenden Forschungsfragen zu beantworten: Welche Stärken sowie Schwächen und welche Chancen sowie Risiken existieren je Lehrform? / Welche Lehrform ist zukünftig am erfolgversprechendsten und sollte durch welche Maßnahmen (im Ansatz) gefördert werden?<br>Hierzu fließen Aspekte theoretischer Begriffsbestimmungen, eine systematische Literaturanalyse (Studien) sowie geführte Interviews und Fragebögen mit Studierenden und Lehrenden ein.<br>Die Forschung zeigt detailliert ein abschließendes Big Picture aller Lehrformen und weist somit alle Aspekte der SWOT-Analysen auf. Ferner belegen die Analysen, dass es notwendig ist, das gesamte Spektrum an Lehrformen für Studierende und Lehrende zu realisieren. <br>
26.04.21;26.09.21;2021;intern;Bachelor;DE;Einsatz von Gamification und E-Learning zur Unterstützung der Erstsemester-Studierenden in der Distanzlehre.;Die vorliegende Arbeit befasst sich mit dem Einsatz von Gamification und E-Learning zur Unterstützung der Erstsemester-Studierenden in der Distanzlehre. Zunächst werden die Grundlagen über Gamification und E-Learning erläutert. Danach werden die vorhandenen Gamification-Elemente aus H5P und Alice 3 herausgesucht und dargestellt. Schließlich wird die Eignung von H5P und Alice 3 für Erstsemester-Studierende bewertet.
30.04.21;30.09.21;2021;extern;Bachelor;DE;Potenziale und Herausforderungen einer softwaregestützten Organisationsintegration mit Simulationen;
30.04.21;30.09.21;2021;intern;Bachelor;DE;Erfassung und Analyse von Problemen in unterrepräsentierten Gruppen von Studierenden während der COVID-19-Pandemie mithilfe von Daten aus Internetbeiträgen.;Die vorliegende Arbeit befasst sich mit dem Einsatz von Themenmodellierung und Sentiment-Analyse zur Auswertung von Beiträgen in sozialen Netzwerken und Internetforen. Das Ziel liegt dabei in der Erfassung und Auswertung von Problemen in unterrepräsentierten Gruppen von Studierenden während der COVID-19-Pandemie. Dazu dient eine umfangreiche Datenbasis, die von Beiträgen aus mehreren Foren und sozialen Netzwerken bezogen wurde. Analysiert werden die Dokumente zunächst über deren Metadaten und anschließend über Verfahren des maschinellen Lernens wie der Themenmodellierung und Sentiment Analyse. Bei der Auswertung zeigt sich vor allem die Kombination beider Methoden in der Betrachtung der Textkorpora als aufschlussreich. Die Identifikation der Fokusgruppe ist in den verwendeten Textbeiträgen hingegen nicht möglich. Nachdem Herausforderungen und Probleme, auch während der COVID-19-Pandemie, durch eine Vielzahl an Umfragen und Studien bekannt sind, ist dennoch eine Auswahl der Texte nach deren Gruppierung in Themen möglich. In der Betrachtung des Zeitverlaufs mit den verwendeten Auswertungsmethoden der Themenmodellierung können jedoch keine signifikanten Änderungen über den Betrachtungszeitraum festgestellt werden. Dennoch lassen die Ergebnisse eine weitergehende Forschung und Betrachtung der bezogenen Daten zu.
30.04.21;02.11.21;2021;intern;Bachelor;DE;Herausforderungen COVID-19: Analyse der Hindernissfaktoren bei unterrepräsentierten Studentengruppen in ihrem Distanzunterricht, unterstützt durch die Methoden der Künstlichen Intelligenz.;
03.05.21;16.09.21;2021;extern;Bachelor;DE;Neukonzeption und Implementierung einer Cross-Plattform-App zur Bereitstellung von Automotive-Spice-Prozessmodellen;Im Rahmen dieser Bachelorarbeit wird eine bestehende App zur Bereitstellung von Automotive-Spice-Prozessmodellen in Zusammenarbeit mit der Method Park Engineering GmbH neukonzipiert und implementiert. Zu Beginn wird die oben genannte App, welche mit Hilfe des Ionic 3 Frameworks erstellt wurde, innerhalb einer Ist- und Schwachstellenanalyse untersucht. Danach werden aktuelle Cross-Plattform-Technologien miteinander verglichen und abgewogen, welche die ideale Technologie für das zu bearbeitende Projekt ist. Anschließend wird mit Hilfe des ausgewählten Frameworks ein Prototyp der App, inklusive neuer Features, implementiert. Ziel dabei ist es die App in Usability- und Funktionalitätsaspekten auf den neusten Stand zu bringen und die zukünftige Instandhaltung zu vereinfachen.
03.05.21;03.01.22;2021;intern;Master;EN;Evaluation of Fairness Tools to Assess Machine Learning Algorithms for Pedestrian Detection;
03.05.21;18.10.21;2021;intern;Bachelor;DE;Analyse von Ontologiesprachen und Entwurf einer Ontologie mit Einsatzszenarien;Ontologien werden mit der zunehmenden Nachfrage nach Methoden zur Speicherung, Verwaltung und Erweiterung von Daten immer wichtiger. Ein besonderes Problem ist die Tatsache, dass es viele Ontologiesprachen gibt, aus denen man wählen kann, und ohne umfassende Kenntnisse ist der Auswahlprozess eine Herausforderung. Die vorliegende Bachelorarbeit versucht, dieses Problem anzugehen. Zunächst werden Ontologien auf einer allgemeinen Ebene erklärt. Danach werden drei Ontologiesprachen analysiert, ihre jeweiligen Syntaxen, Vor- und Nachteile und praktischen Einsatzbereiche dargestellt. Es wird eine Wissensbasis ausgewählt und eine Ontologiesprache, die zu ihrer formalen Beschreibung verwendet wird. Danach wird eine Bewertung der Wissensbasis auf der Grundlage der in der Forschungsphase gesammelten Informationen und Erkenntnisse durchgeführt. Abschließend werden Vorschläge zur Weiterentwicklung der Ontologie gegeben.
10.05.21;10.01.22;2021;extern;Master;EN;Development and Evaluation of a Smart Home Interface based on Electrostatic Tactile Feedback for Visually Impaired Users;Since navigation in unknown environments imposes challenges for visually impaired people, tactile floor plans are used to convey spatial information. These plans are usually fabricated by hand in a time-consuming process and are non-interactable. <br>Although digital solutions solve this problem, the conveyed haptic feedback is not as accurate. <br>This paper thus investigates the presentation of tactile floor plans on an electrostatic display by Tanvas Inc. Besides the exploration of tactile floor plans, the presented system offers the possibility of voice interaction as well as the control of smart home devices. The underlying work additionally describes the technical basics of the utilized display and a prototypical implementation of the solution concept. A two-part user study investigated the extent to which graphic elements can be displayed with electrostatic tactile feedback on the one hand. On the other hand, interaction, as well as exploration strategies, for the described system were evaluated. The results of the study showed that graphic elements could be displayed and recognized on the Tanvas display. However, the subjects needed significantly more time for exploration compared to the presentation on a raisable pin display. It can be concluded that electrostatic tactile feedback can be used in combination with other modalities to enrich graphical applications.
10.05.21;22.11.21;2021;extern;Bachelor;EN;Acoustic event detection through use of deep learning algorithms;This thesis describes the integration of a Time Delay Neural Network (TDNN) as<br>well as a real-world low-resource dataset (target dataset) in the DcaseNet<br>framework. Dcase stands for Detection and Classification of Acoustic Scenes and<br>Events. The categories Acoustic Scene Classification (ASC), segment-based Event<br>Detection (TAG) and frame-based Event Detection with temporal occurrence (SED)<br>are considered. The target dataset is assigned to the category TAG. In addition<br>to the implementation of DcaseNet-V1 and DcaseNet-V2, a TDNN is implemented and<br>corresponding experiments with the focus on the target dataset are made. In<br>addition, the differences between Convolutional Recurrent Neural Networks<br>(CRNNs) and TDNNS in terms of multi-task learning frameworks and Transfer<br>Learning are worked out.
11.05.21;08.11.21;2021;extern;Bachelor;DE;Konzeption und Implementierung eines performanceoptimierten Data Mart zur Analyse von Support-Tickets;Im Rahmen dieser Bachelorarbeit wird ein Data Mart entwickelt und implementiert, um die Performance der interaktiven, aktuell genutzten Visualisierungen zu verbessern und deren Benutzerfreundlichkeit zu steigern.<br>Hierfür wird das Quellsystem und die zugehörigen Daten in der Datenbank zunächst analysiert. Auf diesen Daten wird ein Data Mart mithilfe der Software Alteryx aufgebaut, welcher diese soweit transformiert, dass sie schlussendlich in Form eines Extrakts an die Software Tableau weitergeleitet werden. Hier werden die benötigten Visualisierungen gebaut, um die Kennzahlen der Abteilung optisch ansprechend darzustellen.
16.05.21;16.10.21;2021;intern;Bachelor;DE;Entwicklung eines Leitfadens für die Einführung von Software-Asset-Management mit Schwerpunkt auf der Evaluation aktueller SAM-Software;Software (SW) ist wertvoll und elementar für den Geschäftserfolg eines Unternehmens. Eine konforme und optimierte Nutzung von SW minimiert nicht nur IT-Risiken, sondern auch -Ausgaben. Um dies zu gewährleisten, müssen Unternehmen Software Asset Management (SAM) einführen und proaktiv weiterzuführen.<br>Diese Arbeit bietet eine kompakte wissenschaftliche Einführung in das Thema SAM. In ihr werden die Herausforderungen einer SAM-Einführung und die maßgeblichen Faktoren für ein aktives SAM beschrieben. Ein generisches Konzept wurde entworfen, das Unternehmen schrittweise anleitet, SAM erfolgreich einzuführen. Um die Aufgaben im SAM effektiv auszuführen zu können, ist der Einsatz einer SAM-SW unabdingbar. Allerdings müssen bei der SW-Auswahl und -Einführung diverse Kriterien zur Entscheidungsfindung einbezogen werden. Daher widmet sich der nächste Teil dieser Arbeit der ausführlichen Beschreibung einer systematischen Vorgehensweise bei der Einführung eines SAM-Tools. Basierend auf Fachliteratur wurde ein Bewertungsverfahren ausgearbeitet und anschließend angewendet.<br>Für die SAM-SW der Hersteller Vector Networks, Matrix42, InvGate, ManageEngine und Belarc wurden eine Evaluation durchgeführt. Das Ergebnis zeigt auf, dass die SAM-SW von Matrix42 für den in dieser Bachelorarbeit betrachteten Anwendungsfall ? SAM-SW für Unternehmen, die kein SAM haben oder bei denen SAM zwar eingeführt wurde, aber noch keine verlässliche Datenbasis generiert ? am besten geeignet ist.
17.05.21;14.10.21;2021;extern;Bachelor;DE;Prototyp zum automatisierten Datenaustausch von Tabellendefinitionen zwischen Business Central und Qlik Sense;In dieser Bachelorarbeit wird ein Prototyp zur automatisierten Datenübertragung zwischen Business Central und Qlik entworfen. Aufgrund der Verschiebung in die Cloud von Business Central ist ein Weiterführen der alten Lösung navDiscovery nicht mehr möglich. Über die Schwachstellenanalyse werden die Anforderungen definiert und anschließend auf Machbarkeit untersucht. Aus diesen Komponenten wird eine Architektur entworfen und umgesetzt. Die Oberfläche basiert auf Mockups und wird mithilfe der vorgestellten Technologien umgesetzt.
17.05.21;17.10.21;2021;extern;Bachelor;DE;Standardisierte Ermittlung der Gesamtanlageneffektivität einer Paketsortieranlage;
18.05.21;04.12.21;2021;intern;Bachelor;DE;Weiterentwicklung einer Simulation eines an der Eulenhalswirbelsäule inspirierten Gelenkroboters in Unity3D<br>;Diese Forschungsarbeit befasst sich mit der Weiterentwicklung einer inversen Kinematik,<br>welche im Vorfeld für die Simulation eines an der Eulenhalswirbelsäule inspirierten<br>Gelenkroboters entworfen wurde. Die Simulation findet über die Entwicklungsumgebung<br>Unity mithilfe eines speziellen Zusatzprogrammes statt. Durch das Erstellen von<br>Reachability Maps werden verschiedene Kombinationen von maximalen Winkelauslenkungen<br>der einzelnen Wirbel des Roboters simuliert und ausgewertet. Somit wird eine<br>mögliche Reduzierung der Winkel erarbeitet. Zusätzlich werden die Gelenkwirbel in<br>der Simulation binärisiert, wodurch nur noch die zwei maximalen Auslenkungswerte<br>von einem Wirbel angenommen werden können. Anschließend wird eine Schnittstelle<br>für die Datenübertragung aus der Unity-Anwendung an einen Arduino Mikrocontroller<br>angelegt.
21.05.21;02.12.21;2021;intern;Bachelor;DE;Predictive Maintainance in Schleifmaschinen auf RPI und ESP32;Ziel dieser Arbeit ist es, mittels geeigneter Machine-Learning-Verfahren, eine Aussage über<br>den aktuellen Abnutzungsgrad von Schleifpapier im laufenden Betrieb einer industriellen<br>Großschleifmaschine zu treffen. Ein weiterer Forschungsgegenstand dieser Arbeit ist die Adaption<br>auf eingebetteter Hardware. Exemplarisch wird dies anhand eines Raspberry Pis und<br>eines ESP32 Mikrocontrollers untersucht. Die Kommunikation der eingebetteten Hardware<br>mit einem geeigneten Broker basiert auf dem MQTT-Protokoll. Als Grundlage liegt ein Datensatz<br>mit Rohaufnahmen von Schleifgeräuschen vor. Für die Aufnahme der Daten, wird<br>für diese Arbeit ein IMNP441 Mikrofon verwendet.
26.05.21;26.10.21;2021;intern;Bachelor;DE;Erlernen einer Hexapoden-Gangart unter Anwendung von Reinforcement-Learning;Um das Ziel zu erreichen, einen Hexapoden zu befähigen, eine neue Gangart zu erlernen, wurde in dieser Arbeit ein Algorithmus implementiert, der auf dem DDPG-Algorithmus und der zugrunde liegenden Actor-Critic-Architektur aufbaut. Die Leistungsfähigkeit des implementierten Reinforcement-Learning-Systems konnte mithilfe einer OpenAI-Gym-Testumgebung erfolgreich nachgewiesen werden. Dieser Test zeigte auch, dass sich kein eindeutiges Muster einer Gangart ableiten lässt, da der Agent sehr situativ und individuell reagiert. Bei den für diese Arbeit vorgesehenen Trainingsprozessen, unter Verwendung des Bugbot-Simulators, stellte sich die Simulationsumgebung als Flaschenhals des Versuchsaufbaus heraus. Die eingeschränkte Simulationsgeschwindigkeit in Verbindung mit dem kontinuierlichen und hochdimensionalen Zustands- und Aktionsraum machte ein erfolgreiches Training aufgrund der eingeschränkten Zeit nicht möglich. Der enorme Zeitanspruch einzelner Trainingsdurchläufe war insbesondere mit Blick auf das grundsätzliche Optimierungsproblem von Reinforcement-Learning-Systemen kritisch. So konnten weitere wichtige Aspekte, wie beispielsweise eine passende Reward-Funktion oder eine optimale Lernrate, nur unzureichend getestet werden. Somit war eine finale Bewertung dieser nicht möglich. 
31.05.21;23.05.22;2021;intern;Bachelor;DE;Prototypische Ausarbeitung und Entwicklung einer Anwendung zur automatisierten Generierung von Newslettern;
31.05.21;31.01.22;2021;extern;Master;DE;Prognosemodell für Unternehmenskennzahlen - Ein Proof of Concept zur Unterstützung der EBIT-Planung eines Automobilzulieferers;Business Intelligence ermöglicht die Generierung von Erkenntnissen aus historischen sowie aktuellen Daten eines Unternehmens und unterstützt dadurch Managemententscheidungen. Um vorausschauend handeln zu können und den dadurch entstehenden Wettbewerbsvorteil zu nutzen, hilft Predictive Analytics. Hierbei werden nicht nur historische und aktuelle Daten analysiert, sondern auf Basis der Analysen zukünftige Entwicklungen vorhergesagt.<br><br>Das Ziel der vorliegenden Arbeit ist die Entwicklung eines Prognosemodells zur Vorhersage ausgewählter Kennzahlen in Form eines Proof of Concepts. Das Proof of Concept wird am Beispiel der EBIT-Planung eines Automobilzulieferers entwickelt. Um das Prognosemodell für Nutzende des Controllings bedienbar zu gestalten, wird es in eine Business Intelligence Anwendung integriert.<br><br>Für die Vorhersage werden historische Daten ausgewertet. Mittels statistischer Methoden wird daraufhin ein Prognosemodell entworfen. Der Fokus hierbei liegt auf Formen der exponentiellen Glättung. Das Prognosemodell ist in der Programmiersprache R geschrieben und in die SAP Analytics Cloud integriert. Diese erlaubt das Erstellen von Anwendungen, in denen durch JavaScript Logiken abbildbar sind.<br><br>Das Ergebnis ist eine Anwendung, die durch geeignete Visualisierungen die Prognose unterstützt und Spielraum für Korrekturen durch Experten bietet. Im Ausblick der Arbeit werden notwendige Schritte für eine Weiterentwicklung des Proof of Concepts zu einer produktiven Lösung geboten.
01.06.21;28.10.21;2021;intern;Bachelor;DE;Untersuchung der Einsatzmöglichkeiten von ROS für<br>existierende Roboter-Plattformen und beispielhafte<br>Umsetzung<br>;Das Ziel der Bachelorarbeit ist die Untersuchung der Einsatzmöglichkeiten des Robot Operating System (ROS) für die bereits vorhandenen Roboter-Plattformen an der Technische Hochschule Nürnberg Georg Simon Ohm (OHM), Carbot und Bugbot. Dabei wurde die Möglichkeit einer Migration der vorhandenen Software zu ROS untersucht sowie erforscht, wie diese umsetzbar wäre und eine mögliche Migrations-Strategie aussehe. Des Weiteren wurde die in dieser Bachelorarbeit vorgeschlagene Vorgehensweise anhand einer Komponente beispielhaft umgesetzt. <br><br>Dabei hat sich herausgestellt, dass eine vollständige Migration zu ROS ? im derzeitigen Entwicklungsstand ? mit Kompromissen möglich ist. Das gilt vor allem im Hinblick auf die verwendete Hardware der Roboter. Die partielle Migration von einzelnen Komponenten ist durch den Aufbau von ROS nur unter größeren Einschränkungen möglich. Für die beispielhafte Umsetzung einer Komponente, anhand der vorgeschlagenen Migrations-Strategie, wurden die Fortbewegungssteuerung des Carbots ausgewählt. Dafür wurde auch ein erstes Unified Robot Description Format (URDF) Modell des Carbots zur Simulation erstellt.<br><br>Für die Analyse der Migration wurden die vorhandenen Papiere zu den Robotern sowie die Offizielle Dokumentation von ROS und weitere Webseiten und Bücher zu ROS herangezogen.
07.06.21;07.02.22;2021;extern;Master;DE;Speicher-Dimensionierung des Rechnungswesen-Archivs: Prognosemethoden und deren prototypische Implementierung;Die Softwareentwicklungs-Teams des Unternehmens DATEV e.G. stehen einer zunehmenden Verantwortung für genutzte und zukünftig benötigte Infrastruktur gegenüber.<br>Ziel dieser Arbeit ist es ein geeignetes Vorgehen, welches auf mathematischen Grundlagen basiert, zu ermitteln, um dieser Verantwortung gerecht zu werden.<br>Als Beispiel wird das Umfeld des Rechnungswesen-Archivs herangezogen.<br><br>Es werden folgende Forschungsfragen gestellt:<br>- Welche Kennzahlen sind für das neue System des Rechnungswesen-Archivs relevant?<br>- Wie sind mögliche Prognose-Methoden im DATEV-Umfeld zu beurteilen?<br>-Welche für das IT-Controlling relevanten Schlüsse könnten sich mittels einer prototypischen Implementierung ziehen lassen?<br><br>Als wichtigste Kennzahl des Rechnungswesen-Archivs wurde der benötigte Speicherplatz identifiziert.<br>Diese wurden als Basis für die Analyse verschiedener Prognoseverfahren herangezogen.<br>Untersucht und implementiert wurden exponentielles Glätten nach Holt, einfache lineare Regression und Random Forests mit Regression Trees.<br>Dabei lieferte ersteres die höchste zu erwartende Genauigkeit und wurde deshalb als für diesen Anwendungsfall am besten geeignet eingeschätzt.<br>Allerdings unter Verlust der Erweiterbarkeit des Modells.<br><br>Aufgrund des Fehlens eines automatisierten Datenbeschaffungsmechanismus, hält sich der Einfluss auf das DATEV-IT-Controlling zunächst in Grenzen.<br>Dennoch legt diese Arbeit den Grundstein für weitere Forschung bei DATEV e.G. in diesem Bereich
09.06.21;09.05.22;2021;extern;Master;DE;Empirische Analyse der Verarbeitungszeit und des Ressourcenbedarfs von ungleich verteilten Datenbeständen in Apache Spark-Applikationen;Durch das exponentielle Wachstum der Daten innerhalb des letzten Jahrzehnts werden immer neuere Technologien zur Verarbeitung großer Datensätze benötigt. Eine dieser Technologien, die das ermöglicht, ist Apache Spark. Dessen Datenverarbeitung, verteilt auf mehreren Servern, nutzt bei der Speicherung seiner Zwischenergebnisse den Arbeitsspeicher, um die Performance zu verbessern. Die Daten, die in einem Big Data-Cluster gespeichert werden, können in ihrem Datenschema variieren. Von strukturierten Daten bis hin zu Texten, Bildern oder anderen Beiträgen können viele verschiedene Daten mit einem Big Data-Cluster verarbeitet werden. Dabei können ungleich verteilte Datensätze entstehen. Die Verarbeitung dieser Datensätze in einer Spark-Applikation und die Optimierung derer sind die zwei Themen dieser Arbeit. Zuerst wird die Erkennung von ungleicher Gewichtung behandelt, gefolgt von den Einflüssen auf die exemplarisch verwendete Spark-Applikation. Danach folgt die Optimierung der zugewiesenen Ressourcen (Arbeitsspeicher sowie CPU-Kernen) dieser Applikation, damit die Ausführungszeit minimiert wird. Das dafür vorgeschlagene Modell und das Verfahren zur dynamischen Ressourcenverteilung ermöglichten eine durchschnittlich Verkürzung der Ausführungszeit von 20\%. Zum Schluss wird ein kurzer Ausblick gegeben, wie sich das Verfahren in einer Spark-Applikation integrieren lassen könnte.
14.06.21;11.04.22;2021;extern;Master;DE;Konzeption und prototypische Umsetzung einer semantischen Suchfunktion mit maschinellen Lernverfahren für einen Content Hub;Das Ziel in der vorliegenden Masterarbeit war es, eine semantische Suchfunktion für den<br>Analytical Content Hub der ERGO Group AG zu konzeptionieren und prototypisch zu im-<br>plementieren. Dafür wurden aktuelle Ansätze der kontextbeachtenden Sprachmodellierung<br>mit traditionellen Konzepten der lexikalischen Suche verglichen. Zudem wurde lange Text-<br>dokumente mithilfe von Sentence Embeddings repräsentiert, in einen Index eingepflegt, nach<br>ihrer Relevanz sortiert und über eine HTTP-Schnittstelle durchsuchbar gemacht. Für die<br>Umsetzung wurden Sprachmodelle auf der Basis von Transformern und Attention wie Bi-<br>directional Encoder Representations from Transformers (BERT) sowie die Indizierung von<br>Texten via Facebook AI Similarity Search (FAISS) und Elasticsearch eingesetzt. Die Imple-<br>mentierung zeigt exemplarisch, wie die Bedeutung von Suchanfragen und Texten modelliert<br>werden und dadurch Anwendern innerhalb des Unternehmens zukünftig den betriebswirt-<br>schaftlichen Einsatz verfügbarer Informationen erleichtern kann.
17.06.21;08.11.21;2021;extern;Bachelor;DE;Analyse und Aufbau eines strukturierten Datawarehouse-Ansatzes für Kunden eines mittelständischen Beratungsunternehmens;
18.06.21;18.11.21;2021;intern;Bachelor;DE;Strategien zur Flächenreinigung durch autonome mobile Roboter;
21.06.21;21.02.22;2021;extern;Master;EN;Automatic Speech Recognition with KALDI and ESP.NET and Various Language Models for a Legal Language Corpus;Im Zuge dieser Thesis wurden moderne Spracherkennungsmodelle betrachtet, mit besonderem<br>Fokus auf deren Eignung auf den speziellen Anwendungsfall deutscher Steuerrechtssprache.<br>Darüber hinaus wurde eine Methode entwickelt und evaluiert, um existierende Spracherkennungsmodelle<br>auf diesen speziellen Fall zu adaptieren. Dafür wurden konventionelle und<br>End-To-End Modelle untersucht und mit Blick auf Adaptierungsmöglichkeiten verglichen.<br>Ein Hauptaspekt dieser Arbeit war das Modellieren dieser Fachsprache mithilfe von deutschen<br>Steuerrechtsdokumenten. Sowohl n-gram Sprachmodelle als auch Sprachmodelle auf Basis<br>von rekurrenten neuronalen Netzen (RNNLMs) wurden benutzt, um das optimale Spracherkennungsmodell<br>für den speziellen Anwendungsfall zu bestimmen. Für die Evaluierung der<br>Modelle wurde, mithilfe freiwilliger Leser, ein spezieller Evaluationsdatensatz erstellt, der<br>gelesene Texte aus dem Kontext des deutschen Steuerrechts enthält. In Experimenten konnte<br>gezeigt werden, dass die adaptierten Modelle eine signifikant bessere Erkennungsrate<br>erreichen. Das beste adaptierte Spracherkennungsmodell weist eine TDNN-HMM Architektur<br>auf und basiert auf einem linear interpoliertem n-gram Sprachmodell. Es erreicht eine<br>Wortfehlerrate (WER) von unter 5% nach RNNLM Rescoring. Im Vergleich zu dem besten<br>Basismodel, das eine WER von etwa 20% erreicht, entspricht das einer relativen Reduktion<br>der Wortfehlerrate von etwa 75%.
05.07.21;05.12.21;2021;intern;Bachelor;DE;Konzeption, Implementierung und Evaluation einer Android-Applikation zur Etablierung neuer Gewohnheiten;Gewohnheiten bestimmen annähernd die Hälfte unseres täglichen Handelns, was ein hohes Potenzial mit sich bringt, um das alltägliche Leben gezielt zu vereinfachen. Hier setzt die vorliegende Bachelorarbeit an und befasst sich mit der Etablierung neuer Gewohnheiten mit Hilfe einer Android-Applikation. Dafür werden im ersten Schritt die Entstehung und der Ablauf von Gewohnheiten betrachtet. Im Anschluss wird ein Konzept für eine prototypische Applikation entwickelt, welche den Benutzer bei der Etablierung neuer Gewohnheiten unterstützt. Auf Basis des Konzepts wird dann in Android Studio, der offiziellen Entwicklungsumgebung für Android-Applikationen, ein lauffähiger Prototyp entwickelt. Dieser wird einen Monat lang von über 20 Probanden genutzt und dabei auf seine Anwendbarkeit und Funktionsweise getestet. Zur Evaluation wird ein Fragebogen entworfen, den Probanden zur Verfügung gestellt und anschließend ausgewertet. Die in dieser Arbeit gewonnenen Erkenntnisse können bei der zukünftigen Entwicklung von Android-Applikationen mit sozialwissenschaftlichem Kontext genutzt werden.
19.07.21;19.12.21;2021;intern;Bachelor;DE;Analyse eines iterativen Verfahrens zur Berechnung von dichten Merkmalskorrespondenzen unter Verwendung homographischer Dekomposition für die Photogrammetrie;Fotografie projiziert eine dreidimensionale Szene auf ein zweidimensionales Bild, bei der<br>Informationen über die Geometrie der Szene verloren gehen. Photogrammetrie versucht,<br>diesen Vorgang umzukehren und ein 3D-Modell der Szene durch Analyse mehrerer Bil-<br>der der Szene aus verschiedenen Perspektiven wiederherzustellen.<br>Durch Fortschritte in der 3D-Computergrafik ist es mittlerweile möglich, diesen Vorgang<br>zu automatisieren und aus mehreren Bildern ein 3D-Polygonnetz der Szene zu rekon-<br>struieren. Eine Herausforderung besteht darin, eine ausreichende Korrelation (die sog.<br>Merkmalskorrespondenzen) zwischen den Einzelbildern herzustellen, um ausreichend In-<br>formationen über die Geometrie der Szene zu erhalten.<br>Ziel dieser Arbeit ist es, ein neues, an der Technischen Hochschule Nürnberg Georg<br>Simon Ohm entwickeltes, iteratives Verfahren zur Berechnung von dichten Merkmals-<br>korrespondenzen unter Verwendung homographischer Dekomposition zu verwenden, um<br>festzustellen, wie dieses die Genauigkeit und visuelle Qualität der Rekonstruktion beein-<br>flusst.
01.08.21;23.03.22;2021;extern;Master;DE;Anwendung und Evaluation eines methodischen Gamification-Prozesses zur Identifikation und Lösung motivationaler Probleme bei der Führung eines Sucht-Tagebuches;Diese Arbeit beschäftigt sich mit der Beantwortung der Frage: Ist es mithilfe der EMPAMOS -Methodik möglich, einen spielfremden Kontext so zu modifizieren, dass eine motivationale Steigerung erzeugt werden kann? Als spielfremder Kontext wurde die Suchtberatung gewählt. Während der Betreuung von suchtkranken Menschen wird häufig ein Sucht-Tagebuch eingesetzt. Bei der Führung des Tagebuchs entstehen bei suchtkranken Menschen aufgrund von starker emotionaler und körperlicher Belastung häufig Motivationsdefizite. Diese sollen durch eine Anwendung, welche durch die Durchführung der EMPAMOS-Methodik konzeptioniert wird, verringert werden. Der erste Schritt dieser Arbeit war die Einarbeitung in die Thematik der Sozialarbeit und Suchtberatung, um die Hintergründe vorhandener motivationaler Probleme zu identifizieren. Basierend darauf wurde die EMPAMOS-Methodik angewandt und dadurch ein Konzept entwickelt, welches motivationale Probleme lösen soll. Dieses Konzept wurde prototypisch in einem digitalen Sucht-Tagebuch realisiert. Die entwickelte Lösung wurde mit Klienten von Beratungsstellen getestet und die Ergebnisse wurden mithilfe eines Evaluationsprozesses kontrolliert. Hierbei wurde überprüft, ob die durch die Anwendung der EMPAMOS-Methodik konzeptionierte Konzeptidee zu einer motivationalen Steigerung führt. Die Ergebnisse der Evaluation zeigen, dass mithilfe der EMPAMOS-Methodik ein Lösungskonzept entwickelt werden kann, welches eine positive motivationale Steigerung auslöst.
16.08.21;16.01.22;2021;intern;Bachelor;DE;Konzeption und prototypische Implementierung eines Systems zur automatischen Generierung von Kompetenzprofilen;Die von der Fakultät Informatik an der Technischen Hochschule Nürnberg entwickelte Hochschuljobbörse bietet Studierenden von 17 Hochschulen innerhalb Bayerns eine Plattform für Werkstudententätigkeiten, Praktika und Abschlussarbeiten.<br>Das Angebot der Hochschuljobbörse soll nun dahingehend erweitert werden, dass sich sowohl Unternehmen als auch Professoren und Studierende auf einer Plattform durch Inserate und Kompetenzprofilen zu einem gemeinsamen Transferprojekt zusammenfinden können.<br>Zielsetzung dieser Arbeit ist die automatische Generierung von Kompetenzprofilen von Professoren aus allen bayerischen Hochschulen auf Basis öffentlicher Informationsquellen, um sie in das Matching-System des zukünftigen Hochschultransferforums einbinden zu können. Der Datensatz der Professoren der Informatik soll zusätzlich im Ansatz nach einer Fachsystematik kategorisiert und in einem Suchserver indexiert werden.<br>
23.08.21;23.01.22;2021;intern;Bachelor;EN;Fuzzing D-Bus Applications;Fuzzing, a technique to uncover bugs and vulnerabilities in programs by using randomized<br>data as input, is widely used by security researchers and has brought some dangerous vul-<br>nerabilities to light. D-Bus (Desktop Bus) is a messaging system for application used in<br>most Linux distributions.<br><br>The purpose of this study is to develop a solution to fuzz applications that receive data<br>over the D-Bus. This should be done in a way that can be applied universally to most<br>applications, without the need for major modification of the applications.<br><br>To achieve this, different approaches to fuzzing D-Bus applications are first analyzed, and a<br>suitable solution is designed. This will be implemented as a prototype and tested on several<br>applications as examples.<br><br>The result of this work is an easily extendable fuzzer that is already able to fuzz signals and<br>properties of applications connected to the D-Bus.
24.08.21;24.01.22;2021;extern;Bachelor;EN;Application for generating shareable social media content using web-based augmented reality technologies on mobile devices;
01.09.21;30.01.22;2021;intern;Bachelor;DE;Entwicklung eines Prototyping-basierten Simulators, um situationsabhängige Entscheidungen von Menschen nachvollziehen und im Sinne nachhaltigen Handelns fördern zu können;Um das Pariser Klimaabkommen einzuhalten, müssen wir Menschen nachhaltiger handeln.<br>Das Ziel dieser Arbeit ist es, einen Prototyping-basierten Simulator zu entwickeln, um herauszufinden, ob man die Entscheidungen von Menschen im Sinne nachhaltigen Handelns fördern kann. Zur Modellierung des simulierten Kontext werden die BPMN (Business Process Model Notation) und die DMN (Decision Model and Notation) verwendet. Anschließend werden zwei Prototypen des Simulators entwickelt und mit Thinking-Aloud-Tests evaluiert. Der erste Prototyp ist ein Clickdummy und soll die Visualisierung des Simulators testen. Die Tests ergeben, dass eine gute Visualisierung für den Simulator gefunden werden konnte. Der zweite Prototyp besteht aus zwei Simulationen und setzt diese Visualisierung in einer Webanwendung um. Bei beiden Simulationen handelt es sich um die gleiche Situation, jedoch hat man bei einer Simulation gewisse Entscheidungshilfen zur Verfügung. So wird der zweite Prototyp, mit der Testmethode Within Subject Design, getestet und es wird analysiert, ob sich die Testpersonen mit diesen Entscheidungshilfen für nachhaltigere Optionen entscheiden. In 47% der Fälle, in denen eine Entscheidungsänderung getroffen wurde, wurde in der zweiten Testrunde eine nachhaltigere Alternative gewählt. Zusätzlich konnte herausgefunden werden, dass sich die Testpersonen, im direkten Vergleich der beiden Testrunden, in der zweiten Testrunde sicherer gefühlt haben und zufriedener sind.
01.09.21;01.05.22;2021;intern;Master;DE;Entwicklung einer problemorientierten Sprache zur intuitiven Erstellung von Sensornetzanwendungen.;Das Ziel der vorliegenden Arbeit war es, eine allgemeine problemorientierte Sprache zur Erstellung von Sensornetzanwendungen zu entwickeln. Dabei soll der Benutzer keine hardwarespezifischen Entwicklungsarbeiten mehr durchführen müssen. Es soll zu keinen Einschränkungen durch die Sprache bzgl. der verwendeten Kommunikationsprotokolle kommen und es soll möglich sein, das Routing innerhalb der Sensornetzanwendung durch diese Sprache zu beschreiben. Zur Erreichung dieses Ziels wurde eine allgemeine regelbasierte Sprache zur Beschreibung von Sensornetzanwendungen entwickelt. Die Sprache implementiert dabei einen ereignisorientierten Ansatz. Damit kein eigener Parser entwickelt werden musste, wurde die Auszeichnungssprache HCL als Grundlage für die Syntax der Sprache verwendet. Spezifischere Funktionen, wie z.B. die Realisierung einer Kommunikationsschnittstelle, wurden in Form einer Bibliothek umgesetzt. Um die regelbasierte Sprache auf ihre Praxistauglichkeit überprüfen zu können, wurde ein Prototyp für Sensorknoten vom Typ Zolertia RE-Mote erstellt. Dieser besteht aus einem Code-Generator und einer Laufzeitumgebung. Als Grundlage für die Laufzeitumgebung dient das IoT-Betriebssystem RIOT-OS. Der Quellcode der Laufzeitumgebung kann zusammen mit dem generierten Code in ein Firmwareimage compiliert werden. Mit dem Prototyp konnte gezeigt werden, dass die regelbasierte Sprache zumindest für die problemorientierte Beschreibung einfacher Sensornetzanwendungen geeignet ist.
01.09.21;25.01.22;2021;extern;Bachelor;DE;Framework zur teilautomatischen Parameteroptimierung<br>von Bildverarbeitungen zur Detektion von Fehlstellen an Prüfteilen;Die Intego GmbH beschäftigt sich mit der Herstellung von Kameraprüfsystemen zum Einsatz im industriellen Umfeld, zum Beispiel den Bereichen Solar, Halbleiter und Medizintechnik. Für viele dieser Prüfsysteme ist eine systemspezifische Parametrisierung der verwendeten Bildverarbeitungselemente notwendig.<br><br>Ziel der vorliegenden Arbeit ist die Erstellung eines Frameworks zur Optimierung der Parameter der in Prüfsystemen verwendeten Bildverarbeitungselemente.<br><br>Zur Durchführung des Optimierungsprozesses kommt ein Hauptsystem, welches den Optimierungsprozess verwaltet, sowie ein bis mehrere Systeme, welche die Bildverarbeitung durchführen, zum Einsatz.<br>Zur Kommunikation zwischen dem Hauptsystem und den Bildverarbeitungssystemen wird eine Nachrichtenschnittstelle auf Basis einer SQL-Datenbank erstellt.<br><br>Dem Anwender des Frameworks werden mehrere Optimierungsverfahren zur Verfügung gestellt, welche dieser zu einem gewissen Grad selbst konfigurieren kann.<br><br>Nach Abschluss der Implementierung werden die korrekte Funktion des Frameworks und der Optimierungsverfahren anhand mehrerer mathematischer Testfunktionen sowie einem Bildverarbeitungssystem überprüft und bewertet.<br><br>Abschließend wird unter Verwendung des Frameworks und eines Datensatzes, bestehend aus Aufnahmen von Silizium-Wafern, ein optimaler Parametersatz für ein Bildverarbeitungssystem zur Fehlerdetektion auf Silizium-Wafern bestimmt.
01.09.21;01.05.22;2021;extern;Master;DE;Erarbeitung eines Konzepts zur prototypischen Evaluation und Einführung eines Kabelsatzentwicklungsprozesses;"Die Kabelsatzentwicklung stellt im Prozess der Automobilentwicklung einen wesentlichen Teilbereich dar, schließlich wird über den Kabelsatz das gesamte Fahrzeug gesteuert. Doch so sehr bei dem Bauteil Wert auf Effizienz und Effektivität gesetzt wird, sind diese beiden Eigenschaften im zugehörigen Entwicklungsprozess weniger zu finden. Medienbrüche und manuelle Arbeitsschritte stellen lediglich zwei der im Kabelsatzentwicklungsprozess bei Mercedes-Benz Special Trucks vorherrschenden Probleme dar. Das Ziel dieser Arbeit besteht deshalb darin, einen neuen Soll-Prozess zu entwickeln, über den die Probleme behoben werden können. Dazu stellen sich drei wesentliche Forschungsfragen, die ebenfalls beantwortet werden sollen. Zunächst ist zu klären, welche Schwachstellen im aktuellen Ist-Prozess bestehen. Darüber hinaus gilt es zu prüfen, ob bereits bestehende Soll-Prozesse bei Daimler Trucks gelebt werden, die als Basis für die Konzeptionierung herangezogen werden können. Schließlich ist eine Möglichkeit zu finden, wie der entwickelte Soll-Prozess auf seine Praxistauglichkeit zu prüfen ist. Um diese Forschungsfragen zu beantworten, orientiert sich die Vorgehensweise an dem Referenzmodell der Prozessgestaltung. Über die Phasen ""Initialisierung"", ""Ist-Analyse"", ""Soll-Konzeption"" und ""Umsetzung"" wird der neue Soll-Prozess entwickelt und die dieser Arbeit zugrundeliegenden Forschungsfragen beantwortet. "
01.09.21;29.01.22;2021;extern;Bachelor;DE;Ausarbeitung eines ETL-Prozesses zur automatisierten und optimierten Erstellung von Auswertungen auf der Basis von strukturierten Dateien;Im Rahmen dieser Bachelorarbeit wird ein automatisierter Prozess ausgearbeitet, der die zyklisch angelieferten Datendateien in einem Workflow verarbeitet, um so eine aktuelle und detaillierte Visualisierung zu ermöglichen. Hierfür werden die benötigten Datendateien aus dem Quellsystem heruntergeladen und analysiert. Anschließend werden diese auf einem Netzwerklaufwerk abgelegt. Auf diese Datenbasis wird ein verarbeitender Workflow mithilfe der Software Alteryx aufgebaut. Die verarbeiteten Daten werden danach in einer Datenbank gespeichert. Die benötigten Visualisierungen werden mit der Software Tableau im Bezug auf die Datenbasis erstellt, um die Kennzahlen der Abteilung optisch ansprechend und übersichtlich darzustellen.
01.09.21;26.11.21;2021;intern;Bachelor;DE;Analyse von Herausforderungen und Erfolgspotenzialen von IoT bei Produktionsprozessen in der Elektronikbranche;Das Internet of Things erhält zunehmend Aufmerksamkeit in Unternehmen sowie in der Fachliteratur. Denn immer mehr erkennen das Potential. Gerade in der Produktion wird zukünftig der Einsatz des Internet of Things wachsen, da die Globalisierung und der steigende Konkurrenzdruck in der Elektronikbranche die Produktionsprozesse stetig vor neuen Herausforderungen stellt. Grund dessen wird kontinuierlich nach Optimierungen und neuen Ansätzen geforscht, wie die Produktionsprozesse durch das Internet of Things verbessert werden können. Diese Ausarbeitung beschäftigt sich mit der Identifizierung und Untersuchung dieser neuen Methoden in der Produktion der Elektronikbranche. Als Ergebnis dieser Arbeit werden die Use Cases identifiziert und die Einsatzmöglichkeiten mit Hilfe des Internet of Things mit den aktuellen Prozessen verglichen. Ebenso werden die Erfolgspotentiale und Herausforderungen beim Einsatz, mit Bezug auf die Internet of Things Technologien, erläutert. 
01.09.21;31.01.22;2021;intern;Bachelor;DE;Herstellung von Kryptowährungen in der Kritik. Eine Analyse alternativer Herstellungsmethoden;Mittlerweile gibt es eine Vielzahl an Kryptowährungen, die durch unterschiedlichen Konsensmechanismen erzeugt werden. Bitcoin ist dabei mit Abstand die erfolgreichste und größte virtuelle Währung. Jedoch wird Bitcoin mit dem Proof-of-Work Mechanismus hergestellt, welcher sehr umweltschädlich ist und deshalb zunehmend kritisiert wird. Daher werden in dieser Arbeit alternative Konsensmechanismen aufgezeigt, die sowohl bei anderen Kryptowährungen als auch in Anwendungsbereichen außerhalb des Finanzsektors zum Einsatz kommen. Die Mechanismen werden anschließend anhand verschiedener Kriterien, wie z.B. Energieverbrauch oder Sicherheit bewertet. Bei der Bewertung liegt der Fokus darauf, besonders gute und besonders schlechte Eigenschaften der Mechanismen herauszufiltern. Im Anschluss werden die Konsensmechanismen mit Hilfe einer anschaulichen Tabelle anhand aller analysierten Kriterien bewertet. Ein abschließendes Fazit und ein Ausblick auf die Zukunft, runden die Arbeit ab.  
06.09.21;13.03.22;2021;extern;Bachelor;DE;Metriken der DATEV-Anwendungen effizienter im Kundenservice nutzen;In der DATEV eG liegen vielfältige Konfigurations- und Produktinformationen vor, die bei den Kunden bei Softwarenutzung gesammelt und ausschließlich mit deren Zustimmung übertragen werden. Auf Basis dieser großen Datenmenge ist eine erste Einschätzung des Kundensystems möglich. Auswertungsmöglichkeiten hierfür stehen im Kundenservice bisher jedoch nur in einem sehr begrenzten Umfang zur Verfügung. Ziel der Arbeit ist es, den aktuellen Status zu erheben und verwendete Parameter etwa zur Performance und Stabilität einzuschätzen. Aufbauend darauf wird eine umfangreiche Analysemöglichkeit konzipiert und umgesetzt. Die Metriken, wie beispielsweise die Dauer bestimmter Programmabläufe, werden dabei mit weiteren vorhandenen Daten angereichert und unterstützen so den Servicemitarbeiter bei der Bearbeitung der Kundenanfrage. Zusätzlich soll untersucht werden, ob und wie Automatisierungen bis hin zum Machine Learning bei der Analyse verwendet werden könnten.
06.09.21;20.01.22;2021;extern;Bachelor;DE;Konzeption und Entwicklung einer domänenspezifischen Sprache zur interaktiven Darstellung von Ergebnissen einer Steuerberechnung im Web;"Diese Arbeit beschäftigt sich mit der Konzeption und Entwicklung eines Proof-of-Concepts einer domänenspezifischen Sprache zur Anzeige von Listen im Browser im Rahmen einer Neuschreibung von Steueranwendungen der DATEV eG im Web. Dabei werden unterschiedliche Werkzeuge zur Entwicklung einer solchen domänenspezifischen Sprache betrachtet und die Entwicklungsumgebung ""MPS"" näher erläutert. Neben der Analyse der vorhandenen Entwicklung und der Befragung von Experten im Steuerrecht wird ein Prozess entwickelt, der für Anwender von domänenspezifischen Sprachen auf Basis von ""MPS"" mit der Zieltechnologie ""Web"" einen möglichst angenehmen und integrierten Entwicklungsprozess bietet, sodass einer effizienten Entwicklung nichts im Wege steht. Dieser Prozess wird durch ein Werkzeugfenster mit eingebetteten Browser für die Vorschau realisiert. Das Design und die Gestaltung einzelner Komponenten der domänenspezifischen Sprache wird auf Basis der Anforderungen entwickelt und begründet. Hier liegt ein besonderer Augenmerk auf die einfache Darstellung von komplexen Sachverhalten und der Benutzerfreundlichkeit im Umgang mit dem Inspektor in ""MPS"". Abschließend bewerten, im Rahmen einer Evaluation, Anwender der entwickelten Sprache die Umsetzung und vergleichen den Entwicklungsprozess mit dem aktuellen Prozess aus dem on-premises Programm. Die Ergebnisse werden bewertet und Schwächen sowie Probleme der DSL diskutiert, damit diese Erkenntnisse für eine produktive DSL genutzt werden können."
08.09.21;08.02.22;2021;intern;Bachelor;DE;Entwicklung und Evaluation eines Chatbot-Jobempfehlungs-System für einen unterstützenden Einstieg ins Arbeitsleben unterrepräsentierter MINT-Studierenden;Die Zielstellung der Arbeit ist, herauszufinden, ob ein Chatbot eine möglicher Ansatz und eine geeignete Hilfestellung beim Berufseinstieg unterrepräsentierter MINT-Studierenden/Absolventen ist. <br>Die berufliche Situation, mögliche Barrieren und die Indikatoren, welche die Berufswahl der unterrepräsentierten Zielgruppen beeinflusst wurden erforscht.<br>Dabei wurde der Empfehlungsalgorithmus und die Chatbot-Anwendung weiterentwickelt. Zusätzlich wurden Tests durchgeführt und die damit erzielten Evaluationsergebnisse sind vielsprechend. <br>Das Resultat ist, dass die Chatbot-Technologie ein guter Ansatz für die Unterstützung bei der Berufswahl ist.<br>
09.09.21;06.05.22;2021;intern;Master;DE;Steigerung von Agilität in der Softwareentwicklung mit Hilfe von Reifegradmodellen;Durch die vorliegende Arbeit wird das Ziel verfolgt, zu untersuchen, wie die Agilität in der Softwareentwicklung gesteigert werden kann. Im Mittelpunkt dieser Untersuchung steht der Einsatz von sogenannten Reifegradmodellen. Hierzu wird zunächst anhand einer Literaturrecherche untersucht, welche Reifegradmodelle für die Agilität, insbesondere innerhalb der Softwareentwicklung, existieren. Um deren Beitrag zur Steigerung der Agilität in der Softwareentwicklung zu untersuchen, werden diese Reifegradmodelle methodisch und inhaltlich untersucht und anschließend miteinander verglichen. Abschließend wird durch diese Analysen bewertet, wie Reifegradmodelle nutzbringend eingesetzt werden können und welche Kriterien bei der Auswahl eines geeigneten Modells beachtet werden sollten.
13.09.21;13.04.22;2021;intern;Master;DE;Verfahren zur Visualisierung der Arbeitsweise künstlicher neuronaler Netze;Das Verständnis über die internen Prozesse künstlicher neuronaler Netze (KNN) ist nach wie vor begrenzt, während deren Komplexität zunimmt. Entwickler behandeln diese meist als Black-Box und können oft nicht erklären, warum welche Eingabedaten mit dem größten Lernerfolg korrespondieren. Zu diesem Zweck kommen Visualisierungsverfahren zum Einsatz, um besser verstehen zu können wie ein Netz zu seiner Entscheidung kommt. Die Arbeit bietet hierfür einen Überblick über aktuelle Verfahren der Bereiche der Attribution, Dimensionsreduktion und Feature-Visualisierung zur Visualisierung der Arbeitsweise von KNN. Dabei gilt es zu untersuchen, wie diese funktionieren und wie diese bei der Interpretation der generierten Ausgaben helfen können. Die Verfahren werden weiterhin evaluiert, um festzustellen, welche dieser sich am besten für bestimmte Anwendungsfälle eignen, wo Probleme auftreten und wie sie sich robuster gestalten lassen. Im Zuge dessen werden auch Softwareanwendungen und -bibliotheken für einen Praxiseinsatz vorgestellt. Die Ergebnisse zeigen, dass es grundsätzlich möglich ist, gesamtheitliche Abläufe des Lernverhaltens und die internen Interaktionen von KNN visuell verständlich abzubilden und Zusammenhänge offenzulegen. Jedoch können die erzielten Ergebnisse isoliert betrachtet fragil gegenüber den genutzten Eingabedaten sein, wodurch ein blindes Vertrauen vermieden werden sollte. Weitere Forschungen für einheitliche Bewertungsmetriken erscheinen zukünftig notwendig. 
19.09.21;23.01.22;2021;extern;Bachelor;DE;Konzeption und Implementierung eines Testgenerators für einen Autorisierungsdienst im Geldtransfer;Ausgangssituation: Die Bachelorarbeit wurde in Kooperation mt einem IT-Dienstleister im Bankensektor erstellt. Die beteiligte Firma portiert das bestehende<br>Autorisierungssystem von COBOL auf Java. In der Bachelorarbeit wurde das Problem der nicht <br>bestehenden Test Möglichkeit des neuen Autorisierungssystems betrachtet.<br>Problem: Die autorisierten Elemente sind Anfragen für einen Geldtransfer, welche durch einen <br>Point of Sale (PoS) beim Bezahlen oder einen Geldausgabeautomat beim Geldabheben durch<br>einen Bankkunden erstellt werden. Da jährlich in Deutschland mehrere Milliarde <br>Autorisierungen durchgeführt werden, müssen bestehende Systeme regelmäßig auf <br>Funktionalität getestet werden. Werden die Tests nicht durchgeführt, können 4,3 Millionen <br>Kunden der Sparda Bank nicht mehr am PoS Terminal bezahlen oder Geld abheben. <br>Zielsetzung: Das Ziel der Bachelorarbeit ist einen Testgenerator für den neuen <br>Autorisierungsdienst zu konzipieren und zu implementieren.<br>Umsetzung: Durch eine Applikation werden Userdaten in eine JSON formatiert. Anhand der <br>JSON wird die Autorisierungsanfragen erstellt und an den zu testenden Autorisierungsdienst <br>gesendet. Der Autorisierungsdienst verarbeitet die Anfragen und sendet eine Antwort, die<br>durch den Testgenerator empfangen wird. Die Antwort wird mit dem definierten Testergebnis <br>verglichen und in der Konsole ausgegeben. Mithilfe des Testgenerators werden<br>Erweiterungen und Änderungen am neuen Autorisierungsdienst durch den Entwickler <br>getestet.
22.09.21;18.01.22;2021;extern;Bachelor;DE;Konzeption und Implementierung eines Dashboards für den Versandhandel auf Basis von KatarGo;Business Intelligence kann als eine Lösung definiert werden, die es Unternehmen ermöglicht, in Geschäftsprozessen eine intelligente Entscheidung zu treffen. Es ist ein Dienst, der Daten effektiv organisiert und in Informationen umwandelt, die eine Wissensbasis für die Entscheidungsfindung darstellt. Mit Hilfe einer geeigneten Business-Intelligence-Lösung kann ein Unternehmen eine aktive Rolle bei der zeitnahen Überwachung der Geschäftsleistung spielen und schnell auf externe Geschäftsumgebungen reagieren.<br>In dieser Bachelorarbeit benötigt ein Versandhandel Dashboards, um die monatliche Verkaufsleistung zu überwachen, den Wareneingang und -ausgang für die Abteilung Logistik zu verfolgen und eine Übersicht über die Mitarbeiter der Firma für die Abteilung Personal zu schaffen. Das Ziel dieser Arbeit ist es daher, Dashboards für die oben genannten Abteilungen zu erstellen, das die wichtigsten Kennzahlen und KPIs anzeigt, indem Daten in Power BI visualisiert werden.<br>Diese Arbeit kann in zwei Teile gegliedert werden: Einen theoretischen Teil und einen empirischen Prozess. Zu den Theorien gehören Geschichte und Definition von Business Intelligence, die Eigenschaften eines Dashboards, eine Einführung von Power BI und eine Spezifikation ihrer vier Bausteine. Der empirische Prozess baut die Dashboards für die drei Abteilungen von Power BI auf.<br>
23.09.21;14.02.22;2021;intern;Bachelor;DE;Qualität der Erklärungen des eXplainable-AI-Ansatzes LIME in verschiedenen Konfigurationen;Das Ziel der vorliegenden Arbeit ist es zu beantworten, wie sich Veränderungen der Parameter von LIME auf die Qualität der LIME-Erklärungen auswirken. Außerdem wird untersucht, wie sich sogenannte Adversarial Attacks auf die Erklärungen auswirken. Hierfür wird der Begriff Qualität definiert und quantifizierbar gemacht, indem zwei Metriken beschrieben werden. Die Stabilität gibt an, wie sehr LIME-Erklärungen voneinander abweichen, wenn die Eingabe verrauscht wird. Das Pointing-Game gibt an, wie sehr LIME für seine Erklärung die Pixel, die tatsächlich das gezeigte Objekt darstellen hernimmt. Für eine Parameteränderung sowohl zu einer besseren Stabilität, als auch zu keiner schlechteren Pointing-Game-Präzision, so spricht man von einer besseren Robustheit. Im Anschluss an die Begriffsdefinitionen wurden Vorhersagen des InceptionV3 Bildklassifikators für Bilder des ILS-VRC2012 Datensatzes herangezogen, um LIME-Erklärungen zu generieren, deren Qualität vorab bestimmt wurde. Daraus wurden LIME-Parameter identifiziert, welche die Qualität der LIME-Parameter entweder positiv, negativ oder gar nicht beeinflussen. Außerdem wurde festgestellt, dass Adversarial Attacks die Pointing-Game-Präzision unterschiedlich stark beeinflussen. Daraus konnten konkrete Empfehlungen formuliert werden, wie die verschiedenen LIME-Parameter gewählt werden sollten, um eine hohe Qualität der LIME-Erklärungen zu erreichen.
24.09.21;28.01.22;2021;extern;Bachelor;DE;Spezifikation und Entwurf einer Anwendung für die drahtlose Kommunikation mit dem Target in Testfahrzeugen;Spezifikation und Entwurf einer Anwendung für die drahtlose Kommunikation mit dem Target in Testfahrzeugen
27.09.21;07.04.22;2021;extern;Master;DE;Konzept und Umsetzung einer automatisierten Unit- und Integrations-Testumgebung für Softwarefunktionen einer Familie von Kunststoffspritzgussmaschinen;In dieser Arbeit wird gezeigt, wie automatisierte Unit- und Integrationstests auf Spritzgussmaschinen ausgeführt werden können. Dafür wird zunächst ein Testkonzept entwickelt, das anschließend in Form einer TestApp umgesetzt wurde. <br><br>Anfangs werden die verschiedenen Anforderungen an ein Testkonzept für Spritzgussmaschinen festgelegt.<br><br>Anschliesend wird ein Testkonzept entworfen, das auf verschiedene Testplattformen, Schnittstellen und Softwareprojekte eingeht.  Außerdem unterteilt es die Tests in eine hierarchische Struktur. <br><br>In der Umsetzung wird eine Applikation entworfen, die Tests flexibel und automatisiert starten kann. Zusätzlich wird gezeigt wie die Testabdeckung einzelner Tests gemessen und die Testergebnisse dokumentiert werden können.<br><br>Schließlich wird das Konzept mit der Durchführung beispielhafter Tests auf der Software einer Kunststoffspritzgussmaschine validiert.
30.09.21;23.02.22;2021;extern;Bachelor;DE;Entwicklung eines technischen Grundkonzepts und Prüfung des ROI für die Bereitstellung und Ausführung passender Test-Sets basierend auf der Test-Impact-Analyse im WinCC-ES-Projekt (TIA Portal).;Das TIA-Portal ist mit über 100 Millionen Codezeilen eines der umfangreichsten C#-Projekte weltweit. Der Teilbereich WinCC-ES besteht bereits aus ungefähr sieben Millionen Codezeilen. Aufgrund der Größe hat das WinCC-ES-Projekt lange Build- und Testzeiten. Dabei kann eine Test-Impact-Strategie Abhilfe schaffen. Die Test-Impact-Analyse stellt Beziehungen zwischen einem Anteil des Produktivcodes und den Tests her, die diesen Anteil testen. Durch diese Beziehungen ist es möglich, passende Testsets zu Änderungen auszuwählen. Diese Testsets bestehen dann nur aus Tests, die den geänderten Code testen. Unveränderter Code wird nach Möglichkeit nicht getestet. Dadurch kann die Testlaufzeit bei gleichbleibender Qualität des Feedbacks verringert werden. <br>In dieser Arbeit wird ein Prototyp für die Anwendung der Test-Impact-Analyse im WinCC-ES-Projekt konzipiert und entwickelt. Zusätzlich wird der Return on Investment der projektweiten Einführung einer Test-Impact-Strategie durch eine Schätzung ermittelt. <br>Durch den Prototyp wird gezeigt, dass eine Test-Impact-Strategie im WinCC-ES-Projekt grundsätzlich umsetzbar ist. Jedoch sind dafür noch weitere Anpassungen an der Testbasis und an internen Tools notwendig. Die Auswertung der Schätzung des Return on Investment ergibt, dass die Einführung einer Test-Impact-Strategie im WinCC-ES-Projekt bereits nach weniger als einem Monat rentabel wäre. 
30.09.21;17.02.22;2021;intern;Bachelor;DE;Entwicklung einer Serveranwendung zur automatisierten Konvertierung und Bereitstellung von BIM-Daten und Visualisierung der Daten in einer Augmented-Reality-App;Der Begriff Augmented-Reality (AR)  findet immer größeren Anklang in den verschiedensten Branchen. Diese Arbeit soll aufzeigen, wie in Zukunft Augmented-Reality im Bauingenieurwesen integriert werden kann. Dazu wird die Visualisierung von Building-Information-Modeling-Daten in AR vorgenommen. Für die Entwicklung von Augmented-Reality-Anwendung werden meist Spiele-Engines wie Unity oder die Unreal-Engine verwendet, die eine plattformübergreifende Entwicklung ermöglichen. Diese Spiele-Engines bieten allerdings keine native Unterstützung für den Import der BIM-Daten. Diese Arbeit untersucht daher eine Möglichkeit, wie sich die Daten konvertieren lassen, um einen einfacheren  Import in Unity zu ermöglichen. Der gefundene Ansatz wird anschließend in einer Spring-Java-Anwendung umgesetzt, die sich an Projektarchiv-Software und Git-Repositorien anbinden lässt. Die geometrischen Daten werden mithilfe des IfcConvert-Tools von IfcOpenShell automatisiert in das OBJ-Format konvertiert. Alle weiteren nichtgeometrischen Informationen werden in ein strukturiertes XML-Format konvertiert. Die konvertierten Daten werden anschließend über eine REST-Schnittstelle bereitgestellt. Für die Visualisierung der Daten wird eine Augmented-Reality-App in Unity entwickelt. Die entwickelte App kann die Daten zur Laufzeit herunterladen und entweder in Table-Top-Ansicht oder als Überlagerung im Raum darstellen. Anschließend werden zukünftige Anwendungsmöglichkeiten und fortführende Arbeiten aufgezeigt. 
01.10.21;01.06.22;2022;intern;Master;DE;Reifegradmodelle für die Steuerung der IT in Unternehmen - Überblick, Analyse und der Weg zum Einsatz;"Diese Masterarbeit betrachtet die Thematik der Reifegradmodelle im Kontext der IT in Unternehmen. Neben der grundlegenden Einführung in die Bedeutung des IT-Managements und die Definition und Verwendung von Reifegradmodel-len werden durch diese Kenntnisse eine Übersicht der State-of-the-Art Reife-gradmodelle erzeugt. Dazu werden die Reifegradmodelle der letzten 10 Jahre (2011-2021) mit Bezug zur IT identifiziert, kategorisiert, übersichtlich repräsen-tiert und schließlich auch gesamtheitlich analysiert.	<br>Aus den Datenbanken ""SpringerLink"", ""ScienceDirect"" und ""ProQuest"" konnten insgesamt 105 definierte Reifegradmodelle zusammengestellt werden.	<br>Zusammen mit der Theorie und insbesondere der Kriterienauswahl, der Ent-wicklung und der Einführung eines Reifegradmodells, ist der Einstieg in die Nut-zung von Reifegradmodellen für IT-Unternehmen bzw. Unternehmen mit IT-Bezug geschaffen. "
01.10.21;12.04.22;2022;intern;Bachelor;DE;Veranschaulichung und Analyse von Reifegradmodellen im Bereich Internet of Things(IoT);Der schnell wachsende Markt im Bereich Internet of Things (IoT) stellt die Unternehmen, die beispielsweise IoT-Lösungen anbieten oder sich mit der IoT-Einführung beschäftigen, vor großen Herausforderungen. Diese Herausforderungen erfordern von den Unternehmen ständige Anpassungen und Verbesserungen bezüglich wirtschaftlicher und technischer Aspekte. Manager setzen für die Analyse und Entscheidungsfindung etablierte Instrumente ein. Ein anerkanntes Instrument dieser Art sind Reifegradmodelle. Im Rahmen dieser Abschlussarbeit werden vorhandene Reifegradmodelle im Bereich Internet of Things (IoT) veranschaulicht und anschließend analysiert. Zudem werden Gemeinsamkeiten und Unterschiede der Reifegradmodellen dargestellt, um eine Entscheidungsgrundlage für die Wahl eines geeigneten Reifegradmodells in der Praxis zu schaffen. Abschließend werden daraus gewonnene Erkenntnisse dokumentiert. 
01.10.21;26.02.22;2022;intern;Bachelor;DE;Analyse und Bewertung von Reifegradmodellen für Business Intelligence;Ziel der vorliegenden Arbeit ist es, zu untersuchen, welche Business Intelligence Reifegradmodelle zur Verfügung stehen und welche Faktoren bei der Auswahl dieser Modelle zu beachten sind. Zu Beginn der Arbeit werden die wissenschaftlichen Grundlagen erarbeitet, die für ein gemeinsames Verständnis, sowie eine fundierte Analyse des Themas notwendig sind. Danach werden die in einer ausführlichen Literaturrecherche identifizierten Modelle, zu denen eine hinreichende Dokumentation verfügbar ist, vorgestellt. Durch Vorstellung des breiten Feldes sich stark unterscheidender Reifegradmodelle wird die Relevanz des Themas aufgezeigt und somit die Legitimation für die Arbeit geschaffen und zugleich die Forschungsfrage, welche Reifegradmodelle zur Verfügung stehen, beantwortet. Nach Vorstellung der Modelle werden diese zunächst methodisch und inhaltlich analysiert, anschließend erfolgt eine weitergehende Analyse, in der noch verbleibende Aspekte der Modelle untersucht werden. Im Anschluss werden die in den verschiedenen Analysen gewonnenen Erkenntnisse genutzt, um die eingangs gestellte Frage, nach den bei der Auswahl von BI-Reifegradmodellen zu beachtenden Faktoren, zu beantworten. Hierfür werden die grundlegenden Unterschiede zwischen den Modellen erläutert und verschiedene Fragen formuliert, die es zu beantworten gilt, um die in Betracht zu ziehenden Reifegradmodelle auf eine minimale Anzahl zu reduzieren und somit eine optimale Auswahl zu ermöglichen.
01.10.21;18.03.22;2022;intern;Bachelor;DE;Durchführung eines Penetration-Test für verschiedene Serversysteme der Fakultät Informatik und Entwicklung eines Vorgehens zum Test auf Schwachstellen und Sicherheitslücken für die Zukunft.;Inhalt dieser Arbeit ist die Beschreibung eines Penetrationstests sowie die Durchführung eines solchen. Hierfür wird zunächst das theoretische Vorgehen beschrieben und dieses im Anschluss praktisch für mehrere Serversysteme der Fakultät Informatik ausgeführt. Durch den Penetrationstest wurden erfolgreich einige Sicherheitslücken in den Systemen identifiziert. Ursache hierfür sind vor allem veraltete Softwareversionen. Außerdem wurde im weiteren Verlauf ein Vorgehen für die Zukunft entwickelt, mit dem sich Rechnersysteme effizient auf Sicherheitslücken hin überprüfen lassen. Hierzu werden auch gängige Tools und Programme für einen Penetrationstest verglichen. Abschließend wird, anhand einer Log-Datei der Firewall, eine Analyse von realen Angriffen auf Systeme der Technischen Hochschule Nürnberg durchgeführt. In dieser wurde die Art der Angriffe sowie ihr Auftreten analysiert.
01.10.21;01.03.22;2022;intern;Bachelor;DE;Konzeptionierung und Implementierung des Studierendenausweises der Technischen Hochschule Nürnberg als mobile Applikation<br>;Den Verwendungsmöglichkeiten der OHMcard an der TH Nürnberg stehen einige Einschränkungen gegenüber. So muss die Karte beispielsweise über ein Guthaben verfügen, bevor die entsprechenden Bezahlsysteme genutzt werden können.<br>Das Ziel dieser Bachelorarbeit ist die Implementierung der OHMcard als mobile Anwendung. Dazu wird folgende Forschungsfrage gestellt: Wie kann die OHMcard mitsamt ihrer Funktion als Studentenausweis, Mensakarte und Bibliotheksausweis als eine plattformübergreifende Anwendung für mobile Endgeräte konzipiert und implementiert werden?<br>Um die Forschungsfrage zu beantworten, habe ich ihm Rahmen anhand des Design-Science-Research-Verfahrens eine mobile Anwendung entwickelt. Das Ziel dieser Vorgehensweise ist die Entwicklung sog. Artefakte wie Software oder Konzepte. Um die Entwicklung voranzutreiben, wurde regelmäßig Feedback zur jeweiligen Entwicklungsstufe eingeholt und ausgewertet und die Anwendung wurde während des gesamten Entwicklungszeitraums auf verschiedenen Endgeräten getestet.<br>Das Feedback aus den Tests trug zum Versuch bei, eine benutzerfreundliche Anwendung zu entwickeln. Abgesehen von den oben genannten Funktionen, enthält die ihm Rahmen dieser Arbeit implementierte App zusätzliche Neuerungen, die den analogen Funktionsumfang der OHMcard erweitern.<br>Durch Anschlussarbeiten, die sich mit der Weiterentwicklung der der hier vorgestellten App-Version, können die Handhabung erleichtert und der Funktionsumfang gesteigert werden.<br>
01.10.21;14.03.22;2022;intern;Bachelor;DE;Analyse und Bewertung von Reifegradmodellen für das Management von Projekten;Die Wichtigkeit des richtigen Managements von Projekten wird in vielen Unternehmen heute noch unterschätzt. Selbst wenn ein Bewusstsein für das richtige Management besteht, ist es oftmals dennoch schwer die Güte adäquat zu bewerten und festzumachen, an welchen Stellen Nachbesserungen erforderlich sind. Ein gutes Instrument für die Bewertung der Güte des bestehenden Managements sind Reifegradmodelle. Diese ermöglichen eine präzise Einordnung der einzelnen Komponenten und gleichzeitig die Feststellung, auf welchem Niveau sich das eigene Management von Projekten befindet.<br>In dieser Arbeit wird eine diversifizierte Auswahl von Reifegradmodellen, die passend für die Bewertung des Managements von Projekten sind, analysiert und bewertet, um anschließend aufzuzeigen, welche sich besonders gut dafür eignen, die Güte des Managements einzuordnen. Zuvor werden die wesentlichen Bereiche, Projektmanagement, Projektportfoliomanagement und Programmmanagement, die für das Management von Projekten wichtig sind, erläutert und verständlich definiert, um danach zur eigentlichen Analyse und Bewertung der ausgewählten Reifegradmodelle zu kommen.
01.10.21;01.03.22;2022;extern;Bachelor;DE;Anwendung von generativen Modellen für die Erzeugung von synthetischen Daten und deren Qualitätsbestimmung;Umfangreiche Datenbestände sind im aktuellen Zeitalter mit vielen Möglichkeiten verbunden. So können mit Analysen wertvolle Erkenntnisse gesammelt oder fundierte Entscheidungen getroffen werden. Algorithmen können mittels Machine Learning diese Zusammenhänge<br>in Daten automatisiert erfassen. Jedoch werden hierfür viele qualitative Daten benötigt und<br>deren Verfügbarkeit ist nicht immer gegeben bzw. sind diese aufgrund von Datenschutzrechten o.Ä. nicht nutzbar.<br>Daten können stattdessen synthetisch generiert werden. Eine zufallsbasierte synthetische<br>Generierung kann jedoch in einem willkürlichen Datensatz resultieren. Um Aussagen über<br>die Qualität bzw. den Nutzen dieser Daten machen zu können, braucht es eine Validierung<br>der synthetischen Daten.<br>Aus diesem Grund war das Ziel der vorliegenden Arbeit synthetische Daten zu generieren<br>und insbesondere deren Qualität zu bestimmen. Dafür wurde der Begriff der Datenqualität untersucht und diverse Methoden gesammelt, wie sich ein Datensatz hinsichtlich dieser<br>Qualität prüfen und generieren lässt.<br>In einem Fallbeispiel wurde gezeigt, dass simple Messungen ausreichen, um einen Großteil<br>der Datenqualität zu messen und damit Datensätze zu vergleichen. Die Ansprüche an synthetische Daten hängen dabei von ihrem Anwendungszweck ab. Ist die Realitätsnähe der<br>synthetischen Daten vollumfänglich zu messen, sollten diverse Vergleiche mit echten Daten<br>aus der jeweiligen Domäne durchgeführt werden.
01.10.21;01.02.22;2022;extern;Bachelor;DE;Konventionelle oder verbrauchsbasierte IT-Services: Konzeption und prototypische Implementierung eines Entscheidungsunterstützungssystems für Kunden eines IT-Dienstleisters ;Die zunehmend benötigte Flexibilität durch die schnelllebigen Veränderungen bei der Betreibung von IT-Infrastruktur hat eine neue Form des Bezuges von Ressourcen hervorgebracht. Die verbrauchsbasierten IT-Services versuchen dabei die Vorteile beider bisherig existierenden Bezugsarten zu verbinden. Die Betreibung der Ressourcen erfolgt wie beim Kauf vor Ort im Rechenzentrum, während die Abrechnung, ähnlich wie bei Cloud-Services, dynamisch nach den tatsächlich verbrauchten Ressourcen durchgeführt wird. <br>Im Rahmen dieser Arbeit werden die angesprochenen Bezugsarten erläutert und gegenübergestellt. Dabei wird die Frage behandelt, ob die verbrauchsbasierten IT-Services die Zukunft der Beschaffung von Ressourcen darstellen. Darüber hinaus wird ein System konzipiert und implementiert, mit dem Nutzen den Kunden der SanData EDV-Systemhaus GmbH (kurz: SanData) eine Entscheidungshilfe bei der Wahl der Bezugsart ihrer Ressourcen zu bieten.<br>Die Konzeption findet dabei in enger Zusammenarbeit mit der SanData statt und umfasst die Betrachtung der Bezugsarten aus technischer und monetärer Sicht. <br>
01.10.21;01.03.22;2022;extern;Bachelor;DE;Analyse und spezifische Adaption eines Prozessmodells zur sicheren Entwicklung von Software am Beispiel OWASP-SAMM SSDLC;Exponiertheit, Umfang und Komplexität der Softwaresysteme steigen kontinuierlich an. Dies korreliert mit einer steigenden Anzahl an Vulnerabilitäten und einer Zunahme der Gefahr von Cyberkriminalität.  <br><br>In klassischen sowie agilen Vorgehensmodellen bleibt die Sicherheit in frühen Phasen des Softwarelebenszyklus meist unberücksichtigt. Dieser Ansatz führt zu Ineffizienz und hohen Kosten bei der Behebung von Sicherheitsschwachstellen, die in späteren Phasen des Softwarelebenszyklus entdeckt werden. Eine Lösung für dieses Problem bieten Prozessmodelle zur Konstruktion sicherer Entwicklungsprozesse, durch deren Adaption die Sicherheit in alle Entwicklungsprozesse integriert wird.<br><br>Das Ziel dieser Arbeit ist die Konzeption der bedarfsgerechten Einführung spezifischer Sicherheitsaktivitäten des Prozessmodells OWASP/SAMM in die Projektprozesse des agilen IT-Dienstleisters adorsys, um einen sicheren Softwarelebenszyklus für relevante Situationen zu etablieren. Dazu werden Methodologien und Verfahren ausgearbeitet, Standards und Tools ausgewählt, die zur Erreichung dieses Ziels beitragen. Dies basiert auf der Analyse der Prozess- und Projektlandschaft in adorsys, die zur Ermittlung firmenspezifischer Bedürfnisse durchgeführt wird.
01.10.21;01.03.22;2022;extern;Bachelor;DE;Generierung künstlicher Datenpopulationen für Finance Project Use Cases;Diese Abschlussarbeit befasst sich mit der Generierung von künstlichen (Test-) Datenpopulationen für Anwendungsfälle in Projekten im FinTech-Sektor. Dazu wird der Frage nachgegangen, ob und inwieweit es möglich ist, künstliche Populationen zu erschaffen, deren statistische Eigenschaften denen der deutschen Gesellschaft ähneln. Im ersten Teil wird die Anonymisierung von personenbezogenen Daten am Beispiel des Zensus erläutert. Im Anschluss wird dieses Vorgehen der Erstellung und Nutzung von synthetischen Daten gegenübergestellt. Im nächsten Schritt wird anhand eines Kreditantrags ein Use Case definiert, der als Beispiel für das weitere Vorgehen fungiert. Auf der Grundlage der für den Use Case entwickelten Anforderungen wird eine Basisarchitektur konzipiert. Diese orientiert sich an der Monte-Carlo-Simulation, um neue künstliche Daten zu generieren. Für einen Proof of Concept werden bereits anonymisierte Daten vom statistischen Bundesamt so aufbereitet, dass sie für die Generierung neuer synthetischer Daten verwendet werden können. Nachdem die Integration des finalen Generators in die Modellbank als Software-as-a-Service-Plattform skizziert wurde, kommt es zu dem vorläufigen Ergebnis, dass die Erstellung von künstlichen (Test-) Datenpopulationen möglich ist und diese eine statistische Ähnlichkeit von bis zu 88 % erreichen. Durch die Implementierung von weiteren Komponenten des Generators kann in Zukunft eine noch höhere statistische Ähnlichkeit erreicht werden.
04.10.21;25.02.22;2022;intern;Bachelor;DE;Vergleich von Embedding-Verfahren für die Textklassifikation im Umfeld kritischer Infrastrukturen;Für die frühzeitige Identifikation von Anomalien und Gefahren im Bereich der kritischen Infrastrukturen können zahlreiche Datenquellen wie Sensordaten, Prozessinformationen und Textdokumente herangezogen werden. Insbesondere Textdokumente in informeller Sprache, die durch Meldungen aus der Bevölkerung und Social Media gewonnen werden, stellen für die Klassifikation von Störungen und Bedrohungen eine Herausforderung dar. Embedding- Verfahren als Mechanismus zur vektoriellen Repräsentation der Textdokumente sind ein wichtiger Bestandteil für die Klassifikation von Störungen und Bedrohungen. Im Rahmen dieser Arbeit sollen daher unterschiedliche Embedding-Verfahren umgesetzt und verglichen werden. Hierfür werden als Datensätze Störungsmeldungen aus der Bevölkerung für ein Versorgungsunternehmen mit Fokus auf die Wasserversorgung und Textdokumente aus der Plattform Twitter berücksichtigt.
04.10.21;04.03.22;2022;extern;Bachelor;DE;Extrahieren und Mappen von Inhalten von<br>eingehenden Bedarfsanforderungen mithilfe von<br>Data Science-Verfahren;Ein IT-Dienstleister strebt in innerbetrieblichen Prozessen eine hohe Automatisierung an, um Qualität und Kosten zu optimieren. Dafür müssen natürlichsprachige Texte aus den Word-Dokumenten maschinell interpretiert und weiterverarbeitet werden. Den ersten Schritt hat man bereits im Vertrieb mit einem klassischen Ansatz realisiert. Projekt- und Verfahrensabrufe, die in Form von Word-Dokumenten von Kunden gesendet werden, werden teilautomatisiert mit einem klassischen Ansatz in einem Ticket-System erfasst. Die Realisierung der Daten- bzw. Informationsextraktion basiert hier auf regulären Ausdrücke, um aus semi-strukturierten Word-Dokumenten das Slotfilling im System zu gewährleisten. Das Slotfilling der Felder aus den Word-Dokumenten sowie die Wartung dieser Softwarelösung sind jedoch nicht zufriedenstellend. Gründe dafür sind z. B.gewollte und ungewollte Layoutverändungen im Dokument oder Veränderung der Schreibweise der Entitäten durch den Kunden. In der vorliegenden Arbeit wird auf Basis von Data-Science Verfahren ermittelt, ob das Slotfilling signifikant verbessert werden kann. Ziel ist hierbei verschiedene maschinelle Lernverfahren anzuwenden und die Ergebnisse miteinander zu vergleichen. Neben einem regel- und distanzbasierten Slotfilling umfasst dies den Einsatz konventioneller Lernverfahren sowie neuronaler Netzwerkes. Diese Arbeit baut auf einer verwandten Arbeit im Bereich der automatisierten Datenextraktion aus semi-strukturierten natürlichsprachigen Texten auf.
04.10.21;29.04.22;2022;intern;Bachelor;DE;Feature Extraction aus zweidimensionalen Lidar-Daten;Zum Zweck der Umweltmodellierung verfügen autonome, mobile Roboter über Sensoren zur Umgebungswahrnehmung, darunter auch ein Lidar-Sensor. Dieser liefert eine Punktwolke, die Abstand und Richtung von Hindernissen in Relation zum Roboter darstellt. Diese Punktwolken werden von der Software-Plattform des Roboters automatisch in eine Karte integriert. Für einige Aufgaben, beispielsweise die Klassifikation von Objekten in Wände und Möbel, ist die Darstellung über Punktwolken ungeeignet, da sie auf einem viel zu niedrigen Niveau angesiedelt ist. Ziel dieser Arbeit ist es aus dieser Punktwolke höherwertige Eigenschaften, wie geometrische Formen, zu extrahieren. Bestandteil der Arbeit ist eine Recherche existierender Ansätze und die Entwicklung eines geeigneten Verfahrens für die Carbot-Plattform.
04.10.21;04.03.22;2022;extern;Bachelor;DE;Konzeption und Realisierung eines Programms zur Ermittlung von Objektabhängigkeiten innerhalb eines SAP-Software-Transportauftrags;Mit dieser Arbeit wird das Ziel verfolgt, ein Programm zu entwickeln, mit dem SAP-Softwaretransportaufträge auf Entwicklungsobjekte hin untersucht werden, die Objekte referenzieren, deren Pakete nicht Teil der im Dematic TB ausgewählten Paketstruktur sind. Durch die Ausgabe solcher referenzierten Objekte in einem Protokoll wird der Projektleitung die Möglichkeit gegeben, den auszuliefernden Projektumfang anzupassen, um Nachtransporte fehlender Objekte zu vermeiden.<br>Um das Thema dieser Arbeit umzusetzen, werden zunächst in einer Projektbesprechung mit dem Auftraggeber die der Anwendung zugrunde liegenden Anforderungen erhoben. Hierbei wird zugleich eine Einschränkung des Prüfalgorithmus auf ausgewählte Objekttypen, die bei der Dematic GmbH für einen Großteil aller Nachtransporte verantwortlich sind, vorgenommen.<br>Um den Softwareentwicklungsprozess übersichtlich und beherrschbar zu gestalten, wird, aufbauend auf den ermittelten Anforderungen, ein Vorgehensmodell zur Softwareentwicklung ausgewählt. Der Autor dieser Arbeit entscheidet sich für ein prototypisches Vorgehensmodell. <br>Nach der Festlegung auf ein Vorgehensmodell, werden Konzepte für die Umsetzung der Anwendung erarbeitet. Auf Basis der ermittelten Anforderungen werden ein Prüf- und ein Testkonzept entworfen. Ebenso wird eine Benutzerschnittstelle konzipiert.<br>Die getroffenen Designentscheidungen dienen als Grundlage für die inkrementelle Umsetzung des Programms.<br>
04.10.21;04.03.22;2022;extern;Bachelor;DE;Implementation von Dashboards auf Basis von Open Source Low-Code Frameworks;In dieser Arbeit geht es darum, ein Open Source Low-Code Framework zu finden, mit dem Dashboards zur Visualisierung von Daten erstellt werden können. Dashboards sind heute allgegenwärtig im betrieblichen Controlling erfolgreicher Unternehmen und im Zeitalter der Digitalisierung möchte auch die Ancud IT-Beratung GmbH eine gute Antwort auf die Frage ihrer Kunden haben, wie aus einer Menge von nicht-zusammenhängenden Daten in effizienter Weise aufschlussreiche Diagramme erstellt und zu nützlichen Dashboards zusammengefasst werden können. Eine Studie von Forrester Research kommt zum Ergebnis, dass Low-Code Entwicklungsplattformen die Entwicklung von Software um das 5- bis 10-fache beschleunigen können, wodurch schnell klar wird, warum dieses Thema für einen innovativen IT-Dienstleister interessant ist. Hinzu kommen juristische Bedenken von Kunden bei der Verwendung von SaaS-Produkten, welche auf Cloud-Lösungen von US-Unternehmen zurückgreifen, zu denen Open Source Software die sich sowohl On-Premise, als auch On-Demand betreiben lässt, eine vertrauenswürdige Alternative darstellt. Detailliert wird hierbei der Prozess der Evaluation, die Automatisierung des gesamten Setups, sowie der Arbeitsablauf zur Erstellung von Dashboards mit Apache Superset erläutert. Grundlage ist dabei die Fachliteratur verschiedener Experten, u.a. zu Fragen der Gestlatung von Dashboards und der dazu nötigen Integration der Applikations-Landschaft.
04.10.21;04.03.22;2022;intern;Bachelor;DE;Analyse und Bewertung von Reifegradmodellen für die Softwareentwicklung;Das Ziel der vorliegenden Arbeit ist es zu beantworten, welche Reifegradmodelle für die<br>Softwareentwicklung existieren. Mit dem Ergebnis dieser Forschungsfrage wird beleuchtet,<br>welche Unterschiede und Gemeinsamkeiten die identifizierten Reifegradmodelle besitzen und<br>welches Reifegradmodell für welchen Anwendungsfall in der Praxis geeignet ist. Um die<br>Forschungsfragen zu beantworten wurde eine systematische Literaturrecherche umgesetzt.<br>Anschlie?end wurde eine tiefere, qualitative Analyse der identifizierten Reifegradmodelle<br>durchgeführt, die sich in eine methodische Analyse und eine Inhaltsanalyse aufteilt. Mit<br>Hilfe der Literaturrecherche wurden 19 Reifegradmodelle für die Softwareentwicklung identifiziert.<br>Anhand der qualitativen Analyse konnten neun Unterschiede und Gemeinsamkeiten<br>zwischen den identifizierten Reifegradmodellen gefunden werden. Darüber hinaus wurde<br>für mehrere Anwendungf?lle in fünf verschiedenen Anwendungsbereichen geeignete Reifegradmodelle<br>für Unternehmen identifiziert. Bei der Beantwortung der Forschungsfragen hat<br>sich herausgestellt, dass für Unternehmen kein allgemeingültiges Reifegradmodell empfohlen<br>werden kann. Die Wahl des Reifegradmodells sollte von dem konkreten Anwendungsfall<br>abh?ngig gemacht werden.
04.10.21;04.03.22;2022;extern;Bachelor;DE;Konzeptionierung einer Softwarearchitektur zur Durchführung eines Sim2Real Transfers auf eine mobile Roboterplattform;Das Ziel dieser Arbeit liegt in der Erstellung eines Konzeptes einer Softwarearchitektur für<br>Systeme, mit denen Sim2Real-Transfers durchgeführt werden. Hierbei soll sichergestellt<br>werden, dass Sim2Real-Transfers mit möglichst geringem Aufwand und Fehlerpotential,<br>sowie ohne Beeinflussung der Steuerungslogik durchgeführt werden können.<br>Zunächst werden grundlegende Begrifflichkeiten und Themenbereiche dargestellt und<br>erläutert, die für das Verständnis der Thematik und der daraus resultierenden Anforderungen<br>von Nöten sind. Außerdem wird das ROS-Framework betrachtet, sowie evaluiert,<br>inwiefern dies die Konzeptionierung der Softwarearchitektur beeinflussen könnte. Im<br>Anschluss werden auf Grundlage der vorangegangenen Kapitel Anforderungen definiert,<br>die eine Softwarearchitektur zur Durchführung von Sim2Real-Transfers erfüllen muss.<br>Diese Anforderungen werden im Folgenden herangezogen, um eine allgemeine Form einer<br>Softwarearchitektur zu erstellen. Um dieses Konzept testen und bewerten zu können, wird<br>eine konkrete Softwarearchitektur von der allgemeinen Form abgeleitet und schließlich<br>ein Softwaresystem implementiert, das dieser konkreten Architektur folgt. Mithilfe dieses<br>Systems wird ein Sim2Real-Transfer auf eine mobile Roboterplattform durchgeführt,<br>sowie auf Grundlage der Ergebnisse des Transfers die Auswirkungen der konzeptionierten<br>Softwarearchitektur auf Sim2Real-Transfers evaluiert und diskutiert.
06.10.21;06.03.22;2022;intern;Bachelor;DE;Blockchain und NFTs<br>Eine Analyse von NFTs und Ethereum als zukünftige Plattform;NFTs sind ein zeitgemäßes Thema und oft wird die Blockchain Ethereum parallel erwähnt. Noch verursacht Ethereum, dessen Grundlage NFTs sind, etliche Probleme aufgrund dramatisch hoher Gebühren. Es ist weiterhin nötig die Funktionalität von Blockchains zu verstehen da diese grundlegend für NFTs sind. Das Ziel dieser Arbeit ist es NFTs und ihre Basis, die Blockchain, zu betrachten. Dazu ist folgende Frage zu stellen: Was sind NFTs und existiert bereits die notwendige Plattform für diese Technologie?<br>Nach der Betrachtung von NFTs werden Potential und Risiko erläutert. Dabei werden die massiven Skalierungsprobleme, (in Form von Gebühren) welche Ethereum durch neue Ideen, wie NFTs, erfahren hat, dargestellt. Außerdem werden zwei weitere Blockchains betrachtet: Algorand und Cardano. Diese drei Varianten werden im sogenannten Trilemma untersucht, bei dem die Skalierung eine wichtige Rolle spielt. Es werden hierbei mehrere Kriterien erfasst, beschrieben und diskutiert und im Zusammenhang mit NFTs betrachtet.<br>Die Diskussion und Auswertung des Trilemmas zeigt, dass jede der Blockchains verschiedene theoretische Ansätze verfolgt, jedoch keine der drei Varianten bisher eine praxistaugliche Lösung darstellt. NFTs benötigen prinzipiell eine Blockchain die beständig, sicher und skalierbar ist, um sowohl dauerhaft, als auch sicher zu bestehen. Ohne Skalierung können NFTs nie bei der breiten Masse Anwendung finden. Das gesamte Thema unterliegt einer dynamischen Betrachtung und Entwicklung.<br>
06.10.21;05.03.22;2022;extern;Bachelor;DE;Analyse und Überarbeitung der Benutzeroberfläche eines Pick-by-Light-Systems zur Verbesserung der Usability am Beispiel des Projekts TRILUM;Im Rahmen dieser Bachelorarbeit wird die grafische Benutzeroberfläche des Pick-by-Light-Systems TRILUM analysiert und überarbeitet. Um eine Verbesserung der Benutzerfreundlichkeit der Webseite zu erzielen, werden die Nutzer in den Entwicklungsprozess mit einbezogen.<br>Das von der Fraunhofer-Gesellschaft, am Fraunhofer-Institut für Integrierte Schaltungen entwickelte System TRILUM bildet die Basis für die zugrundeliegende Arbeit. Das Pick-by-Light-System leitet Mitarbeiter, die Material aus Regalen entnehmen müssen, per Leuchtsignal zum richtigen Entnahmefach. Es stellt Informationen für die Nutzer auf der zu überarbeitenden Desktopanwendung bereit.<br>Die Anwendung wurde zunächst analysiert, wobei in dieser Phase auch andere Pick-by-Light-Systeme betrachtet sowie Nutzungsanforderungen dokumentiert wurden. Im Anschluss wurden geeignete Methoden der Usability Evaluation ausgewählt, um nachfolgend Usability-Tests entwerfen und durchführen zu können. Auf Basis der Testevaluationen wurden Usability-Probleme identifiziert und Gestaltungslösungen für die Verbesserung der Nutzerfreundlichkeit entwickelt. Die Optimierungsvorschläge wurden anschließend priorisiert und im bestehenden System umgesetzt, sodass die Usability-Tests schließlich ein zweites Mal durchgeführt werden konnten. Die Ergebnisse der Kontrolltests zeigen, dass die Benutzerfreundlichkeit deutlich verbessert werden konnte und die Interaktion mit dem System intuitiver möglich ist.
07.10.21;07.03.22;2022;intern;Bachelor;DE;Product Analytics für digitale Produkte - Entwicklung von Handlungsempfehlungen für den Einsatz von Product Analytics im Produktentwicklungsprozess;Product Analytics ist als Disziplin ein Teilbereich von Data Analytics und beschäftigt sich mit der Analyse von Produktdaten. Produktdaten können Daten zum Nutzerverhalten und zum Nutzererlebnis sein. Die Analyse des Nutzerverhaltens ist die Betrachtung darüber, wie Nutzer Produkte auswählen, nutzen aber auch die Nutzung beenden ? bspw. durch das Schließen von Anwendungen. Die Verhaltensdaten können bspw. über die Data Mining Methoden Clustering oder Klassifikation analysiert werden. Das Nutzererlebnis lässt sich an sogenannten Kontaktpunkten (engl.: Touchpoints) messen. Diese Touchpoints stehen grundsätzlich für jede mögliche Interaktion zwischen Kunden und Unternehmen. Durch Befragungen und Feedback-Bitten in der Anwendung lässt sich das Nutzererlebnis erheben und analysieren. Im Rahmen der Bachelorarbeit wurden Handlungsempfehlungen für den Einsatz von Product Analytics im Produktentwicklungsprozess entwickelt. Hierfür wurde die Organisation und ein Entwicklungsteam analysiert und Experteninterviews durchgeführt. 
08.10.21;08.03.22;2022;intern;Bachelor;DE;Digitale Transformation mit Hilfe von Reifegradmodellen - Analyse und Bewertung;Das Ziel dieser Arbeit ist es, eine Bewertung und Analyse bestehender Reifegradmodelle durchzuführen. Hierbei wird die Forschungsfrage, welche Reifegradmodelle sich für die Steuerung der digitalen Transformation im Unternehmen eignen, anhand eines definierten Rahmens mit anschließender Auswahl zu empfehlender Reifegradmodelle beantwortet. Die Empfehlung richtet sich nach der getroffenen Stichprobe der Literatur Review. Die Anfertigung der Literatur Review wurde mithilfe von Google Scholar, Research Gate und IEEE Explore Digital Library durchgeführt. Die gefundenen Reifegradmodelle wurden anschließend durch ein Phasenkonzept ausgewählt und in einem Steckbrief im Anhang vorgestellt. Die ausgewählten Reifegradmodelle wurden mithilfe eines Klassifikationssystems verglichen und die Erkenntnisse abgeleitet. Abschließend folgt eine Bewertung aufbauend auf den Erkenntnissen und den in der Arbeit vorgestellten Grundlagen. Aus der Ableitung der Erkenntnisse geht ein Rahmen hervor, der Unternehmen bei der Auswahl der Reifegradmodelle unterstützen soll und eine weitere Bewertungsgrundlage bietet. Anhand der Bewertung wurden vier Reifegradmodelle identifiziert, die eine unternehmensabhängige Empfehlung inkludiert. Die generalisierende Empfehlung ist nicht möglich, da jedes Unternehmen andere Anforderungen besitzt. Kontextlos kann kein Reifegradmodell empfohlen werden, da jedes Modell Vor- und Nachteile aufweist und jedes Unternehmen andere Anforderungen hat. 
08.10.21;08.03.22;2022;extern;Bachelor;DE;Konzeption und Implementierung eines interaktiven <br>Dashboards zur Analyse von Jira-Projekten bei der N-ERGIE AG<br>;Um die Daten des Versorgungsunternehmens N-ERGIE AG zu verwalten, wird unter anderem SAP IS-U eingesetzt. Der interne technische Support für dieses System ist der IS-U Service, welcher Jira verwendet, um eingehende Anfragen zu verwalten. Das Ziel dieser Arbeit ist es, mithilfe von Dashboards einen Überblick über die Jira Daten des IS-U Service zu schaffen. Dafür werden Grundlagen über Dashboards erarbeitet. Weiterhin wird die Ist-Situation analysiert. Anschließend werden in Zusammenarbeit mit den Stakeholdern Ziele und Anforderungen für das Projekt festgelegt. Mit der geschaffenen Grundlage wird ein Konzept für die Dashboards erstellt. Dieses Konzept wird mit Tableau und Exasol umgesetzt und im Un-ternehmen veröffentlicht. Abschließend werden die Dashboards von Mitarbeitern im Unternehmen evaluiert.
08.10.21;22.03.22;2022;extern;Bachelor;DE;Konzeption und Implementierung von Prozessen der Medienbranche durch SAP Cloud Platform Workflow;In dieser Arbeit wurden Workflows in der in SAP Cloud Platform Workflow umgesetzt.<br>Zu Beginn wurden anhand von Anforderungen der IT2media Geschäftsprozessmodelle erstellt und die zugehörigen Oberflächen konzipiert. Danach wurden Vorbereitungen, darunter<br>das Erstellen von Rollen für Benutzer, die Auswahl der Entwicklungsumgebung, das Anbinden der Schnittstellen für die späteren Workflows und das Anlegen der Workflow Applikationen, für die Entwicklung von Workflows mit SAP Cloud Platform Workflow getroffen.<br>Nachdem die Vorbereitungen beendet waren wurden die Workflows anhand der vorher erstellten Konzepte in der Software umgesetzt. Die Oberflächen für die Workflows wurden<br>mit sogenannten Workflow Forms umgesetzt. Für die Benutzeraufgabe des ersten Workflows wurde eine SAPUI5 Applikationen programmiert. Zum Abschluss der Arbeit wurden<br>die Workflows und das Zusammenspiel mit den Oberflächen noch getestet.<br>
08.10.21;08.03.22;2022;intern;Bachelor;DE;Fusion Neuronaler Netze zur automatischen Sprecher- und Spracherkennung<br>;
11.10.21;18.02.22;2022;extern;Bachelor;DE;Entwicklung eines Standardtoolsets zur Ermittlung und Darstellung von Lagerkennzahlen aus einem SAP-System bei der Dematic GmbH;Die Dematic GmbH ist einer der internationalen Marktführer im Bereich Supply-Chain Lösungen und Intralogistik. Neben den Hardwarelösungen für die Lagerung und den Transport von Produkten innerhalb eines Lagers bietet Dematic verschiedene Softwareprodukte zur Steuerung und Überwachung der Lagersysteme an.<br>Die bislang vorhandenen Lösungen zur Ermittlung und Darstellung von Kennzahlen in den verwendeten SAP Systemen variieren von Projekt zu Projekt und müssen aufwendig angepasst werden.<br>Das Ziel dieser Bachelorarbeit ist es, ein einheitliches Standardtoolset zu konzipieren, welches die Ermittlung und Darstellung von Lagerkennzahlen aus SAP Systemen vereinfacht und sich flexibel an verschiedene Projekte anpassen lässt.<br>Dabei werden die vorteilhaften Eigenschaften der SAP HANA Datenbanktechnologie berücksichtigt, die eine Echtzeiterhebung und Analyse der Kennzahlen möglich machen. Außerdem wird durch den Einsatz des SAP Fiori Launchpads als Dashboard für die Kennzahlendarstellung sichergestellt, dass die Kennzahlen auf einer Vielzahl von Endgeräten überwacht werden können.<br>Während der Konzepterstellung wird darauf geachtet, dass durch einen modularen Aufbau und die Verwendung von standardisierten Schnittstellen sicherstellt ist, dass einzelne Module austauschbar und so sehr flexibel an Kundenwünsche anpassbar sind.<br>Das entwickelte Konzept wird anschließend anhand einer prototypischen Implementierung auf seine Realisierbarkeit hin getestet und anschließend bewertet.
11.10.21;11.06.22;2022;intern;Master;EN;Automation of the CERAD Neuropsychological Battery;
11.10.21;11.06.22;2022;intern;Master;DE;Image-Warping mittels Hierarchical Graph-Based Video-Segmentation;
11.10.21;11.03.22;2022;intern;Bachelor;DE;Zentrale, kollaborative Routenplanung für mobile Roboter;Die kollaborative Routenplanung mehrerer mobiler Roboter ist ein häufig behandeltes Thema im Fachgebiet der Robotik. Es beschäftigt sich mit der Problemstellung Roboter bzw. Entitäten auf einem Navigationsgraphen von ihrem Startknoten zu einem gegebenen Zielknotenpunkt kosteneffizient und kollisionsfrei zu bewegen. Im Bestreben algorithmischer Vollständigkeit und Optimalität wurden unterschiedliche Lösungsansätze entwickelt, wobei sich die häufigsten Ansätze der Literatur in zwei verschiedene Vorgehensweisen gliedern. Der zentrale Ansatz interpretiert die Roboter als ein großes zusammengesetztes System, berechnet dessen Routen und leidet durch seinen hochdimensionalen Konfigurationsraum an exponentieller Komplexität, findet im Austausch dafür aber häufiger vollständige Lösungen. Bei dem dezentralen Ansatz plant jeder Roboter für sich selbst eine Route zu seinem Ziel. Dieser ist zwar deutlich leistungsfähiger und weist eine bessere Skalierbarkeit auf, ist jedoch in seiner Lösung meist nicht vollständig, d. h. diese Arten von Algorithmen finden manchmal keine Lösung, selbst wenn eine existiert. Darüber hinaus sind die resultierenden Lösungen oft nicht optimal. Diese Arbeit beschäftigt sich mit dem zentralen Ansatz der kollaborativen Routenplanung, soll zunächst einen Einblick in bestehende Lösungsansätze der Literatur hierzu geben und eine prototypische Implementierung eines Verfahrens aus der Literatur zur zentralen kollaborativen Routenplanung mobiler Roboter präsentieren.
11.10.21;11.03.22;2022;intern;Bachelor;DE;Robustes Speicher- und Ressourcenmanagement in der Programmiersprache Rust;Das Ziel der Bachelorarbeit ist es, die bisherigen Probleme klassischer systemnaher Programmiersprachen beim Ressourcenmanagement und deren Auswirkungen zu analysieren. Dabei wird zunächst analysiert, welche Herangehensweisen bisher verwendet werden, um das Ressourcenmanagement für den Entwickler zu vereinfachen. Daraufhin werden die Ansätze von Rust mit den Bestehenden verglichen. Dies geschieht im Kontext der Entwicklung einer Erweiterung für den Linux-Kernel. Daraus wird schließlich geschlussfolgert, ob Rust eine sinnvolle alternative Sprache für die systemnahe Entwicklung im Linux-Kernel ist.
12.10.21;12.03.22;2022;extern;Bachelor;DE;Front-End-Testwerkzeuge für das Visual Testing von Online-Oberflächen bei DATEV eG;"Das Thema dieser Bachelorarbeit handelt es sich um die Auswahl eines passenden Front-End-Testwerkzeugs (engl.: Tools) für das Visual Testing von Online-Oberflächen der DATEV eG. Es werden unter anderem die Testwerkzeuge ""Cypress"", ""Storybook"" und ""BackstopJS"" anhand mehrerer Kriterien untersucht. Nach der Auswahl folgt der prototypische Einsatz, um zu überprüfen, ob das ausgewählte Tool visuell Testen kann. Dieser Einsatz erfolgt bei einer Online-Anwendungen der DATEV eG. Die DATEV eG steigt immer mehr auf die Onlinewelt um und hat somit einige Online-Oberflächen. Aktuell werden mit den oben genannten Tools nur funktionale Tests abgedeckt."
14.10.21;14.03.22;2022;extern;Bachelor;DE;Konzeption und prototypische Realisierung einer AR-Anwendung für die erleichterte<br>Bedienung einer Werkzeugmaschine im Produktionsumfeld;Eine Werkzeugmaschine stellt ein komplexes System dar, das für die Bedienung qualifizierte Fachkräfte voraussetzt. Durch die fortschreitende Automatisierung von Produktionsmaschinen in Fertigungsprozessen kommt es vermehrt zu größer werdenden Aufgabenbereichen von Maschinenbedienern. Dies hat zur Folge, dass sich Fachpersonal auf die Bedienung und Konfiguration von immer mehr Werkzeugmaschinen spezialisieren muss.<br><br>Im Rahmen dieser Bachelorarbeit werden eine Mixed Reality und eine Assisted Reality Anwendung in Zusammenarbeit mit dem Unternehmen SIEMENS geschaffen, die es dem Bediener einer Werkzeugmaschine ermöglichen, spezifische Parameter, die für das Rüsten der Maschine benötigt werden, direkt im Blickfeld anzuzeigen. Hierbei wird besonders untersucht, welche Art der AR-Darstellungsweise sich im Arbeitsumfeld und im Inhaltskontext am besten eignet.<br><br>Die Arbeit untergliedert sich hierbei in die Analyse und Konzeptionierungsphase, in der die unterschiedlichen Technologien hinsichtlich Ihrer Einsatzmöglichkeiten bewertet und die späteren Prototypen geplant werden. Die anschließende Implementierungsphase zeigt hierauf die Umsetzung der Prototypen auf.<br><br>Als Ergebnis der prototypischen Anwendungen lässt sich zusammenfassen, dass beide Technologieformen für den beschriebenen Anwendungsfall genutzt werden können. Hinsichtlich künftiger Weiterentwicklungsmöglichkeiten bietet die Mixed Reality Anwendung jedoch das größte Potenzial und wird dahingehend empfohlen.
14.10.21;14.03.22;2022;intern;Bachelor;DE;Untersuchung der Eignung von Code Property Graphs zur Erkennung von Input-Validation-Schwachstellen in dbus-Programmen;Diese Arbeit beschäftigt sich mit der Frage, inwieweit sich der Code Property Graph (CPG)<br>zur Erkennung von Inputvalidierungsschwachstellen von dbus-Programmen eignet. Dafür<br>wurde ein PoC entwickelt, der mittels Joern Datenpfade aus der dbus-Schnittstelle verfolgt und diese anhand konfigurierbarer Filter auf potenziell vulnerable Senken reduziert.<br>Dabei wurden Erweiterungsmöglichkeiten der Grenzen der Datenabhängigkeitsanalyse in<br>vorhandenen Funktionalitäten bei Argumentenmodifikation durch unterschiedliche Ansätze<br>untersucht. Es konnte die Funktionsweise anhand eines quellcodeoffenen Beispielprojektes<br>veranschaulicht werden. Darüber hinaus wurden die Erkenntnisse für das Auffinden einer<br>vergangenen Schwachstelle in der Bibliothek systemd angewandt. Schließlich konnte eine<br>grundsätzliche Anwendbarkeit festgestellt, aber praktische Grenzen in der Implementierung<br>der Plattform Joern und bei großen zu analysierenden Projekten ausgemacht werden.
15.10.21;14.03.22;2022;extern;Bachelor;DE;Identifikation steuerlicher Sachverhalte von Belegen mit Machine-Learning-Verfahren: Konzeption und Implementierung eines Prototyps für die DATEV eG;Bei der vorliegenden Arbeit geht es um die systematische Überprüfung, ob sich steuerliche Sachverhalte mit Machine-Learning-Unterstützung klassifizieren lassen. Dies soll auf Grundlage von Belegen untersucht werden. Für die Konzeption dieses Systems wurde sich für zwei unterschiedliche Ansätze entschieden.<br>Da für diese Prämisse nur wenig Belege zur Verfügung stehen und diese auch keine ausgeglichene Klassenverteilung haben, befasst sich ein Ansatz mit dem Ausgleich dieser Problematiken. Der zweite Ansatz handelt davon, dass ein Beleg alleine nicht ausreicht, einen Sachverhalt eindeutig zu identifizieren und dementsprechend Zusatzinformationen hinzugefügt werden. Dabei wird als Erstes auf die Konzeption der jeweiligen Komponenten eingegangen. Die systematische Beurteilung, ob eine solche Klassifikation möglicht ist, wird aus den Ergebnissen verschiedener Modelle und zwei Experteninterviews verschiedener Fachrichtungen überprüft. Bei dieser Untersuchung stellte sich heraus, dass mit den definierten Einschränkungen eine sinnvolle Klassifikation steuerlicher Sachverhalte nicht möglicht ist. Nichtsdestotrotz wurde mit diesen Ergebnissen bewiesen, dass eine Klassifikation nur mit Zusatzinformationen bewerkstelligt werden kann. Des Weiteren wurde erkannt, dass Machine-Learning es ermöglicht, Regeln der Sachverhaltszuordnung zu identifizieren. Somit können Domäneexperten Machine-Learning dafür nutzten, Regeln zu finden, welche ansonsten sich überlegt werden müssten.
15.10.21;18.02.22;2022;extern;Bachelor;DE;Integration von RFID in ein Warenwirtschaftssystem am Beispiel von LS Central;In dieser Bachelorarbeit werden die Potenziale von RFID im Einzelhandel aufgezeigt und eine Umsetzung für die RFID-Integration in ein Warenwirtschaftssystem am Beispiel von LS Central aufgezeigt. <br>Dazu wird erläutert, wie die Technologie funktioniert und eingesetzt werden kann und welchen Mehrwert Unternehmen, aber auch Kunden daraus ziehen können. Das Augenmerk liegt hier unter anderem auf dem Unterschied zum Barcode, den RFID in Verbindung mit dem EPC ersetzen könnte. Dabei werden die beiden Codes EPC und GTIN genauer erklärt und darauf eingegangen, welche Daten diese beiden enthalten. Um einen Eindruck zu gewinnen, was ein Einsatz dieser Technologie in der Praxis bewirken kann, wird der Sportartikeleinzelhändler Decathlon beispielhaft betrachtet, welcher RFID bereits flächendeckend einsetzt. <br>Für die Umsetzung der Integration wurde ein Konzept erstellt.  Zunächst wird hier ein Überblick der zur Verfügung stehenden Hard- und Software gegeben. Anschließend werden mittels EPKs, die Prozesse für die Erfassung der RFID Tags am Kassensystem modelliert. Ebenso wurden Anforderungen definiert, die von der Software erfüllt werden müssen. <br>Die auf dem entworfenen Konzept basierende Implementierung wird mit der Programmiersprache AL umgesetzt. Diese wird anhand der verwendeten Objektarten erläutert und zeigt, wie jene genutzt wurden. Dabei wird auch die Erfüllung der Anforderungen aufgezeigt. 
18.10.21;18.08.22;2022;intern;Master;DE;History-Based Active-Learning-Ansätze für überwachte Machine-Learning-Verfahren zur Textklassifikation;
18.10.21;18.03.22;2022;intern;Bachelor;DE;Warum Web Components noch nicht die Norm sind - eine Analyse von Schwachstellen und möglichen Lösungsansätzen;Obwohl die meisten Browser bereits seit mehreren Jahren den Web-Component-Standard unterstützen, wird dieser nur innerhalb der wenigsten Webseiten verwendet. Das Ziel der Arbeit ist zum einen, den aktuellen Stand von Web Components im Kontext der modernen Webentwicklung zu analysieren, und zum anderen neue Erkenntnisse im Hinblick auf die langsame Adaption des Standards zu ermitteln.<br><br>Die Schwachstellen und Limitationen werden sowohl aus Sicht der Komponentenentwickler als auch der Komponentennutzer untersucht. Hierfür wird eine benutzerdefinierte Komponente entwickelt, die anschließend in die Frontend-Frameworks React, Angular und Vue.js eingebunden wird.<br><br>Mögliche Ursachen für die langsame Adaption sind die Herausforderungen im Bereich der Developer Experience und der Codequalität. Zudem haben Web Components diverse Limitationen sowohl bei der Verwendung in Webformularen als auch bei der Browserkompatibilität der Unterspezifikation von Customized built-in Elements. Des Weiteren ist die Einbindung der Komponente aufgrund der unzureichenden Kompatibilität mit dem React-Framework nicht ohne Umstände möglich.<br><br>Der Web-Component-Standard wird zu keiner Norm, solange die Form Participation API sowie die Customized built-in Elements nicht von allen Browsern implementiert wurden und sich die Unterstützung seitens React im experimentellen Stadium befindet.<br>
19.10.21;18.03.22;2022;extern;Bachelor;DE;Konzeption und Entwicklung einer Segmentierung zustandsbehafteter Ablaufdiagramme in wiederverwendbare Bausteine in SCHEMA ST4;Ziel meiner Arbeit ist es, Anwendern des Redaktionssystems SCHEMA ST4 zu ermöglichen, ihre Workflows besser zu modularisieren. Dazu werden die Möglichkeiten analysiert, die SCHEMA ST4 bisher zur Unterteilung von Workflows in Module bietet. Zusätzlich werden Segmentierungsmöglichkeiten für Prozessgraphen in Business Process Model and Notation (BPMN), einem Standard für Prozessmodellierung, betrachtet und hinsichtlich ihrer Übertragbarkeit auf SCHEMA ST4 untersucht.<br><br>Unter Berücksichtigung der technischen Rahmenbedingungen wird ein neues Segmentierungskonzept für Workflows in SCHEMA ST4 entworfen und implementiert. Anstatt die bisherigen Modularisierungsmöglichkeiten in SCHEMA ST4 zu modifizieren, erlaubt die umgesetzte Lösung einen neuen Ansatz, um Workflows zu segmentieren. Dadurch kann die Kompatibilität von SCHEMA ST4 mit in der Vergangenheit erstellten Workflows gewährleistet werden. Die neue Möglichkeit soll vor allem durch lose Kopplung bessere Modularisierung ermöglichen.
20.10.21;11.02.22;2022;extern;Bachelor;DE;Konzeption und Implementierung einer Webanwendung zur automatisierten Prüfung von Leistungsnachweisen in der IT-Dienstleistungs-Branche;Der Leistungsnachweis stellt die Grundlage für die Erstellung von Rechnungen der ISO Public Services GmbH dar. Am Ende eines jeden Monats wird ein Leistungsnachweis für jeden einzelnen Consultant des IT-Dienstleisters erstellt und dieser muss in einem internen Prozessschritt manuell geprüft werden, damit die Einhaltung der offiziellen Kunden-Vorgaben gewährleistet wird.<br>In dieser Arbeit wird eine Webanwendung anhand von firmeninternen Anforderungen konzipiert und entwickelt, die das Prüfen von Leistungsnachweisen durchführt. Hierbei werden die Daten der Leis- tungsnachweise mit klassischen Algorithmen sowie mit Methoden des maschinellen Lernens validiert. Im Falle von Tätigkeitsbeschreibungen in einem Leistungsnachweis wird mithilfe von Vergangenheitsdaten ein Modell erstellt, dass die Korrektheit einer solchen Beschreibung bewerten kann.<br>Die Anwendung wird evaluiert, indem die Effizienz und Effektivität einer manuellen Leistungsnachweisprüfung mit der einer automati- schen Prüfung gegenübergestellt wird. Durch die entwickelte Anwendung kann eine Vervielfältigung der Prüfungseffizienz erzielt werden, ohne dabei die Fehlererkennung zu beeinträchtigen.
20.10.21;20.06.22;2022;intern;Master;EN;Predicting dementia with an automatic version of the SKT short cognitive performance test;
20.10.21;18.01.22;2022;extern;Bachelor;EN;"Concept, Design and Implementation of management dashboards to accelerate the ""EDI Migration"" project at Electrolux AG";Dashboard is an important tool for managers to monitor the progress of their projects. The EDIMGR-Project of the Electrolux AG currently does not have a suitable management dashboard and compensates this by using multiple Jira standard dashboards. One of the limitations of Jira?s standard dashboards is that they offer limited to no customization. As a result, manual effort is needed to generate reports for management meetings. Since this is a time-consuming task, the analysis results, when they become available, are often not representative of the actual progress of the project. <br>In the current state of technological advancement, there are many third-party solutions which aim to tackle this weakness of Jira. One solution is based on the REST API concept that helps connect analysis tools to the data that are programmatically extracted from Jira. <br>For this thesis, an in-house dashboard solution was developed. In the first step, interviews with the IT project managers at three different management levels were conducted for gathering requirements, which were then used as the basis for a comprehensive conceptual design. Finally, the concept was implemented using Tableau and Python.<br>This new tool will not only reduce the workload of manual reports on the project?s progress, but also provides an optimized interface and a relatively cost-efficient solution that tailors to the data needs of the users while keeping a certain level of data privacy and security.<br>
22.10.21;13.02.22;2022;intern;Bachelor;DE;Visualisierung und Quantisierung von Vocal Aging und Voice Fatigue mithilfe von neuronalen Netzen;Mit dieser Arbeit sollen das Altern der Stimme durch neuronale Netze und den daraus<br>resultierenden Embeddings visualisiert und quantisiert werden.<br>Konkret soll das mithilfe von x-vectors und einem Time-Delayed Neural Network umge-<br>setzt werden. Dazu soll ein Vergleich mit den Embeddings eines Encoder-Modells gezogen<br>werden. Aufnahmen von Queen Elizabeth, Alisatir Cooke und LMELectures werden für<br>die Extrahierung der Embeddings benutzt.<br>Es konnte gezeigt werden, dass t-SNE und UMAP sich eignen um Vocal Aging dar-<br>zustellen. Voice Fatigue konnte zwar auch visualisiert werden, jedoch nur durch das<br>Time-Delayed Neural Network. Das wav2vev-Modell erzielte dabei schlechtere Ergeb-<br>nisse.
22.10.21;22.03.22;2022;extern;Bachelor;EN;Security Analysis of the Client-Server Application ProZubi;This bachelor's thesis has two major purposes: \(1) to investigate and point out cybersecurity issues of the client-server application ProZubi. \(2) to teach you, the reader, the methods used in searching and evaluating these vulnerabilities. \In the first part, ProZubi and its general functionality are presented. Doing so, the growing need for both more security in ProZubi and a thorough evaluation of it are shown. <br>Additionally, a description for the key concepts and properties of information security, as a foundation for this thesis, is provided.<br>The paper then introduces threat modeling. This includes the steps in creating a threat model as well as and an explanation of STRIDE, the method used for analysis.<br>Afterwards the theory for assessing vulnerabilities and high level solutions for every category in STRIDE are provided.<br>The previously found threats are then evaluated and specific approaches to fix elaborated. Concluding the topic a risk analysis for not implementing a mitigation is carried out.<br>Continuing on, a penetration test for ProZubi is conducted.<br>Before carrying out the pentest, all steps taken and tools used in it are explained. Finally, the vulnerabilities found are evaluated.\This thesis hopes to offer useful tips and an introduction in both threat modeling and penetration testing while improving security for ProZubi.
25.10.21;25.03.22;2022;intern;Bachelor;DE;Analyse und Bewertung von Reifegradmodellen für Geschäftsprozesse;"Gesamtziel der Arbeit ist eine Analyse und eine Bewertung bestehender Reifegradmodelle <br>für Geschäftsprozesse. Hierfür werden zunächst die Forschungsmethodik und die <br>Auswahl der zu untersuchenden Reifegradmodelle dargestellt und abgegrenzt. Außerdem <br>werden die Begrifflichkeiten und Inhalte zu den Hauptpunkten ""Geschäftsprozesse"" und <br>""Reifegradmodelle"" definiert. Auf dieser Grundlage werden die Reifegradmodelle für <br>Geschäftsprozesse vorgestellt sowie Vergleichskriterien der inhaltlichen und <br>methodischen Analyse festgelegt. Die Erkenntnisse der Analyse sollen als Anhaltspunkt <br>für einen Vergleich der Modelle und als Handlungsempfehlung bei der Auswahl und dem <br>Einsatz solcher Reifegradmodelle in der Praxis dienen.<br>"
25.10.21;25.06.22;2022;extern;Master;EN;Design and development of an explainer system for neural networks with the application in money laundering detection;
27.10.21;27.03.22;2022;extern;Bachelor;DE;Automatische Erzeugung von Simulationsdaten einer Produktionsanlage zur Erstellung einer Demo des MES-Systems Plant Integrate iT Workflow;Da auf Fachmessen den Kunden eine realitätsnahe Demonstration des MES-Systems der Firma ProLeiT geboten werden soll, muss das System immer mit aktuellen und schlüssigen Daten gefüllt sein. Deshalb wird das Demosystem des Plant Integrate iT Workflow vor jedem Einsatz händisch neu parametriert. Da dies eine nicht unerhebliche Menge Zeit in Anspruch nimmt, wurde das Neuparametrieren im Zuge dieser Arbeit automatisiert und die Funktionen des Demosystems wurden erweitert.<br>Hierzu wurden während dieser Arbeit Skripte erstellt, welche alle benötigten Stammdaten in die Systemdatenbank einspielen. Des Weiteren wurden Skripte erstellt, welche zur Laufzeit des Demosystems automatisch Bewegungsdaten erzeugen, sodass sich das Demosystem so verhält als würde im Hintergrund eine echte Produktion laufen. Damit auch schon zu Beginn der Messe Bewegungsdaten vorhanden sind, wurde ferner ein Skript erstellt, welches simulierte Bewegungsdaten für sieben Tage in die Vergangenheit erzeugt. So kann auch zum Messestart schon die Produktionsanalyse präsentiert werden. Um diese möglichst realistisch wirken zu lassen, werden alle Bewegungsdaten, welche in einer echten Produktion durch die physikalischen Umstände schwanken, von einem im Zuge dieser Arbeit erstellten Pseudozufallsgenerator erzeugt.<br>Das erstellte Demosystem deckt die wichtigsten Bestandteile von Plant Integrate iT Workflow ab und ist auf Messen einsetzbar. Einige Erweiterungsmöglichkeiten der Demo sind am Ende dieser Arbeit aufgelistet.
01.11.21;01.07.22;2022;intern;Master;DE;Neuronales bildbasiertes Rendering - Aktueller Stand der Technik und prototypische Implementierung;
01.11.21;01.07.22;2022;extern;Master;DE;Implementierung einer Machine-Learning-unterstützten Render-Pipeline unter Android am Beispiel von OpenGL;
01.11.21;30.03.22;2022;extern;Bachelor;DE;Deployment einer Legacy-Anwendung mit Hilfe von Containervirtualisierung und Vergleich mit traditionellen Deployment;Die vorliegende Studienarbeit wurde in Kooperation mit dem Unternehmen PRODATO Retail Solutions GmbH angefertigt. Das Ziel der Studienarbeit ist es, die grundsätzliche Architektur einer in Software-Container bereitgestellten Anwendungen und den dazugehörigen Lebenszyklus dieser Anwendungen zu entwerfen und ausführlich zu dokumentieren.<br><br>Ein weiterer Aspekt dieser Arbeit soll der Vergleich zum traditionellen Vorgehen bei der Bereitstellung von Anwendungen mit der Verwendung von Software-Containern bei der Bereitstellung sein. Weiterhin soll untersucht werden, welche Voraussetzungen geschaffen werden müssen, um einen Parallelbetrieb von mehreren Software-Containern zur Lastverteilung in der Anwendung zu ermöglichen. Die Technologien Docker, Kubernetes und Jenkins werden in dieser Arbeit zum Einsatz kommen. Die Erkenntnisse dieser Arbeit sollen vor allem im Deployment eines ECommerce-Projektes der Firma Anwendung finden.
01.11.21;01.04.22;2022;intern;Bachelor;DE;Entwicklung eines PAMGuard Plugins zum Erstellen gelabelter Trainingsdaten für Neuronale Netzwerk Lokalisatoren.;In den Bereichen der Bioakustik helfen maschinelle Lern-Algorithmen den Biologen dabei,<br>Rufe von Tieren zu bestimmten Tierverhalten zuzuordnen. Jedoch bei Meereslebewesen<br>mit einer hohen vermuteten Intelligenz und komplexen Verhaltensweisen wie dem Killerwal<br>(Orcinus Orca) reicht der Ruf alleine nicht für eine Verhaltenszuordnung aus.<br>Man vermutet, dass für das komplexe Verhalten eine kontextbezogene Analyse notwendig<br>ist, welche weitere Informationen wie die Tageszeit, die Umgebung und die Position<br>bei der Auswertung berücksichtigt. Zudem muss zwischen den kommunizierenden Tieren<br>unterschieden werden, was in erster Linie mit bestehenden traditionellen Lokalisatoren und<br>aktiven/passiven akustischen Überwachungskonzepten gelöst wird. Im Bereich der Lokalisierung<br>wurden, wegen eines Mangels an gelabelten Trainingsdatensätzen, bisher nur wenige<br>Ansätze mit maschinellen Lernverfahren erforscht. Solche gelabelten Daten<br>können jedoch durch akustische Simulatoren erzeugt werden. Das Ziel dieser Arbeit ist es, eine<br>Code-Erweiterung für den Unterwasser-Akustischen-Simulator der Open-Source-Software<br>PAMGuard (Passive Acoustic Guardianship) zu entwickeln, um simulierte mehrkanalige<br>Hydro-/Mikrofondaten aus vorhandenen Aufnahmen zu erzeugen. Neben dem vollautomatischen<br>Verfahren zur Generierung gelabelter Datenmengen für die Killerwal-Lokalisierung<br>werden die Ergebnisse von ORCA-SPY, einem PAMGuard akustischen Datenverarbeitungsfluss<br>mit TDOA-Lokalisierung, mit den Ergebnissen von ...
02.11.21;02.04.22;2022;intern;Bachelor;DE;Methoden zur Gait-Transition ohne Zwischenschritte bei krabbelnden<br>Robotern;Die Arbeit befasst sich mit Bugbot, einem autonomen, mobilen Roboter, der an der Technischen Hochschule Nürnberg entwickelt wurde. Es handelt sich um einen insektenartigen Roboter mit sechs Beinen, der sich anhand von verschiedenen Gangarten fortbewegen kann. Tritt ein Gangartwechsel auf, entstehen allerdings ruckhafte Bewegungen, die die Ausrichtung des Roboters negativ beeinflussen. Um diesem Problem entgegenzuwirken, wurde ein Konzept der Gait-Transition mit Zwischenschritten entwickelt. Um den Bewegungsfluss des Roboters weiterhin zu verbessern, sollen die Gangarten zukünftig gleitend ohne Zwischenschritte ineinander übergehen. Das Ziel der Arbeit ist es, eine Methode zu finden, die diesen Ansatz verfolgt und auf Bugbot übertragen werden kann. Dafür wurden unterschiedliche Methoden recherchiert, um eine Gait-Transition ohne Zwischenschritte auf Bugbot anzuwenden. Dabei wurden nicht nur Ansätze für Hexapoden untersucht, sondern das Forschungsfeld wurde auch auf den Bereich der Quadropoden erweitert. Durch die Recherchearbeit wurden Erkenntnisse zu den Auslösern von Gait-Transitions gezogen und analysiert. Unter der Berücksichtigung der Stabilitätskriterien wurde der Fokus auf den CPG-Ansatz gelegt, in dem der Bewegungsablauf des Hexapoden durch sinus-ähnliche Schwingungen vereinfacht wird. 
02.11.21;02.04.22;2022;extern;Bachelor;EN;Development and Evaluation of a Toolbox for Conversion Between Various Camera Parameter Conventions;Darstellungen virtueller Kameras sind ein wesentlicher Bestandteil der Computergrafik und der Computer Vision. Intrinsische Parameter beschreiben Eigenschaften wie Brennweite und Linsenverzerrung, die der Kamera selbst inhärent sind, während extrinsische Parameter die Orientierung und Translation der Kamera beschreiben. Da der Bereich Computer Vision viele Teilgebiete umfasst, exisitieren viele verschiedene spezialisierte Softwareanwendungen. Es ist wünschenswert, Daten wie Kameraparameter zwischen Anwendungen auszutauschen, um ihre Stärken in einem Arbeitsablauf zu nutzen. Eine Vielzahl von Formaten und Konventionen erschweren jedoch den Transport von Kameraparametern von einem Softwarepaket zum anderen. Diese Arbeit stellt eine einfach zu verwendende Python-Bibliothek ´´camorph'' vor, um verschiedene Formate ineinander zu konvertieren. Zusätzlich wurde ein Plug-In-Mechanismus entwickelt, um weitere Formate und Konventionen einfach hinzufügen und unterstützen zu können.
02.11.21;02.04.22;2022;extern;Bachelor;EN;Optimization of a Deep Neural Network for Voice Activity Detection and Loudness Estimation;Deep Neural Networks (DNNs) for image or audio processing consist of millions of weights, which can get very computationally heavy and take up quite a large amount of memory space. Training of these Artificial Neural Networks (ANNs) can be performed on specialized and powerful hardware. However, for inferencing on edge devices that have limited computational power and memory, this is an issue. Especially if the application requires the data to be processed in real-time. Therefore, optimization methods have been developed to reduce the complexity of large Deep Neural Networks that have only a small degrading effect on their estimation performance.<br>In this thesis, four optimization methods for DNNs, namely quantization, structural pruning, depthwise separable convolution and dilated convolution are investigated. Furthermore, the fundamentals of Artificial Neural Networks as well as the corresponding frameworks and tools used in this work are presented. The implementation of the four methods of DNN optimization and their effect on computational cost, memory usage and performance degradation on a DNN, which uses convolutional and fully connected layers with approximately 560, 000 parameters is described and evaluated. The resulting optimized models are also compared to a smaller variation of the same network architecture with reduced convolutional filters and approximately 150, 000 parameters.<br>Quantization optimization was achieved with the ONNX Runtime library and yielded ...
03.11.21;25.03.22;2022;extern;Bachelor;DE;Konzeptionierung und Implementierung von Maßnahmen zur Einführung einer Bug Policy im Team Auswerten der DATEV eG;Das Team Auswerten der DATEV eG betreut drei OnPremise-Produkte. Bei diesen werden teilweise noch neue Features entwickelt, teilweise ist keine Weiterentwicklung mehr vorgesehen. Im Rahmen des Portfoliowandels der DATEV eG soll jedoch die Anzahl der Mitarbeiter in den OnPremise-Produkten mittelfristig abnehmen und diese nur noch mit einer geringen Anzahl an Personen betreut werden. Damit dies erfolgreich geschehen kann, muss die zu wartende Software möglichst fehlerfrei sein.<br>Das Team Auswerten hat jedoch in seinem Backlog einige Bugs, welche teilweise schon sehr lange Zeit dort liegen und nur wenig Beachtung erhalten. Im Rahmen der Qualitätsoffensive soll die Produktqualität gesteigert werden und eine Bug Policy eingeführt werden.<br>Im Rahmen der Arbeit wurde hierzu ein Vorgehensmodell entwickelt und im Rahmen eines zeitlich begrenzten Experiments in das Team Auswerten eingeführt. Dabei wurde festgestellt, dass die Einführung einer Bug Policy nicht ohne Probleme stattfinden konnte, da in anderen Prozessen noch Verbesserungspotential steckt. <br>
15.11.21;15.04.22;2022;extern;Bachelor;DE;Konzeptionierung und Implementierung der Nachschubsteuerung auf Basis des Frameworks Plant iT base;Das Plant iT Workflow Modul Nachschubsteuerung regelt den Datenaustausch zwischen einem Lagerverwaltungssystem und dem MES Plant iT Workflow von ProLeiT. Das Modul liegt in vier unterschiedlichen kundenspezifischen Versionen vor. ProLeiT überführt bestehende Funktionalitäten des MES Plant iT Workflow in das aktuellere MES Plant iT base. Die Funktionen der bisherigen Varianten der Nachschubsteuerung sollen in einem neuem Plant iT base Modul vereinigt werden. Die gewählte Umsetzung soll dazu beitragen, dass zukünftige Projekte leichter mit einem gemeinsamen Stand umsetzbar sind. Der Funktionsumfang der vier Projektstände wird analysiert, ein Konzept erstellt und ein Plant iT base Modul umgesetzt, welches die, in diesem MES, realisierbaren Funktionen abdecken kann. Bei der Umsetzung soll die Einbindung von BPMN-Diagrammen dazu beitragen, dass Projektanpassungen möglichst ohne Eingriffe in den Programmcode zu realisieren sind. Die Varianten des Plant iT Workflow Moduls beinhalten Funktionalitäten, die durch eine enge Kopplung mit angrenzenden Modulen verfügbar gemacht werden. Das Plant iT base Modul stellt seine Funktionen anderen Modulen lediglich über Schnittstellen zur Verfügung, um Modulgrenzen einhalten zu können. Es werden zukünftig noch weitere angrenzende Module benötigt, um den gesamten Funktionsumfang der Plant iT Workflow Nachschubsteuerung in Plant iT base realisieren zu können. 
15.11.21;15.07.22;2022;extern;Master;DE;Segmentierung von Gefäßerkrankungen und Hautläsionen: ein Vergleich verschiedener Methoden auf Präzision und Performanz auf einem eingebetteten System;
19.11.21;19.04.22;2022;extern;Bachelor;DE;Erhöhung der Prüfungsqualität und -effizienz im Rahmen der Jahresabschlussprüfung durch den Einsatz von Process Mining in einer mittelständischen Prüfungs- und Beratungsgesellschaft;Process Mining ermöglicht es, anhand von (Ereignis-)Daten aus ERP-Systemen, die geschäftlichen Ist-Prozesse eines Unternehmens zu rekonstruieren. Durch den Abgleich mit vordefinierten Soll-Prozessen können Abweichungen durch Fehler oder Betrug identifiziert und Schlussfolgerungen über die Notwendigkeit von weiterführenden Prüfungshandlungen, im Rahmen der Jahresabschlussprüfung, getroffen werden. Das Ziel in der vorliegenden Arbeit war es herauszufinden, inwieweit die Prüfungsqualität und -effizienz in der Jahresabschlussprüfung durch Process Mining erhöht werden kann. Aus der qualitativen Studie ging hervor, dass die fachmännisch korrekte Anwendung von Process Mining die Prüfungsqualität und -effizienz der Jahresabschlussprüfung, bei produzierenden Unternehmen, ab einer bestimmten Unternehmensgröße, erhöhen kann. Grundvoraussetzung ist ein ordentlich geführtes, lückenloses, standardisiertes ERP-System, da darauf basierend Process Mining betrieben wird. Der Einsatz vereinfacht die Prozessaufnahme und das Testen des internen Kontrollsystems. Insbesondere bei Unternehmen mit Massentransaktionen ist es wahrscheinlicher Unregelmäßigkeiten in den Prozessen aufzudecken, als beim stichprobeorientierten Verfahren, da der komplette Datenbestand geprüft wird. Dadurch können Risiken besser beurteilt, der Prüfungsumfang besser bestimmt und die Prüfungssicherheit erhöht werden.<br>Wichtig ist die Förderung der Nutzung durch Aufklärung der Anwender über die alternativen Prüfungsmöglichkeiten.
19.11.21;14.01.22;2022;extern;Bachelor;DE;Evaluierung von ADS-B zur Erfassung von Flugbewegungen in Flughafennähe;Die vorliegende Bachelorarbeit befasst sich mit Automatic Dependent Surveillance - Broadcast (ADS-B), das von Luftfahrzeugen ausgesendet wird, und der Anwendung dieser Überwachungstechnik im Flughafenumfeld. Das Ziel dieser Arbeit war es, den Einsatz von ADS-B zur Überwachung der Situation im Umfeld eines Flughafens zu evaluieren, um die Frage zu beantworten, welche für den Flughafen relevanten Informationen aus den ADS-B-Daten gewonnen werden können. Dazu wurde ein bestehendes Softwaremodul, das Teil einer Flughafenmanagementsoftware ist, entsprechend erweitert und an einen ADS-B-Empfänger angebunden. Eine Implementierung zur Verarbeitung von ADS-B-Daten, die in Echtzeit übermittelt werden, folgte der Auswertung der empfangenen und dekodierten Daten. Durch die Analyse von Flugbahnen und Anwendung von Verfahren zur Überwachung geographischer Bereiche konnten anhand der ADS-B-Daten Zeitstempel sowie Statusinformationen zu einem Flug ermittelt werden. Darüber hinaus wurden Vorhersagen über Zeitpunkte getroffen und Ergebnisse mit tatsächlichen Daten verglichen.
19.11.21;19.07.22;2022;intern;Master;DE;Entwurf und prototypische Implementierung einer gedruckten, kryptografischen und Zeit überdauernden Signatur für Papierdokumente;
28.11.21;21.04.22;2022;intern;Bachelor;DE;Interaktions-, Filterungs- und Darstellungskonzepte im Virtuellen Raum;"Das Ziel dieser Arbeit ist es herauszufinden, ob sich ein qualitativer Mehrwert bei der Darstellung, Interaktion und Filterung großer Datenmengen im ""Virtuellen Raum"" gegenüber herkömmlichen zweidimensionalen Systemen erzielen lässt. Dazu werden in den Kapiteln unterschiedliche Interaktions-, Filterungs- und Darstellungskonzepte für Virtual Reality Anwendungen, basierend auf der Methode der heuristischen Evaluation analysiert und bewertet. Anschließend werden einige dieser Konzepte ausgewählt, um innerhalb eines Prototypen realisiert zu werden. Dadurch sollen weitere Erkenntnisse über diese Konzepte gesammelt werden. Die Implementation des Prototypen findet dabei unter der Verwendung der Oculus Quest 2 VR-Brille in der Unity Engine statt. Die für die Interaktions- und Filterungskonzepte betrachteten Eingabemethoden sind die Quest Controller sowie die Handtrackingfunktion der VR-Brille."
28.11.21;28.04.22;2022;extern;Bachelor;EN;Perceptual similarity of hot stamping foils;One method used to decorate products is the use of hot stamping foils. One collection by KURZ is composed of foils that appear differently depending on the viewing angle. This makes automatic comparison difficult. The only way to find a foil at the moment is to look at all existing ones until that foil or a sufficiently similar one is discovered. Although there are approaches to perceptual similarity in existing literature, none of them apply to the given scenario. The goal of this thesis is to develop and evaluate a method to identify foils that are perceptually similar to a given foil.<br><br>Based on findings from relevant literature, an approach with two training phases using convolutional neural networks is developed. The training is executed on a subset of all available foils. Two datasets are generated using custom algorithms and a survey of human perception. Following that, the implementation is evaluated on a small-scale representation of a potential future use case. The approach returns a network that can calculate representations for images of foils. They can be used to quantify their perceptual similarity and to find similar foils to a given one using nearest neighbor classification. The top-performing network achieves a 95.6% agreement rate with humans on the perceptual data, and the correct foil appears in 98.8% of the network?s top-three predictions for three images of that foil. Based on these findings, the proposed method is deemed suitable for further development.
29.11.21;29.04.22;2022;intern;Bachelor;DE;Untersuchung der Potenziale und Grenzen von End-to-End Learning bei der Entwicklung eines Chatbots für die psychosoziale Beratung.;In dieser Arbeit wurde ein Chatbot entwickelt, welcher als Grundlage für die Untersuchung der Deep Learning Methode End-to-End-Learning verwendet wurde. Die Datengrundlage für die Entwicklung des Chatbots, für die Online-Schlafberatung, wurden durch die Analyse der Homepage und Interessenten-Emails entnommen. <br>Zu Beginn wurden die grundlegenden Technologien im Bereich des maschinellen Lernens erläutert, darauf folgte zunächst eine Einführung in die Chatbots und deren funktionsweise, hierbei wurde der Fokus auf die Methoden der Spracherkennung Verarbeitung und Ausgabe gelegt. Danach wurde zunächst die Motivation der Weiterentwicklung, dargelegt und erläutert weshalb dies eine Methoden Änderung nach sich ziehen sollte, diese Methoden wurden da-nach Inbezugnahme des verwendeten Chatbot Frameworks Rasa verglichen.<br>Als nächstes erfolgte die Konzeption, in welcher zunächst die Konzeption der eingesetzten und zu vergleichenden Systeme, darunter das Hybride arbeitende System aus der Kombination von Pipeline und End-to-End-System und das nur aus der End-to-End Methode bestehende System vorgestellt wird.<br>Darauf folgt die Implementierung und Bewertung der Chatbot-Systeme mit den in der Konzeption dargelegten Methoden und der dazu benötigten Program-mierung. Als letztes folgt eine Schlussbetrachtung mit einer Zusammenfassung und einem Ausblick.<br>
29.11.21;12.04.22;2022;intern;Bachelor;DE;Legal Tech Systeme: Technische Grundlagen und Einfluss auf den Rechtsbereich; 
01.12.21;27.04.22;2022;intern;Bachelor;DE;Entwicklung eines Educational-Software-Prototypen zum Einstieg in das Thema der Kantenvorhersage in Sozialen Netzwerken;"Das Ziel dieser Arbeit ist es einen Educational-Software-Prototyp zu entwickeln, mit dem der Einstieg in das Thema der Kantenvorhersage vereinfacht werden soll. Es wird die folgende Forschungsfrage untersucht: Wie kann durch einen Educational-Software-Prototyp, der es ermöglicht Kantenvorhersagen in sozialen Netzwerken tutorialbasiert anhand einer GUI durchzuführen, der Einstieg in das Thema Kantenvorhersage erleichtert und ein Lerneffekt erzielt werden? Um die Forschungsfrage zu beantworten wurde nach dem Design-Science-Ansatz vorgegangen. Es wurde ein Educational-Software-Prototyp zum Einstieg in das Thema Kantenvorhersage entwickelt. Dieser wurde anschließend von sechs Testpersonen mit Hilfe von zwei Fragebögen hinsichtlich eines möglichen Lerneffekts sowie der Usability evaluiert. Die Evaluation mittels des ""one-sample Wilcoxon signed rank""-Tests ergab, dass mit dem Prototyp ein statistisch signifikanter Lerneffekt erzielt werden kann. Des Weiteren wurde festgestellt, dass die Usability des Prototyps als ""gut"" bewertet wurde. Außerdem gaben die Testpersonen in der Evaluation an, dass der Prototyp sie beim Einstieg in das Thema der Kantenvorhersage in sozialen Netzwerken unterstützen kann. Daher ist der in der Arbeit entwickelte Educational-Software-Prototyp geeignet, den Einstieg in das Thema der Kantenvorhersage in sozialen Netzwerken zu erleichtern."
01.12.21;01.04.22;2022;extern;Bachelor;DE;Customer Relationship Management (CRM) im Finanzwesen (Schwerpunkt Bankwesen) - Analyse und Implementierungsperspektiven serviceorientierter Geschäftsprozesse innerhalb der bestehenden Systemlandschaft am Beispiel der UmweltBank AG Nürnberg;"Die UmweltBank AG Nürnberg ist mit der Herausforderung konfrontiert, ihre Softwarelandschaft zu konsolidieren. Um dahingehend aktiv werden zu können, wird eine aktuelle und vollständige Bestandsanalyse (Status Quo; inkl. textueller/visueller Dokumentation) über die laufenden Geschäftsprozesse benötigt, welche in diesem erforderlichen Umfang und der Aktualität derzeit nicht vorhanden ist. <br><br>Ziel dieser Bachelorthesis ist es, die bestehenden Prozesse für ausgewählte Bereiche im Privatkunden-Sektor mit Hilfe verschiedener bewährter Methoden zu erfassen, zu analysieren, ggf. zu harmonisieren und in einer (DIN-) konformen und einheitlichen Prozessvisualisierung (i. A. a. eine Prozesslandkarte) zu normieren. Insbesondere hinsichtlich des bestehenden CRM Systems und/oder der Nutzung bzw. des Einsatzes weiterer informationstechnischer Komponenten (Stichwort Handlungsempfehlung), werden auf Grundlage dieser Analyse (Stichwort Entscheidungsgrundlage/-hilfe) und einer anschließenden Bewertung perspektivische Entscheidungen durch die Geschäftsführung getroffen.? <br>"
01.12.21;31.07.22;2022;intern;Master;DE;Minimierung der Fertigungszeit von 3D-Drucken von Stadtmodellen durch Teil-Substitution mit standardisierten Bausteinen<br>;
07.12.21;07.08.22;2022;intern;Master;DE;Analyse und Bewertung von Reifegradmodellen für Agilität in Unternehmen;
08.12.21;08.05.22;2022;extern;Bachelor;DE;Erhebung und Evaluation von Erfolgskriterien im agilen Projektmanagement für die Remote-Arbeit;Für das Management und die Steuerung von Projekten hat sich agiles Projektmanagement in vielen Unternehmen durchgesetzt. Eine Grundlage von agilen Projekten bildet die räumliche Präsenz der Teammitglieder. Viele Unternehmen bieten jedoch inzwischen mobiles Arbeiten an, weshalb die räumliche Nähe der Beteiligten nicht mehr gewährleistet werden kann. Diese Arbeit beschäftigt sich mit der Frage, welche Voraussetzungen in agilen, verteilten Softwareentwicklungsprojekten gegeben sein müssen, so dass diese erfolgreich durchgeführt werden können. Außerdem soll analysiert werden, ob Ergebnisse von ausgewählten Erfolgskennzahlen auch für den Erfolg verteilter, agiler Softwareentwicklungsprojekte aussagekräftig sind und ob diese durch die Remote-Arbeit negativ beeinflusst werden. <br>Mit Hilfe einer Online-Umfrage wurden 56 Personen hinsichtlich deren Remote-Arbeit in einem agilen Softwareentwicklungsprojekt befragt. In den Ergebnissen der Auswertung lassen sich sowohl positive wie auch negative Auffälligkeiten erkennen, welche sich auf den Erfolg eines agilen Projektes auswirken können. Die Ergebnisse haben außerdem gezeigt, dass Erfolgskennzahlen auch für den Erfolg verteilter, agiler Softwareentwicklungsprojekte aussagekräftig sind, allerdings lassen sich auffällige Ergebnisse oft auf andere Aspekte als bei der zentralen Projektarbeit zurückführen. Alle definierten Erfolgskriterien und empfohlene Maßnahmen wurden abschließend durch ein Experteninterview evaluiert.<br>
15.12.21;15.05.22;2022;intern;Bachelor;DE;Konzeption und Entwicklung von E-Government-Prozessen: Analyse, Optimierung und Digitalisierung des Verwaltungsprozesses von Softwarelizenzen für Schulpersonal der Stadt Nürnberg ;Diese Arbeit beschreibt eine E-Government Fallstudie der Abteilung Schul-IT der Stadt Nürnberg.  Sie analysiert bestehende Verwaltungsprozesse und erarbeitet darauf basierend Lösungsvorschläge zur Optimierung und Digitalisierung der Account- und Lizenzverwaltung des Schulpersonals durch die Schul-IT. 
22.12.21;22.08.22;2022;intern;Master;DE;Konzeptionierung einer flexiblen Datenbankstruktur und einer semantischen Abstraktionsschicht für ein generisches Nutzerkonto der Hochschuljobbörse;
01.01.22;01.06.22;2022;intern;Bachelor;DE;Untersuchung der Adaptierbarkeit verschiedener Ansätze zur 3D Human Pose Estimation an sich ändernde Kamerasetups;
10.01.22;10.06.22;2022;intern;Bachelor;DE;Wissensbilanzen als Instrument der Wissenssteuerung;
11.01.22;11.06.22;2022;intern;Bachelor;DE;Produktverbesserungen anhand von Kundenrezensionen - Analyse verschiedener Text Mining Methoden;
21.01.22;21.06.22;2022;intern;Bachelor;DE;Analyse der Einsatzmöglichkeiten und Grenzen von KI und Robotik in Industrie 4.0;
24.01.22;24.09.22;2022;intern;Master;EN;"Case Study of Digitalization in the Real Estate Sector - <br>Innovation Challenge Hessen: Digitalization of the ""Construction Application""-Process";
01.02.22;01.07.22;2022;extern;Bachelor;DE;Konzeption und Implementierung eines gamifizierten Tools zur Evaluierung von Cyber Security-Kenntnissen von Kunden der infoteam software AG;
02.02.22;02.07.22;2022;intern;Bachelor;DE;Frameworks im Vergleich - Eine Analyse der JavaScript Frameworks Angular und React;
10.02.22;10.10.22;2022;intern;Master;NULL;Management der Softwareentwicklung in internationalen IT-Projekten<br>Eine Analyse über das Management in Softwareprojekten bezogen auf die Softwareentwicklung in <br>internationalen IT-Projekten;
14.02.22;04.08.22;2022;intern;Bachelor;DE;Kompetenzprofile: Web Scraping und Text Mining im Kontext des Hochschultransferforums;
15.02.22;15.10.22;2022;intern;Master;DE;Eine skalierbare Architektur zur Integration heterogener Toolkits und vortrainierter Machine Learning Modelle;
17.02.22;17.10.22;2022;intern;Master;DE;Generierung von Panoramabildern mittels Multi-Homographie Warping;
21.02.22;21.07.22;2022;extern;Bachelor;DE;Optimierung der Supply- und Operations-Planung mit SAP IBP bei Rehau Industries ;
22.02.22;22.07.22;2022;intern;Bachelor;DE;Einsatz digitaler Technologien in der ambulanten Pflege bei der Caritas im Nürnberger Land;
23.02.22;23.10.22;2022;extern;Master;DE;Decentralized Lending: Konzeption und prototypische Implementierung eines dezentralen Kreditsystems in Ethereum;
28.02.22;28.07.22;2022;intern;Bachelor;DE;Entwicklung einer Webapplikation zur semi-automatischen Erfassung von Publikationen an der TH Nürnberg;
01.03.22;01.08.22;2022;intern;Bachelor;DE;Chatbots im industriellen Einkauf: Bestandsaufnahme und Weiterentwicklung;
01.03.22;01.11.22;2022;intern;Master;DE;Digitale Geschäftsmodelle im Metaverse;
01.03.22;01.11.22;2022;intern;Master;DE;Analyse und Bewertung von Reifegradmodellen für Künstliche Intelligenz;
01.03.22;01.08.22;2022;intern;Bachelor;DE;Untersuchung der Herausforderungen von Klein- und Kleinstunternehmen bei der Digitalisierung mit Fallbeispiel;
07.03.22;07.08.22;2022;extern;Bachelor;DE;Erstellung & Ausarbeitung eines Protokollierungskonzepts für das gbws (Gemeinsames Betriebswirtschaftliches System) der Deutschen Rentenversicherung Nordbayern;
07.03.22;07.11.22;2022;intern;Master;DE;Erfassung, Verwaltung und Auswertung von Trainingsdaten im Schwimmsport;
09.03.22;09.08.22;2022;intern;Bachelor;DE;Modernisierung von ERP-Systemen - Eine Analyse von Ansätzen zur Durchführung einer systematischen Modernisierung von ERP-Systemen;
10.03.22;10.08.22;2022;intern;Bachelor;DE;Konzeption und prototypische Implementierung einer Chatbot-Schnittstelle für den Serviceroboter Pepper;
14.03.22;14.08.22;2022;intern;Bachelor;DE;Metastudie zum Vergleich von E-Learning und Präsenzlehre mit den pandemiebedingten Einflüssen von Covid 19;
15.03.22;15.11.22;2022;intern;Master;DE;Die Rolle von Mindsets im Digital Leadership und der digitalen Transformation;
15.03.22;15.08.22;2022;extern;Bachelor;DE;Ermittlung & Anwendung von Methoden zur Quantifizierung der Kundenentwicklung eines Business Process Management Tools;
15.03.22;15.08.22;2022;intern;Bachelor;DE;Analyse und Bewertung von Reifegradmodellen für das Cloud Computing;
15.03.22;15.11.22;2022;intern;Master;DE;Evaluierung von Einsatzmöglichkeiten eines Brain-Computer-Interface auf Basis von VEP (Visually Evoked Potential) in realen, intelligenten Umgebungen;
15.03.22;15.08.22;2022;intern;Bachelor;DE;Echtzeitanalyse von Cookies auf Webseiten zur Reduktion von Nutzertracking;
15.03.22;15.11.22;2022;extern;Master;EN;Varying aspects of a Virtual Reality Environment in real-time for adaptive trainings based on biometric sensor data;
15.03.22;15.11.22;2022;intern;Master;DE;Optimierung des Cloud-Financial Managements durch ein Cloud-Broker-System;
16.03.22;16.08.22;2022;intern;Bachelor;DE;Analyse aktueller Password-Authenticated Key Exchange Protokolle hinsichtlich praktischer Einsatzmöglichkeiten;
19.03.22;19.11.22;2022;intern;Master;DE;Dezentralisierte Autonome Organisationen (DAO) - Auswirkungen auf bestehende Geschäfts- und Wettbewerbsstrukturen;
22.03.22;22.08.22;2022;intern;Bachelor;EN;Global software engineering in international project groups;
22.03.22;22.08.22;2022;intern;Bachelor;DE;Change Management für die erfolgreiche digitale Transformation;
23.03.22;23.11.22;2022;extern;Master;DE;Erstellung einer Applikation zur Unterstützung von digitalisierten Industrieabläufen bei der Robert Bosch GmbH;
29.03.22;29.08.22;2022;intern;Bachelor;DE;Möglichkeiten zur Verbesserung der Sicherheit von IoT-Devices;
30.03.22;30.11.22;2022;intern;Master;EN;Implementation of gamification elements in an e-learning platform to improve user motivation;
01.04.22;01.09.22;2022;extern;Bachelor;DE;Entwicklung eines Simulators auf Basis eines elektronischen Personendosimeters;
01.04.22;01.12.22;2022;extern;Master;DE;Erkennung von Deepfakes mit Hilfe digitaler Bildforensik;
01.04.22;01.12.22;2022;extern;Master;DE;Job-Recommender-System: Ein automatisierter Ansatz auf der Basis von Kompetenzprofilen an einem Beispiel aus der IT-Dienstleistungsbranche;
01.04.22;01.09.22;2022;intern;Bachelor;DE;Entwicklung eines nutzerfreundlichen und erweiterbaren Textsatzsystems;
01.04.22;01.12.22;2022;intern;Master;DE;Digitale Geschäftsmodelle - Ansatzpunkte und Gestaltungsempfehlungen;
01.04.22;01.09.22;2022;extern;Bachelor;EN;Analysis of transmission methods used in distribution of smart meter data from a security perspective.;
01.04.22;01.12.22;2022;extern;Master;EN;Data Quality Validation and Enhancement of Knowledge Graphs with Machine Learning;
01.04.22;01.12.22;2022;extern;Master;DE;Evaluation von optischen Identifikationsverfahren von unbearbeiteten Werkstücken in der CNC-Fertigung auf Basis von CAD-Modellen;
01.04.22;01.09.22;2022;intern;Bachelor;DE;Lieferantenintegration in der Beschaffung: Bestandsaufnahme und Weiterentwicklungen;
01.04.22;01.09.22;2022;intern;Bachelor;DE;Analyse der Geschäftsmodelle in der Videospielindustrie mit Schwerpunkt auf Mikrotransaktion;
03.04.22;03.12.22;2022;intern;Master;DE;IT-Umweltmanagement nach EMAS - Ein Leitfaden für den Aufbau einer Green-IT der bayerischen Hochschulen;
05.04.22;05.09.22;2022;intern;Bachelor;DE;Entwicklung eines computergestützten Code Reviews von WordPress-Erweiterungen<br>;
06.04.22;06.09.22;2022;extern;Bachelor;DE;Konzipierung und Implementierung eines Dashboards für einen IT-Personaldienstleister;
06.04.22;06.09.22;2022;intern;Bachelor;DE;Anwendung von Maschine-Learning-Ansätzen auf einen autonomen mobilen Roboter;
06.04.22;06.09.22;2022;intern;Bachelor;DE;Gestaltung und Umsetzung datenbasierter Geschäftsmodelle;
06.04.22;06.09.22;2022;intern;Bachelor;DE;Anforderungsanalyse für die Konzeption eines modernen Arbeitsplatzreservierungstools ;
11.04.22;11.09.22;2022;extern;Bachelor;DE;Weiterentwicklung einer iOS Applikation zur Ansteuerung von Fahrzeugfunktionen mit Xamarin.iOS ;
11.04.22;11.09.22;2022;intern;Bachelor;DE;Konzeption und prototypische Implementierung eines virtuellen Avatars für Chatbots;
11.04.22;11.09.22;2022;intern;Bachelor;DE;Erkennung von Fake News im Themengebiet COVID-19 mithilfe maschineller Lernverfahren;
11.04.22;11.12.22;2022;intern;Master;DE;Fachliche Charakterisierung von Stellenanzeigen durch Topic Modeling;
13.04.22;13.09.22;2022;extern;Bachelor;DE;Sammlung und Auswertung von Online-Datenquellen zur Analyse der TV-Nutzung mittels State-of-the-Art NLP Methoden bei der GfK SE;
13.04.22;13.09.22;2022;extern;Bachelor;DE;Anwendung und Auswertung von State-of-the-Art NLP-Methoden auf Electronic Program Guides für GfK Media Measurement;
22.04.22;22.09.22;2022;intern;Bachelor;DE;Wissenskarten als ein Instrument zur Identifizierung von Wissen in Organisationen - eine systematische Literaturanalyse;
26.04.22;26.09.22;2022;extern;Bachelor;DE;Konzeption und Implementierung eines Performance- und Kosten-Dashboards zur effektiven Steuerung des Logistiknetzwerkes der Schaeffler AG;
02.05.22;02.10.22;2022;intern;Bachelor;DE;Analyse und Optimierung von Webseitenelementen bezüglich deren Darstellung und Interaktion in einem Virtual-Reality-Kontext;
02.05.22;02.01.23;2022;extern;Master;DE;Entwicklung eines Dashboards zur Überwachung von Erfolgsindikatoren (KPIs) für ein digitales Produkt der Mercedes-Benz AG;
02.05.22;02.10.22;2022;intern;Bachelor;DE;Untersuchung der durch Eindämmungsmaßnahmen der Corona-Pandemie geschaffenen Potenziale zum nachhaltigen Handeln in Unternehmen unter Betrachtung der Unterstützungspotenzial durch die Digitalisierung.;
02.05.22;02.10.22;2022;extern;Bachelor;DE;Konzeption und Implementierung von Maßnahmen zur Verbesserung der Monitoring-Umgebung von virtuellen Maschinen der DATEV eG;
04.05.22;04.01.23;2022;intern;Master;DE;Entwicklung eines vorlesungsbegleitenden Praktikumskonzepts zur Implementierung und Analyse von Schedulingverfahren in einem eingebetteten Echtzeitbetriebssystem;
09.05.22;09.10.22;2022;intern;Bachelor;DE;Browser-in-the-Middle-Angriffe - Analyse, Evaluation und Maßnahmen zur Mitigation der Angriffsform am Beispiel von Multi-Faktor-Authentifizierung <br>;
09.05.22;09.10.22;2022;extern;Bachelor;DE;Konzeption und Implementierung eines Modells zur Analyse von Installationsdauern mittels Methoden der künstlichen Intelligenz zur Evaluation einer Softwareauslieferung;
09.05.22;09.10.22;2022;extern;Bachelor;DE;Welche Auswirkungen haben IT-Sicherheitstechnologien/ gesetzliche Vorgaben auf Reporting Tools und am Unternehmen am Beispiel von PRODATO Integration Technology GmbH?;
15.05.22;15.10.22;2022;extern;Bachelor;DE;Verbesserung der Personenortung eines autonomen mobilen Roboters durch Sensordatenfusion von UWB- und LIDAR-Daten;
16.05.22;16.10.22;2022;intern;Bachelor;DE;Praktischer Vergleich der JavaScript Frameworks Next.js und Vue.js;
18.05.22;18.01.23;2022;intern;Master;EN;Q-Learning for the implementation of non-player characters in interactive text stories;
19.05.22;19.10.22;2022;extern;Bachelor;DE;Evaluierung der Einsatzmöglichkeiten künstlicher Intelligenz im <br>Bereich des HIL-Tests;