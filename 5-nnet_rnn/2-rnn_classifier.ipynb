{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2183f50-3d39-4832-af72-42791571713d",
   "metadata": {},
   "source": [
    "# Assignment 5: Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996891f9-c12d-47bb-93f5-2f25cc60709b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2) RNN for Classification\n",
    "\n",
    "The theses dataset also contains types (diploma, bachelor, master) and categories (internal/external) for each thesis. \n",
    "In this part, we want to classify whether the thesis is bachelor or master; and if it's internal or external. \n",
    "Since PyTorch provides most things sort-of out of the box, we want you to compare the following Recurrent Neural Network variation: \n",
    "[RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html), [GRU](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html), [LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html), and Bidirectional-[LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) by using the `bidirectional` flag.\n",
    "The basic setup as well as some code and steps can be reused from your solution for the language modeling task.\n",
    "\n",
    "### Data\n",
    "\n",
    "Download the `theses.csv` data set from the `Supplemental Materials` in the `Files` section of our Microsoft Teams group.\n",
    "This dataset consists of approx. 3,000 theses topics chosen by students in the past.\n",
    "Here are some examples of the file content:\n",
    "\n",
    "```\n",
    "27.10.94;14.07.95;1995;intern;Diplom;DE;Monte Carlo-Simulation für ein gekoppeltes Round-Robin-System;\n",
    "04.11.94;14.03.95;1995;intern;Diplom;DE;Implementierung eines Testüberdeckungsgrad-Analysators für RAS;\n",
    "01.11.20;01.04.21;2021;intern;Bachelor;DE;Landessprachenerkennung mittels X-Vektoren und Meta-Klassifikation;\n",
    "```\n",
    "\n",
    "### Basic Setup\n",
    "\n",
    "For the assignment on Recurrent Neural Networks, we'll (again) heavily use [PyTorch](https://pytorch.org) as go-to Deep Learning library.\n",
    "Here, we'll rely on the RNN and Embedding modules already implemented by PyTorch.\n",
    "You can imagine the Embedding layer as a simple lookup table that stores embeddings of a fixed dictionary and size (quite similar to the Word2Vec parameters we've trained in assignment 2).\n",
    "Head over to the [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) and [Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) modules to gain some understanding of their functionality.\n",
    "Code for processing data samples, batching, converting to tensors, etc. can get messy and hard to maintain. \n",
    "Therefore, you can use PyTorch's [Datasets & DataLoaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). \n",
    "Get familiar with the basics of data handling, as it will help you for upcoming assignments.\n",
    "As always, you can use [NumPy](https://numpy.org) and [Pandas](https://pandas.pydata.org) for data handling etc.\n",
    "\n",
    "*In this Jupyter Notebook, we will provide the steps to solve this task and give hints via functions & comments. However, code modifications (e.g., function naming, arguments) and implementation of additional helper functions & classes are allowed. The code aims to help you get started.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb0527-90ea-4f0a-ab0c-40817df51dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf666267-390d-402a-aae9-e3588b51c262",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "\n",
    "1.1 Spend some time on preparing the dataset. It may be helpful to lower-case the data and to filter for German titles. The format of the CSV-file should be:\n",
    "\n",
    "```\n",
    "Anmeldedatum;Abgabedatum;JahrAkademisch;Art;Grad;Sprache;Titel;Abstract\n",
    "```\n",
    "\n",
    "1.2 Create the vocabulary from the prepared dataset. You'll need it for the modeling part such as nn.Embedding.\n",
    "\n",
    "1.3 Filter out all diploma theses; they might be too easy to spot because they only cover \"old\" topics.\n",
    "\n",
    "1.4 Create a PyTorch Dataset class which handles your tokenized data with respect to input and (class) labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_theses_dataset(filepath):\n",
    "    \"\"\"Loads all theses instances and returns them as a dataframe.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa699c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Notice: Think about start and end of sentence tokens\n",
    "\n",
    "def preprocess(dataframe):\n",
    "    \"\"\"Preprocesses and tokenizes the given theses titles for further use.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = load_theses_dataset(...)\n",
    "# tokenized_data = preprocess(dataframe)\n",
    "# vocabulary = ...\n",
    "# word2idx = ...\n",
    "# idx2word = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc975e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: 1.3 Implement the PyTorch theses dataset\n",
    "### Notice: It is possible to solve the task without this class.\n",
    "### Notice: However, with respect to DataLoaders it makes your life easier.\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "class ThesesClassificationDataset(Dataset):\n",
    "    def __init__(self, dataset, classes, word2idx):\n",
    "        # TODO\n",
    "        self.data, self.labels = [], []\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # TODO\n",
    "        sample = None\n",
    "        labels = None\n",
    "        return sample, labels\n",
    "    \n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffb8bb6",
   "metadata": {},
   "source": [
    "### Train and Evaluate\n",
    "\n",
    "2.1 Implement the RNN for Classification. Therefore, you can use the nn.Module and overwrite the forward function.\n",
    "\n",
    "2.2 Train and evaluate your models with 5-fold cross-validation. As in RNN-LM, you can either learn the embeddings from scratch or reuse the ones from word2vec.\n",
    "\n",
    "2.3 Assemble a table: Recall/Precision/F1 measure for each of the mentioned RNN variants (RNN, GRU, LSTM). Which one works best?\n",
    "\n",
    "2.4 Bonus: Apply your best classifier to the remaining diploma theses; are those on average more bachelor or master? :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d309048",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: 2.1 Implement the RNN classifier (nn.Module)\n",
    "### Notice: Think about padding for batch sizes > 1\n",
    "### Notice: 'torch.nn.utils.rnn' provides functionality\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "class RNN_Classifier(nn.Module):\n",
    "    def __init__(self, arguments):\n",
    "        super(RNN_Classifier, self).__init__()\n",
    "        # TODO\n",
    "\n",
    "    \n",
    "    def forward(self, X, hidden=None):\n",
    "        # TODO\n",
    "        raise NotImplementedError()\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: 2.2 Implement the train functionality\n",
    "### Notice: If you want, you can also combine train and eval functionality\n",
    "\n",
    "def train(arguments):\n",
    "    \"\"\"Trains the RNN-Classifier for one epoch.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02549c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: 2.2 Implement the evaluation functionality\n",
    "### Notice: If you want, you can also combine train and eval\n",
    "\n",
    "def eval(arguments):\n",
    "    \"\"\"Evaluates the optimized RNN-Classifier.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5fa1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: 2.2 Initialize and train the RNN-Classifier for X epochs\n",
    "\n",
    "# For split reproducibility\n",
    "# Use 5-fold cross validation\n",
    "SEED = 42\n",
    "\n",
    "EPOCHS = 25\n",
    "\n",
    "DEVICE = \"cpu\" # 'cpu', 'mps' or 'cuda'\n",
    "\n",
    "LABEL_COL = \"Grad\"\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Use batch_size=1 if you want to avoid padding handling\n",
    "train_dataset = None\n",
    "train_dataloader = None\n",
    "\n",
    "# Use batch_size=1 if you want to avoid padding handling\n",
    "test_dataset = None\n",
    "test_dataloader = None\n",
    "\n",
    "# Your language model\n",
    "model = None\n",
    "\n",
    "# Your loss function\n",
    "criterion = None\n",
    "\n",
    "# Your optimizer (optim.SGD should be okay)\n",
    "optimizer = None\n",
    "\n",
    "\n",
    "# TODO: Training for epoch i\n",
    "\n",
    "# TODO: Evaluation for epoch i\n",
    "\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a178fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: 2.3 Compare the results of various RNN variants (classification metrics)\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: 2.4 (Optional) Apply your best classifier to the diploma theses\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
